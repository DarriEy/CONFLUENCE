{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model decision analysis in CONFLUENCE\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook focuses on decision analysis for hydrological models in CONFLUENCE. Appropriate model parameterization is essential for model performance and reliability in simulating hydrological processes.\n",
    "\n",
    "Key aspects covered in this notebook include:\n",
    "\n",
    "1. Generation of model decision combinations\n",
    "2. Running model decision combinations\n",
    "3. Evaluation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we import the libraries and functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import logging\n",
    "import yaml # type: ignore\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from utils.evaluation_util.evaluation_utils import DecisionAnalyzer # type: ignore\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check configurations\n",
    "\n",
    "Now we should print our configuration settings and make sure that we have defined all the settings we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path('../../0_config_files/config_active.yaml')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    print(f\"DECISION_OPTIONS: {config['DECISION_OPTIONS']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define default paths\n",
    "\n",
    "Now let's define the paths to data directories before we run the pre processing scripts and create the containing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main project directory\n",
    "data_dir = config['CONFLUENCE_DATA_DIR']\n",
    "project_dir = Path(data_dir) / f\"domain_{config['DOMAIN_NAME']}\"\n",
    "\n",
    "# Data directoris\n",
    "evaluation_results = project_dir / 'optimization' / 'decision_analysis'\n",
    "benchmarking_plots = project_dir / 'plots' / 'benchmarking'\n",
    "\n",
    "# Make sure the new directories exists\n",
    "evaluation_results.mkdir(parents = True, exist_ok = True)\n",
    "benchmarking_plots.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate decision combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 22:55:14,272 - INFO - Starting decision analysis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lightSnow', 'logBelowCanopy', 'consettl'),\n",
       " ('lightSnow', 'logBelowCanopy', 'anderson'),\n",
       " ('lightSnow', 'exponential', 'consettl'),\n",
       " ('lightSnow', 'exponential', 'anderson'),\n",
       " ('stickySnow', 'logBelowCanopy', 'consettl'),\n",
       " ('stickySnow', 'logBelowCanopy', 'anderson'),\n",
       " ('stickySnow', 'exponential', 'consettl'),\n",
       " ('stickySnow', 'exponential', 'anderson')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"Starting decision analysis\")\n",
    "da = DecisionAnalyzer(config, logger)\n",
    "da.generate_combinations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run decision combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 22:56:07,486 - INFO - Starting decision analysis\n",
      "2024-10-21 22:56:07,491 - INFO - Running combination 1 of 8\n",
      "2024-10-21 22:56:07,497 - INFO - Starting SUMMA run\n"
     ]
    }
   ],
   "source": [
    "results_file, best_combinations = da.run_full_analysis()\n",
    "\n",
    "logger.info(\"Decision analysis completed\")\n",
    "logger.info(f\"Results saved to: {results_file}\")\n",
    "logger.info(\"Best combinations for each metric:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, data in best_combinations.items():\n",
    "    logger.info(f\"  {metric}: score = {data['score']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confluenec_env",
   "language": "python",
   "name": "confluence_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
