{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation in CONFLUENCE\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook focuses on the crucial task of parameter estimation for hydrological models in CONFLUENCE. Accurate parameter estimation is essential for model performance and reliability in simulating hydrological processes.\n",
    "\n",
    "Key aspects covered in this notebook include:\n",
    "\n",
    "1. Setting up calibration experiments\n",
    "2. Running calibration algorithms\n",
    "3. Evaluating calibration results\n",
    "\n",
    "In this notebook we explore various techniques for parameter estimation. By the end of this notebook, you will have a calibrated model ready for scenario analysis, forecasting, or other applications in your hydrological study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we import the libraries and functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import logging\n",
    "import yaml # type: ignore\n",
    "import subprocess\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "#from utils.optimization_utils.ostrich_util import OstrichOptimizer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check configurations\n",
    "\n",
    "Now we should print our configuration settings and make sure that we have defined all the settings we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCING_DATASET: ERA5\n",
      "EASYMORE_CLIENT: easymore cli\n",
      "FORCING_VARIABLES: longitude,latitude,time,LWRadAtm,SWRadAtm,pptrate,airpres,airtemp,spechum,windspd\n",
      "EXPERIMENT_TIME_START: 2010-01-01 01:00\n",
      "EXPERIMENT_TIME_START: 2010-01-01 01:00\n"
     ]
    }
   ],
   "source": [
    "config_path = Path('../../0_config_files/config_active.yaml')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    print(f\"FORCING_DATASET: {config['FORCING_DATASET']}\")\n",
    "    print(f\"EASYMORE_CLIENT: {config['EASYMORE_CLIENT']}\")\n",
    "    print(f\"FORCING_VARIABLES: {config['FORCING_VARIABLES']}\")\n",
    "    print(f\"EXPERIMENT_TIME_START: {config['EXPERIMENT_TIME_START']}\")\n",
    "    print(f\"EXPERIMENT_TIME_START: {config['EXPERIMENT_TIME_START']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define default paths\n",
    "\n",
    "Now let's define the paths to data directories before we run the pre processing scripts and create the containing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main project directory\n",
    "data_dir = config['CONFLUENCE_DATA_DIR']\n",
    "project_dir = Path(data_dir) / f\"domain_{config['DOMAIN_NAME']}\"\n",
    "\n",
    "# Data directoris\n",
    "simulation_dir = project_dir / 'simulations' / f\"{config['EXPERIMENT_ID']}\"\n",
    "hydro_model_dir = simulation_dir / f\"{config['HYDROLOGICAL_MODEL']}\"\n",
    "routing_model_dir = simulation_dir / f\"{config['ROUTING_MODEL']}\"\n",
    "\n",
    "# Make sure the new directories exists\n",
    "hydro_model_dir.mkdir(parents = True, exist_ok = True)\n",
    "routing_model_dir.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run parameter estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: parallel_parameter_estimation.main(): Process 0 initialized\n",
      "INFO: parallel_parameter_estimation.main(): Process 1 initialized\n",
      "INFO: parallel_parameter_estimation.main(): Process 2 initialized\n",
      "INFO: parallel_parameter_estimation.main(): Process 3 initialized\n",
      "INFO: results_utils.create_iteration_results_file(): Created iteration results file: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/optimisation/run_2_parallel_iteration_results.csv\n",
      "INFO: parallel_utils.run(): Worker 2 started and waiting for tasks\n",
      "INFO: results_utils.create_iteration_results_file(): Created iteration results file: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/optimisation/run_2_parallel_iteration_results.csv\n",
      "INFO: parallel_utils.run(): Worker 3 started and waiting for tasks\n",
      "INFO: parallel_parameter_estimation.main(): Starting optimization with NSGA-II algorithm\n",
      "INFO: parallel_utils.run(): Worker 1 started and waiting for tasks\n",
      "INFO: parallel_parameter_estimation.main(): Optimization metric: KGE\n",
      "INFO: parallel_parameter_estimation.main(): Number of iterations: 100\n",
      "INFO: parallel_parameter_estimation.main(): Calibration period: 2011-01-01 to 2014-12-31\n",
      "INFO: parallel_parameter_estimation.main(): Evaluation period: 2015-01-01 to 2018-12-31\n",
      "INFO: parallel_parameter_estimation.run_optimization(): Starting optimization with NSGA-II algorithm\n",
      "INFO: parallel_parameter_estimation.run_multi_objective_optimization(): algorithm parameters: {'maxiter': 100, 'pop_size': 100, 'n_offsprings': 100, 'eliminate_duplicates': True, 'crossover': <pymoo.operators.crossover.sbx.SBX object at 0x2b783fd22dd0>, 'mutation': <pymoo.operators.mutation.pm.PolynomialMutation object at 0x2b784491b450>}\n",
      "INFO: parallel_parameter_estimation.parallel_objective_function(): parallel_objective_function called with 100 parameter sets\n",
      "INFO: parallel_parameter_estimation.parallel_objective_function(): Master sending initial parameters to worker 1\n",
      "INFO: parallel_parameter_estimation.parallel_objective_function(): Master sending initial parameters to worker 2\n",
      "INFO: parallel_utils.run(): Worker 1 received parameters for index 0\n",
      "INFO: parallel_parameter_estimation.parallel_objective_function(): Master sending initial parameters to worker 3\n",
      "INFO: parallel_utils.evaluate_params(): Worker 1 starting parameter evaluation\n",
      "INFO: parallel_utils.run(): Worker 2 received parameters for index 1\n",
      "INFO: parallel_utils.evaluate_params(): Worker 2 starting parameter evaluation\n",
      "INFO: parallel_utils.run(): Worker 3 received parameters for index 2\n",
      "INFO: parallel_utils.evaluate_params(): Worker 3 starting parameter evaluation\n",
      "INFO: opt_model_utils.run_models(): Rank 3 starting model run attempt 1\n",
      "INFO: opt_model_utils.run_models(): Rank 3 prepared model run. SUMMA path: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/simulations/run_2_rank3/SUMMA, mizuRoute path: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/simulations/run_2_rank3/mizuRoute\n",
      "INFO: opt_model_utils.run_models(): Rank 1 starting model run attempt 1\n",
      "INFO: opt_model_utils.run_models(): Rank 1 prepared model run. SUMMA path: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/simulations/run_2_rank1/SUMMA, mizuRoute path: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/simulations/run_2_rank1/mizuRoute\n",
      "INFO: opt_model_utils.run_models(): Rank 2 starting model run attempt 1\n",
      "INFO: opt_model_utils.run_models(): Rank 2 prepared model run. SUMMA path: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/simulations/run_2_rank2/SUMMA, mizuRoute path: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/simulations/run_2_rank2/mizuRoute\n"
     ]
    }
   ],
   "source": [
    "# Calibrate the model using specified method and objectives\n",
    "if config.get('OPTMIZATION_ALOGORITHM') == 'OSTRICH':\n",
    "    optimizer = OstrichOptimizer(config, logger)\n",
    "    optimizer.run_optimization()\n",
    "\n",
    "else:\n",
    "    config_path = Path(config.get('CONFLUENCE_CODE_DIR')) / '0_config_files' / 'config_active.yaml'\n",
    "\n",
    "    cmd = [\n",
    "        'srun',\n",
    "        '-n', str(config.get('MPI_PROCESSES')),\n",
    "        'python',\n",
    "        str(Path(f\"{config['CONFLUENCE_CODE_DIR']}\") / 'utils' / 'optimization_utils' / 'parallel_parameter_estimation.py'), \n",
    "        str(config_path)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"Error running parallel optimization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confluenec_env",
   "language": "python",
   "name": "confluence_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
