{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Agnostic Input Data Preprocessing in CONFLUENCE\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook focuses on the model-agnostic preprocessing steps for input data in CONFLUENCE. Model-agnostic preprocessing involves tasks that are common across different hydrological models, such as data acquisition, and initial formatting.\n",
    "\n",
    "Key steps covered in this notebook include:\n",
    "\n",
    "1. Running the model agnostic orchestrator\n",
    "2. Optional lapse rate adjustment on forcing variables\n",
    "\n",
    "In this preprocessing stage we ensure that our input data is consistent, complete, and properly formatted before we move on to model-specific preprocessing steps. By the end of this notebook, you will have clean, standardized datasets ready for further model-specific processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we import the libraries and functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import logging\n",
    "import yaml # type: ignore\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from utils.dataHandling_utils.data_utils import DataAcquisitionProcessor # type: ignore\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check configurations\n",
    "\n",
    "Now we should print our configuration settings and make sure that we have defined all the settings we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCING_DATASET: ERA5\n",
      "EASYMORE_CLIENT: easymore cli\n",
      "FORCING_VARIABLES: longitude,latitude,time,LWRadAtm,SWRadAtm,pptrate,airpres,airtemp,spechum,windspd\n",
      "EXPERIMENT_TIME_START: 2010-01-01 01:00\n",
      "EXPERIMENT_TIME_START: 2010-01-01 01:00\n"
     ]
    }
   ],
   "source": [
    "config_path = Path('../../0_config_files/config_active.yaml')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    print(f\"FORCING_DATASET: {config['FORCING_DATASET']}\")\n",
    "    print(f\"EASYMORE_CLIENT: {config['EASYMORE_CLIENT']}\")\n",
    "    print(f\"FORCING_VARIABLES: {config['FORCING_VARIABLES']}\")\n",
    "    print(f\"EXPERIMENT_TIME_START: {config['EXPERIMENT_TIME_START']}\")\n",
    "    print(f\"EXPERIMENT_TIME_START: {config['EXPERIMENT_TIME_START']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define default paths\n",
    "\n",
    "Now let's define the paths to data directories before we run the pre processing scripts and create the containing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main project directory\n",
    "data_dir = config['CONFLUENCE_DATA_DIR']\n",
    "project_dir = Path(data_dir) / f\"domain_{config['DOMAIN_NAME']}\"\n",
    "\n",
    "# Data directoris\n",
    "raw_data_dir = project_dir / 'forcing' / 'raw_data'\n",
    "basin_averaged_data = project_dir / 'forcing' / 'basin_averaged_data'\n",
    "catchment_intersection_dir = project_dir / 'shapefiles' / 'catchment_intersection'\n",
    "\n",
    "# Make sure the new directories exists\n",
    "basin_averaged_data.mkdir(parents = True, exist_ok = True)\n",
    "catchment_intersection_dir.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run Model Agnostic Orchestrator\n",
    "\n",
    "Now let's run the model agnostic orchestrator to acquire and pre-process our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 19:08:57,973 - INFO - MAF configuration JSON saved to: /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/forcing/maf_config.json\n",
      "2024-10-20 19:08:57,974 - INFO - Starting data acquisition process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-agnostic.sh: Model-agnostic workflow job submission to SLURM scheduler on DRA HPC.\n",
      "model-agnostic.sh: details are logged in /home/darri/data/CONFLUENCE_data/installs/MAF/02_model_agnostic_component/model-agnostic.log\n",
      "model-agnostic.sh: Script for independant :gis:#1 process is executed\n",
      "model-agnostic.sh: Script for independant :gis:#2 process is executed\n",
      "model-agnostic.sh: Script for independant :gis:#3 process is executed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 19:28:51,092 - INFO - Model Agnostic Framework completed successfully.\n",
      "2024-10-20 19:28:51,093 - INFO - Data acquisition process completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-agnostic.sh: Script for :met:#1 process is executed for the parent process\n",
      "model-agnostic.sh: Script for :remap: for the #1 process is executed for the child process with parent ID(s) of (2024-10-20 23:09:07) era5_simplified.sh: processing ECMWF ERA5...\n",
      "(2024-10-20 23:09:07) era5_simplified.sh: creating output directory under /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/forcing/raw_data\n",
      "(2024-10-20 23:28:51) era5_simplified.sh: results are produced under /home/darri/data/CONFLUENCE_data/domain_Bow_at_Banff/forcing/raw_data.\n"
     ]
    }
   ],
   "source": [
    "# Initialize forcingReampler class\n",
    "dap = DataAcquisitionProcessor(config, logger)\n",
    "\n",
    "# Run resampling\n",
    "dap.run_data_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confluenec_env",
   "language": "python",
   "name": "confluence_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
