name: SYMFLUENCE - Full Install & Validate

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch: {}

defaults:
  run:
    shell: bash

concurrency:
  group: symfluence-${{ github.head_ref || github.ref_name }}
  cancel-in-progress: true

jobs:
  install-validate:
    runs-on: ubuntu-22.04
    env:
      TZ: UTC
      CI: "1"
      NONINTERACTIVE: "1"
      # Repo root (already /home/runner/work/SYMFLUENCE/SYMFLUENCE)
      SYMFLUENCE_CODE: ${{ github.workspace }}
      SYMFLUENCE_DATA: ${{ github.workspace }}/SYMFLUENCE_data   # <= no ..

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

    # -------------------------------
    # Core system build dependencies
    # -------------------------------
      # Move this near the top of install-validate (after setup-python)
      - name: Restore build cache
        id: symf_cache
        uses: actions/cache@v4
        with:
          path: |
            ${{ github.workspace }}/venv
            ${{ github.workspace }}/SYMFLUENCE_data/installs

          key: symfluence-22_04-${{ runner.os }}-${{ hashFiles('pyproject.toml', 'setup.cfg', 'requirements*.txt', '0_config_files/**') }}
          restore-keys: |
            symfluence-22_04-${{ runner.os }}-
            symfluence-22_04-

      # Only install system deps when cache is cold
      - name: Install system build deps
        if: steps.symf_cache.outputs.cache-hit != 'true'
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y software-properties-common
          sudo add-apt-repository -y ppa:ubuntugis/ppa
          sudo apt-get update

          # ------------------------------------------------------------------
          # Core compilation and parallel libraries
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            build-essential gfortran cmake make pkg-config \
            ninja-build autoconf automake libtool \
            git wget curl unzip tar

          # ------------------------------------------------------------------
          # OpenMPI stack (choose ONE MPI implementation)
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            openmpi-bin libopenmpi-dev

          # ------------------------------------------------------------------
          # GDAL / PROJ / NetCDF / HDF5 (via UbuntuGIS Stable)
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            gdal-bin libgdal-dev libproj-dev \
            libnetcdf-dev libnetcdff-dev \
            libhdf5-dev hdf5-tools \
            libudunits2-dev

          # ------------------------------------------------------------------
          # Python bindings and CMake helpers (optional but useful for tools)
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            python3-dev python3-pip python3-numpy python3-gdal

          # ------------------------------------------------------------------
          # Sanity checks for MPI and GDAL
          # ------------------------------------------------------------------
          mpicc --version
          mpirun --version
          gdal-config --version
          echo "✅ System dependencies installed successfully"


      # ------------------------------------------------
      # Env discovery for NetCDF / HDF5 / UDUNITS (Ubuntu)
      # ------------------------------------------------
      - name: Configure compiler and library env
        if: steps.symf_cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          set -e

          # pkg-config search paths (cover Ubuntu placements)
          echo "PKG_CONFIG_PATH=/usr/lib/x86_64-linux-gnu/pkgconfig:/usr/lib/pkgconfig:/usr/share/pkgconfig:${PKG_CONFIG_PATH}" >> $GITHUB_ENV

          # ---- NetCDF discovery (C & Fortran) ----
          NETCDF_PREFIX=$(nc-config --prefix 2>/dev/null || echo /usr)
          NETCDF_LIBDIR=$(nc-config --libdir 2>/dev/null || echo /usr/lib/x86_64-linux-gnu)
          NETCDF_INC=$(nc-config --includedir 2>/dev/null || echo /usr/include)

          echo "NETCDF=${NETCDF_PREFIX}" >> $GITHUB_ENV
          echo "NETCDF_FORTRAN=$(nf-config --prefix 2>/dev/null || echo ${NETCDF_PREFIX})" >> $GITHUB_ENV
          echo "NETCDF_DIR=${NETCDF_PREFIX}" >> $GITHUB_ENV
          echo "NETCDF_LIBDIR=${NETCDF_LIBDIR}" >> $GITHUB_ENV
          echo "NETCDF_INCLUDE=${NETCDF_INC}" >> $GITHUB_ENV

          # ---- HDF5 discovery (Ubuntu 'serial' multiarch layout) ----
          # Libraries live here; includes under /usr/include/hdf5/serial
          echo "HDF5_ROOT=/usr/lib/x86_64-linux-gnu/hdf5/serial" >> $GITHUB_ENV
          echo "HDF5_LIBDIR=/usr/lib/x86_64-linux-gnu/hdf5/serial" >> $GITHUB_ENV
          echo "HDF5_INCLUDE_DIR=/usr/include/hdf5/serial" >> $GITHUB_ENV

          # UDUNITS2 prefix (helps CMake find scripts)
          echo "UDUNITS2_DIR=$(pkg-config --variable=prefix udunits2 2>/dev/null || echo /usr)" >> $GITHUB_ENV

          # General linker paths for old Makefiles
          echo "LD_LIBRARY_PATH=${NETCDF_LIBDIR}:${HDF5_LIBDIR}:${LD_LIBRARY_PATH}" >> $GITHUB_ENV
          echo "LIBRARY_PATH=${NETCDF_LIBDIR}:${HDF5_LIBDIR}:${LIBRARY_PATH}" >> $GITHUB_ENV

          # R for rpy2 (if present)
          if command -v R >/dev/null 2>&1; then
            echo "R_HOME=$(R RHOME)" >> $GITHUB_ENV
            echo "PATH=$(dirname "$(command -v R)"):${PATH}" >> $GITHUB_ENV
          fi

          # MPI compilers for TauDEM/CMake discovery
          echo "CC=mpicc"  >> $GITHUB_ENV
          echo "CXX=mpicxx" >> $GITHUB_ENV

          # ------- Convenience flags for FUSE (used if your wrapper picks them up) -------
          NF_FLIBS="$(nf-config --flibs 2>/dev/null || echo "-L${NETCDF_LIBDIR} -lnetcdff")"
          NC_LIBS="$(nc-config --libs  2>/dev/null || echo "-L${NETCDF_LIBDIR} -lnetcdf")"
          H5_LIBS="$(pkg-config --libs hdf5_hl hdf5 2>/dev/null || echo "-L${HDF5_LIBDIR} -lhdf5_hl -lhdf5")"
          echo "FUSE_LIBRARIES=${NF_FLIBS} ${NC_LIBS} ${H5_LIBS}" >> $GITHUB_ENV

          NF_FFLAGS="$(nf-config --fflags 2>/dev/null || true)"
          NC_CFLAGS="$(nc-config --cflags 2>/dev/null || true)"
          H5_CFLAGS="$(pkg-config --cflags hdf5 2>/dev/null || echo "-I${HDF5_INCLUDE_DIR}")"
          echo "FUSE_INCLUDE=${NC_CFLAGS} ${NF_FFLAGS} ${H5_CFLAGS} -I${NETCDF_INCLUDE}" >> $GITHUB_ENV

          # Extra Fortran compatibility for old NetCDF calls
          echo "FUSE_FFLAGS_EXTRA=-fallow-argument-mismatch -std=legacy -ffree-line-length-none -fmax-errors=0" >> $GITHUB_ENV

          # Debug prints (will show in logs)
          echo "NETCDF_PREFIX=${NETCDF_PREFIX}"
          echo "NETCDF_LIBDIR=${NETCDF_LIBDIR}"
          echo "NETCDF_INCLUDE=${NETCDF_INC}"
          echo "HDF5_LIBDIR=${HDF5_LIBDIR}"
          echo "HDF5_INCLUDE_DIR=${HDF5_INCLUDE_DIR}"
          echo "FUSE_LIBRARIES=${FUSE_LIBRARIES}"
          echo "FUSE_INCLUDE=${FUSE_INCLUDE}"

      - name: Show dpkg-buildflags (sanity)
        if: steps.symf_cache.outputs.cache-hit != 'true'
        run: |
          set -e
          echo "CFLAGS:   $(dpkg-buildflags --get CFLAGS || true)"
          echo "CXXFLAGS: $(dpkg-buildflags --get CXXFLAGS || true)"
          echo "LDFLAGS:  $(dpkg-buildflags --get LDFLAGS || true)"

      - name: Create /usr/lib64 symlinks for legacy builds (HDF5/NetCDF)
        if: steps.symf_cache.outputs.cache-hit != 'true'
        run: |
          set -e
          sudo mkdir -p /usr/lib64

          # NetCDF
          for so in /usr/lib/x86_64-linux-gnu/libnetcdf.so* /usr/lib/x86_64-linux-gnu/libnetcdff.so*; do
            [ -e "$so" ] || continue
            base=$(basename "$so")
            [ -e "/usr/lib64/${base}" ] || sudo ln -s "$so" "/usr/lib64/${base}" || true
          done

          # HDF5 (Ubuntu stores in hdf5/serial)
          for so in /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5.so* \
                    /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5_hl.so* \
                    /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5_fortran.so* \
                    /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5hl_fortran.so*; do
            [ -e "$so" ] || continue
            base=$(basename "$so")
            [ -e "/usr/lib64/${base}" ] || sudo ln -s "$so" "/usr/lib64/${base}" || true
          done

      # --------------------------
      # Run your full installation
      # --------------------------

      - name: Ensure data dir exists
        if: steps.symf_cache.outputs.cache-hit != 'true'
        run: mkdir -p "${{ env.SYMFLUENCE_DATA }}"

      # Only build when cache is cold
      - name: Full install (build venv + tools)
        if: steps.symf_cache.outputs.cache-hit != 'true'
        env:
          CC: mpicc
          CXX: mpicxx
          CFLAGS: ""
          CXXFLAGS: ""
          LDFLAGS: ""
          LD_LIBRARY_PATH: ""
          DEB_BUILD_MAINT_OPTIONS: ""
        run: |
          set -e
          chmod +x ./symfluence
          ./symfluence --install


      - name: Wrapper info
        run: |
          set -e
          ./symfluence --wrapper-info || true

      # ----------------
      # Validate binaries
      # ----------------
      - name: Validate
        run: |
          set -e
          test -x ./symfluence
          . ./venv/bin/activate || . ./.venv/bin/activate
          python --version
          python symfluence.py --validate_binaries

      - name: Prune installs and venv (shrink cache)
        run: |
          set -e
          INST="${SYMFLUENCE_DATA}/installs"
          # Drop heavy build trees & VCS metadata
          find "${INST}" -type d \( -name build -o -name cmake_build -o -name .git \) -prune -exec rm -rf {} + || true
          # Move final ngen binary out of build dir if present
          if [ -f "${INST}/ngen/cmake_build/ngen" ]; then
            mkdir -p "${INST}/ngen/bin"
            cp -f "${INST}/ngen/cmake_build/ngen" "${INST}/ngen/bin/ngen"
            rm -rf "${INST}/ngen/cmake_build" || true
          fi
          # Remove .o/.a/.la etc. and __pycache__/pyc
          find "${INST}" -type f \( -name '*.o' -o -name '*.a' -o -name '*.la' \) -delete || true
          find ./venv -type f -name '*.pyc' -delete || true
          find ./venv -type d -name '__pycache__' -prune -exec rm -rf {} + || true
          # Strip ELF executables to cut size (best effort)
          if command -v strip >/dev/null 2>&1; then
            find "${INST}" -type f -perm -111 -exec bash -c 'file -b "$1" | grep -q ELF && strip --strip-unneeded "$1" || true' _ {} \; || true
          fi



      # --------------------------
      # Upload logs on failure only
      # --------------------------
      - name: Upload build logs (on fail)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: symfluence-build-logs
          path: |
            **/build/**/CMakeFiles/CMakeOutput.log
            **/build/**/CMakeFiles/CMakeError.log
            **/logs/**
            **/*build*.log
            **/cmake_build/**/*.log
          if-no-files-found: warn



  smoke-tests:
    needs: install-validate
    runs-on: ubuntu-22.04
    env:
      SYMFLUENCE_CODE: ${{ github.workspace }}
      SYMFLUENCE_DATA: ${{ github.workspace }}/SYMFLUENCE_data   # <= no ..

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'  # small speedup

      - name: Restore build cache
        id: symf_cache
        uses: actions/cache@v4
        with:
          path: |
            ${{ github.workspace }}/venv
            ${{ github.workspace }}/SYMFLUENCE_data/installs
          key: symfluence-22_04-${{ runner.os }}-${{ hashFiles('pyproject.toml', 'setup.cfg', 'requirements*.txt', '0_config_files/**') }}
          restore-keys: |
            symfluence-22_04-${{ runner.os }}-
            symfluence-22_04-



      - name: Verify venv & package import
        run: |
          set -e
          . ./venv/bin/activate || . ./.venv/bin/activate
          which python
          python --version
          python -c "import symfluence; print('symfluence OK')"

      - name: Ensure wrapper is executable
        run: chmod +x ./symfluence

      - name: CLI help
        run: bash ./symfluence --help > /dev/null

      - name: Wrapper info
        run: bash ./symfluence --wrapper-info



  step_tests-domain:
    needs: smoke-tests
    runs-on: ubuntu-22.04
    env:
      TZ: UTC
      CI: "1"
      NONINTERACTIVE: "1"
      SYMFLUENCE_CODE: ${{ github.workspace }}
      SYMFLUENCE_DATA: ${{ github.workspace }}/SYMFLUENCE_data   # <= no ..
      DOMAIN: Bow_at_Banff
      DOMAIN_DEF: delineate
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'  # small speedup

      - name: Restore build cache
        id: symf_cache
        uses: actions/cache@v4
        with:
          path: |
            ${{ github.workspace }}/venv
            ${{ github.workspace }}/SYMFLUENCE_data/installs
          key: symfluence-22_04-${{ runner.os }}-${{ hashFiles('pyproject.toml', 'setup.cfg', 'requirements*.txt', '0_config_files/**') }}
          restore-keys: |
            symfluence-22_04-${{ runner.os }}-
            symfluence-22_04-

      - name: Verify venv & package import
        run: |
          set -e
          . ./venv/bin/activate || . ./.venv/bin/activate
          which python
          python --version
          python -c "import symfluence; print('symfluence OK')"


      - name: Ensure wrapper is executable
        run: chmod +x ./symfluence


      - name: Create CI config for Bow at Banff
        run: |
          set -e
          mkdir -p 0_config_files "${SYMFLUENCE_DATA}"
          cat > 0_config_files/config_ci_bow.yaml <<'YAML'
          SYMFLUENCE_CODE_DIR: "${{ env.SYMFLUENCE_CODE }}"
          SYMFLUENCE_DATA_DIR: "${{ env.SYMFLUENCE_DATA }}"
          DOMAIN_NAME: "${{ env.DOMAIN }}"
          DOMAIN_DEFINITION_METHOD: "${{ env.DOMAIN_DEF }}"
          LOG_LEVEL: "INFO"
          YAML

      - name: Step 1 — setup_project (creates domain scaffolding)
        run: |
          set -e
          ./symfluence --config 0_config_files/config_ci_bow.yaml --setup_project

      - name: Step 2 — copy repo data into created domain folder
        run: |
          set -e
          SRC="./src/data/domain_${DOMAIN}"
          DEST="${SYMFLUENCE_DATA}/domain_${DOMAIN}"
          mkdir -p "${DEST}"
          # Copy everything (shapefiles, any sidecars, etc.)
          cp -a "${SRC}/." "${DEST}/"
          echo "Copied data into ${DEST}"
          ls -R "${DEST}" || true

      - name: Step 3 — run define_domain using CLI
        run: |
          set -e
          ./symfluence --config 0_config_files/config_ci_bow.yaml --define_domain

      - name: Step 4 — run discretise_domain using CLI
        run: |
          set -e
          ./symfluence --config 0_config_files/config_ci_bow.yaml --discretize_domain

      - name: Assertions — river basins shapefile exists; logs exist
        run: |
          set -e
          DOMAIN_DIR="${SYMFLUENCE_DATA}/domain_${DOMAIN}"
          RIV_DIR="${DOMAIN_DIR}/shapefiles/river_basins"
          # Expect a river basins shapefile (method suffix may vary; allow wildcard)
          test -d "${RIV_DIR}"
          ls "${RIV_DIR}/${DOMAIN}_riverBasins_"*.shp >/dev/null
          # Also check that workflow logs are written in the standard location
          ls "_workLog_${DOMAIN}" >/dev/null
          echo "✅ Expected outputs present."

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: domain-define-minimal-logs
          path: |
            _workLog_${{ env.DOMAIN }}/**
            ${{ env.SYMFLUENCE_DATA }}/domain_${{ env.DOMAIN }}/**/*
          if-no-files-found: warn

