name: SYMFLUENCE - Full Install & Validate

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch: {}

jobs:
  install-validate:
    runs-on: ubuntu-22.04
    env:
      TZ: UTC
      CI: "1"
      NONINTERACTIVE: "1"
      # Repo root (already /home/runner/work/SYMFLUENCE/SYMFLUENCE)
      SYMFLUENCE_CODE: ${{ github.workspace }}
      # Data is a sibling of the repo dir
      SYMFLUENCE_DATA: ${{ github.workspace }}/../SYMFLUENCE_data

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # Meets the 3.11+ requirement


    # -------------------------------
    # Core system build dependencies
    # -------------------------------
      - name: Install system build deps
        run: |
          set -e
          sudo apt-get update

          # ------------------------------------------------------------------
          # Enable UbuntuGIS Stable PPA for consistent GDAL/PROJ versions
          # (GDAL 3.6+ on 22.04, or 3.8+ on 24.04)
          # ------------------------------------------------------------------
          sudo add-apt-repository -y ppa:ubuntugis/ppa
          sudo apt-get update

          # ------------------------------------------------------------------
          # Core compilation and parallel libraries
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            build-essential gfortran cmake make pkg-config \
            ninja-build autoconf automake libtool \
            git wget curl unzip tar

          # ------------------------------------------------------------------
          # OpenMPI stack (choose ONE MPI implementation)
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            openmpi-bin libopenmpi-dev

          # ------------------------------------------------------------------
          # GDAL / PROJ / NetCDF / HDF5 (via UbuntuGIS Stable)
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            gdal-bin libgdal-dev libproj-dev \
            libnetcdf-dev libnetcdff-dev \
            libhdf5-dev hdf5-tools \
            libudunits2-dev

          # ------------------------------------------------------------------
          # Python bindings and CMake helpers (optional but useful for tools)
          # ------------------------------------------------------------------
          sudo apt-get install -y \
            python3-dev python3-pip python3-numpy python3-gdal

          # ------------------------------------------------------------------
          # Sanity checks for MPI and GDAL
          # ------------------------------------------------------------------
          mpicc --version
          mpirun --version
          gdal-config --version
          echo "✅ System dependencies installed successfully"


      # ------------------------------------------------
      # Env discovery for NetCDF / HDF5 / UDUNITS (Ubuntu)
      # ------------------------------------------------
      - name: Configure compiler and library env
        shell: bash
        run: |
          set -e

          # pkg-config search paths (cover Ubuntu placements)
          echo "PKG_CONFIG_PATH=/usr/lib/x86_64-linux-gnu/pkgconfig:/usr/lib/pkgconfig:/usr/share/pkgconfig:${PKG_CONFIG_PATH}" >> $GITHUB_ENV

          # ---- NetCDF discovery (C & Fortran) ----
          NETCDF_PREFIX=$(nc-config --prefix 2>/dev/null || echo /usr)
          NETCDF_LIBDIR=$(nc-config --libdir 2>/dev/null || echo /usr/lib/x86_64-linux-gnu)
          NETCDF_INC=$(nc-config --includedir 2>/dev/null || echo /usr/include)

          echo "NETCDF=${NETCDF_PREFIX}" >> $GITHUB_ENV
          echo "NETCDF_FORTRAN=$(nf-config --prefix 2>/dev/null || echo ${NETCDF_PREFIX})" >> $GITHUB_ENV
          echo "NETCDF_DIR=${NETCDF_PREFIX}" >> $GITHUB_ENV
          echo "NETCDF_LIBDIR=${NETCDF_LIBDIR}" >> $GITHUB_ENV
          echo "NETCDF_INCLUDE=${NETCDF_INC}" >> $GITHUB_ENV

          # ---- HDF5 discovery (Ubuntu 'serial' multiarch layout) ----
          # Libraries live here; includes under /usr/include/hdf5/serial
          echo "HDF5_ROOT=/usr/lib/x86_64-linux-gnu/hdf5/serial" >> $GITHUB_ENV
          echo "HDF5_LIBDIR=/usr/lib/x86_64-linux-gnu/hdf5/serial" >> $GITHUB_ENV
          echo "HDF5_INCLUDE_DIR=/usr/include/hdf5/serial" >> $GITHUB_ENV

          # UDUNITS2 prefix (helps CMake find scripts)
          echo "UDUNITS2_DIR=$(pkg-config --variable=prefix udunits2 2>/dev/null || echo /usr)" >> $GITHUB_ENV

          # General linker paths for old Makefiles
          echo "LD_LIBRARY_PATH=${NETCDF_LIBDIR}:${HDF5_LIBDIR}:${LD_LIBRARY_PATH}" >> $GITHUB_ENV
          echo "LIBRARY_PATH=${NETCDF_LIBDIR}:${HDF5_LIBDIR}:${LIBRARY_PATH}" >> $GITHUB_ENV

          # R for rpy2 (if present)
          if command -v R >/dev/null 2>&1; then
            echo "R_HOME=$(R RHOME)" >> $GITHUB_ENV
            echo "PATH=$(dirname "$(command -v R)"):${PATH}" >> $GITHUB_ENV
          fi

          # MPI compilers for TauDEM/CMake discovery
          echo "CC=mpicc"  >> $GITHUB_ENV
          echo "CXX=mpicxx" >> $GITHUB_ENV

          # ------- Convenience flags for FUSE (used if your wrapper picks them up) -------
          NF_FLIBS="$(nf-config --flibs 2>/dev/null || echo "-L${NETCDF_LIBDIR} -lnetcdff")"
          NC_LIBS="$(nc-config --libs  2>/dev/null || echo "-L${NETCDF_LIBDIR} -lnetcdf")"
          H5_LIBS="$(pkg-config --libs hdf5_hl hdf5 2>/dev/null || echo "-L${HDF5_LIBDIR} -lhdf5_hl -lhdf5")"
          echo "FUSE_LIBRARIES=${NF_FLIBS} ${NC_LIBS} ${H5_LIBS}" >> $GITHUB_ENV

          NF_FFLAGS="$(nf-config --fflags 2>/dev/null || true)"
          NC_CFLAGS="$(nc-config --cflags 2>/dev/null || true)"
          H5_CFLAGS="$(pkg-config --cflags hdf5 2>/dev/null || echo "-I${HDF5_INCLUDE_DIR}")"
          echo "FUSE_INCLUDE=${NC_CFLAGS} ${NF_FFLAGS} ${H5_CFLAGS} -I${NETCDF_INCLUDE}" >> $GITHUB_ENV

          # Extra Fortran compatibility for old NetCDF calls
          echo "FUSE_FFLAGS_EXTRA=-fallow-argument-mismatch -std=legacy -ffree-line-length-none -fmax-errors=0" >> $GITHUB_ENV

          # Debug prints (will show in logs)
          echo "NETCDF_PREFIX=${NETCDF_PREFIX}"
          echo "NETCDF_LIBDIR=${NETCDF_LIBDIR}"
          echo "NETCDF_INCLUDE=${NETCDF_INC}"
          echo "HDF5_LIBDIR=${HDF5_LIBDIR}"
          echo "HDF5_INCLUDE_DIR=${HDF5_INCLUDE_DIR}"
          echo "FUSE_LIBRARIES=${FUSE_LIBRARIES}"
          echo "FUSE_INCLUDE=${FUSE_INCLUDE}"



      - name: Disable distro LTO flags (match earlier working TauDEM build)
        shell: bash
        run: |
          set -e
          # Disable Debian/Ubuntu’s default LTO in dpkg-buildflags consumers (like CMake toolchains)
          echo "DEB_BUILD_MAINT_OPTIONS=optimize=-lto" >> $GITHUB_ENV
          # Also pin “set” overrides so nothing re-injects LTO later
          echo "DEB_CFLAGS_SET=-O2"       >> $GITHUB_ENV
          echo "DEB_CXXFLAGS_SET=-O2"     >> $GITHUB_ENV
          echo "DEB_LDFLAGS_SET="         >> $GITHUB_ENV


      - name: Show dpkg-buildflags (sanity)
        run: |
          set -e
          echo "CFLAGS:   $(dpkg-buildflags --get CFLAGS || true)"
          echo "CXXFLAGS: $(dpkg-buildflags --get CXXFLAGS || true)"
          echo "LDFLAGS:  $(dpkg-buildflags --get LDFLAGS || true)"


      # --------------------
      # Sanity prints (logs)
      # --------------------
      - name: Print discovery info
        run: |
          which nc-config || true
          which nf-config || true
          pkg-config --modversion hdf5 || true
          pkg-config --modversion udunits2 || true
          echo "nc-config --libs: $(nc-config --libs 2>/dev/null || echo 'N/A')"
          echo "nf-config --flibs: $(nf-config --flibs 2>/dev/null || echo 'N/A')"
          echo "pkg-config hdf5 libs: $(pkg-config --libs hdf5 2>/dev/null || echo 'N/A')"
          echo "pkg-config udunits2 cflags: $(pkg-config --cflags udunits2 2>/dev/null || echo 'N/A')"


      - name: Create /usr/lib64 symlinks for legacy builds (HDF5/NetCDF)
        run: |
          set -e
          sudo mkdir -p /usr/lib64

          # NetCDF
          for so in /usr/lib/x86_64-linux-gnu/libnetcdf.so* /usr/lib/x86_64-linux-gnu/libnetcdff.so*; do
            [ -e "$so" ] || continue
            base=$(basename "$so")
            [ -e "/usr/lib64/${base}" ] || sudo ln -s "$so" "/usr/lib64/${base}" || true
          done

          # HDF5 (Ubuntu stores in hdf5/serial)
          for so in /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5.so* \
                    /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5_hl.so* \
                    /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5_fortran.so* \
                    /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5hl_fortran.so*; do
            [ -e "$so" ] || continue
            base=$(basename "$so")
            [ -e "/usr/lib64/${base}" ] || sudo ln -s "$so" "/usr/lib64/${base}" || true
          done

      # --------------------------
      # Run your full installation
      # --------------------------
      - name: Full install (build venv + tools)
        shell: bash
        # --- DEFINITIVE FIX ---
        # Create a clean environment for this step to prevent interference from
        # variables set in previous steps (like CFLAGS, LDFLAGS, DEB_..._FLAGS).
        # We explicitly set only the essential MPI compilers.
        env:
          CC: mpicc
          CXX: mpicxx
          CFLAGS: ""
          CXXFLAGS: ""
          LDFLAGS: ""
          LD_LIBRARY_PATH: ""
          DEB_BUILD_MAINT_OPTIONS: ""
        run: |
          set -e
          echo "SYMFLUENCE_CODE: ${SYMFLUENCE_CODE}"
          echo "SYMFLUENCE_DATA: ${SYMFLUENCE_DATA}"
          mkdir -p "${SYMFLUENCE_DATA}"
          
          # Ensure the installer script is executable
          chmod +x ./symfluence
          
          # Run the installation in the newly cleaned environment.
          ./symfluence --install



      - name: Wrapper info
        run: |
          set -e
          ./symfluence --wrapper-info || true

      # ----------------
      # Validate binaries
      # ----------------
      - name: Validate
        shell: bash
        run: |
          set -e
          echo "CODE=$SYMFLUENCE_CODE"
          echo "DATA=$SYMFLUENCE_DATA"
          # Use the venv Python created during install
          . ./venv/bin/activate || . ./.venv/bin/activate
          python --version
          python symfluence.py --validate_binaries

      # --------------------------
      # Upload logs on failure only
      # --------------------------
      - name: Upload build logs (on fail)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: symfluence-build-logs
          path: |
            **/build/**/CMakeFiles/CMakeOutput.log
            **/build/**/CMakeFiles/CMakeError.log
            **/logs/**
            **/*build*.log
            **/cmake_build/**/*.log
          if-no-files-found: warn


  smoke-tests:
    needs: install-validate
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'


      # If your install/setup already happened in install-validate, you can remove this block.
      - name: Install SYMFLUENCE (wrapper)
        run: |
          set -e
          chmod +x ./symfluence
          ./symfluence --install

      - name: CLI help (parses and exits 0)
        run: |
          set -e
          ./symfluence --help > /dev/null

      - name: Dry-run (no execution, just plan)
        run: |
          set -e
          ./symfluence --dry_run

      - name: Wrapper info (env sanity)
        run: |
          set -e
          ./symfluence --wrapper-info

      - name: Python API import + status keys
        run: |
          set -e
          . ./venv/bin/activate || . ./.venv/bin/activate || true
          python - << 'PY'
          from pathlib import Path
          from symfluence import SYMFLUENCE
          c = SYMFLUENCE(Path('./0_config_files/config_template.yaml'))
          s = c.get_workflow_status()
          assert isinstance(s, dict) and {'total_steps','step_details'}.issubset(s), s
          print("API status OK:", s['total_steps'], "steps")
          PY

  step_tests-domain:
    needs: smoke-tests
    runs-on: ubuntu-latest
    env:
      TZ: UTC
      CI: "1"
      NONINTERACTIVE: "1"
      SYMFLUENCE_CODE: ${{ github.workspace }}
      # Put CI working data outside the repo tree
      SYMFLUENCE_DATA: ${{ github.workspace }}/.sym_data
      DOMAIN: Bow_at_Banff
      DOMAIN_DEF: delineate
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      # Reuse your existing install procedure; keep if not inherited from prior job
      - name: Install SYMFLUENCE (wrapper)
        run: |
          set -e
          chmod +x ./symfluence
          ./symfluence --install

      - name: Create CI config for Bow at Banff
        run: |
          set -e
          mkdir -p 0_config_files "${SYMFLUENCE_DATA}"
          cat > 0_config_files/config_ci_bow.yaml <<'YAML'
          SYMFLUENCE_CODE_DIR: "${{ env.SYMFLUENCE_CODE }}"
          SYMFLUENCE_DATA_DIR: "${{ env.SYMFLUENCE_DATA }}"
          DOMAIN_NAME: "${{ env.DOMAIN }}"
          DOMAIN_DEFINITION_METHOD: "${{ env.DOMAIN_DEF }}"
          LOG_LEVEL: "INFO"
          YAML

      - name: Step 1 — setup_project (creates domain scaffolding)
        run: |
          set -e
          ./symfluence --config 0_config_files/config_ci_bow.yaml --setup_project

      - name: Step 2 — copy repo data into created domain folder
        run: |
          set -e
          SRC="./src/data/domain_${DOMAIN}"
          DEST="${SYMFLUENCE_DATA}/domain_${DOMAIN}"
          mkdir -p "${DEST}"
          # Copy everything (shapefiles, any sidecars, etc.)
          cp -a "${SRC}/." "${DEST}/"
          echo "Copied data into ${DEST}"
          ls -R "${DEST}" || true

      - name: Step 3 — run define_domain using CLI
        run: |
          set -e
          ./symfluence --config 0_config_files/config_ci_bow.yaml --define_domain

      - name: Step 4 — run discretise_domain using CLI
        run: |
          set -e
          ./symfluence --config 0_config_files/config_ci_bow.yaml --discretize_domain

      - name: Assertions — river basins shapefile exists; logs exist
        run: |
          set -e
          DOMAIN_DIR="${SYMFLUENCE_DATA}/domain_${DOMAIN}"
          RIV_DIR="${DOMAIN_DIR}/shapefiles/river_basins"
          # Expect a river basins shapefile (method suffix may vary; allow wildcard)
          test -d "${RIV_DIR}"
          ls "${RIV_DIR}/${DOMAIN}_riverBasins_"*.shp >/dev/null
          # Also check that workflow logs are written in the standard location
          ls "_workLog_${DOMAIN}" >/dev/null
          echo "✅ Expected outputs present."

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: domain-define-minimal-logs
          path: |
            _workLog_${{ env.DOMAIN }}/**
            ${{ env.SYMFLUENCE_DATA }}/domain_${{ env.DOMAIN }}/**/*
          if-no-files-found: warn


  step_tests-model_agnostic:
    needs: step_tests-domain
    runs-on: ubuntu-latest
    env:
      TZ: UTC
      CI: "1"
      NONINTERACTIVE: "1"
      SYMFLUENCE_CODE: ${{ github.workspace }}
      # Keep CI working data outside the repo tree
      SYMFLUENCE_DATA: ${{ github.workspace }}/.sym_data
      DOMAIN: Bow_at_Banff
      DOMAIN_DEF: delineate
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - name: Install SYMFLUENCE (wrapper)
        run: |
          set -e
          chmod +x ./symfluence
          ./symfluence --install

      - name: Create CI config for Bow at Banff
        run: |
          set -e
          mkdir -p 0_config_files "${SYMFLUENCE_DATA}"
          cat > 0_config_files/config_ci_bow.yaml <<'YAML'
          SYMFLUENCE_CODE_DIR: "${{ env.SYMFLUENCE_CODE }}"
          SYMFLUENCE_DATA_DIR: "${{ env.SYMFLUENCE_DATA }}"
          DOMAIN_NAME: "${{ env.DOMAIN }}"
          DOMAIN_DEFINITION_METHOD: "${{ env.DOMAIN_DEF }}"
          LOG_LEVEL: "INFO"
          YAML

      - name: Setup project scaffold
        run: |
          set -e
          ./symfluence --config 0_config_files/config_ci_bow.yaml --setup_project

      - name: Copy domain seed data
        run: |
          set -e
          SRC="./src/data/domain_${DOMAIN}"
          DEST="${SYMFLUENCE_DATA}/domain_${DOMAIN}"
          mkdir -p "${DEST}"
          cp -a "${SRC}/." "${DEST}/"
          echo "Copied data into ${DEST}"
          ls -R "${DEST}" || true

      # >>> Model-agnostic preprocessing (runs in parallel with define_domain in the other job) <<<
      - name: Run model-agnostic preprocessing
        run: |
          set -e
          # If your CLI name differs, adjust the flag below:
          ./symfluence --config 0_config_files/config_ci_bow.yaml --model_agnostic_preprocess

      - name: Assertions — check outputs/logs
        run: |
          set -e
          DOMAIN_DIR="${SYMFLUENCE_DATA}/domain_${DOMAIN}"
          # Example expected outputs; tweak to your actual locations:
          test -d "${DOMAIN_DIR}/preprocessed"
          ls "${DOMAIN_DIR}/preprocessed"/* >/dev/null
          # Logs should exist
          ls "_workLog_${DOMAIN}" >/dev/null
          echo "✅ Model-agnostic preprocessing outputs present."

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: model-agnostic-preprocess-logs
          path: |
            _workLog_${{ env.DOMAIN }}/**
            ${{ env.SYMFLUENCE_DATA }}/domain_${{ env.DOMAIN }}/**/*
          if-no-files-found: warn
