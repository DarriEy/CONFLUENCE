{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARAVAN Large Sample Experiment Tutorial\n",
    "\n",
    "This notebook demonstrates how to run CONFLUENCE over multiple watersheds from the CARAVAN dataset for large-sample hydrology analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the large sample experiment\n",
    "experiment_config = {\n",
    "    'dataset': 'camels',  # CARAVAN dataset to use\n",
    "    'max_watersheds': 5,  # Number of watersheds to process\n",
    "    'dry_run': False,  # Set to True to test without submitting jobs\n",
    "    'experiment_name': 'caravan_tutorial',\n",
    "    'template_config': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/config_caravan_template.yaml',\n",
    "    'config_dir': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/caravan',\n",
    "    'caravan_script': '/home/darri.eythorsson/code/CONFLUENCE/examples/run_watersheds_caravan.py'\n",
    "}\n",
    "\n",
    "# Create experiment directory\n",
    "experiment_dir = Path(f\"./experiments/{experiment_config['experiment_name']}\")\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "with open(experiment_dir / 'experiment_config.yaml', 'w') as f:\n",
    "    yaml.dump(experiment_config, f)\n",
    "\n",
    "print(f\"Experiment configured: {experiment_config['experiment_name']}\")\n",
    "print(f\"Processing {experiment_config['max_watersheds']} watersheds from {experiment_config['dataset']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. List Available CARAVAN Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available CARAVAN datasets\n",
    "cmd = ['python', experiment_config['caravan_script'], '--list-datasets']\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discover Watersheds in Selected Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get watershed information for the selected dataset\n",
    "watersheds_csv = experiment_dir / f\"{experiment_config['dataset']}_watersheds.csv\"\n",
    "\n",
    "cmd = [\n",
    "    'python', experiment_config['caravan_script'],\n",
    "    '--dataset', experiment_config['dataset'],\n",
    "    '--watersheds-csv', str(watersheds_csv)\n",
    "]\n",
    "\n",
    "print(f\"Discovering watersheds in {experiment_config['dataset']}...\")\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "# Load watershed information\n",
    "if watersheds_csv.exists():\n",
    "    watersheds_df = pd.read_csv(watersheds_csv)\n",
    "    print(f\"Found {len(watersheds_df)} watersheds\")\n",
    "    print(\"\\nFirst 5 watersheds:\")\n",
    "    print(watersheds_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Launch CONFLUENCE for Multiple Watersheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Launch the large sample experiment\n",
    "cmd = [\n",
    "    'python', experiment_config['caravan_script'],\n",
    "    '--dataset', experiment_config['dataset'],\n",
    "    '--template', experiment_config['template_config'],\n",
    "    '--config-dir', experiment_config['config_dir'],\n",
    "    '--max-watersheds', str(experiment_config['max_watersheds']),\n",
    "    '--watersheds-csv', str(watersheds_csv)\n",
    "]\n",
    "\n",
    "if experiment_config['dry_run']:\n",
    "    cmd.append('--dry-run')\n",
    "    print(\"DRY RUN MODE - No jobs will be submitted\")\n",
    "\n",
    "print(f\"Launching CONFLUENCE for {experiment_config['max_watersheds']} watersheds...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "\n",
    "# Execute\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(result.stdout[:500] + \"...\" if len(result.stdout) > 500 else result.stdout)\n",
    "\n",
    "# Save submission log\n",
    "with open(experiment_dir / 'submission.log', 'w') as f:\n",
    "    f.write(result.stdout)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitor Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Check SLURM job status\n",
    "def check_job_status(user=None):\n",
    "    user = user or os.environ.get('USER')\n",
    "    cmd = ['squeue', '-u', user]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return result.stdout\n",
    "\n",
    "print(\"Current jobs:\")\n",
    "print(check_job_status())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Find Completed Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find completed watershed simulations\n",
    "confluence_data_dir = Path(\"/work/comphyd_lab/data/CONFLUENCE_data\")\n",
    "caravan_dir = confluence_data_dir / \"caravan\"\n",
    "\n",
    "completed = []\n",
    "if caravan_dir.exists():\n",
    "    for domain_dir in caravan_dir.glob(f\"domain_{experiment_config['dataset']}_*\"):\n",
    "        watershed_id = domain_dir.name.split('_')[-1]\n",
    "        sim_dir = domain_dir / \"simulations\"\n",
    "        \n",
    "        # Check if simulation files exist\n",
    "        if sim_dir.exists() and list(sim_dir.rglob(\"*.nc\")):\n",
    "            completed.append({\n",
    "                'watershed_id': watershed_id,\n",
    "                'domain_dir': domain_dir,\n",
    "                'sim_dir': sim_dir\n",
    "            })\n",
    "\n",
    "print(f\"Completed simulations: {len(completed)}\")\n",
    "for ws in completed:\n",
    "    print(f\"  - Watershed {ws['watershed_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simple function to load results\n",
    "def load_summa_output(sim_dir, variable='averageRoutedRunoff'):\n",
    "    import xarray as xr\n",
    "    \n",
    "    output_files = list(sim_dir.rglob(\"*timestep*.nc\"))\n",
    "    if output_files:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        if variable in ds.variables:\n",
    "            return pd.DataFrame({\n",
    "                'time': pd.to_datetime(ds.time.values),\n",
    "                'value': ds[variable].values.flatten()\n",
    "            })\n",
    "    return None\n",
    "\n",
    "# Plot results for completed watersheds\n",
    "if completed:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for ws in completed[:10]:  # Plot first 10\n",
    "        data = load_summa_output(ws['sim_dir'])\n",
    "        if data is not None:\n",
    "            ax.plot(data['time'], data['value'], \n",
    "                   label=f\"Watershed {ws['watershed_id']}\", \n",
    "                   linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Snow Water Equivalent (mm)')\n",
    "    ax.set_title(f'SWE Comparison - {experiment_config[\"dataset\"].upper()} Watersheds')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NSE and KGE for watersheds with streamflow data\n",
    "import numpy as np\n",
    "\n",
    "def calculate_nse(obs, sim):\n",
    "    \"\"\"Calculate Nash-Sutcliffe Efficiency\"\"\"\n",
    "    mask = ~(np.isnan(obs) | np.isnan(sim))\n",
    "    obs, sim = obs[mask], sim[mask]\n",
    "    \n",
    "    if len(obs) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return 1 - np.sum((obs - sim)**2) / np.sum((obs - np.mean(obs))**2)\n",
    "\n",
    "def calculate_kge(obs, sim):\n",
    "    \"\"\"Calculate Kling-Gupta Efficiency\"\"\"\n",
    "    mask = ~(np.isnan(obs) | np.isnan(sim))\n",
    "    obs, sim = obs[mask], sim[mask]\n",
    "    \n",
    "    if len(obs) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate components\n",
    "    r = np.corrcoef(obs, sim)[0, 1]  # Correlation\n",
    "    alpha = np.std(sim) / np.std(obs)  # Relative variability\n",
    "    beta = np.mean(sim) / np.mean(obs)  # Bias\n",
    "    \n",
    "    # Calculate KGE\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "# Enhance the existing load_summa_output function to handle streamflow variables\n",
    "def load_model_streamflow(sim_dir):\n",
    "    \"\"\"Load streamflow from model outputs using existing function with streamflow variables\"\"\"\n",
    "    # Try to find mizuRoute output first (processed streamflow)\n",
    "    mizu_dir = sim_dir.parent / \"mizuRoute\"\n",
    "    if mizu_dir.exists():\n",
    "        import xarray as xr\n",
    "        mizu_files = list(mizu_dir.glob(\"*.nc\"))\n",
    "        if mizu_files:\n",
    "            try:\n",
    "                ds = xr.open_dataset(mizu_files[0])\n",
    "                # Check for common mizuRoute variables\n",
    "                for var in ['IRFroutedRunoff', 'flow', 'streamflow']:\n",
    "                    if var in ds.variables:\n",
    "                        return pd.DataFrame({\n",
    "                            'time': pd.to_datetime(ds.time.values),\n",
    "                            'value': ds[var].values.flatten()\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading mizuRoute output: {e}\")\n",
    "    \n",
    "    # Fall back to SUMMA runoff if routing not found\n",
    "    runoff_vars = ['averageRunoff', 'scalarTotalRunoff', 'scalarAquiferBaseflow']\n",
    "    for var in runoff_vars:\n",
    "        df = load_summa_output(sim_dir, variable=var)\n",
    "        if df is not None:\n",
    "            return df\n",
    "    \n",
    "    # If no specific streamflow variable found, use the default function\n",
    "    return load_summa_output(sim_dir)\n",
    "\n",
    "def load_observation_data(ws_dir, watershed_id, dataset=\"camels\"):\n",
    "    \"\"\"Load observation data for a watershed\n",
    "    \n",
    "    Args:\n",
    "        ws_dir: Path to the domain directory\n",
    "        watershed_id: Watershed ID (e.g., '01047000')\n",
    "        dataset: Dataset name prefix (default: 'camels')\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with observation data or None if not found\n",
    "    \"\"\"\n",
    "    # Check common observation file locations and formats based on the actual directory structure\n",
    "    obs_paths = [\n",
    "        # New pattern based on the screenshot\n",
    "        ws_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{dataset}_{dataset}_{watershed_id}_streamflow_processed.csv\",\n",
    "        # Original patterns as fallbacks\n",
    "        ws_dir / 'observations' / 'streamflow' / 'raw_data' / f\"{dataset}_{watershed_id}_Discharge.csv\",\n",
    "        ws_dir / 'observations' / 'streamflow' / 'raw_data' / f\"{watershed_id}_streamflow.csv\",\n",
    "        ws_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{watershed_id}_streamflow_processed.csv\"\n",
    "    ]\n",
    "    \n",
    "    # Try each possible path\n",
    "    for path in obs_paths:\n",
    "        if path.exists():\n",
    "            print(f\"Found observation data at: {path}\")\n",
    "            try:\n",
    "                return pd.read_csv(path, parse_dates=['datetime'])\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # If no file is found, search for any files that might match\n",
    "    print(f\"No observation data found for watershed {watershed_id}\")\n",
    "    \n",
    "    # Print available files to help debugging\n",
    "    preprocessed_dir = ws_dir / 'observations' / 'streamflow' / 'preprocessed'\n",
    "    if preprocessed_dir.exists():\n",
    "        print(f\"Available files in preprocessed directory:\")\n",
    "        for file in preprocessed_dir.glob(\"*\"):\n",
    "            print(f\"  - {file.name}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Calculate metrics for the completed watersheds\n",
    "metrics = []\n",
    "\n",
    "for ws in completed:\n",
    "    try:\n",
    "        watershed_id = ws['watershed_id']\n",
    "        print(f\"Processing watershed {watershed_id}...\")\n",
    "        \n",
    "        # Load simulated data using the enhanced function\n",
    "        sim_df = load_model_streamflow(ws['sim_dir'])\n",
    "        \n",
    "        if sim_df is None:\n",
    "            print(f\"  No simulation data found for watershed {watershed_id}\")\n",
    "            continue\n",
    "            \n",
    "        # Load observed data\n",
    "        obs_df = load_observation_data(ws['domain_dir'], watershed_id, experiment_config['dataset'])\n",
    "        \n",
    "        if obs_df is None:\n",
    "            print(f\"  No observation data found for watershed {watershed_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Align the time series by merging on time column\n",
    "        # Convert both to same frequency if needed (daily is common for hydrological studies)\n",
    "        print(sim_df)\n",
    "        sim_df['datetime'] = sim_df['time']\n",
    "        sim_df.set_index('datetime', inplace=True)\n",
    "        obs_df.set_index('datetime', inplace=True)\n",
    "        \n",
    "        # Resample to daily if data is higher frequency\n",
    "        sim_daily = sim_df.resample('D').mean()\n",
    "        obs_daily = obs_df.resample('D').mean()\n",
    "        \n",
    "        # Merge the datasets on the date index\n",
    "        merged = pd.merge(obs_daily, sim_daily, \n",
    "                         left_index=True, right_index=True, \n",
    "                         how='inner',\n",
    "                         suffixes=('_obs', '_sim'))\n",
    "        \n",
    "        if len(merged) < 30:\n",
    "            print(f\"  Insufficient matching data points for watershed {watershed_id} ({len(merged)} points)\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate performance metrics\n",
    "        print(merged)\n",
    "        nse = calculate_nse(merged['discharge_cms'].values, merged['value'].values)\n",
    "        kge = calculate_kge(merged['discharge_cms'].values, merged['value'].values)\n",
    "        \n",
    "        print(f\"  Metrics calculated - NSE: {nse:.3f}, KGE: {kge:.3f}\")\n",
    "        \n",
    "        # Store the metrics\n",
    "        metrics.append({\n",
    "            'watershed_id': watershed_id,\n",
    "            'nse': nse,\n",
    "            'kge': kge,\n",
    "            'data_points': len(merged),\n",
    "            'start_date': merged.index.min().strftime('%Y-%m-%d'),\n",
    "            'end_date': merged.index.max().strftime('%Y-%m-%d')\n",
    "        })\n",
    "        \n",
    "        # Plot the comparison\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(merged.index, merged['discharge_cms'], 'k-', label='Observed', linewidth=1.5)\n",
    "        plt.plot(merged.index, merged['value'], 'b-', label='Simulated', linewidth=1.5, alpha=0.7)\n",
    "        plt.title(f\"Watershed {watershed_id} - NSE: {nse:.3f}, KGE: {kge:.3f}\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Streamflow')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure\n",
    "        comparison_file = experiment_dir / f\"watershed_{watershed_id}_comparison.png\"\n",
    "        plt.savefig(comparison_file)\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing watershed {ws['watershed_id']}: {str(e)}\")\n",
    "\n",
    "# Create a dataframe with the metrics\n",
    "if metrics:\n",
    "    metrics_df = pd.DataFrame(metrics).sort_values('kge', ascending=False)\n",
    "    \n",
    "    # Display metrics\n",
    "    print(\"\\nPerformance Metrics (sorted by KGE):\")\n",
    "    display(metrics_df)\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    metrics_file = experiment_dir / 'performance_metrics.csv'\n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"\\nMetrics saved to {metrics_file}\")\n",
    "    \n",
    "    # Create scatter plot comparing NSE and KGE\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(metrics_df['nse'], metrics_df['kge'], s=60, alpha=0.7)\n",
    "    \n",
    "    # Add watershed IDs as labels\n",
    "    for i, row in metrics_df.iterrows():\n",
    "        plt.annotate(row['watershed_id'], \n",
    "                   (row['nse'], row['kge']),\n",
    "                   xytext=(5, 5), \n",
    "                   textcoords='offset points',\n",
    "                   fontsize=9)\n",
    "    \n",
    "    # Add 1:1 line\n",
    "    lims = [\n",
    "        min(min(metrics_df['nse']), min(metrics_df['kge'])) - 0.1,\n",
    "        max(max(metrics_df['nse']), max(metrics_df['kge'])) + 0.1\n",
    "    ]\n",
    "    plt.plot(lims, lims, 'k--', alpha=0.5)\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlabel('Nash-Sutcliffe Efficiency (NSE)')\n",
    "    plt.ylabel('Kling-Gupta Efficiency (KGE)')\n",
    "    plt.title(f'Performance Metrics - {experiment_config[\"dataset\"].upper()} Watersheds')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(experiment_dir / 'nse_kge_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"Number of watersheds: {len(metrics_df)}\")\n",
    "    print(f\"Mean NSE: {metrics_df['nse'].mean():.3f}\")\n",
    "    print(f\"Mean KGE: {metrics_df['kge'].mean():.3f}\")\n",
    "    print(f\"Best watershed (by KGE): {metrics_df.iloc[0]['watershed_id']} (KGE={metrics_df.iloc[0]['kge']:.3f})\")\n",
    "else:\n",
    "    print(\"No performance metrics could be calculated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This tutorial covered the basics of running CONFLUENCE over multiple CARAVAN watersheds. For more advanced analysis:\n",
    "\n",
    "1. **Regional Analysis**: Group watersheds by climate or geography\n",
    "2. **Model Comparison**: Test different model structures\n",
    "3. **Parameter Transfer**: Develop regionalization relationships\n",
    "4. **Machine Learning**: Predict performance from attributes\n",
    "5. **Climate Scenarios**: Run future projections\n",
    "\n",
    "See the full documentation for detailed examples of these analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
