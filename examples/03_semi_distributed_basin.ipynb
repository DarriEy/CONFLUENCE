{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Distributed Basin Workflow with Delineation\n",
    "\n",
    "This notebook demonstrates the distributed modeling approach using the delineation method. We'll use the same Bow River at Banff location but create a distributed model with multiple GRUs (Grouped Response Units).\n",
    "\n",
    "## Key Differences from Lumped Model\n",
    "\n",
    "- **Domain Method**: `delineate` instead of `lumped`\n",
    "- **Stream Threshold**: 5000 (creates more sub-basins)\n",
    "- **Multiple GRUs**: Each sub-basin becomes a GRU\n",
    "- **Routing**: mizuRoute connects the GRUs\n",
    "- **Spatial Mode**: Distributed instead of Lumped\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand watershed delineation with stream networks\n",
    "2. Create a distributed model with multiple GRUs\n",
    "3. Compare with lumped approach from Tutorial 1\n",
    "4. Learn how to reuse data across experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize CONFLUENCE\n",
    "First, let's set up our directories and load the configuration. We'll modify the configuration from Tutorial 1 to create a distributed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # ‚Üê User should modify this path\n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load template configuration\n",
    "config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "\n",
    "# Read config file\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update core paths\n",
    "config_dict['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config_dict['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "\n",
    "# Modify for distributed delineation\n",
    "config_dict['DOMAIN_NAME'] = 'Bow_at_Banff_distributed'\n",
    "config_dict['EXPERIMENT_ID'] = 'distributed_tutorial'\n",
    "config_dict['DOMAIN_DEFINITION_METHOD'] = 'delineate'  # Changed from 'lumped'\n",
    "config_dict['STREAM_THRESHOLD'] = 5000  # Higher threshold for fewer sub-basins\n",
    "config_dict['DOMAIN_DISCRETIZATION'] = 'GRUs'  # Keep as GRUs\n",
    "config_dict['SPATIAL_MODE'] = 'Distributed'  # Changed from 'Lumped'\n",
    "\n",
    "# Use just one parallel process for this tutorial\n",
    "config_dict['MPI_PROCESSES'] = 1\n",
    "\n",
    "# Save updated config to a temporary file\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_distributed.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f)\n",
    "\n",
    "# Initialize CONFLUENCE\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "# Display configuration\n",
    "print(\"=== Directory Configuration ===\")\n",
    "print(f\"Code Directory: {CONFLUENCE_CODE_DIR}\")\n",
    "print(f\"Data Directory: {CONFLUENCE_DATA_DIR}\")\n",
    "print(\"\\n=== Key Configuration Settings ===\")\n",
    "print(f\"Domain Name: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Pour Point: {confluence.config['POUR_POINT_COORDS']}\")\n",
    "print(f\"Domain Method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "print(f\"Stream Threshold: {confluence.config['STREAM_THRESHOLD']}\")\n",
    "print(f\"Spatial Mode: {confluence.config['SPATIAL_MODE']}\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Simulation Period: {confluence.config['EXPERIMENT_TIME_START']} to {confluence.config['EXPERIMENT_TIME_END']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Lumped vs Distributed Concept\n",
    "\n",
    "Before we start building the distributed model, let's visualize the difference between lumped and distributed approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization comparing lumped vs distributed\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Lumped representation\n",
    "ax1.add_patch(plt.Rectangle((0, 0), 1, 1, fill=True, color='lightblue', alpha=0.7))\n",
    "ax1.text(0.5, 0.5, 'Entire Basin\\n(1 Unit)', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "ax1.arrow(0.5, 0.05, 0, -0.1, head_width=0.03, head_length=0.02, fc='blue', ec='blue')\n",
    "ax1.text(0.5, -0.08, 'Single Output', ha='center', fontsize=10)\n",
    "ax1.set_xlim(-0.1, 1.1)\n",
    "ax1.set_ylim(-0.15, 1.1)\n",
    "ax1.set_title('Lumped Model (Tutorial 1)', fontsize=16, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Distributed representation\n",
    "# Create sub-basins with river network\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "positions = [(0.2, 0.7), (0.7, 0.7), (0.2, 0.3), (0.5, 0.1)]\n",
    "labels = ['GRU 1', 'GRU 2', 'GRU 3', 'GRU 4']\n",
    "\n",
    "for i, (pos, color, label) in enumerate(zip(positions, colors, labels)):\n",
    "    circle = plt.Circle(pos, 0.15, fill=True, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax2.add_patch(circle)\n",
    "    ax2.text(pos[0], pos[1], label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Draw river network\n",
    "ax2.plot([0.2, 0.2, 0.5], [0.7, 0.3, 0.1], 'b-', linewidth=3)  # Main stem\n",
    "ax2.plot([0.7, 0.5], [0.7, 0.1], 'b-', linewidth=2)  # Tributary\n",
    "ax2.arrow(0.5, 0.1, 0, -0.1, head_width=0.03, head_length=0.02, fc='blue', ec='blue')\n",
    "ax2.text(0.5, -0.02, 'Routed Output', ha='center', fontsize=10)\n",
    "\n",
    "ax2.set_xlim(-0.1, 1.1)\n",
    "ax2.set_ylim(-0.15, 1.1)\n",
    "ax2.set_title('Distributed Model (This Tutorial)', fontsize=16, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Project Setup - Organizing the Modeling Workflow\n",
    "\n",
    "First, we'll establish a well-organized project structure, similar to what we did in Tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Project Initialization\n",
    "print(\"=== Step 1: Project Initialization ===\")\n",
    "\n",
    "# Setup project\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# Create pour point\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  üìÅ {item.name}\")\n",
    "\n",
    "print(\"\\nNote: The pour point location is identical to the lumped model.\")\n",
    "print(\"The difference is in how we subdivide the watershed above this point.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Geospatial Domain Definition - Data Acquisition and Preparation\n",
    "\n",
    "We'll reuse some of the geospatial data from the lumped model tutorial, where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we can reuse data from the lumped model\n",
    "lumped_dem_path = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_lumped' / 'attributes' / 'elevation' / 'dem'\n",
    "can_reuse = lumped_dem_path.exists()\n",
    "\n",
    "if can_reuse:\n",
    "    print(\"Found existing geospatial data from lumped model. This will speed up the process.\")\n",
    "    print(\"The distributed model can reuse some of these data layers.\")\n",
    "else:\n",
    "    print(\"No existing data found from the lumped model. Will acquire all data from scratch.\")\n",
    "\n",
    "# Step 2: Geospatial Domain Definition - Data Acquisition\n",
    "print(\"\\n=== Step 2: Geospatial Domain Definition - Data Acquisition ===\")\n",
    "\n",
    "# Acquire attributes\n",
    "print(\"Acquiring geospatial attributes (DEM, soil, land cover)...\")\n",
    "confluence.managers['data'].acquire_attributes()\n",
    "\n",
    "print(\"\\n‚úì Geospatial attributes acquired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geospatial Domain Definition - Delineation with Stream Network\n",
    "\n",
    "This is where the main difference occurs - we'll create multiple sub-basins connected by a stream network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Geospatial Domain Definition - Delineation\n",
    "print(\"=== Step 3: Geospatial Domain Definition - Delineation ===\")\n",
    "\n",
    "# Define domain\n",
    "print(f\"Delineating distributed watershed...\")\n",
    "print(f\"Method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "print(f\"Stream threshold: {confluence.config['STREAM_THRESHOLD']}\")\n",
    "print(\"\\nThis will create multiple sub-basins connected by a stream network.\")\n",
    "\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "\n",
    "# Check outputs\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "network_path = project_dir / 'shapefiles' / 'river_network'\n",
    "\n",
    "if basin_path.exists():\n",
    "    basin_files = list(basin_path.glob('*.shp'))\n",
    "    print(f\"\\n‚úì Created basin shapefiles: {len(basin_files)}\")\n",
    "    \n",
    "if network_path.exists():\n",
    "    network_files = list(network_path.glob('*.shp'))\n",
    "    print(f\"‚úì Created river network shapefiles: {len(network_files)}\")\n",
    "    \n",
    "    # Load and check number of basins\n",
    "    if basin_files:\n",
    "        gdf = gpd.read_file(basin_files[0])\n",
    "        print(f\"\\nNumber of sub-basins (GRUs): {len(gdf)}\")\n",
    "        print(f\"Total area: {gdf.geometry.area.sum() / 1e6:.2f} km¬≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the Distributed Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the delineated domain with stream network\n",
    "basin_files = list((project_dir / 'shapefiles' / 'river_basins').glob('*.shp'))\n",
    "network_files = list((project_dir / 'shapefiles' / 'river_network').glob('*.shp'))\n",
    "    \n",
    "if basin_files and network_files:\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Load data\n",
    "    basins = gpd.read_file(basin_files[0])\n",
    "    rivers = gpd.read_file(network_files[0])\n",
    "    \n",
    "    # Plot basins with different colors\n",
    "    basins.plot(ax=ax, column='GRU_ID', cmap='viridis', \n",
    "               alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Plot river network\n",
    "    rivers.plot(ax=ax, color='blue', linewidth=2)\n",
    "    \n",
    "    # Add pour point\n",
    "    pour_point = gpd.read_file(pour_point_path)\n",
    "    pour_point.plot(ax=ax, color='red', markersize=150, marker='o', zorder=5)\n",
    "    \n",
    "    ax.set_title(f'Distributed Domain: {len(basins)} Sub-basins', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    # Add colorbar for GRU IDs\n",
    "    sm = plt.cm.ScalarMappable(cmap='viridis', \n",
    "                               norm=plt.Normalize(vmin=basins['GRU_ID'].min(), \n",
    "                                                 vmax=basins['GRU_ID'].max()))\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, ax=ax, shrink=0.8)\n",
    "    cbar.set_label('GRU ID', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Geospatial Domain Definition - Discretization\n",
    "\n",
    "Now we'll create Hydrologic Response Units (HRUs) based on the Grouped Response Units (GRUs) we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Geospatial Domain Definition - Discretization\n",
    "print(\"=== Step 4: Geospatial Domain Definition - Discretization ===\")\n",
    "\n",
    "# Discretize domain\n",
    "print(f\"Creating HRUs based on GRUs...\")\n",
    "print(f\"Method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "print(\"For this tutorial: 1 GRU = 1 HRU (simplest case)\")\n",
    "\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "# Check the created HRU shapefile\n",
    "catchment_path = project_dir / 'shapefiles' / 'catchment'\n",
    "if catchment_path.exists():\n",
    "    hru_files = list(catchment_path.glob('*.shp'))\n",
    "    print(f\"\\n‚úì Created HRU shapefiles: {len(hru_files)}\")\n",
    "    \n",
    "    if hru_files:\n",
    "        hru_gdf = gpd.read_file(hru_files[0])\n",
    "        print(f\"\\nHRU Statistics:\")\n",
    "        print(f\"Number of HRUs: {len(hru_gdf)}\")\n",
    "        print(f\"Number of GRUs: {hru_gdf['GRU_ID'].nunique()}\")\n",
    "        print(f\"Total area: {hru_gdf.geometry.area.sum() / 1e6:.2f} km¬≤\")\n",
    "        \n",
    "        # Show HRU distribution\n",
    "        hru_counts = hru_gdf.groupby('GRU_ID').size()\n",
    "        print(f\"\\nHRUs per GRU:\")\n",
    "        for gru_id, count in hru_counts.items():\n",
    "            print(f\"  GRU {gru_id}: {count} HRUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Agnostic Data Processing - Observed Data\n",
    "\n",
    "The observed streamflow data will be the same for both the lumped and distributed models since they use the same pour point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Agnostic Data Processing - Observed Data\n",
    "print(\"=== Step 5: Model Agnostic Data Processing - Observed Data ===\")\n",
    "\n",
    "# Check if we can reuse data from the lumped model\n",
    "lumped_obs_path = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_lumped' / 'observations' / 'streamflow' / 'preprocessed'\n",
    "can_reuse_obs = lumped_obs_path.exists() and list(lumped_obs_path.glob('*.csv'))\n",
    "\n",
    "if can_reuse_obs:\n",
    "    print(\"Found existing observed data from lumped model. Reusing...\")\n",
    "    # We can proceed, but CONFLUENCE will handle the reuse internally\n",
    "\n",
    "# Process observed data\n",
    "print(\"Processing observed streamflow data...\")\n",
    "confluence.managers['data'].process_observed_data()\n",
    "\n",
    "# Visualize observed streamflow data\n",
    "obs_path = project_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{confluence.config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "if obs_path.exists():\n",
    "    obs_df = pd.read_csv(obs_path)\n",
    "    obs_df['datetime'] = pd.to_datetime(obs_df['datetime'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(obs_df['datetime'], obs_df['discharge_cms'], \n",
    "            linewidth=1.5, color='blue', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Discharge (m¬≥/s)', fontsize=12)\n",
    "    ax.set_title(f'Observed Streamflow - Bow River at Banff (WSC Station: {confluence.config[\"STATION_ID\"]})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    ax.text(0.02, 0.95, f'Mean: {obs_df[\"discharge_cms\"].mean():.1f} m¬≥/s\\nMax: {obs_df[\"discharge_cms\"].max():.1f} m¬≥/s', \n",
    "            transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "            verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Agnostic Data Processing - Forcing Data\n",
    "\n",
    "For the distributed model, we need forcing data for each GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Agnostic Data Processing - Forcing Data\n",
    "print(\"=== Step 6: Model Agnostic Data Processing - Forcing Data ===\")\n",
    "\n",
    "# Check if we can reuse some forcing data from the lumped model\n",
    "lumped_forcing_path = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_lumped' / 'forcing'\n",
    "can_reuse_forcing = lumped_forcing_path.exists()\n",
    "\n",
    "if can_reuse_forcing:\n",
    "    print(\"Found existing forcing data from lumped model.\")\n",
    "    print(\"Note: Distributed model requires unique forcing for each GRU, so data will be reprocessed.\")\n",
    "\n",
    "# Acquire forcings\n",
    "print(f\"\\nAcquiring forcing data: {confluence.config['FORCING_DATASET']}\")\n",
    "confluence.managers['data'].acquire_forcings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Agnostic Data Processing - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Model Agnostic Data Processing - Preprocessing\n",
    "print(\"=== Step 7: Model Agnostic Data Processing - Preprocessing ===\")\n",
    "\n",
    "# Run model-agnostic preprocessing\n",
    "print(\"\\nRunning model-agnostic preprocessing...\")\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "\n",
    "print(\"\\n‚úì Model-agnostic preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model-Specific Processing - Preprocessing\n",
    "\n",
    "Now we prepare inputs specific to our chosen hydrological model (SUMMA in this case), set up for a distributed configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Model Specific Processing and Initialization\n",
    "print(\"=== Step 8: Model Specific Processing and Initialization ===\")\n",
    "\n",
    "# Preprocess models\n",
    "print(f\"Preparing {confluence.config['HYDROLOGICAL_MODEL']} input files...\")\n",
    "print(f\"Note: For distributed mode with {confluence.config['HYDROLOGICAL_MODEL']}, this includes generating:\")\n",
    "print(f\"  - Model parameter files for each GRU\")\n",
    "print(f\"  - Routing configuration for river network\")\n",
    "print(f\"  - Connections between GRUs based on stream topology\")\n",
    "\n",
    "confluence.managers['model'].preprocess_models()\n",
    "\n",
    "print(\"\\n‚úì Model-specific preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Run the Distributed Model\n",
    "\n",
    "Now we execute the SUMMA model in distributed mode with routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Run the Distributed Model\n",
    "print(\"=== Step 9: Run the Distributed Model ===\")\n",
    "\n",
    "# Run the model\n",
    "print(f\"Running distributed {confluence.config['HYDROLOGICAL_MODEL']} model...\")\n",
    "print(f\"Number of GRUs: (check from previous output)\")\n",
    "print(\"Note: This will take longer than the lumped model due to multiple units.\")\n",
    "\n",
    "confluence.managers['model'].run_models()\n",
    "\n",
    "print(\"\\n‚úì Model execution completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Distributed Model Benchmarking\n",
    "\n",
    "Let's run benchmarking to evaluate the performance of our distributed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Distributed Model Benchmarking\n",
    "print(\"=== Step 10: Distributed Model Benchmarking ===\")\n",
    "\n",
    "# Run benchmarking\n",
    "print(\"\\nRunning benchmarking analysis...\")\n",
    "benchmark_results = confluence.managers['analysis'].run_benchmarking()\n",
    "\n",
    "print(\"\\n‚úì Benchmarking completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Visualize Distributed Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess results and visualize\n",
    "print(\"Post-processing model results...\")\n",
    "confluence.managers['model'].postprocess_results()\n",
    "\n",
    "# Load and plot simulation results\n",
    "sim_path = project_dir / 'simulations' / confluence.config['EXPERIMENT_ID'] / 'mizuRoute'\n",
    "sim_files = list(sim_path.glob('*.nc'))\n",
    "\n",
    "if sim_files:\n",
    "    # Load simulation data\n",
    "    sim_data = xr.open_dataset(sim_files[0])\n",
    "    \n",
    "    # Load observation data\n",
    "    obs_path = project_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{confluence.config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "    obs_df = pd.read_csv(obs_path)\n",
    "    obs_df['datetime'] = pd.to_datetime(obs_df['datetime'])\n",
    "    \n",
    "    # Find the segment ID for the outlet\n",
    "    if 'reachID' in sim_data.dims:\n",
    "        outlet_idx = sim_data.reachID.values == confluence.config['SIM_REACH_ID']\n",
    "        if any(outlet_idx):\n",
    "            # Extract simulated flow at outlet\n",
    "            sim_flow = sim_data.IRFroutedRunoff.sel(reachID=confluence.config['SIM_REACH_ID']).to_pandas()\n",
    "            sim_df = pd.DataFrame({'datetime': sim_flow.index, 'flow': sim_flow.values})\n",
    "            \n",
    "            # Plot comparison\n",
    "            fig, ax = plt.subplots(figsize=(14, 6))\n",
    "            \n",
    "            # Plot observed flow\n",
    "            ax.plot(obs_df['datetime'], obs_df['discharge_cms'], \n",
    "                    color='blue', linewidth=1.5, label='Observed')\n",
    "            \n",
    "            # Plot simulated flow\n",
    "            ax.plot(sim_df['datetime'], sim_df['flow'], \n",
    "                    color='red', linewidth=1.5, alpha=0.7, label='Simulated (Distributed)')\n",
    "            \n",
    "            ax.set_xlabel('Date', fontsize=12)\n",
    "            ax.set_ylabel('Discharge (m¬≥/s)', fontsize=12)\n",
    "            ax.set_title('Distributed Model Results - Bow River at Banff', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    else:\n",
    "        print(\"Could not find reachID dimension in simulation output\")\n",
    "else:\n",
    "    print(\"No simulation results found. Check model execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Compare Lumped vs Distributed Results (Optional)\n",
    "\n",
    "If you've completed the lumped model tutorial, we can compare results between the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load lumped model results for comparison\n",
    "lumped_sim_path = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_lumped' / 'simulations' / 'run_1' / 'mizuRoute'\n",
    "lumped_sim_files = list(lumped_sim_path.glob('*.nc')) if lumped_sim_path.exists() else []\n",
    "\n",
    "if lumped_sim_files:\n",
    "    print(\"Found lumped model results. Creating comparison plot...\")\n",
    "    \n",
    "    # Load lumped simulation data\n",
    "    lumped_data = xr.open_dataset(lumped_sim_files[0])\n",
    "    \n",
    "    # Load distributed simulation data\n",
    "    dist_sim_path = project_dir / 'simulations' / confluence.config['EXPERIMENT_ID'] / 'mizuRoute'\n",
    "    dist_sim_files = list(dist_sim_path.glob('*.nc'))\n",
    "    \n",
    "    if dist_sim_files:\n",
    "        dist_data = xr.open_dataset(dist_sim_files[0])\n",
    "        \n",
    "        # Load observation data\n",
    "        obs_path = project_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{confluence.config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "        obs_df = pd.read_csv(obs_path)\n",
    "        obs_df['datetime'] = pd.to_datetime(obs_df['datetime'])\n",
    "        \n",
    "        # Extract flows\n",
    "        # Find the segment ID for the outlet\n",
    "        if 'reachID' in dist_data.dims and 'reachID' in lumped_data.dims:\n",
    "            # Extract distributed flow\n",
    "            dist_flow = dist_data.IRFroutedRunoff.sel(reachID=confluence.config['SIM_REACH_ID']).to_pandas()\n",
    "            dist_df = pd.DataFrame({'datetime': dist_flow.index, 'flow': dist_flow.values})\n",
    "            \n",
    "            # Extract lumped flow\n",
    "            lumped_flow = lumped_data.IRFroutedRunoff.sel(reachID=confluence.config['SIM_REACH_ID']).to_pandas()\n",
    "            lumped_df = pd.DataFrame({'datetime': lumped_flow.index, 'flow': lumped_flow.values})\n",
    "            \n",
    "            # Plot comparison\n",
    "            fig, ax = plt.subplots(figsize=(14, 6))\n",
    "            \n",
    "            # Plot observed flow\n",
    "            ax.plot(obs_df['datetime'], obs_df['discharge_cms'], \n",
    "                    color='black', linewidth=1.5, label='Observed')\n",
    "            \n",
    "            # Plot lumped flow\n",
    "            ax.plot(lumped_df['datetime'], lumped_df['flow'], \n",
    "                    color='blue', linewidth=1.5, alpha=0.7, label='Lumped Model')\n",
    "            \n",
    "            # Plot distributed flow\n",
    "            ax.plot(dist_df['datetime'], dist_df['flow'], \n",
    "                    color='red', linewidth=1.5, alpha=0.7, label='Distributed Model')\n",
    "            \n",
    "            ax.set_xlabel('Date', fontsize=12)\n",
    "            ax.set_ylabel('Discharge (m¬≥/s)', fontsize=12)\n",
    "            ax.set_title('Lumped vs Distributed Model Comparison - Bow River at Banff', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    else:\n",
    "        print(\"Distributed simulation results not found. Run the distributed model first.\")\n",
    "else:\n",
    "    print(\"Lumped model results not found. Complete Tutorial 2 first for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Optional Steps - Optimization and Analysis\n",
    "\n",
    "These steps are optional and could be run to further explore the distributed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Optional Steps (Optimization and Analysis)\n",
    "print(\"=== Step 11: Optional Steps ===\")\n",
    "\n",
    "# Check if optimization is enabled\n",
    "if confluence.config.get('RUN_ITERATIVE_OPTIMISATION', False):\n",
    "    print(\"Running model calibration...\")\n",
    "    optimization_results = confluence.managers['optimization'].calibrate_model()\n",
    "else:\n",
    "    print(\"Model calibration skipped (RUN_ITERATIVE_OPTIMISATION = False)\")\n",
    "\n",
    "# Check if emulation is enabled\n",
    "if confluence.config.get('RUN_LARGE_SAMPLE_EMULATION', False) or confluence.config.get('RUN_RANDOM_FOREST_EMULATION', False):\n",
    "    print(\"Running parameter emulation...\")\n",
    "    emulation_results = confluence.managers['optimization'].run_emulation()\n",
    "else:\n",
    "    print(\"Parameter emulation skipped\")\n",
    "\n",
    "# Check if decision analysis is enabled\n",
    "if confluence.config.get('RUN_DECISION_ANALYSIS', False):\n",
    "    print(\"Running decision analysis...\")\n",
    "    decision_results = confluence.managers['analysis'].run_decision_analysis()\n",
    "else:\n",
    "    print(\"Decision analysis skipped\")\n",
    "\n",
    "# Check if sensitivity analysis is enabled\n",
    "if confluence.config.get('RUN_SENSITIVITY_ANALYSIS', False):\n",
    "    print(\"Running sensitivity analysis...\")\n",
    "    sensitivity_results = confluence.managers['analysis'].run_sensitivity_analysis()\n",
    "else:\n",
    "    print(\"Sensitivity analysis skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Compare Domain Structures: Lumped vs Distributed\n",
    "\n",
    "Let's create a visual comparison of the domain structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Lumped model visualization (if exists)\n",
    "lumped_basin_path = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_lumped' / 'shapefiles' / 'river_basins'\n",
    "if lumped_basin_path.exists():\n",
    "    lumped_files = list(lumped_basin_path.glob('*.shp'))\n",
    "    if lumped_files:\n",
    "        lumped_basin = gpd.read_file(lumped_files[0])\n",
    "        lumped_basin.plot(ax=ax1, color='lightblue', edgecolor='navy', linewidth=2)\n",
    "        ax1.set_title('Lumped Model\\n(1 Unit)', fontsize=14, fontweight='bold')\n",
    "        ax1.axis('off')\n",
    "\n",
    "# Distributed model visualization\n",
    "dist_basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "dist_network_path = project_dir / 'shapefiles' / 'river_network'\n",
    "\n",
    "if dist_basin_path.exists() and dist_network_path.exists():\n",
    "    dist_basin_files = list(dist_basin_path.glob('*.shp'))\n",
    "    dist_network_files = list(dist_network_path.glob('*.shp'))\n",
    "    \n",
    "    if dist_basin_files and dist_network_files:\n",
    "        basins = gpd.read_file(dist_basin_files[0])\n",
    "        network = gpd.read_file(dist_network_files[0])\n",
    "        \n",
    "        basins.plot(ax=ax2, column='GRU_ID', cmap='viridis', \n",
    "                   edgecolor='black', linewidth=0.5, alpha=0.7)\n",
    "        network.plot(ax=ax2, color='blue', linewidth=2)\n",
    "        ax2.set_title(f'Distributed Model\\n({len(basins)} GRUs)', fontsize=14, fontweight='bold')\n",
    "        ax2.axis('off')\n",
    "\n",
    "plt.suptitle('Lumped vs Distributed Domain Structure', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Summary and Key Differences\n",
    "\n",
    "### What we accomplished:\n",
    "1. Created a distributed model with multiple GRUs\n",
    "2. Used stream network delineation\n",
    "3. Maintained 1:1 relationship between GRUs and HRUs\n",
    "4. Ran the same model (SUMMA) in distributed mode\n",
    "5. Reused data from the lumped model where possible\n",
    "\n",
    "### Key differences from lumped model:\n",
    "- **Multiple spatial units**: Several GRUs instead of one\n",
    "- **River routing**: mizuRoute connects the GRUs\n",
    "- **More detailed representation**: Captures spatial variability\n",
    "- **Longer computation time**: More units to simulate\n",
    "\n",
    "### Next steps:\n",
    "1. Compare performance metrics between lumped and distributed\n",
    "2. Experiment with different stream thresholds\n",
    "3. Try different discretization methods (elevation bands, land cover)\n",
    "4. Calibrate parameters for individual GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=== Distributed Workflow Complete ===\\n\")\n",
    "print(f\"Project: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "print(f\"Stream Threshold: {confluence.config['STREAM_THRESHOLD']}\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"\\nKey outputs:\")\n",
    "print(f\"  - Basin shapefile: {project_dir}/shapefiles/river_basins/\")\n",
    "print(f\"  - River network: {project_dir}/shapefiles/river_network/\")\n",
    "print(f\"  - Model results: {project_dir}/simulations/{confluence.config['EXPERIMENT_ID']}/\")\n",
    "print(f\"  - Comparison plots: {project_dir}/plots/results/\")\n",
    "\n",
    "# Get workflow status\n",
    "status = confluence.workflow_orchestrator.get_workflow_status()\n",
    "print(f\"\\nWorkflow Status:\")\n",
    "print(f\"Total steps: {status['total_steps']}\")\n",
    "print(f\"Completed steps: {status['completed_steps']}\")\n",
    "print(f\"Pending steps: {status['pending_steps']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Alternative - Run Complete Workflow\n",
    "\n",
    "Instead of running the workflow step by step, you could use CONFLUENCE's built-in workflow orchestration to run the entire process at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Run the complete workflow in one step\n",
    "# (Uncomment to use this instead of the step-by-step approach)\n",
    "\n",
    "# confluence.run_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE (HPC Modules)",
   "language": "python",
   "name": "conf-env-hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}