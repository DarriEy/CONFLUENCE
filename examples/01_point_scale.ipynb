{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Point-Scale Workflow (Flux Tower Example)\n",
    "\n",
    "This notebook demonstrates CONFLUENCE's simplest spatial configuration: point-scale modeling. We'll simulate vertical processes at a single location, typical for flux tower sites, weather stations, or snow monitoring locations.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Point-scale modeling focuses on vertical processes without spatial heterogeneity:\n",
    "- Energy balance\n",
    "- Soil moisture dynamics  \n",
    "- Snow accumulation and melt\n",
    "- Evapotranspiration\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand point-scale modeling in CONFLUENCE\n",
    "2. Configure CONFLUENCE for single-point simulations\n",
    "3. Compare with spatially distributed approaches\n",
    "4. Analyze point-scale model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Point-Scale Modeling\n",
    "\n",
    "Before we simulate entire watersheds, we need to understand the vertical processes at a single point.\n",
    "\n",
    "### When to Use Point-Scale Modeling:\n",
    "\n",
    "- **Flux tower validation**: Compare model outputs with eddy covariance measurements\n",
    "- **Process understanding**: Study vertical water and energy fluxes without spatial complexity\n",
    "- **Parameter calibration**: Optimize parameters at well-instrumented sites\n",
    "- **Model development**: Test new parameterizations before scaling up\n",
    "- **SNOTEL/Weather stations**: Validate snow accumulation and melt processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Point-Scale Configuration\n",
    "\n",
    "For point-scale modeling, we need to modify our configuration to:\n",
    "1. Set `SPATIAL_MODE: Point`\n",
    "2. Create a minimal domain (single point with small buffer)\n",
    "3. Focus on vertical processes\n",
    "\n",
    "We'll use a SNOTEL site as our example: Loveland Pass in Colorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # ‚Üê User should modify this path\n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load template configuration\n",
    "config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_point_template.yaml'\n",
    "\n",
    "# Read config file\n",
    "with open(config_template_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update paths and settings for point-scale\n",
    "config_dict['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config_dict['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "\n",
    "# Modify for point-scale modeling\n",
    "config_dict['DOMAIN_NAME'] = 'loveland_pass_snotel'\n",
    "config_dict['EXPERIMENT_ID'] = 'point_scale_tutorial'\n",
    "config_dict['SPATIAL_MODE'] = 'Point'  # Key setting for point-scale\n",
    "config_dict['POUR_POINT_COORDS'] = '39.68/-105.88'  # Loveland Pass SNOTEL site\n",
    "\n",
    "# Use lumped configuration (single unit)\n",
    "config_dict['DOMAIN_DEFINITION_METHOD'] = 'lumped'\n",
    "config_dict['DOMAIN_DISCRETIZATION'] = 'GRUs'\n",
    "\n",
    "# Update experiment period for tutorial\n",
    "config_dict['EXPERIMENT_TIME_START'] = '2020-10-01 00:00'\n",
    "config_dict['EXPERIMENT_TIME_END'] = '2021-09-30 23:00'\n",
    "\n",
    "# Set forcing data parameters\n",
    "config_dict['FORCING_DATASET'] = 'ERA5'\n",
    "config_dict['FORCING_VARIABLES'] = 'default'\n",
    "\n",
    "# Save point-scale configuration to temporary file\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_point_notebook.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f)\n",
    "\n",
    "print(\"=== Point-Scale Configuration ===\")\n",
    "print(f\"Domain Name: {config_dict['DOMAIN_NAME']}\")\n",
    "print(f\"Spatial Mode: {config_dict['SPATIAL_MODE']}\")\n",
    "print(f\"Location: {config_dict['POUR_POINT_COORDS']}\")\n",
    "print(f\"Period: {config_dict['EXPERIMENT_TIME_START']} to {config_dict['EXPERIMENT_TIME_END']}\")\n",
    "print(f\"Forcing Data: {config_dict['FORCING_DATASET']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize CONFLUENCE for Point-Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CONFLUENCE with point-scale configuration\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "print(\"=== CONFLUENCE Point-Scale Setup ===\")\n",
    "print(f\"Project directory: {confluence.managers['project'].project_dir}\")\n",
    "print(f\"Spatial mode: {confluence.config['SPATIAL_MODE']}\")\n",
    "print(f\"Domain: {confluence.config['DOMAIN_NAME']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Project Initialization\n",
    "print(\"=== Step 1: Project Initialization ===\")\n",
    "print(\"Creating point-scale project structure...\")\n",
    "\n",
    "# Setup project\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# Create pour point (in this case, our SNOTEL location)\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  üìÅ {item.name}\")\n",
    "\n",
    "print(\"\\nNote: For point-scale modeling, we still use the same directory structure\")\n",
    "print(\"but the spatial extent is minimal (single point with small buffer).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Geospatial Domain Definition - Data acquisition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Acquire attributes\n",
    "print(\"Acquiring geospatial attributes for point location...\")\n",
    "print(f\"Minimal bounding box: {confluence.config.get('BOUNDING_BOX_COORDS')}\")\n",
    "confluence.managers['data'].acquire_attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geospatial Domain Definition - Domain creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Geospatial Domain Definition and Analysis\n",
    "print(\"=== Step 2: Geospatial Domain Definition and Analysis ===\")\n",
    "\n",
    "# Define domain\n",
    "print(\"\\nDefining minimal domain for point-scale simulation...\")\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "# Discretize domain (single HRU for point-scale)\n",
    "print(\"\\nCreating single HRU for point-scale simulation...\")\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "# Check outputs\n",
    "print(\"\\nDomain definition complete:\")\n",
    "print(f\"  - Watershed defined: {watershed_path is not None}\")\n",
    "print(f\"  - HRUs created: {hru_path is not None}\")\n",
    "\n",
    "# Verify single HRU\n",
    "hru_dir = project_dir / 'shapefiles' / 'catchment'\n",
    "if hru_dir.exists():\n",
    "    hru_files = list(hru_dir.glob('*.shp'))\n",
    "    if hru_files:\n",
    "        hru_gdf = gpd.read_file(hru_files[0])\n",
    "        print(f\"  - Number of HRUs: {len(hru_gdf)} (should be 1 for point-scale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Agnostic Data Pre-Processing - Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Agnostic Data Pre-Processing\n",
    "print(\"=== Step 3: Model Agnostic Data Pre-Processing ===\")\n",
    "\n",
    "# Process observed data (if we had real SNOTEL data, it would be processed here)\n",
    "print(\"Processing observed data...\")\n",
    "# Note: We skip this for synthetic data, but normally would process SNOTEL data here\n",
    "\n",
    "# Acquire forcings\n",
    "print(f\"\\nAcquiring forcing data for point location...\")\n",
    "print(f\"Dataset: {confluence.config['FORCING_DATASET']}\")\n",
    "confluence.managers['data'].acquire_forcings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Agnostic Data Pre-Processing - Remapping and zonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run model-agnostic preprocessing\n",
    "print(\"\\nRunning model-agnostic preprocessing...\")\n",
    "print(\"For point-scale simulations:\")\n",
    "print(\"  - No spatial averaging needed\")\n",
    "print(\"  - Apply elevation corrections if needed\")\n",
    "print(\"  - Convert units to model requirements\")\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "\n",
    "print(\"\\nModel-agnostic preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Specific - Pre Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Model Specific Processing and Initialization\n",
    "print(\"=== Step 4: Model Specific Processing and Initialization ===\")\n",
    "\n",
    "# Preprocess models\n",
    "print(f\"Preparing {confluence.config['HYDROLOGICAL_MODEL']} input files for point-scale simulation...\")\n",
    "print(\"Point-scale specific settings:\")\n",
    "print(\"  - Single HRU configuration\")\n",
    "print(\"  - No lateral flow between units\")\n",
    "print(\"  - Focus on vertical processes\")\n",
    "confluence.managers['model'].preprocess_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Specific - Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run models\n",
    "print(f\"\\nRunning {confluence.config['HYDROLOGICAL_MODEL']} for point-scale simulation...\")\n",
    "confluence.managers['model'].run_models()\n",
    "\n",
    "print(\"\\nPoint-scale model run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Point-Scale Modeling Insights\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. **Set up point-scale simulation** for a SNOTEL site\n",
    "2. **Minimal spatial domain** with single HRU\n",
    "3. **Focused on vertical processes** without lateral flow\n",
    "4. **Analyzed key variables** relevant to point observations\n",
    "\n",
    "### Key Differences from Spatial Models:\n",
    "\n",
    "- **No spatial heterogeneity**: Single point representation\n",
    "- **No routing**: All processes occur at one location\n",
    "- **Direct comparison**: Easy validation with point observations\n",
    "- **Computational efficiency**: Fast execution for testing\n",
    "\n",
    "### Applications of Point-Scale Modeling:\n",
    "\n",
    "1. **Parameter calibration**: Optimize parameters at well-observed sites\n",
    "2. **Process validation**: Test model physics against observations\n",
    "3. **Model development**: Develop new parameterizations\n",
    "4. **Sensitivity analysis**: Understand parameter influence\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Scale up to lumped basin**: Use calibrated parameters\n",
    "2. **Compare multiple sites**: Test model transferability\n",
    "3. **Ensemble simulations**: Explore parameter uncertainty\n",
    "4. **Process experiments**: Test different model configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE (HPC Modules)",
   "language": "python",
   "name": "conf-env-hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
