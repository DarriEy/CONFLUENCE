{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Point-Scale Workflow (Flux Tower Example)\n",
    "\n",
    "This notebook demonstrates CONFLUENCE's simplest spatial configuration: point-scale modeling. We'll simulate vertical processes at a single location, typical for flux tower sites, weather stations, or snow monitoring locations.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Point-scale modeling focuses on vertical processes without spatial heterogeneity:\n",
    "- Energy balance\n",
    "- Soil moisture dynamics  \n",
    "- Snow accumulation and melt\n",
    "- Evapotranspiration\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand point-scale modeling in CONFLUENCE\n",
    "2. Configure CONFLUENCE for single-point simulations\n",
    "3. Compare with spatially distributed approaches\n",
    "4. Analyze point-scale model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Point-Scale Modeling\n",
    "\n",
    "Point-scale modeling is the foundation of land surface modeling. Before we simulate entire watersheds, we need to understand the vertical processes at a single point.\n",
    "\n",
    "### When to Use Point-Scale Modeling:\n",
    "\n",
    "- **Flux tower validation**: Compare model outputs with eddy covariance measurements\n",
    "- **Process understanding**: Study vertical water and energy fluxes without spatial complexity\n",
    "- **Parameter calibration**: Optimize parameters at well-instrumented sites\n",
    "- **Model development**: Test new parameterizations before scaling up\n",
    "- **SNOTEL/Weather stations**: Validate snow accumulation and melt processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import CONFLUENCE components\n",
    "from utils.project.project_manager import ProjectManager\n",
    "from utils.config.config_utils import ConfigManager\n",
    "from utils.config.logging_manager import LoggingManager\n",
    "from utils.geospatial.domain_manager import DomainManager\n",
    "from utils.data.data_manager import DataManager\n",
    "from utils.models.model_manager import ModelManager\n",
    "from utils.evaluation.analysis_manager import AnalysisManager\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Point-Scale Configuration\n",
    "\n",
    "For point-scale modeling, we need to modify our configuration to:\n",
    "1. Set `SPATIAL_MODE: Point`\n",
    "2. Create a minimal domain (single point with small buffer)\n",
    "3. Focus on vertical processes\n",
    "\n",
    "We'll use a SNOTEL site as our example: Loveland Pass in Colorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load template configuration\n",
    "config_template_path = confluence_path / '0_config_files' / 'config_point_template.yaml'\n",
    "config_manager = ConfigManager(config_template_path)\n",
    "config = config_manager.config\n",
    "\n",
    "# Update directory paths\n",
    "config['CONFLUENCE_CODE_DIR'] = str(confluence_path)\n",
    "config['CONFLUENCE_DATA_DIR'] = '/work/comphyd_lab/data/CONFLUENCE_data'\n",
    "\n",
    "# Modify for point-scale modeling\n",
    "config['DOMAIN_NAME'] = 'loveland_pass_snotel'\n",
    "config['EXPERIMENT_ID'] = 'point_scale_tutorial'\n",
    "config['SPATIAL_MODE'] = 'Point'  # Key setting for point-scale\n",
    "config['POUR_POINT_COORDS'] = '39.68/-105.88'  # Loveland Pass SNOTEL site\n",
    "\n",
    "# Use lumped configuration (single unit)\n",
    "config['DOMAIN_DEFINITION_METHOD'] = 'lumped'\n",
    "config['DOMAIN_DISCRETIZATION'] = 'lumped'\n",
    "\n",
    "# Update experiment period for tutorial\n",
    "config['EXPERIMENT_TIME_START'] = '2020-10-01 00:00'\n",
    "config['EXPERIMENT_TIME_END'] = '2021-09-30 23:00'\n",
    "\n",
    "# Set forcing data parameters\n",
    "config['FORCING_DATASET'] = 'ERA5'\n",
    "config['FORCING_VARIABLES'] = 'default'  # Will use all available ERA5 variables\n",
    "\n",
    "# Save point-scale configuration\n",
    "point_config_path = Path('./point_scale_config.yaml')\n",
    "with open(point_config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"=== Point-Scale Configuration ===\")\n",
    "print(f\"Domain Name: {config['DOMAIN_NAME']}\")\n",
    "print(f\"Spatial Mode: {config['SPATIAL_MODE']}\")\n",
    "print(f\"Location: {config['POUR_POINT_COORDS']}\")\n",
    "print(f\"Period: {config['EXPERIMENT_TIME_START']} to {config['EXPERIMENT_TIME_END']}\")\n",
    "print(f\"Forcing Data: {config['FORCING_DATASET']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Point-Scale vs Spatial Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conceptual diagram showing point vs spatial modeling\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Point-scale representation\n",
    "ax1.scatter(0.5, 0.5, s=500, c='red', marker='o', edgecolor='black', linewidth=2)\n",
    "ax1.text(0.5, 0.7, 'SNOTEL/Flux Tower\\n(Single Point)', ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add vertical arrows for fluxes\n",
    "flux_labels = ['Radiation', 'Precipitation', 'ET', 'Heat Flux']\n",
    "x_positions = [0.2, 0.4, 0.6, 0.8]\n",
    "for i, (x, label) in enumerate(zip(x_positions, flux_labels)):\n",
    "    # Downward arrows\n",
    "    if label in ['Radiation', 'Precipitation']:\n",
    "        ax1.arrow(x, 0.45, 0, -0.15, head_width=0.02, head_length=0.03, fc='blue', ec='blue')\n",
    "        ax1.text(x, 0.25, label, ha='center', fontsize=10, rotation=90)\n",
    "    # Upward arrows  \n",
    "    else:\n",
    "        ax1.arrow(x, 0.55, 0, 0.15, head_width=0.02, head_length=0.03, fc='red', ec='red')\n",
    "        ax1.text(x, 0.75, label, ha='center', fontsize=10, rotation=90)\n",
    "\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_title('Point-Scale Model', fontsize=16, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Spatial representation for comparison\n",
    "from matplotlib.patches import Rectangle\n",
    "colors = ['lightblue', 'lightgreen', 'wheat', 'lightcoral']\n",
    "labels = ['Forest', 'Grassland', 'Agriculture', 'Urban']\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        rect = Rectangle((j*0.4+0.1, i*0.4+0.1), 0.35, 0.35, \n",
    "                        facecolor=colors[i*2+j], edgecolor='black')\n",
    "        ax2.add_patch(rect)\n",
    "        ax2.text(j*0.4+0.275, i*0.4+0.275, labels[i*2+j], \n",
    "                ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_title('Spatial Model (Multiple Units)', fontsize=16, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.suptitle('Point-Scale vs Spatial Modeling Approaches', fontsize=18, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize CONFLUENCE for Point-Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point-scale configuration\n",
    "config_manager = ConfigManager(point_config_path)\n",
    "config = config_manager.config\n",
    "\n",
    "# Initialize logger\n",
    "logging_manager = LoggingManager(config)\n",
    "logger = logging_manager.logger\n",
    "\n",
    "# Initialize project manager\n",
    "project_manager = ProjectManager(config, logger)\n",
    "\n",
    "print(\"=== CONFLUENCE Point-Scale Setup ===\")\n",
    "print(f\"Project directory: {project_manager.project_dir}\")\n",
    "print(f\"Spatial mode: {config['SPATIAL_MODE']}\")\n",
    "print(f\"Domain: {config['DOMAIN_NAME']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step 1: Setup Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project structure\n",
    "print(\"Creating point-scale project structure...\")\n",
    "project_dir = project_manager.setup_project()\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  ðŸ“ {item.name}\")\n",
    "\n",
    "print(\"\\nNote: For point-scale modeling, we still use the same directory structure\")\n",
    "print(\"but the spatial extent is minimal (single point with small buffer).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Step 2: Create Point Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pour point (in this case, our SNOTEL location)\n",
    "print(f\"Creating point location from coordinates: {config['POUR_POINT_COORDS']}\")\n",
    "pour_point_path = project_manager.create_pour_point()\n",
    "\n",
    "if pour_point_path and pour_point_path.exists():\n",
    "    print(f\"âœ“ Point location created: {pour_point_path}\")\n",
    "    \n",
    "    # Quick visualization of the point location\n",
    "    import geopandas as gpd\n",
    "    import contextily as cx\n",
    "    \n",
    "    gdf = gpd.read_file(pour_point_path)\n",
    "    gdf_web = gdf.to_crs(epsg=3857)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    gdf_web.plot(ax=ax, color='red', markersize=200, marker='*', \n",
    "                 edgecolor='white', linewidth=2, zorder=5)\n",
    "    \n",
    "    # Add basemap\n",
    "    cx.add_basemap(ax, source=cx.providers.Esri.WorldImagery, zoom=12)\n",
    "    \n",
    "    # Set extent\n",
    "    minx, miny, maxx, maxy = gdf_web.total_bounds\n",
    "    pad = 2000  # 2km padding\n",
    "    ax.set_xlim(minx - pad, maxx + pad)\n",
    "    ax.set_ylim(miny - pad, maxy + pad)\n",
    "    \n",
    "    ax.set_title('Loveland Pass SNOTEL Site Location', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add text annotation\n",
    "    lat, lon = gdf.geometry.iloc[0].y, gdf.geometry.iloc[0].x\n",
    "    ax.text(0.02, 0.98, f'Location: {lat:.4f}Â°N, {abs(lon):.4f}Â°W\\nElevation: ~3,700 m', \n",
    "            transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "            verticalalignment='top', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Step 3: Acquire Geospatial Attributes for Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize geospatial data manager\n",
    "from utils.geospatial.geospatial_utils import GeospatialDataAcquisition\n",
    "geospatial_manager = GeospatialDataAcquisition(config, logger)\n",
    "\n",
    "print(\"Acquiring geospatial attributes for point location...\")\n",
    "print(f\"Minimal bounding box: {config.get('BOUNDING_BOX_COORDS')}\")\n",
    "print(\"Note: CONFLUENCE automatically creates a small buffer for point-scale simulations\")\n",
    "\n",
    "# Acquire attributes (DEM, soil, land cover)\n",
    "geospatial_manager.acquire_attributes()\n",
    "\n",
    "# Check downloaded files\n",
    "attribute_dirs = {\n",
    "    'DEM': project_dir / 'attributes' / 'elevation' / 'dem',\n",
    "    'Soil': project_dir / 'attributes' / 'soilclass',\n",
    "    'Land': project_dir / 'attributes' / 'landclass'\n",
    "}\n",
    "\n",
    "print(\"\\nDownloaded attribute files:\")\n",
    "for name, path in attribute_dirs.items():\n",
    "    if path.exists():\n",
    "        files = list(path.glob('*.tif')) + list(path.glob('*.tiff'))\n",
    "        print(f\"  {name}: {len(files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Step 4: Define Minimal Domain\n",
    "\n",
    "For point-scale modeling, we create a minimal domain around our point. CONFLUENCE automatically creates a small buffer around the point when `SPATIAL_MODE: Point` is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize domain manager\n",
    "domain_manager = DomainManager(config, logger)\n",
    "\n",
    "print(\"Defining minimal domain for point-scale simulation...\")\n",
    "print(f\"Method: {config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "print(f\"Bounding box automatically set to: {config.get('BOUNDING_BOX_COORDS')}\")\n",
    "\n",
    "# Define domain\n",
    "domain_manager.define_domain()\n",
    "\n",
    "# Check created files\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "if basin_path.exists():\n",
    "    files = list(basin_path.glob('*.shp'))\n",
    "    print(f\"\\nâœ“ Created {len(files)} domain file(s)\")\n",
    "    \n",
    "    # Load and check the domain\n",
    "    if files:\n",
    "        domain_gdf = gpd.read_file(files[0])\n",
    "        area_km2 = domain_gdf.geometry.area.sum() * 111**2  # Rough conversion\n",
    "        print(f\"Domain area: {area_km2:.2f} kmÂ² (minimal)\")\n",
    "        print(\"This represents a small buffer around the point location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Step 5: Create Point-Scale HRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HRU (single unit for point-scale)\n",
    "print(f\"Creating single HRU for point-scale simulation...\")\n",
    "print(f\"Discretization method: {config['DOMAIN_DISCRETIZATION']}\")\n",
    "\n",
    "# Create HRU\n",
    "domain_manager.discretize_domain()\n",
    "\n",
    "# Check the created HRU\n",
    "hru_path = project_dir / 'shapefiles' / 'catchment'\n",
    "if hru_path.exists():\n",
    "    hru_files = list(hru_path.glob('*.shp'))\n",
    "    print(f\"\\nâœ“ Created {len(hru_files)} HRU file(s)\")\n",
    "    \n",
    "    if hru_files:\n",
    "        hru_gdf = gpd.read_file(hru_files[0])\n",
    "        print(f\"Number of HRUs: {len(hru_gdf)} (should be 1 for point-scale)\")\n",
    "        print(f\"HRU ID: {hru_gdf['HRU_ID'].iloc[0]}\")\n",
    "        print(\"This single HRU represents the point location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Step 6: Process Point Observations (if available)\n",
    "\n",
    "For SNOTEL sites, we often have snow water equivalent (SWE) data. For flux towers, we have additional energy flux measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing point-scale observations...\")\n",
    "print(\"Note: For this tutorial, we'll use synthetic data\")\n",
    "print(\"In practice, you would load SNOTEL or flux tower data here\")\n",
    "\n",
    "# Create synthetic SNOTEL-like data for demonstration\n",
    "date_range = pd.date_range(\n",
    "    start=config['EXPERIMENT_TIME_START'],\n",
    "    end=config['EXPERIMENT_TIME_END'],\n",
    "    freq='D'\n",
    ")\n",
    "\n",
    "# Generate realistic snow water equivalent pattern\n",
    "day_of_year = date_range.dayofyear\n",
    "n_days = len(date_range)\n",
    "\n",
    "# Create seasonal SWE pattern (peaks in March-April)\n",
    "swe_seasonal = np.maximum(0, 300 * np.sin(2 * np.pi * (day_of_year - 80) / 365 - np.pi/2))\n",
    "swe_noise = np.random.normal(0, 10, n_days)\n",
    "swe = np.maximum(0, swe_seasonal + swe_noise)\n",
    "\n",
    "# Create snow depth (assuming density of 300 kg/mÂ³)\n",
    "snow_depth = swe / 300\n",
    "\n",
    "# Create dataframe\n",
    "snotel_data = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'swe_mm': swe,\n",
    "    'snow_depth_m': snow_depth,\n",
    "    'temperature_c': -5 + 15 * np.sin(2 * np.pi * day_of_year / 365) + np.random.normal(0, 3, n_days)\n",
    "})\n",
    "\n",
    "# Save to observation directory\n",
    "obs_path = project_dir / 'observations' / 'snow' / 'raw_data'\n",
    "obs_path.mkdir(parents=True, exist_ok=True)\n",
    "snotel_data.to_csv(obs_path / f'{config[\"DOMAIN_NAME\"]}_snow_data.csv', index=False)\n",
    "\n",
    "# Plot the seasonal snow pattern\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "ax1.fill_between(snotel_data['date'], 0, snotel_data['swe_mm'], \n",
    "                 color='lightblue', alpha=0.7, label='SWE')\n",
    "ax1.set_ylabel('Snow Water Equivalent (mm)')\n",
    "ax1.set_title('Synthetic SNOTEL Data for Point-Scale Tutorial', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(snotel_data['date'], snotel_data['temperature_c'], \n",
    "         color='red', linewidth=1.5, alpha=0.7)\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax2.set_ylabel('Temperature (Â°C)')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Created synthetic observation data: {obs_path / f'{config['DOMAIN_NAME']}_snow_data.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Step 7: Acquire Forcing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data manager\n",
    "data_manager = DataManager(config, logger)\n",
    "\n",
    "print(f\"Acquiring forcing data for point location...\")\n",
    "print(f\"Dataset: {config['FORCING_DATASET']}\")\n",
    "print(f\"Period: {config['EXPERIMENT_TIME_START']} to {config['EXPERIMENT_TIME_END']}\")\n",
    "print(\"\\nThe Model Agnostic Framework (MAF) will:\")\n",
    "print(\"  1. Extract data for the point location\")\n",
    "print(\"  2. Process meteorological variables\")\n",
    "print(\"  3. Create model-ready forcing files\")\n",
    "\n",
    "# Run data acquisition through MAF\n",
    "data_manager.acquire_forcing_data()\n",
    "\n",
    "# Check outputs\n",
    "forcing_path = project_dir / 'forcing' / 'easymore-outputs'\n",
    "if forcing_path.exists():\n",
    "    files = list(forcing_path.glob('*.nc'))\n",
    "    print(f\"\\nâœ“ Processed {len(files)} forcing files\")\n",
    "    \n",
    "    if files:\n",
    "        # Show a sample of the forcing data\n",
    "        ds = xr.open_dataset(files[0])\n",
    "        print(f\"\\nForcing variables: {list(ds.variables)}\")\n",
    "        print(f\"Time steps: {len(ds.time)}\")\n",
    "        print(f\"Location: {ds.latitude.values[0]:.4f}Â°N, {ds.longitude.values[0]:.4f}Â°W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Step 8: Model-Agnostic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process forcing data for the point\n",
    "print(\"Running model-agnostic preprocessing...\")\n",
    "print(\"For point-scale simulations:\")\n",
    "print(\"  - No spatial averaging needed\")\n",
    "print(\"  - Apply elevation corrections if needed\")\n",
    "print(\"  - Convert units to model requirements\")\n",
    "\n",
    "# Run preprocessing\n",
    "data_manager.preprocess_forcing_data()\n",
    "\n",
    "# Check outputs\n",
    "processed_forcing_path = project_dir / 'forcing' / 'basin_averaged_data'\n",
    "if processed_forcing_path.exists():\n",
    "    files = list(processed_forcing_path.glob('*.nc'))\n",
    "    print(f\"\\nâœ“ Created {len(files)} processed forcing files\")\n",
    "    \n",
    "    # Quick visualization of forcing data\n",
    "    if files:\n",
    "        ds = xr.open_dataset(files[0])\n",
    "        \n",
    "        # Plot a week of forcing data\n",
    "        week_slice = slice('2021-01-01', '2021-01-07')\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "        \n",
    "        # Temperature\n",
    "        axes[0].plot(ds.time.sel(time=week_slice), \n",
    "                    ds.airtemp.sel(time=week_slice).values - 273.15,\n",
    "                    color='red', linewidth=2)\n",
    "        axes[0].set_ylabel('Temperature (Â°C)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Precipitation\n",
    "        axes[1].bar(ds.time.sel(time=week_slice), \n",
    "                   ds.pptrate.sel(time=week_slice).values * 3600,\n",
    "                   width=0.04, color='blue', alpha=0.7)\n",
    "        axes[1].set_ylabel('Precipitation (mm/hr)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Solar radiation\n",
    "        axes[2].plot(ds.time.sel(time=week_sliceds.SWRadAtm.sel(time=week_slice).values,\n",
    "                    color='orange', linewidth=2)\n",
    "        axes[2].set_ylabel('Solar Radiation (W/mÂ²)')\n",
    "        axes[2].set_xlabel('Date')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Sample Forcing Data for Point Location (1 Week)', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Step 9: Model-Specific Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model manager\n",
    "model_manager = ModelManager(config, logger)\n",
    "\n",
    "print(f\"Preparing {config['HYDROLOGICAL_MODEL']} input files for point-scale simulation...\")\n",
    "print(\"This includes:\")\n",
    "print(\"  - Model configuration files\")\n",
    "print(\"  - Parameter files (single HRU)\")\n",
    "print(\"  - Initial conditions\")\n",
    "print(\"  - Output control settings\")\n",
    "\n",
    "# Run model-specific preprocessing\n",
    "model_manager.prepare_model_inputs()\n",
    "\n",
    "# Check created files\n",
    "settings_path = project_dir / 'settings' / config['HYDROLOGICAL_MODEL']\n",
    "if settings_path.exists():\n",
    "    files = list(settings_path.glob('*'))\n",
    "    print(f\"\\nâœ“ Created {len(files)} model configuration files:\")\n",
    "    for f in files[:10]:  # Show first 10\n",
    "        print(f\"  - {f.name}\")\n",
    "        \n",
    "    # For point-scale, highlight key configuration aspects\n",
    "    print(\"\\nPoint-scale specific settings:\")\n",
    "    print(\"  - Single HRU configuration\")\n",
    "    print(\"  - No lateral flow between units\")\n",
    "    print(\"  - Focus on vertical processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Step 10: Run the Point-Scale Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hydrological model\n",
    "print(f\"Running {config['HYDROLOGICAL_MODEL']} for point-scale simulation...\")\n",
    "print(\"\\nPoint-scale models typically:\")\n",
    "print(\"  - Run faster than distributed models\")\n",
    "print(\"  - Focus on energy balance and vertical fluxes\")\n",
    "print(\"  - Are ideal for process-level validation\")\n",
    "\n",
    "# Run the model\n",
    "model_manager.run_model()\n",
    "\n",
    "# Check output files\n",
    "sim_path = project_dir / 'simulations' / config['EXPERIMENT_ID'] / config['HYDROLOGICAL_MODEL']\n",
    "if sim_path.exists():\n",
    "    files = list(sim_path.glob('*.nc'))\n",
    "    print(f\"\\nâœ“ Model completed. Created {len(files)} output files.\")\n",
    "    \n",
    "    # For point-scale, routing is usually not needed\n",
    "    print(\"\\nNote: Point-scale simulations typically don't require routing\")\n",
    "    print(\"All outputs are for the single point location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Step 11: Analyze Point-Scale Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analysis manager\n",
    "analysis_manager = AnalysisManager(config, logger)\n",
    "\n",
    "print(\"Analyzing point-scale model results...\")\n",
    "print(\"Key variables for point-scale analysis:\")\n",
    "print(\"  - Snow water equivalent (SWE)\")\n",
    "print(\"  - Soil moisture profiles\")\n",
    "print(\"  - Energy fluxes (latent, sensible heat)\")\n",
    "print(\"  - Evapotranspiration\")\n",
    "\n",
    "# Load model output\n",
    "output_files = list((project_dir / 'simulations' / config['EXPERIMENT_ID'] / \n",
    "                    config['HYDROLOGICAL_MODEL']).glob('*.nc'))\n",
    "\n",
    "if output_files:\n",
    "    ds_sim = xr.open_dataset(output_files[0])\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    gs = fig.add_gridspec(4, 2, hspace=0.3)\n",
    "    \n",
    "    # Snow water equivalent\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    if 'scalarSWE' in ds_sim.variables:\n",
    "        ax1.plot(ds_sim.time, ds_sim.scalarSWE.values, \n",
    "                color='blue', linewidth=2, label='Simulated SWE')\n",
    "        ax1.fill_between(ds_sim.time, 0, ds_sim.scalarSWE.values, \n",
    "                        color='lightblue', alpha=0.5)\n",
    "    ax1.set_ylabel('SWE (mm)')\n",
    "    ax1.set_title('Snow Water Equivalent', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Temperature and precipitation\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    if 'scalarRainPlusMelt' in ds_sim.variables:\n",
    "        ax2.bar(ds_sim.time, ds_sim.scalarRainPlusMelt.values * 3600, \n",
    "               width=0.04, color='blue', alpha=0.7, label='Rain+Melt')\n",
    "    ax2.set_ylabel('Water Input (mm/hr)')\n",
    "    ax2.set_title('Precipitation and Melt', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Soil moisture\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    if 'scalarSoilMoisture' in ds_sim.variables:\n",
    "        ax3.plot(ds_sim.time, ds_sim.scalarSoilMoisture.values, \n",
    "                color='brown', linewidth=2)\n",
    "    ax3.set_ylabel('Soil Moisture (-)')\n",
    "    ax3.set_title('Soil Moisture Content', fontsize=12)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Energy fluxes\n",
    "    ax4 = fig.add_subplot(gs[2, :])\n",
    "    if 'scalarLatHeatTotal' in ds_sim.variables:\n",
    "        ax4.plot(ds_sim.time, ds_sim.scalarLatHeatTotal.values, \n",
    "                color='green', linewidth=1.5, label='Latent Heat', alpha=0.7)\n",
    "    if 'scalarSenHeatTotal' in ds_sim.variables:\n",
    "        ax4.plot(ds_sim.time, ds_sim.scalarSenHeatTotal.values, \n",
    "                color='red', linewidth=1.5, label='Sensible Heat', alpha=0.7)\n",
    "    ax4.set_ylabel('Energy Flux (W/mÂ²)')\n",
    "    ax4.set_title('Surface Energy Fluxes', fontsize=12)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.legend()\n",
    "    \n",
    "    # ET components\n",
    "    ax5 = fig.add_subplot(gs[3, :])\n",
    "    if 'scalarActualET' in ds_sim.variables:\n",
    "        ax5.plot(ds_sim.time, ds_sim.scalarActualET.values * 3600, \n",
    "                color='purple', linewidth=2, label='Total ET')\n",
    "    ax5.set_ylabel('ET (mm/hr)')\n",
    "    ax5.set_xlabel('Date')\n",
    "    ax5.set_title('Evapotranspiration', fontsize=12)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.legend()\n",
    "    \n",
    "    plt.suptitle(f'Point-Scale Model Results: {config[\"DOMAIN_NAME\"]}', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = project_dir / 'plots' / 'results'\n",
    "    plot_path.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(plot_path / 'point_scale_results.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nâœ“ Saved results plot to: {plot_path / 'point_scale_results.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Compare with Observations (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observation data\n",
    "obs_file = project_dir / 'observations' / 'snow' / 'raw_data' / f'{config[\"DOMAIN_NAME\"]}_snow_data.csv'\n",
    "if obs_file.exists():\n",
    "    obs_data = pd.read_csv(obs_file)\n",
    "    obs_data['date'] = pd.to_datetime(obs_data['date'])\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot observations\n",
    "    ax.plot(obs_data['date'], obs_data['swe_mm'], \n",
    "            color='black', linewidth=2, label='Observed SWE', alpha=0.7)\n",
    "    \n",
    "    # Plot simulations if available\n",
    "    if 'scalarSWE' in ds_sim.variables:\n",
    "        ax.plot(pd.to_datetime(ds_sim.time.values), ds_sim.scalarSWE.values, \n",
    "                color='red', linewidth=2, label='Simulated SWE', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Snow Water Equivalent (mm)', fontsize=12)\n",
    "    ax.set_title('Point-Scale Model Validation: SWE Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate basic metrics if both exist\n",
    "    if 'scalarSWE' in ds_sim.variables:\n",
    "        # Align time series\n",
    "        sim_df = pd.DataFrame({'date': pd.to_datetime(ds_sim.time.values),\n",
    "                              'sim_swe': ds_sim.scalarSWE.values})\n",
    "        merged = pd.merge(obs_data, sim_df, on='date', how='inner')\n",
    "        \n",
    "        if len(merged) > 0:\n",
    "            rmse = np.sqrt(np.mean((merged['swe_mm'] - merged['sim_swe'])**2))\n",
    "            bias = np.mean(merged['sim_swe'] - merged['swe_mm'])\n",
    "            corr = merged[['swe_mm', 'sim_swe']].corr().iloc[0, 1]\n",
    "            \n",
    "            print(\"\\nModel Performance Metrics:\")\n",
    "            print(f\"RMSE: {rmse:.2f} mm\")\n",
    "            print(f\"Bias: {bias:.2f} mm\")\n",
    "            print(f\"Correlation: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Summary: Point-Scale Modeling Insights\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. **Set up point-scale simulation** for a SNOTEL site\n",
    "2. **Minimal spatial domain** with single HRU\n",
    "3. **Focused on vertical processes** without lateral flow\n",
    "4. **Analyzed key variables** relevant to point observations\n",
    "\n",
    "### Key Differences from Spatial Models:\n",
    "\n",
    "- **No spatial heterogeneity**: Single point representation\n",
    "- **No routing**: All processes occur at one location\n",
    "- **Direct comparison**: Easy validation with point observations\n",
    "- **Computational efficiency**: Fast execution for testing\n",
    "\n",
    "### Applications of Point-Scale Modeling:\n",
    "\n",
    "1. **Parameter calibration**: Optimize parameters at well-observed sites\n",
    "2. **Process validation**: Test model physics against observations\n",
    "3. **Model development**: Develop new parameterizations\n",
    "4. **Sensitivity analysis**: Understand parameter influence\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Scale up to lumped basin**: Use calibrated parameters\n",
    "2. **Compare multiple sites**: Test model transferability\n",
    "3. **Ensemble simulations**: Explore parameter uncertainty\n",
    "4. **Process experiments**: Test different model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=== Point-Scale Workflow Complete ===\\n\")\n",
    "print(f\"Project: {config['DOMAIN_NAME']}\")\n",
    "print(f\"Location: {config['POUR_POINT_COORDS']}\")\n",
    "print(f\"Model: {config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Period: {config['EXPERIMENT_TIME_START']} to {config['EXPERIMENT_TIME_END']}\")\n",
    "\n",
    "print(\"\\nKey characteristics of point-scale modeling:\")\n",
    "print(\"  âœ“ Single spatial unit (1 HRU)\")\n",
    "print(\"  âœ“ Focus on vertical processes\")\n",
    "print(\"  âœ“ Direct comparison with observations\")\n",
    "print(\"  âœ“ Computationally efficient\")\n",
    "print(\"  âœ“ Ideal for process understanding\")\n",
    "\n",
    "print(\"\\nKey outputs:\")\n",
    "print(f\"  - Configuration: {point_config_path}\")\n",
    "print(f\"  - Model results: {project_dir}/simulations/{config['EXPERIMENT_ID']}/\")\n",
    "print(f\"  - Visualizations: {project_dir}/plots/results/\")\n",
    "print(f\"  - Forcing data: {project_dir}/forcing/basin_averaged_data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE",
   "language": "python",
   "name": "confluence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
