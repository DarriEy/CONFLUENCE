{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6c1149",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 8: Large Sample Studies (FLUXNET Multi-Site Analysis)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial represents the culmination of our CONFLUENCE series: large sample studies. While our previous tutorials focused on modeling individual domains (from points to continents), large sample studies leverage CONFLUENCE's workflow efficiency to systematically analyze hundreds or thousands of sites. Using the global FLUXNET network as our example, we'll demonstrate how to transform CONFLUENCE from a single-domain modeling platform into a powerful tool for comparative hydrology and large sample analysis.\n",
    "\n",
    "### What are Large Sample Studies?\n",
    "\n",
    "Large sample studies in hydrology involve systematic analysis across many sites, watersheds, or regions to:\n",
    "\n",
    "- **Identify patterns**: Understand how hydrological processes vary across different environments\n",
    "- **Test hypotheses**: Evaluate theoretical concepts across diverse conditions\n",
    "- **Improve models**: Develop better parameterizations based on multi-site evidence\n",
    "- **Quantify uncertainty**: Assess model performance and reliability across different settings\n",
    "- **Enable comparative hydrology**: Compare hydrological responses across climates, landscapes, and scales\n",
    "\n",
    "### The Scientific Revolution of Large Sample Hydrology\n",
    "\n",
    "Large sample studies have revolutionized hydrology by moving beyond single-site case studies:\n",
    "\n",
    "**Traditional Approach**: Intensive study of individual watersheds or sites\n",
    "- Deep understanding of specific locations\n",
    "- Limited generalizability\n",
    "- Difficult to separate site-specific vs. universal processes\n",
    "\n",
    "**Large Sample Approach**: Systematic analysis across many sites\n",
    "- Identifies universal patterns and regional variations\n",
    "- Enables statistical analysis of hydrological controls\n",
    "- Supports development of general theories and models\n",
    "- Quantifies uncertainty across different environments\n",
    "\n",
    "### Why FLUXNET for Large Sample Studies?\n",
    "\n",
    "The FLUXNET network provides an ideal framework for large sample hydrological analysis:\n",
    "\n",
    "**Global Coverage**: \n",
    "- 900+ tower sites across all continents\n",
    "- Diverse ecosystems: forests, grasslands, wetlands, croplands\n",
    "- Multiple climate zones: tropical, temperate, boreal, arid\n",
    "- Elevation range: sea level to high mountains\n",
    "\n",
    "**Standardized Measurements**:\n",
    "- Consistent eddy covariance methodology\n",
    "- Quality-controlled data processing\n",
    "- Standardized temporal resolution\n",
    "- Comparable variables across sites\n",
    "\n",
    "**Scientific Value**:\n",
    "- Energy balance validation for land surface models\n",
    "- Ecosystem-scale process understanding\n",
    "- Climate-vegetation interactions\n",
    "- Model benchmarking across diverse conditions\n",
    "\n",
    "### From Single Sites to Large Samples\n",
    "\n",
    "Our tutorial progression has prepared you for large sample studies:\n",
    "\n",
    "| Tutorial | Scale | Sites | Purpose |\n",
    "|----------|-------|-------|---------|\n",
    "| 1-2 | Point | 1 | Process understanding |\n",
    "| 3-5 | Watershed | 1 | Spatial integration |\n",
    "| 6-7 | Regional/Continental | 1 | Large-scale hydrology |\n",
    "| 8 | Multi-site | 100s | Comparative analysis |\n",
    "\n",
    "### CONFLUENCE's Advantages for Large Sample Studies\n",
    "\n",
    "CONFLUENCE's design makes it particularly well-suited for large sample analysis:\n",
    "\n",
    "1. **Workflow Automation**: Standardized workflow reduces manual effort per site\n",
    "2. **Consistent Methodology**: Same modeling approach across all sites ensures comparability\n",
    "3. **Scalable Configuration**: Template-based configuration enables rapid site setup\n",
    "4. **Reproducible Science**: Complete workflow documentation ensures reproducibility\n",
    "5. **High-Performance Computing**: Parallel execution across multiple sites\n",
    "6. **Standardized Outputs**: Consistent output formats facilitate multi-site analysis\n",
    "\n",
    "### Technical Implementation\n",
    "\n",
    "Large sample studies with CONFLUENCE involve several key components:\n",
    "\n",
    "**Site Selection**: Choose representative sites across environmental gradients\n",
    "**Configuration Generation**: Automatically create site-specific configurations\n",
    "**Batch Processing**: Run CONFLUENCE across multiple sites efficiently\n",
    "**Results Aggregation**: Collect and standardize outputs from all sites\n",
    "**Comparative Analysis**: Analyze patterns and relationships across sites\n",
    "\n",
    "### Research Questions Addressed\n",
    "\n",
    "Large sample studies enable investigation of questions impossible at single sites:\n",
    "\n",
    "1. **Process Generalization**: Do hydrological processes scale consistently across environments?\n",
    "2. **Climate Controls**: How do different climate variables control hydrological responses?\n",
    "3. **Ecosystem Influences**: How do vegetation types affect water and energy balance?\n",
    "4. **Model Performance**: Where do models perform well vs. poorly, and why?\n",
    "5. **Parameter Transferability**: Can model parameters be transferred between similar sites?\n",
    "\n",
    "### Methodological Considerations\n",
    "\n",
    "Large sample studies require careful methodological choices:\n",
    "\n",
    "**Site Selection Criteria**:\n",
    "- Spatial distribution across environmental gradients\n",
    "- Data quality and availability\n",
    "- Representativeness of broader regions\n",
    "- Temporal coverage consistency\n",
    "\n",
    "**Standardization Approaches**:\n",
    "- Consistent model configuration across sites\n",
    "- Standardized evaluation metrics\n",
    "- Comparable temporal periods\n",
    "- Unified data processing protocols\n",
    "\n",
    "**Analysis Strategies**:\n",
    "- Statistical analysis of multi-site results\n",
    "- Clustering sites by characteristics\n",
    "- Regression analysis of controls\n",
    "- Uncertainty quantification\n",
    "\n",
    "### Expected Outcomes\n",
    "\n",
    "This tutorial demonstrates several key large sample capabilities:\n",
    "\n",
    "1. **Multi-Site Configuration**: Automatically generate configurations for hundreds of sites\n",
    "2. **Batch Execution**: Run CONFLUENCE across multiple sites efficiently\n",
    "3. **Results Synthesis**: Aggregate and analyze multi-site model outputs\n",
    "4. **Comparative Visualization**: Create plots showing patterns across sites\n",
    "5. **Statistical Analysis**: Quantify relationships between site characteristics and model performance\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "By completing this tutorial, you'll understand how to:\n",
    "\n",
    "1. **Design large sample experiments** with appropriate site selection\n",
    "2. **Automate configuration generation** for hundreds of sites\n",
    "3. **Manage batch processing** of multiple CONFLUENCE runs\n",
    "4. **Aggregate and analyze results** from multi-site experiments\n",
    "5. **Visualize patterns** across environmental gradients\n",
    "6. **Apply statistical methods** to understand hydrological controls\n",
    "\n",
    "### Tutorial Structure\n",
    "\n",
    "This tutorial demonstrates the complete large sample workflow:\n",
    "\n",
    "1. **Experiment Design**: Define objectives and select FLUXNET sites\n",
    "2. **Configuration Generation**: Create site-specific CONFLUENCE configurations\n",
    "3. **Batch Processing**: Execute CONFLUENCE across multiple sites\n",
    "4. **Results Collection**: Aggregate outputs from all successful runs\n",
    "5. **Comparative Analysis**: Analyze patterns and relationships across sites\n",
    "6. **Visualization**: Create plots showing multi-site results\n",
    "7. **Statistical Summary**: Quantify patterns and uncertainties\n",
    "\n",
    "### Scientific Impact\n",
    "\n",
    "Large sample studies represent the future of hydrological science:\n",
    "\n",
    "- **Robust Conclusions**: Statistical significance from many sites\n",
    "- **Universal Patterns**: Identify processes that transcend individual sites\n",
    "- **Model Improvement**: Better parameterizations based on multi-site evidence\n",
    "- **Uncertainty Quantification**: Understand model reliability across conditions\n",
    "- **Predictive Capability**: Develop models that work in ungauged locations\n",
    "\n",
    "### Tutorial Series Culmination\n",
    "\n",
    "This tutorial represents the culmination of our CONFLUENCE journey:\n",
    "\n",
    "**Foundation**: Point-scale process understanding\n",
    "**Scaling**: Watershed to continental modeling\n",
    "**Application**: Large sample comparative hydrology\n",
    "\n",
    "By mastering large sample studies, you've gained the tools to conduct cutting-edge hydrological research that leverages CONFLUENCE's power across multiple scales and environments. This approach positions you to contribute to the next generation of hydrological science, where systematic multi-site analysis drives theoretical advances and practical applications.\n",
    "\n",
    "The combination of CONFLUENCE's workflow efficiency with large sample methodologies opens new possibilities for understanding how hydrological processes vary across Earth's diverse environments - from individual flux towers to global patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the FLUXNET large sample experiment\n",
    "experiment_config = {\n",
    "    'experiment_name': 'fluxnet_tutorial',\n",
    "    'max_sites': 5,\n",
    "    'dry_run': False,\n",
    "    'template_config': '../CONFLUENCE/0_config_files/config_point_template.yaml',\n",
    "    'config_dir': '../CONFLUENCE/0_config_files/fluxnet',\n",
    "    'fluxnet_script': '../CONFLUENCE/9_scripts/run_towers_fluxnet.py',\n",
    "    'fluxnet_csv': 'fluxnet_transformed.csv'\n",
    "}\n",
    "\n",
    "# Create experiment directory\n",
    "experiment_dir = Path(f\"./experiments/{experiment_config['experiment_name']}\")\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "with open(experiment_dir / 'experiment_config.yaml', 'w') as f:\n",
    "    yaml.dump(experiment_config, f)\n",
    "\n",
    "print(f\"Experiment configured: {experiment_config['experiment_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FLUXNET sites data\n",
    "fluxnet_df = pd.read_csv(experiment_config['fluxnet_csv'])\n",
    "\n",
    "print(f\"Loaded {len(fluxnet_df)} FLUXNET sites\")\n",
    "print(\"\\nColumns in dataset:\")\n",
    "for col in fluxnet_df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Display first few sites\n",
    "print(\"\\nFirst 5 sites:\")\n",
    "display(fluxnet_df[['ID', 'Watershed_Name', 'KG', 'Dominant_LC', 'Area_km2']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates from POUR_POINT_COORDS\n",
    "coords = fluxnet_df['POUR_POINT_COORDS'].str.split('/', expand=True)\n",
    "fluxnet_df['lat'] = coords[0].astype(float)\n",
    "fluxnet_df['lon'] = coords[1].astype(float)\n",
    "\n",
    "# Create global distribution plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(fluxnet_df['lon'], fluxnet_df['lat'], c='red', alpha=0.6)\n",
    "plt.title('Global Distribution of FLUXNET Sites')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(-180, 180)\n",
    "plt.ylim(-60, 80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b316a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Optional Select sites based on criteria - diverse climate types\n",
    "climate_types = fluxnet_df['KG'].unique()\n",
    "\n",
    "# Select one site from each climate type (up to max_sites)\n",
    "selected_sites = []\n",
    "for climate in climate_types[:experiment_config['max_sites']]:\n",
    "    site = fluxnet_df[fluxnet_df['KG'] == climate].iloc[0]\n",
    "    selected_sites.append(site)\n",
    "\n",
    "selected_df = pd.DataFrame(selected_sites)\n",
    "\n",
    "print(f\"Selected {len(selected_df)} sites for processing:\")\n",
    "display(selected_df[['ID', 'Watershed_Name', 'KG', 'Dominant_LC']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8224e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Generate configs for selected sites\n",
    "config_dir = Path(experiment_config['config_dir'])\n",
    "config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "generated_configs = []\n",
    "\n",
    "for _, site in fluxnet_df.iterrows():\n",
    "    site_name = site['Watershed_Name']\n",
    "    pour_point = site['POUR_POINT_COORDS']\n",
    "    bounding_box = site['BOUNDING_BOX_COORDS']\n",
    "    \n",
    "    # Create config file name\n",
    "    config_path = config_dir / f\"config_{site_name}.yaml\"\n",
    "    \n",
    "    # Generate config using the script function\n",
    "    cmd = [\n",
    "        'python', '-c',\n",
    "        f\"\"\"\n",
    "import sys\n",
    "sys.path.append('{str(confluence_path)}/9_scripts')\n",
    "from run_towers_fluxnet import generate_config_file\n",
    "generate_config_file(\n",
    "    '{experiment_config['template_config']}',\n",
    "    '{config_path}',\n",
    "    '{site_name}',\n",
    "    '{pour_point}',\n",
    "    '{bounding_box}'\n",
    ")\n",
    "\"\"\"\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        generated_configs.append(config_path)\n",
    "        print(f\"Generated config for {site_name}\")\n",
    "\n",
    "print(f\"\\nGenerated {len(generated_configs)} configuration files\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d81a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Launch CONFLUENCE runs\n",
    "cmd = ['python', experiment_config['fluxnet_script']]\n",
    "\n",
    "# For dry run, add appropriate option\n",
    "if experiment_config['dry_run']:\n",
    "    print(\"DRY RUN MODE - No jobs will be submitted\")\n",
    "\n",
    "print(f\"Launching CONFLUENCE for FLUXNET sites...\")\n",
    "\n",
    "# Execute the script (requires user input)\n",
    "result = subprocess.run(cmd, input='n\\n' if experiment_config['dry_run'] else 'y\\n', \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(result.stdout[:500] + \"...\" if len(result.stdout) > 500 else result.stdout)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f096af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find completed FLUXNET simulations\n",
    "confluence_data_dir = Path(\"/work/comphyd_lab/data/CONFLUENCE_data\")\n",
    "fluxnet_dir = confluence_data_dir / \"fluxnet\"\n",
    "\n",
    "completed = []\n",
    "if fluxnet_dir.exists():\n",
    "    for domain_dir in fluxnet_dir.glob(\"domain_*\"):\n",
    "        site_name = domain_dir.name.replace(\"domain_\", \"\")\n",
    "        sim_dir = domain_dir / \"simulations\"\n",
    "        \n",
    "        if sim_dir.exists() and list(sim_dir.rglob(\"*.nc\")):\n",
    "            completed.append({\n",
    "                'site_name': site_name,\n",
    "                'sim_dir': sim_dir\n",
    "            })\n",
    "\n",
    "print(f\"Completed simulations: {len(completed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413641e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze model results\n",
    "def load_summa_output(sim_dir, variable='scalarSWE'):\n",
    "    import xarray as xr\n",
    "    \n",
    "    output_files = list(sim_dir.rglob(\"*day*.nc\"))\n",
    "    if output_files:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        if variable in ds.variables:\n",
    "            return pd.DataFrame({\n",
    "                'time': pd.to_datetime(ds.time.values),\n",
    "                'value': ds[variable].values.flatten()\n",
    "            })\n",
    "    return None\n",
    "\n",
    "# Summary Report\n",
    "if completed:\n",
    "    print(\"### FLUXNET Experiment Summary Report ###\")\n",
    "    print(f\"Experiment Name: {experiment_config['experiment_name']}\")\n",
    "    print(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Total Sites Selected: {len(fluxnet_df)}\")\n",
    "    print(f\"Completed Simulations: {len(completed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177ab61-f4c9-4f89-8354-c7a506782a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract model results from all completed simulations and create histogram\n",
    "if completed:\n",
    "    # Dictionary to store average values for each site\n",
    "    site_averages = {}\n",
    "    \n",
    "    # Variable to extract (using the one from the function definition as default)\n",
    "    variable_name = 'scalarSWE'\n",
    "    \n",
    "    print(f\"Extracting average {variable_name} values from all completed simulations...\")\n",
    "    \n",
    "    # Loop through all completed simulations\n",
    "    for site_info in completed:\n",
    "        site_name = site_info['site_name']\n",
    "        sim_dir = site_info['sim_dir']\n",
    "        \n",
    "        # Load data using the existing function\n",
    "        data = load_summa_output(sim_dir, variable=variable_name)\n",
    "        \n",
    "        if data is not None:\n",
    "            # Calculate average for this site\n",
    "            site_avg = data['value'].mean()\n",
    "            site_averages[site_name] = site_avg\n",
    "            print(f\"  - {site_name}: Average {variable_name} = {site_avg:.2f}\")\n",
    "        else:\n",
    "            print(f\"  - {site_name}: Could not extract {variable_name} data\")\n",
    "    \n",
    "    # Create dataframe from the averages\n",
    "    averages_df = pd.DataFrame({\n",
    "        'site': list(site_averages.keys()),\n",
    "        'average_value': list(site_averages.values())\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    averages_csv = experiment_dir / f'site_averages_{variable_name}.csv'\n",
    "    averages_df.to_csv(averages_csv, index=False)\n",
    "    print(f\"\\nSaved site averages to {averages_csv}\")\n",
    "    \n",
    "    # Create histogram of the averages\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(averages_df['average_value'], kde=True)\n",
    "    plt.title(f'Distribution of Average {variable_name} Across FLUXNET Sites')\n",
    "    plt.xlabel(f'Average {variable_name}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save plot\n",
    "    hist_path = experiment_dir / f'histogram_{variable_name}.png'\n",
    "    plt.savefig(hist_path, dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Histogram saved to {hist_path}\")\n",
    "    \n",
    "    # Additional statistical summary\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(f\"Number of sites: {len(site_averages)}\")\n",
    "    print(f\"Mean across sites: {averages_df['average_value'].mean():.2f}\")\n",
    "    print(f\"Median across sites: {averages_df['average_value'].median():.2f}\")\n",
    "    print(f\"Min: {averages_df['average_value'].min():.2f}\")\n",
    "    print(f\"Max: {averages_df['average_value'].max():.2f}\")\n",
    "else:\n",
    "    print(\"No completed simulations found for analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
