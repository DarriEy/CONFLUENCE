{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6c1149",
   "metadata": {},
   "source": [
    "# FLUXNET Large Sample Experiment Tutorial\n",
    "\n",
    "This notebook demonstrates how to run CONFLUENCE over multiple FLUXNET tower sites for point-scale large-sample analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the FLUXNET large sample experiment\n",
    "experiment_config = {\n",
    "    'experiment_name': 'fluxnet_tutorial',\n",
    "    'max_sites': 5,\n",
    "    'dry_run': False,\n",
    "    'template_config': '../CONFLUENCE/0_config_files/config_point_template.yaml',\n",
    "    'config_dir': '../CONFLUENCE/0_config_files/fluxnet',\n",
    "    'fluxnet_script': '../CONFLUENCE/9_scripts/run_towers_fluxnet.py',\n",
    "    'fluxnet_csv': 'fluxnet_transformed.csv'\n",
    "}\n",
    "\n",
    "# Create experiment directory\n",
    "experiment_dir = Path(f\"./experiments/{experiment_config['experiment_name']}\")\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "with open(experiment_dir / 'experiment_config.yaml', 'w') as f:\n",
    "    yaml.dump(experiment_config, f)\n",
    "\n",
    "print(f\"Experiment configured: {experiment_config['experiment_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FLUXNET sites data\n",
    "fluxnet_df = pd.read_csv(experiment_config['fluxnet_csv'])\n",
    "\n",
    "print(f\"Loaded {len(fluxnet_df)} FLUXNET sites\")\n",
    "print(\"\\nColumns in dataset:\")\n",
    "for col in fluxnet_df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Display first few sites\n",
    "print(\"\\nFirst 5 sites:\")\n",
    "display(fluxnet_df[['ID', 'Watershed_Name', 'KG', 'Dominant_LC', 'Area_km2']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates from POUR_POINT_COORDS\n",
    "coords = fluxnet_df['POUR_POINT_COORDS'].str.split('/', expand=True)\n",
    "fluxnet_df['lat'] = coords[0].astype(float)\n",
    "fluxnet_df['lon'] = coords[1].astype(float)\n",
    "\n",
    "# Create global distribution plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(fluxnet_df['lon'], fluxnet_df['lat'], c='red', alpha=0.6)\n",
    "plt.title('Global Distribution of FLUXNET Sites')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(-180, 180)\n",
    "plt.ylim(-60, 80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b316a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Optional Select sites based on criteria - diverse climate types\n",
    "climate_types = fluxnet_df['KG'].unique()\n",
    "\n",
    "# Select one site from each climate type (up to max_sites)\n",
    "selected_sites = []\n",
    "for climate in climate_types[:experiment_config['max_sites']]:\n",
    "    site = fluxnet_df[fluxnet_df['KG'] == climate].iloc[0]\n",
    "    selected_sites.append(site)\n",
    "\n",
    "selected_df = pd.DataFrame(selected_sites)\n",
    "\n",
    "print(f\"Selected {len(selected_df)} sites for processing:\")\n",
    "display(selected_df[['ID', 'Watershed_Name', 'KG', 'Dominant_LC']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8224e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Generate configs for selected sites\n",
    "config_dir = Path(experiment_config['config_dir'])\n",
    "config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "generated_configs = []\n",
    "\n",
    "for _, site in fluxnet_df.iterrows():\n",
    "    site_name = site['Watershed_Name']\n",
    "    pour_point = site['POUR_POINT_COORDS']\n",
    "    bounding_box = site['BOUNDING_BOX_COORDS']\n",
    "    \n",
    "    # Create config file name\n",
    "    config_path = config_dir / f\"config_{site_name}.yaml\"\n",
    "    \n",
    "    # Generate config using the script function\n",
    "    cmd = [\n",
    "        'python', '-c',\n",
    "        f\"\"\"\n",
    "import sys\n",
    "sys.path.append('{str(confluence_path)}/9_scripts')\n",
    "from run_towers_fluxnet import generate_config_file\n",
    "generate_config_file(\n",
    "    '{experiment_config['template_config']}',\n",
    "    '{config_path}',\n",
    "    '{site_name}',\n",
    "    '{pour_point}',\n",
    "    '{bounding_box}'\n",
    ")\n",
    "\"\"\"\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        generated_configs.append(config_path)\n",
    "        print(f\"Generated config for {site_name}\")\n",
    "\n",
    "print(f\"\\nGenerated {len(generated_configs)} configuration files\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d81a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Launch CONFLUENCE runs\n",
    "cmd = ['python', experiment_config['fluxnet_script']]\n",
    "\n",
    "# For dry run, add appropriate option\n",
    "if experiment_config['dry_run']:\n",
    "    print(\"DRY RUN MODE - No jobs will be submitted\")\n",
    "\n",
    "print(f\"Launching CONFLUENCE for FLUXNET sites...\")\n",
    "\n",
    "# Execute the script (requires user input)\n",
    "result = subprocess.run(cmd, input='n\\n' if experiment_config['dry_run'] else 'y\\n', \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(result.stdout[:500] + \"...\" if len(result.stdout) > 500 else result.stdout)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f096af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find completed FLUXNET simulations\n",
    "confluence_data_dir = Path(\"/work/comphyd_lab/data/CONFLUENCE_data\")\n",
    "fluxnet_dir = confluence_data_dir / \"fluxnet\"\n",
    "\n",
    "completed = []\n",
    "if fluxnet_dir.exists():\n",
    "    for domain_dir in fluxnet_dir.glob(\"domain_*\"):\n",
    "        site_name = domain_dir.name.replace(\"domain_\", \"\")\n",
    "        sim_dir = domain_dir / \"simulations\"\n",
    "        \n",
    "        if sim_dir.exists() and list(sim_dir.rglob(\"*.nc\")):\n",
    "            completed.append({\n",
    "                'site_name': site_name,\n",
    "                'sim_dir': sim_dir\n",
    "            })\n",
    "\n",
    "print(f\"Completed simulations: {len(completed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413641e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze model results\n",
    "def load_summa_output(sim_dir, variable='scalarSWE'):\n",
    "    import xarray as xr\n",
    "    \n",
    "    output_files = list(sim_dir.rglob(\"*day*.nc\"))\n",
    "    if output_files:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        if variable in ds.variables:\n",
    "            return pd.DataFrame({\n",
    "                'time': pd.to_datetime(ds.time.values),\n",
    "                'value': ds[variable].values.flatten()\n",
    "            })\n",
    "    return None\n",
    "\n",
    "# Summary Report\n",
    "if completed:\n",
    "    print(\"### FLUXNET Experiment Summary Report ###\")\n",
    "    print(f\"Experiment Name: {experiment_config['experiment_name']}\")\n",
    "    print(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Total Sites Selected: {len(fluxnet_df)}\")\n",
    "    print(f\"Completed Simulations: {len(completed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177ab61-f4c9-4f89-8354-c7a506782a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract model results from all completed simulations and create histogram\n",
    "if completed:\n",
    "    # Dictionary to store average values for each site\n",
    "    site_averages = {}\n",
    "    \n",
    "    # Variable to extract (using the one from the function definition as default)\n",
    "    variable_name = 'scalarSWE'\n",
    "    \n",
    "    print(f\"Extracting average {variable_name} values from all completed simulations...\")\n",
    "    \n",
    "    # Loop through all completed simulations\n",
    "    for site_info in completed:\n",
    "        site_name = site_info['site_name']\n",
    "        sim_dir = site_info['sim_dir']\n",
    "        \n",
    "        # Load data using the existing function\n",
    "        data = load_summa_output(sim_dir, variable=variable_name)\n",
    "        \n",
    "        if data is not None:\n",
    "            # Calculate average for this site\n",
    "            site_avg = data['value'].mean()\n",
    "            site_averages[site_name] = site_avg\n",
    "            print(f\"  - {site_name}: Average {variable_name} = {site_avg:.2f}\")\n",
    "        else:\n",
    "            print(f\"  - {site_name}: Could not extract {variable_name} data\")\n",
    "    \n",
    "    # Create dataframe from the averages\n",
    "    averages_df = pd.DataFrame({\n",
    "        'site': list(site_averages.keys()),\n",
    "        'average_value': list(site_averages.values())\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    averages_csv = experiment_dir / f'site_averages_{variable_name}.csv'\n",
    "    averages_df.to_csv(averages_csv, index=False)\n",
    "    print(f\"\\nSaved site averages to {averages_csv}\")\n",
    "    \n",
    "    # Create histogram of the averages\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(averages_df['average_value'], kde=True)\n",
    "    plt.title(f'Distribution of Average {variable_name} Across FLUXNET Sites')\n",
    "    plt.xlabel(f'Average {variable_name}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save plot\n",
    "    hist_path = experiment_dir / f'histogram_{variable_name}.png'\n",
    "    plt.savefig(hist_path, dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Histogram saved to {hist_path}\")\n",
    "    \n",
    "    # Additional statistical summary\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(f\"Number of sites: {len(site_averages)}\")\n",
    "    print(f\"Mean across sites: {averages_df['average_value'].mean():.2f}\")\n",
    "    print(f\"Median across sites: {averages_df['average_value'].median():.2f}\")\n",
    "    print(f\"Min: {averages_df['average_value'].min():.2f}\")\n",
    "    print(f\"Max: {averages_df['average_value'].max():.2f}\")\n",
    "else:\n",
    "    print(\"No completed simulations found for analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
