{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial 02a — Basin-Scale Workflow (Bow River at Banff, Lumped)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates basin-scale hydrological modeling using CONFLUENCE's lumped representation approach. Building on the point-scale workflows from Tutorials 01a and 01b, we now simulate streamflow from an entire watershed—the Bow River at Banff in the Canadian Rockies.\n",
    "\n",
    "A lumped basin model treats the watershed as a single computational unit, spatially averaging all characteristics across the catchment. This simplified approach provides computational efficiency ideal for calibration and establishes baseline performance before adding spatial complexity.\n",
    "\n",
    "The **Bow River at Banff** watershed encompasses ~2,210 km² with elevations from 1,384 m to over 3,400 m. Water Survey of Canada station 05BB001 provides streamflow observations for model evaluation. This snow-dominated mountain system presents strong elevation gradients, complex snow dynamics, and pronounced spring freshet periods.\n",
    "\n",
    "Through this tutorial, you will see how the same CONFLUENCE workflow scales seamlessly from point validation to basin prediction: configuration → domain → data → model → evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 — Configuration\n",
    "\n",
    "We generate a basin-scale configuration that specifies the lumped representation approach, gauging station coordinates, and watershed delineation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — Create basin-scale configuration\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Define directories\n",
    "CONFLUENCE_CODE_DIR = Path(\"../..\").resolve()\n",
    "CONFLUENCE_DATA_DIR = Path(\"/path/to/CONFLUENCE_data\").resolve()\n",
    "\n",
    "# Load template configuration\n",
    "config_template = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "with open(config_template, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# === Modify key entries for Bow River lumped basin ===\n",
    "config['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "config['DOMAIN_NAME'] = 'Bow_at_Banff_lumped'\n",
    "config['EXPERIMENT_ID'] = 'run_1'\n",
    "\n",
    "# Gauging station coordinates (Banff WSC 05BB001)\n",
    "config['POUR_POINT_COORDS'] = '51.1722/-115.5717'\n",
    "\n",
    "# Lumped basin settings\n",
    "config['DOMAIN_DEFINITION_METHOD'] = 'lumped'\n",
    "config['DOMAIN_DISCRETIZATION'] = 'GRUs'\n",
    "\n",
    "# Model configuration\n",
    "config['HYDROLOGICAL_MODEL'] = 'SUMMA'\n",
    "config['ROUTING_MODEL'] = 'mizuRoute'\n",
    "\n",
    "# Temporal extent\n",
    "config['EXPERIMENT_TIME_START'] = '2004-01-01 01:00'\n",
    "config['EXPERIMENT_TIME_END'] = '2018-12-31 23:00'\n",
    "config['CALIBRATION_PERIOD'] = '2004-01-01, 2010-12-31'\n",
    "config['EVALUATION_PERIOD'] = '2011-01-01, 2018-12-31'\n",
    "config['SPINUP_PERIOD'] = '2004-01-01, 2005-12-31'\n",
    "\n",
    "# Streamflow observations\n",
    "config['STATION_ID'] = '05BB001'\n",
    "config['DOWNLOAD_WSC_DATA'] = True\n",
    "\n",
    "# Save configuration\n",
    "config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_basin_lumped.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"✅ Configuration saved: {config_path}\")\n",
    "\n",
    "# Initialize CONFLUENCE\n",
    "confluence = CONFLUENCE(config_path)\n",
    "\n",
    "# Create project structure\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"✅ Project structure created at: {project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — Domain definition\n",
    "\n",
    "For basin-scale modeling, we delineate the watershed boundary and create a single lumped HRU representing the entire catchment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a — Geospatial attribute acquisition - **Only available through MAF supported HPCs**\n",
    "\n",
    "Acquires watershed attributes (elevation, land cover, soils) that will be spatially averaged for the lumped representation.\n",
    "\n",
    "- If using downloaded example data, copy attributes, forcing, and observation directories into the domain directory from Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a — Attribute acquisition\n",
    "# If using MAF supported HPC, uncomment the line below\n",
    "# confluence.managers['data'].acquire_attributes()\n",
    "print(\"✅ Attribute acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b — Watershed delineation\n",
    "\n",
    "Delineates the basin boundary using automated watershed analysis from the pour point coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b — Watershed delineation\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "print(\"✅ Watershed delineation complete\")\n",
    "print(f\"Watershed file: {watershed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2c — Domain discretization\n",
    "\n",
    "Creates a single HRU that represents the lumped basin with spatially-averaged characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2c — Discretization (single lumped HRU)\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "print(\"✅ Domain discretization complete\")\n",
    "print(f\"HRU file: {hru_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2d — Visualization\n",
    "\n",
    "Quick visualization of the lumped basin boundary and pour point location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2d — Basin visualization\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load spatial data\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins' / f\"{config['DOMAIN_NAME']}_riverBasins_lumped.shp\"\n",
    "hru_file = project_dir / 'shapefiles' / 'catchment' / f\"{config['DOMAIN_NAME']}_HRUs_GRUs.shp\"\n",
    "\n",
    "watershed_gdf = gpd.read_file(str(basin_path))\n",
    "hru_gdf = gpd.read_file(str(hru_file))\n",
    "pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "\n",
    "# Calculate area\n",
    "watershed_proj = watershed_gdf.to_crs('EPSG:32611')  # UTM Zone 11N\n",
    "area_km2 = watershed_proj.geometry.area.sum() / 1e6\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "watershed_gdf.boundary.plot(ax=ax, color='blue', linewidth=2, label='Watershed')\n",
    "hru_gdf.plot(ax=ax, facecolor='lightblue', edgecolor='blue', alpha=0.3)\n",
    "pour_point_gdf.plot(ax=ax, color='red', markersize=100, marker='*', label='Pour Point')\n",
    "\n",
    "ax.set_title(f'{config[\"DOMAIN_NAME\"]}\\n'\n",
    "             f'Area: {area_km2:.0f} km²', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Watershed area: {area_km2:.0f} km²\")\n",
    "print(f\"Number of HRUs: {len(hru_gdf)} (lumped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Data acquisition and preprocessing\n",
    "\n",
    "Process streamflow observations, meteorological forcing data, and prepare model-ready inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3a — Streamflow observations\n",
    "\n",
    "Download and process Water Survey of Canada streamflow data for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a — Streamflow data processing\n",
    "# If using MAF supported HPC, uncomment the line below\n",
    "# confluence.managers['data'].process_observed_data()\n",
    "print(\"✅ Streamflow data processing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b — Meteorological forcing\n",
    "\n",
    "Acquire and spatially average meteorological forcing data over the basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b — Forcing acquisition\n",
    "# If using MAF supported HPC, uncomment the line below\n",
    "# confluence.managers['data'].acquire_forcings()\n",
    "print(\"✅ Forcing acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3c — Model-agnostic preprocessing\n",
    "\n",
    "Standardize variable names, units, and time steps for model consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3c — Model-agnostic preprocessing\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"✅ Model-agnostic preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 — Model configuration and execution\n",
    "\n",
    "Configure SUMMA for basin-scale simulation with mizuRoute routing, then execute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a — SUMMA-specific preprocessing\n",
    "confluence.managers['model'].preprocess_models()\n",
    "print(\"✅ Model configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b — Model execution\n",
    "print(f\"Running {config['HYDROLOGICAL_MODEL']} with {config.get('ROUTING_MODEL', 'no routing')}...\")\n",
    "confluence.managers['model'].run_models()\n",
    "print(\"✅ Basin-scale simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 — Streamflow evaluation\n",
    "\n",
    "Compare simulated and observed streamflow using standard hydrological metrics and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 — Streamflow evaluation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load observed streamflow\n",
    "obs_path = project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Load simulated streamflow from mizuRoute\n",
    "routing_dir = project_dir / \"simulations\" / config['EXPERIMENT_ID'] / \"mizuRoute\"\n",
    "sim_files = list(routing_dir.glob('*_routed.nc'))\n",
    "if not sim_files:\n",
    "    raise FileNotFoundError(f\"No routed streamflow found in: {routing_dir}\")\n",
    "\n",
    "import xarray as xr\n",
    "sim_ds = xr.open_dataset(sim_files[0])\n",
    "sim_df = sim_ds['IRFroutedRunoff'].to_dataframe().reset_index()\n",
    "sim_df = sim_df.rename(columns={'time': 'datetime', 'IRFroutedRunoff': 'discharge_sim'})\n",
    "sim_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Merge and align\n",
    "eval_df = obs_df.join(sim_df, how='inner')\n",
    "obs_valid = eval_df['discharge_obs'].dropna()\n",
    "sim_valid = eval_df.loc[obs_valid.index, 'discharge_sim']\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def nse(obs, sim):\n",
    "    return float(1 - np.sum((obs - sim)**2) / np.sum((obs - obs.mean())**2))\n",
    "\n",
    "def kge(obs, sim):\n",
    "    r = obs.corr(sim)\n",
    "    alpha = sim.std() / obs.std()\n",
    "    beta = sim.mean() / obs.mean()\n",
    "    return float(1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2))\n",
    "\n",
    "def pbias(obs, sim):\n",
    "    return float(100 * (sim.sum() - obs.sum()) / obs.sum())\n",
    "\n",
    "metrics = {\n",
    "    'NSE': round(nse(obs_valid, sim_valid), 3),\n",
    "    'KGE': round(kge(obs_valid, sim_valid), 3),\n",
    "    'PBIAS': round(pbias(obs_valid, sim_valid), 1)\n",
    "}\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Time series (top left)\n",
    "axes[0, 0].plot(obs_valid.index, obs_valid.values, 'b-', label='Observed', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].plot(sim_valid.index, sim_valid.values, 'r-', label='Simulated', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].set_ylabel('Discharge (m³/s)')\n",
    "axes[0, 0].set_title('Streamflow Time Series')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].text(0.02, 0.95, f\"NSE: {metrics['NSE']}\\nKGE: {metrics['KGE']}\\nBias: {metrics['PBIAS']}%\",\n",
    "                transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                bbox=dict(facecolor='white', alpha=0.8), fontsize=9)\n",
    "\n",
    "# Scatter (top right)\n",
    "axes[0, 1].scatter(obs_valid, sim_valid, alpha=0.5, s=10)\n",
    "max_val = max(obs_valid.max(), sim_valid.max())\n",
    "axes[0, 1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Observed (m³/s)')\n",
    "axes[0, 1].set_ylabel('Simulated (m³/s)')\n",
    "axes[0, 1].set_title('Observed vs Simulated')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly climatology (bottom left)\n",
    "monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1, 0].plot(monthly_obs.index, monthly_obs.values, 'b-o', label='Observed', markersize=6)\n",
    "axes[1, 0].plot(monthly_sim.index, monthly_sim.values, 'r-o', label='Simulated', markersize=6)\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].set_xticklabels(month_names)\n",
    "axes[1, 0].set_ylabel('Mean Discharge (m³/s)')\n",
    "axes[1, 0].set_title('Seasonal Flow Regime')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Flow duration curve (bottom right)\n",
    "obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "axes[1, 1].semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "axes[1, 1].semilogy(sim_ranks, sim_sorted, 'r-', label='Simulated', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Exceedance Probability (%)')\n",
    "axes[1, 1].set_ylabel('Discharge (m³/s)')\n",
    "axes[1, 1].set_title('Flow Duration Curve')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Lumped Basin Evaluation — {config[\"DOMAIN_NAME\"]}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Streamflow evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated CONFLUENCE's seamless scaling from point-scale validation to basin-scale streamflow simulation. The lumped representation provides computational efficiency and establishes baseline performance for the Bow River watershed.\n",
    "\n",
    "Key achievements:\n",
    "- Basin-scale domain delineation and lumped HRU creation\n",
    "- Spatial aggregation of watershed characteristics\n",
    "- Coupled SUMMA-mizuRoute simulation for streamflow generation\n",
    "- Standard hydrological evaluation metrics\n",
    "\n",
    "The same workflow principles applied in point-scale tutorials (01a, 01b) scale directly to basin applications without architectural changes, demonstrating CONFLUENCE's flexibility and reproducibility.\n",
    "\n",
    "### Next: Semi-Distributed Modeling\n",
    "\n",
    "**Ready for spatial complexity?** → **[Tutorial 02b: Semi-Distributed Watershed](./02b_basin_semi_distributed.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
