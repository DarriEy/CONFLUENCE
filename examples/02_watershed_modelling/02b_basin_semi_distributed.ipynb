{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial 02b ‚Äî Basin-Scale Workflow (Bow River at Banff, Semi-Distributed)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial advances from lumped to semi-distributed watershed modeling. Instead of representing the basin as a single unit, we now subdivide it into multiple connected sub-basins (GRUs) that capture spatial variability while maintaining computational efficiency.\n",
    "\n",
    "Building on Tutorial 02a's lumped approach, semi-distributed modeling adds spatial detail through automated watershed delineation that creates multiple sub-basins, stream network topology that connects GRUs through routing, and spatially-distributed characteristics that better represent elevation gradients and heterogeneous processes.\n",
    "\n",
    "The key configuration change is `DOMAIN_DEFINITION_METHOD: 'delineate'` with a `STREAM_THRESHOLD` parameter controlling the number of sub-basins. Smaller thresholds create more GRUs (finer spatial detail) but increase computational cost.\n",
    "\n",
    "We continue with the **Bow River at Banff** watershed, now discretized into multiple GRUs connected by mizuRoute for explicit stream network routing. This approach improves representation of snowmelt timing, spatial climate variability, and runoff generation patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 ‚Äî Configuration and data reuse\n",
    "\n",
    "We generate a semi-distributed configuration and intelligently reuse data from Tutorial 02a where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 ‚Äî Semi-distributed configuration with data reuse\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Define directories\n",
    "CONFLUENCE_CODE_DIR = Path(\"../..\").resolve()\n",
    "CONFLUENCE_DATA_DIR = Path(\"/path/to/CONFLUENCE_data\").resolve()\n",
    "\n",
    "# Load template\n",
    "config_template = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "with open(config_template, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# === Modify for semi-distributed basin ===\n",
    "config['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "config['DOMAIN_NAME'] = 'Bow_at_Banff_semi_distributed'\n",
    "config['EXPERIMENT_ID'] = 'run_1'\n",
    "config['POUR_POINT_COORDS'] = '51.1722/-115.5717'\n",
    "\n",
    "# Key changes for semi-distributed\n",
    "config['DOMAIN_DEFINITION_METHOD'] = 'delineate'  # Watershed subdivision\n",
    "config['STREAM_THRESHOLD'] = 5000  # Controls number of sub-basins\n",
    "config['DOMAIN_DISCRETIZATION'] = 'GRUs'\n",
    "\n",
    "config['HYDROLOGICAL_MODEL'] = 'SUMMA'\n",
    "config['ROUTING_MODEL'] = 'mizuRoute'\n",
    "\n",
    "config['EXPERIMENT_TIME_START'] = '2011-01-01 01:00'\n",
    "config['EXPERIMENT_TIME_END'] = '2018-12-31 23:00'\n",
    "config['CALIBRATION_PERIOD'] = '2011-01-01, 2015-12-31'\n",
    "config['EVALUATION_PERIOD'] = '2016-01-01, 2018-12-31'\n",
    "config['SPINUP_PERIOD'] = '2011-01-01, 2011-12-31'\n",
    "config['STATION_ID'] = '05BB001'\n",
    "config['DOWNLOAD_WSC_DATA'] = True\n",
    "\n",
    "# Save configuration\n",
    "config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_semi_distributed.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"‚úÖ Configuration saved: {config_path}\")\n",
    "\n",
    "# === Data reuse from Tutorial 02a ===\n",
    "lumped_domain = 'Bow_at_Banff_lumped'\n",
    "lumped_data_dir = CONFLUENCE_DATA_DIR / f'domain_{lumped_domain}'\n",
    "\n",
    "def copy_with_name_adaptation(src, dst, old_name, new_name):\n",
    "    \"\"\"Copy directory and adapt filenames\"\"\"\n",
    "    if not src.exists():\n",
    "        return False\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if src.is_file():\n",
    "        shutil.copy2(src, dst)\n",
    "        return True\n",
    "    shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    # Rename files containing old domain name\n",
    "    for file in dst.rglob('*'):\n",
    "        if file.is_file() and old_name in file.name:\n",
    "            new_file = file.parent / file.name.replace(old_name, new_name)\n",
    "            file.rename(new_file)\n",
    "    return True\n",
    "\n",
    "# Initialize CONFLUENCE first\n",
    "confluence = CONFLUENCE(config_path)\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "if lumped_data_dir.exists():\n",
    "    print(f\"\\nüìã Reusing data from Tutorial 02a: {lumped_data_dir}\")\n",
    "    \n",
    "    reusable_data = {\n",
    "        'Elevation': lumped_data_dir / 'attributes' / 'elevation',\n",
    "        'Land Cover': lumped_data_dir / 'attributes' / 'land_cover',\n",
    "        'Soils': lumped_data_dir / 'attributes' / 'soils',\n",
    "        'Forcing': lumped_data_dir / 'forcing' / 'raw_data',\n",
    "        'Streamflow': lumped_data_dir / 'observations' / 'streamflow'\n",
    "    }\n",
    "    \n",
    "    for data_type, src_path in reusable_data.items():\n",
    "        if src_path.exists():\n",
    "            rel_path = src_path.relative_to(lumped_data_dir)\n",
    "            dst_path = project_dir / rel_path\n",
    "            success = copy_with_name_adaptation(src_path, dst_path, lumped_domain, config['DOMAIN_NAME'])\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ {data_type}: Copied\")\n",
    "        else:\n",
    "            print(f\"   üìã {data_type}: Not found\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No data from Tutorial 02a found. Will acquire fresh data.\")\n",
    "\n",
    "# Create pour point\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "print(f\"\\n‚úÖ Project structure created at: {project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Domain definition (multi-GRU)\n",
    "\n",
    "Delineate the watershed into multiple sub-basins using stream network analysis and create connected GRUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a ‚Äî Attribute check\n",
    "\n",
    "Verify DEM availability from data reuse, or acquire fresh if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a ‚Äî DEM availability check\n",
    "dem_path = project_dir / 'attributes' / 'elevation' / 'dem'\n",
    "if not dem_path.exists() or len(list(dem_path.glob('*.tif'))) == 0:\n",
    "    print(\"   DEM not found, acquiring geospatial attributes...\")\n",
    "    # If using MAF supported HPC, uncomment the line below\n",
    "    # confluence.managers['data'].acquire_attributes()\n",
    "    print(\"‚úÖ Geospatial attributes acquired\")\n",
    "else:\n",
    "    print(\"‚úÖ DEM available from previous workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b ‚Äî Stream network delineation\n",
    "\n",
    "Automated watershed subdivision based on stream threshold parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b ‚Äî Stream network delineation\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "print(\"‚úÖ Stream network delineation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2c ‚Äî GRU discretization\n",
    "\n",
    "Convert sub-basins to GRUs with routing connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2c ‚Äî GRU discretization\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "print(\"‚úÖ GRU discretization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2d ‚Äî Network visualization\n",
    "\n",
    "Visualize the semi-distributed structure: sub-basins and stream network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2d ‚Äî Network structure visualization\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load spatial products\n",
    "basin_dir = project_dir / 'shapefiles' / 'river_basins'\n",
    "network_dir = project_dir / 'shapefiles' / 'river_network'\n",
    "\n",
    "basin_files = list(basin_dir.glob('*.shp'))\n",
    "network_files = list(network_dir.glob('*.shp'))\n",
    "\n",
    "if basin_files:\n",
    "    basins_gdf = gpd.read_file(basin_files[0])\n",
    "    print(f\"Number of GRUs: {len(basins_gdf)}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    basins_gdf.boundary.plot(ax=ax, color='blue', linewidth=1)\n",
    "    basins_gdf.plot(ax=ax, column='GRU_ID', cmap='tab20', alpha=0.5, legend=False)\n",
    "    \n",
    "    if network_files:\n",
    "        network_gdf = gpd.read_file(network_files[0])\n",
    "        network_gdf.plot(ax=ax, color='darkblue', linewidth=2, label='Stream Network')\n",
    "    \n",
    "    pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "    pour_point_gdf.plot(ax=ax, color='red', markersize=150, marker='*', label='Pour Point')\n",
    "    \n",
    "    ax.set_title(f'Semi-Distributed Structure\\n{len(basins_gdf)} Connected GRUs', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Basin shapefiles not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî Data preprocessing\n",
    "\n",
    "Process forcing and observation data for multiple GRUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a ‚Äî Streamflow observations\n",
    "# If using MAF supported HPC, uncomment the line below\n",
    "# confluence.managers['data'].process_observed_data()\n",
    "print(\"‚úÖ Streamflow data processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b ‚Äî Forcing data\n",
    "# If using MAF supported HPC, uncomment the line below  \n",
    "# confluence.managers['data'].acquire_forcings()\n",
    "print(\"‚úÖ Forcing acquisition complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3c ‚Äî Model-agnostic preprocessing\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"‚úÖ Model-agnostic preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 ‚Äî Model execution\n",
    "\n",
    "Configure and run SUMMA-mizuRoute with multiple connected GRUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a ‚Äî Model configuration\n",
    "confluence.managers['model'].preprocess_models()\n",
    "print(\"‚úÖ Semi-distributed model configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b ‚Äî Model execution\n",
    "print(f\"Running {config['HYDROLOGICAL_MODEL']} with {config['ROUTING_MODEL']} ({len(basins_gdf)} GRUs)...\")\n",
    "confluence.managers['model'].run_models()\n",
    "print(\"‚úÖ Semi-distributed simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 ‚Äî Evaluation\n",
    "\n",
    "Compare semi-distributed results against observations and lumped baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 ‚Äî Semi-distributed evaluation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "# Load observed streamflow\n",
    "obs_path = project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Load simulated streamflow\n",
    "routing_dir = project_dir / \"simulations\" / config['EXPERIMENT_ID'] / \"mizuRoute\"\n",
    "sim_files = list(routing_dir.glob('*_routed.nc'))\n",
    "if not sim_files:\n",
    "    raise FileNotFoundError(f\"No routed streamflow in: {routing_dir}\")\n",
    "\n",
    "sim_ds = xr.open_dataset(sim_files[0])\n",
    "sim_df = sim_ds['IRFroutedRunoff'].to_dataframe().reset_index()\n",
    "sim_df = sim_df.rename(columns={'time': 'datetime', 'IRFroutedRunoff': 'discharge_sim'})\n",
    "sim_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Merge and align\n",
    "eval_df = obs_df.join(sim_df, how='inner')\n",
    "obs_valid = eval_df['discharge_obs'].dropna()\n",
    "sim_valid = eval_df.loc[obs_valid.index, 'discharge_sim']\n",
    "\n",
    "# Metrics\n",
    "def nse(obs, sim):\n",
    "    return float(1 - np.sum((obs - sim)**2) / np.sum((obs - obs.mean())**2))\n",
    "\n",
    "def kge(obs, sim):\n",
    "    r = obs.corr(sim)\n",
    "    alpha = sim.std() / obs.std()\n",
    "    beta = sim.mean() / obs.mean()\n",
    "    return float(1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2))\n",
    "\n",
    "def pbias(obs, sim):\n",
    "    return float(100 * (sim.sum() - obs.sum()) / obs.sum())\n",
    "\n",
    "nse_val = round(nse(obs_valid, sim_valid), 3)\n",
    "kge_val = round(kge(obs_valid, sim_valid), 3)\n",
    "pbias_val = round(pbias(obs_valid, sim_valid), 1)\n",
    "\n",
    "print(f\"Performance Metrics:\")\n",
    "print(f\"  NSE: {nse_val}\")\n",
    "print(f\"  KGE: {kge_val}\")\n",
    "print(f\"  PBIAS: {pbias_val}%\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Time series\n",
    "axes[0, 0].plot(obs_valid.index, obs_valid.values, 'b-', label='Observed', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].plot(sim_valid.index, sim_valid.values, 'r-', label=f'Semi-Distributed ({len(basins_gdf)} GRUs)', \n",
    "                linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].set_ylabel('Discharge (m¬≥/s)')\n",
    "axes[0, 0].set_title('Semi-Distributed Streamflow')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].text(0.02, 0.95, f\"NSE: {nse_val}\\nKGE: {kge_val}\\nBias: {pbias_val}%\\nGRUs: {len(basins_gdf)}\",\n",
    "                transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                bbox=dict(facecolor='white', alpha=0.8), fontsize=9)\n",
    "\n",
    "# Scatter\n",
    "axes[0, 1].scatter(obs_valid, sim_valid, alpha=0.5, s=10, c='green')\n",
    "max_val = max(obs_valid.max(), sim_valid.max())\n",
    "axes[0, 1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Observed (m¬≥/s)')\n",
    "axes[0, 1].set_ylabel('Simulated (m¬≥/s)')\n",
    "axes[0, 1].set_title('Observed vs Simulated')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly climatology\n",
    "monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1, 0].plot(monthly_obs.index, monthly_obs.values, 'b-o', label='Observed', markersize=6)\n",
    "axes[1, 0].plot(monthly_sim.index, monthly_sim.values, 'r-o', label='Simulated', markersize=6)\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].set_xticklabels(month_names)\n",
    "axes[1, 0].set_ylabel('Mean Discharge (m¬≥/s)')\n",
    "axes[1, 0].set_title('Seasonal Flow Regime')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Flow duration curve\n",
    "obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "axes[1, 1].semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "axes[1, 1].semilogy(sim_ranks, sim_sorted, 'r-', label='Simulated', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Exceedance Probability (%)')\n",
    "axes[1, 1].set_ylabel('Discharge (m¬≥/s)')\n",
    "axes[1, 1].set_title('Flow Duration Curve')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Semi-Distributed Evaluation ‚Äî {config[\"DOMAIN_NAME\"]} ({len(basins_gdf)} GRUs)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Semi-distributed evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated semi-distributed watershed modeling with multiple connected GRUs. Key advances over lumped modeling include spatial representation of elevation gradients, explicit stream network routing between sub-basins, and improved process attribution across the watershed.\n",
    "\n",
    "Achievements:\n",
    "- Automated watershed subdivision using stream threshold\n",
    "- Multi-GRU model configuration with routing connectivity\n",
    "- Efficient data reuse from Tutorial 02a\n",
    "- Spatially-distributed process simulation\n",
    "\n",
    "The semi-distributed approach balances spatial detail with computational efficiency, providing the foundation for fully distributed modeling applications.\n",
    "\n",
    "### Next: Elevation-Based Distributed Modeling\n",
    "\n",
    "**Ready for maximum spatial detail?** ‚Üí **[Tutorial 02c: Elevation-Based Distributed Watershed](./02c_basin_distributed.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
