{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 4: Semi-Distributed Basin Workflow (Bow River at Banff)\n",
    "\n",
    "## Introduction\n",
    "This tutorial demonstrates the next advancement in spatial modeling complexity through semi-distributed basin modeling. Building on the lumped basin approach from Tutorial 02a, we now introduce spatial discretization by dividing the watershed into multiple connected units called Grouped Response Units (GRUs). This approach bridges the gap between simple lumped models and fully distributed representations, offering an optimal balance between computational efficiency and spatial realism.\n",
    "\n",
    "## Semi-Distributed Modeling Philosophy\n",
    "Semi-distributed modeling divides the watershed into multiple sub-basins, with each unit treated as a separate modeling component within a connected network. This approach employs spatial discretization where the watershed is divided into multiple GRUs based on stream network topology, creating connected units where each GRU links to downstream units through a routing network. The methodology represents intermediate complexity that provides more spatial realism than lumped models while maintaining greater simplicity than fully distributed approaches, ensuring computational efficiency with fewer units than fully distributed models while remaining suitable for calibration and uncertainty analysis.\n",
    "\n",
    "## Key Scientific Concepts\n",
    "The Grouped Response Unit concept represents sub-basins that drain to specific points along the stream network, with each GRU containing similar hydrological characteristics and responding as a unified computational unit. Stream network delineation employs digital elevation models and flow accumulation algorithms to automatically identify stream channels and divide the watershed into connected sub-basins. Routing processes move water from upstream GRUs to downstream GRUs through the stream network while accounting for travel time and channel storage effects. The stream threshold parameter critically controls model complexity by determining how many sub-basins are created, with higher thresholds producing fewer, larger GRUs.\n",
    "\n",
    "## Scientific Advantages and Applications\n",
    "Semi-distributed modeling captures important spatial variations in climate, topography, and land cover across the watershed while better representing elevation-dependent processes like snow accumulation and temperature gradients. This approach maintains computational efficiency with fewer units than fully distributed models while preserving key spatial patterns, explicitly represents routing dynamics including travel time and attenuation effects in the stream network, and provides diagnostic capabilities that allow examination of contributions from different watershed regions.\n",
    "\n",
    "## Case Study: Bow River at Banff Semi-Distributed Configuration\n",
    "For this tutorial, we employ the same Bow River watershed from Tutorial 02a but divide it into multiple GRUs through several configuration modifications. The domain method changes from lumped to delineate for watershed subdivision, a stream threshold of 5000 creates multiple sub-basins, mizuRoute provides routing connectivity between GRUs, and spatial complexity increases from single-unit to multi-unit representation. Expected outcomes include better representation of elevation gradients, improved timing of snowmelt contributions, more realistic representation of spatial climate variability, and enhanced ability to diagnose spatial process patterns.\n",
    "\n",
    "## Technical Implementation Framework\n",
    "The semi-distributed approach integrates several key components through automated watershed delineation that identifies sub-basins using flow accumulation algorithms, stream network extraction that creates river network topology connecting the sub-basins, GRU characterization that calculates average characteristics for each sub-basin, routing setup that configures mizuRoute to move water between GRUs, and model integration that couples SUMMA land surface processes with mizuRoute routing capabilities.\n",
    "\n",
    "## Learning Objectives and Tutorial Structure\n",
    "Through this tutorial, you will master configuration of semi-distributed models with multiple GRUs, understand control of spatial discretization using stream threshold parameters, comprehend routing processes and their impact on streamflow timing, develop skills in visualizing spatial model structure with GRUs and stream networks, learn to interpret distributed model results and compare with lumped approaches, and manage increased model complexity while maintaining workflow efficiency.\n",
    "\n",
    "This tutorial follows the established CONFLUENCE workflow with key modifications for spatial complexity, including project setup initialization for semi-distributed modeling, domain delineation to create multiple sub-basins using stream network analysis, spatial discretization to convert sub-basins to GRUs for modeling, data processing to prepare inputs for multiple modeling units, model configuration to set up coupled SUMMA and mizuRoute systems, model execution to run the integrated land surface and routing model, and comprehensive results analysis comparing semi-distributed versus lumped model performance. By completing this tutorial, you will understand how to add spatial complexity to hydrological models while maintaining computational efficiency, establishing crucial foundations for fully distributed modeling applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Semi-Distributed Setup with Data Reuse\n",
    "Building on the lumped basin modeling from Tutorial 02a, we now advance to semi-distributed watershed modeling. This represents an optimal balance between computational efficiency and spatial realism: multiple connected sub-basins that capture key spatial heterogeneity while maintaining manageable model complexity.\n",
    "\n",
    "The same CONFLUENCE framework seamlessly handles this complexity increase while data reuse from Tutorial 02a eliminates redundant preprocessing, demonstrating efficient workflow management for iterative model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll need in this notebook\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION FOR SEMI-DISTRIBUTED BOW RIVER MODELING\n",
    "# =============================================================================\n",
    "\n",
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/Users/darrieythorsson/compHydro/data/CONFLUENCE_data')  \n",
    "#CONFLUENCE_DATA_DIR = Path('/path/to/your/CONFLUENCE_data') \n",
    "\n",
    "# Load template configuration and customize for semi-distributed modeling\n",
    "config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "\n",
    "with open(config_template_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update for semi-distributed Bow River modeling\n",
    "config_updates = {\n",
    "    'CONFLUENCE_CODE_DIR': str(CONFLUENCE_CODE_DIR),\n",
    "    'CONFLUENCE_DATA_DIR': str(CONFLUENCE_DATA_DIR),\n",
    "    'DOMAIN_NAME': 'Bow_at_Banff_distributed',\n",
    "    'EXPERIMENT_ID': 'distributed_tutorial',\n",
    "    'POUR_POINT_COORDS': '51.1722/-115.5717',  # Same as lumped model\n",
    "    'DOMAIN_DEFINITION_METHOD': 'delineate',    # KEY CHANGE: watershed delineation vs lumped\n",
    "    'STREAM_THRESHOLD': 5000,                   # Controls number of sub-basins\n",
    "    'DOMAIN_DISCRETIZATION': 'GRUs',            # Grouped Response Units\n",
    "    'HYDROLOGICAL_MODEL': 'SUMMA',\n",
    "    'ROUTING_MODEL': 'mizuRoute',               \n",
    "    'EXPERIMENT_TIME_START': '2011-01-01 01:00',\n",
    "    'EXPERIMENT_TIME_END': '2018-12-31 23:00',\n",
    "    'CALIBRATION_PERIOD': '2011-01-01, 2015-12-31',\n",
    "    'EVALUATION_PERIOD': '2016-01-01, 2018-12-31',\n",
    "    'SPINUP_PERIOD': '2011-01-01, 2011-12-31',\n",
    "    'STATION_ID': '05BB001',\n",
    "    'DOWNLOAD_WSC_DATA': True\n",
    "}\n",
    "\n",
    "config_dict.update(config_updates)\n",
    "\n",
    "# Save configuration\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_semi_distributed.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "# =============================================================================\n",
    "# DATA REUSE FROM TUTORIAL 02A\n",
    "# =============================================================================\n",
    "\n",
    "# Check for existing data from lumped model tutorial\n",
    "lumped_domain = 'Bow_at_Banff'  # From Tutorial 02a\n",
    "lumped_data_dir = CONFLUENCE_DATA_DIR / f'domain_{lumped_domain}'\n",
    "\n",
    "if lumped_data_dir.exists():\n",
    "    print(f\"âœ… Found existing data from Tutorial 02a: {lumped_data_dir}\")\n",
    "    \n",
    "    # Define reusable data categories\n",
    "    reusable_data = {\n",
    "        'Elevation (DEM)': lumped_data_dir / 'attributes' / 'elevation',\n",
    "        'Soil Data': lumped_data_dir / 'attributes' / 'soilclass', \n",
    "        'Land Cover': lumped_data_dir / 'attributes' / 'landclass',\n",
    "        'ERA5 Forcing': lumped_data_dir / 'forcing' / 'raw_data',\n",
    "        'WSC Observations': lumped_data_dir / 'observations' / 'streamflow'\n",
    "    }\n",
    "    \n",
    "    # Check availability and copy reusable data\n",
    "    print(f\"\\nðŸ”„ Copying and Adapting Reusable Data...\")\n",
    "    \n",
    "    # Initialize CONFLUENCE first to create directory structure\n",
    "    confluence = CONFLUENCE(temp_config_path)\n",
    "    project_dir = confluence.managers['project'].setup_project()\n",
    "    \n",
    "    def copy_with_name_adaptation(src_path, dst_path, old_name, new_name):\n",
    "        \"\"\"Copy files with name adaptation for new domain\"\"\"\n",
    "        if not src_path.exists():\n",
    "            return False\n",
    "            \n",
    "        dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if src_path.is_dir():\n",
    "            # Copy directory contents with name adaptation\n",
    "            for src_file in src_path.rglob('*'):\n",
    "                if src_file.is_file():\n",
    "                    rel_path = src_file.relative_to(src_path)\n",
    "                    # Adapt filename\n",
    "                    new_filename = src_file.name.replace(old_name, new_name)\n",
    "                    dst_file = dst_path / rel_path.parent / new_filename\n",
    "                    dst_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "            return True\n",
    "        elif src_path.is_file():\n",
    "            # Copy single file with name adaptation\n",
    "            new_filename = dst_path.name.replace(old_name, new_name)\n",
    "            dst_file = dst_path.parent / new_filename\n",
    "            dst_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(src_path, dst_file)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # Copy reusable data with appropriate naming\n",
    "    for data_type, src_path in reusable_data.items():\n",
    "        if src_path.exists():\n",
    "            # Determine destination path\n",
    "            rel_path = src_path.relative_to(lumped_data_dir)\n",
    "            dst_path = project_dir / rel_path\n",
    "            \n",
    "            # Copy with name adaptation\n",
    "            success = copy_with_name_adaptation(\n",
    "                src_path, dst_path, \n",
    "                lumped_domain, config_dict['DOMAIN_NAME']\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                print(f\"   âœ… {data_type}: Copied and adapted\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸  {data_type}: Copy failed\")\n",
    "        else:\n",
    "            print(f\"   ðŸ“‹ {data_type}: Not found, will acquire fresh\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âš ï¸  No existing data found from Tutorial 02a\")\n",
    "    print(f\"   Will acquire all data from scratch\")\n",
    "    \n",
    "    # Initialize CONFLUENCE and create project structure\n",
    "    confluence = CONFLUENCE(temp_config_path)\n",
    "    project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# Create pour point\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Stream Network Delineation and Spatial Connectivity\n",
    "The transition to semi-distributed modeling requires sophisticated spatial analysis to automatically identify sub-basins and their connectivity. This process transforms a continuous landscape into a network of connected modeling units that preserve the essential topology of watershed drainage while creating computationally-manageable spatial discretization.\n",
    "Scientific Context: Stream Network Analysis\n",
    "Hydrologic Network Principles:\n",
    "\n",
    "- Flow Accumulation: Upslope area contributing to each grid cell\n",
    "- Stream Threshold: Minimum contributing area to define stream channels\n",
    "- Watershed Segmentation: Division of landscape by stream network topology\n",
    "- Connectivity Preservation: Maintaining upstream-downstream relationships\n",
    "- Scale Optimization: Balancing spatial detail with computational tractability\n",
    "\n",
    "The stream threshold parameter critically controls model complexity: lower values create more sub-basins with finer spatial detail, while higher values produce fewer, larger units with reduced computational demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if DEM was copied from Tutorial 02a, otherwise run data acquisition\n",
    "dem_path = project_dir / 'attributes' / 'elevation' / 'dem'\n",
    "if not dem_path.exists() or len(list(dem_path.glob('*.tif'))) == 0:\n",
    "    print(f\"   DEM not found, acquiring fresh geospatial attributes...\")\n",
    "    confluence.managers['data'].acquire_attributes()\n",
    "    print(\"âœ… Geospatial attributes acquired\")\n",
    "else:\n",
    "    print(f\"âœ… DEM available from previous workflow\")\n",
    "\n",
    "# Executing stream network delineation\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "print(\"âœ… Stream network delineation complete\")\n",
    "\n",
    "# Execute domain discretization to create GRUs\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "print(\"âœ… GRU discretization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK STRUCTURE ANALYSIS AND VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze created spatial products\n",
    "basin_dir = project_dir / 'shapefiles' / 'river_basins'\n",
    "network_dir = project_dir / 'shapefiles' / 'river_network'\n",
    "catchment_dir = project_dir / 'shapefiles' / 'catchment'\n",
    "\n",
    "# Load spatial data\n",
    "basin_files = list(basin_dir.glob('*.shp'))\n",
    "network_files = list(network_dir.glob('*.shp'))\n",
    "\n",
    "basins_gdf = gpd.read_file(basin_files[0])\n",
    "network_gdf = gpd.read_file(network_files[0])\n",
    "\n",
    "# Project to appropriate CRS for area calculations\n",
    "# For Bow River at Banff (Alberta), UTM Zone 11N is appropriate\n",
    "target_crs = 'EPSG:32611'  # UTM Zone 11N\n",
    "basins_projected = basins_gdf.to_crs(target_crs)\n",
    "\n",
    "print(f\"\\nðŸ“‹ Network Structure Summary:\")\n",
    "print(f\"   Sub-basins (GRUs): {len(basins_gdf)}\")\n",
    "print(f\"   Stream segments: {len(network_gdf)}\")\n",
    "\n",
    "# Calculate areas using projected geometries\n",
    "total_area_m2 = basins_projected.geometry.area.sum()\n",
    "total_area_km2 = total_area_m2 / 1e6\n",
    "avg_gru_size_km2 = total_area_km2 / len(basins_gdf)\n",
    "\n",
    "print(f\"   Total watershed area: {total_area_km2:.1f} kmÂ²\")\n",
    "print(f\"   Average GRU size: {avg_gru_size_km2:.1f} kmÂ²\")\n",
    "\n",
    "# Analyze GRU characteristics\n",
    "if 'elevation' in basins_gdf.columns:\n",
    "    print(f\"   Elevation range: {basins_gdf['elevation'].min():.0f}m to {basins_gdf['elevation'].max():.0f}m\")\n",
    "    print(f\"   Elevation gradient: {basins_gdf['elevation'].max() - basins_gdf['elevation'].min():.0f}m span\")\n",
    "\n",
    "# Stream network characteristics\n",
    "if 'Length' in network_gdf.columns:\n",
    "    total_length = network_gdf['Length'].sum() / 1000  # Convert to km\n",
    "    print(f\"   Total stream length: {total_length:.1f} km\")\n",
    "\n",
    "print(f\"\\nðŸ—ºï¸  Creating network structure visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(18, 9))\n",
    "\n",
    "# Left plot: Sub-basin network with elevation (use original CRS for plotting)\n",
    "ax1 = axes\n",
    "\n",
    "if 'elevation' in basins_gdf.columns:\n",
    "    # Color by elevation\n",
    "    basins_plot = basins_gdf.plot(ax=ax1, column='elevation', cmap='terrain',\n",
    "                                edgecolor='black', linewidth=1, legend=True,\n",
    "                                legend_kwds={'label': 'Elevation (m)', 'shrink': 0.8})\n",
    "else:\n",
    "    # Color by GRU ID\n",
    "    basins_plot = basins_gdf.plot(ax=ax1, column='GRU_ID', cmap='viridis',\n",
    "                                edgecolor='black', linewidth=1, legend=True,\n",
    "                                legend_kwds={'label': 'GRU ID', 'shrink': 0.8})\n",
    "\n",
    "# Add stream network\n",
    "network_gdf.plot(ax=ax1, color='blue', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add pour point\n",
    "pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "pour_point_gdf.plot(ax=ax1, color='red', markersize=150, marker='o',\n",
    "                   edgecolor='white', linewidth=2, zorder=5)\n",
    "\n",
    "ax1.set_title(f'Semi-Distributed Network\\n{len(basins_gdf)} Sub-basins', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Longitude', fontsize=12)\n",
    "ax1.set_ylabel('Latitude', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multi-GRU Data Pipeline\n",
    "The same model-agnostic preprocessing framework now scales to multiple connected sub-basins, demonstrating CONFLUENCE's seamless transition from single-unit to multi-unit spatial modeling. The core data quality and standardization principles remain unchanged; however, spatial processing now handles distributed forcing across the GRU network and routing connectivity between sub-basins.\n",
    "\n",
    "The same preprocessing philosophy ensures consistent data standards across spatial scales, enabling robust model intercomparison and maintaining the scientific rigor established in previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute streamflow data processing \n",
    "confluence.managers['data'].process_observed_data()\n",
    "print(\"âœ… Streamflow validation data ready\")\n",
    "\n",
    "# Check if forcing data was copied, otherwise acquire\n",
    "forcing_dir = project_dir / 'forcing' / 'raw_data'\n",
    "if not forcing_dir.exists() or len(list(forcing_dir.glob('*.nc'))) == 0:\n",
    "    # confluence.managers['data'].acquire_forcings()\n",
    "    print(\"âœ… Forcing acquisition complete (simulated)\")\n",
    "\n",
    "# Execute model-agnostic preprocessing\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"âœ… Multi-GRU preprocessing complete\")\n",
    "\n",
    "\n",
    "# Execute model-specific preprocessing\n",
    "confluence.managers['model'].preprocess_models()\n",
    "print(\"âœ… Semi-distributed model configuration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Streamlined Semi-Distributed Model Execution\n",
    "The same SUMMA process-based physics now executes across multiple connected sub-basins, representing an advance in spatial modeling complexity. This integration of distributed runoff generation with explicit network routing demonstrates how the same computational framework scales from single-unit to multi-unit watershed simulation while maintaining physical realism and computational efficiency. The same workflow orchestration ensures robust execution across this increased complexity while mizuRoute integration transforms the distributed runoff into realistic streamflow with routing delays and channel storage effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute the semi-distributed model system\n",
    "confluence.managers['model'].run_models()\n",
    "print(\"âœ… Semi-distributed simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation and Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observed streamflow (same as lumped model for direct comparison)\n",
    "obs_path = confluence.project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config_dict['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Load semi-distributed simulation from mizuRoute\n",
    "routing_dir = confluence.project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"mizuRoute\"\n",
    "routing_files = list(routing_dir.glob(\"*.nc\"))\n",
    "print(routing_dir)\n",
    "\n",
    "if routing_files:\n",
    "    # Load mizuRoute network output\n",
    "    routing_ds = xr.open_dataset(routing_files[0])\n",
    "    \n",
    "    # Extract outlet streamflow (typically the downstream-most segment)\n",
    "    if 'IRFroutedRunoff' in routing_ds.data_vars:\n",
    "        # Find outlet segment (could be identified by SIM_REACH_ID or maximum downstream position)\n",
    "        reach_id = int(config_dict.get('SIM_REACH_ID', routing_ds.reachID.values[-1]))\n",
    "        \n",
    "        # Find segment index for outlet\n",
    "        segment_indices = np.where(routing_ds.reachID.values == reach_id)[0]\n",
    "        \n",
    "        if len(segment_indices) > 0:\n",
    "            segment_idx = segment_indices[0]\n",
    "            sim_streamflow = routing_ds['IRFroutedRunoff'].isel(seg=segment_idx)\n",
    "            sim_df = sim_streamflow.to_pandas()\n",
    "                        \n",
    "        else:\n",
    "            print(f\"âš ï¸  Outlet segment {reach_id} not found\")\n",
    "            sim_df = None\n",
    "    else:\n",
    "        print(f\"âš ï¸  Streamflow variable not found in routing output\")\n",
    "        sim_df = None\n",
    "        \n",
    "    routing_ds.close()\n",
    "else:\n",
    "    print(f\"âš ï¸  mizuRoute output not found\")\n",
    "    sim_df = None\n",
    "\n",
    "# =============================================================================\n",
    "# SEMI-DISTRIBUTED PERFORMANCE ASSESSMENT\n",
    "# =============================================================================\n",
    "    \n",
    "# Align data to common period\n",
    "start_date = max(obs_df.index.min(), sim_df.index.min())\n",
    "end_date = min(obs_df.index.max(), sim_df.index.max())\n",
    "\n",
    "# Skip initial spinup period\n",
    "start_date = start_date + pd.DateOffset(months=6)\n",
    "\n",
    "# Resample to daily and filter to common period\n",
    "obs_daily = obs_df['discharge_cms'].resample('D').mean().loc[start_date:end_date]\n",
    "sim_daily = sim_df.resample('D').mean().loc[start_date:end_date]\n",
    "\n",
    "# Remove NaN values\n",
    "valid_mask = ~(obs_daily.isna() | sim_daily.isna())\n",
    "obs_valid = obs_daily[valid_mask]\n",
    "sim_valid = sim_daily[valid_mask]\n",
    "\n",
    "# Calculate comprehensive performance metrics\n",
    "print(f\"\\nðŸ“ˆ Semi-Distributed Performance Metrics:\")\n",
    "\n",
    "# Basic statistics\n",
    "rmse = np.sqrt(((obs_valid - sim_valid) ** 2).mean())\n",
    "bias = (sim_valid - obs_valid).mean()\n",
    "mae = np.abs(obs_valid - sim_valid).mean()\n",
    "pbias = 100 * bias / obs_valid.mean()\n",
    "\n",
    "# Efficiency metrics\n",
    "nse = 1 - ((obs_valid - sim_valid) ** 2).sum() / ((obs_valid - obs_valid.mean()) ** 2).sum()\n",
    "\n",
    "# Kling-Gupta Efficiency\n",
    "r = obs_valid.corr(sim_valid)\n",
    "alpha = sim_valid.std() / obs_valid.std()\n",
    "beta = sim_valid.mean() / obs_valid.mean()\n",
    "kge = 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "# Display performance metrics\n",
    "print(f\"   ðŸ“Š RMSE: {rmse:.2f} mÂ³/s\")\n",
    "print(f\"   ðŸ“Š Bias: {bias:+.2f} mÂ³/s ({pbias:+.1f}%)\")\n",
    "print(f\"   ðŸ“Š MAE: {mae:.2f} mÂ³/s\")\n",
    "print(f\"   ðŸ“Š Correlation (r): {r:.3f}\")\n",
    "print(f\"   ðŸ“Š Nash-Sutcliffe (NSE): {nse:.3f}\")\n",
    "print(f\"   ðŸ“Š Kling-Gupta (KGE): {kge:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ROUTING AND SPATIAL EFFECTS ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Analyze peak flow timing (routing delay effects)\n",
    "obs_peaks = obs_valid[obs_valid > obs_valid.quantile(0.95)]\n",
    "sim_peaks = sim_valid[sim_valid > sim_valid.quantile(0.95)]\n",
    "\n",
    "if len(obs_peaks) > 0 and len(sim_peaks) > 0:\n",
    "    # Find largest peak in common period\n",
    "    obs_max_date = obs_valid.idxmax()\n",
    "    sim_max_date = sim_valid.idxmax()\n",
    "    peak_timing_diff = (sim_max_date - obs_max_date).days\n",
    "    \n",
    "# Flow regime analysis\n",
    "flow_stats = {\n",
    "    'High flows (Q95)': (obs_valid.quantile(0.95), sim_valid.quantile(0.95)),\n",
    "    'Medium flows (Q50)': (obs_valid.quantile(0.50), sim_valid.quantile(0.50)),\n",
    "    'Low flows (Q05)': (obs_valid.quantile(0.05), sim_valid.quantile(0.05))\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ“Š Flow Regime Assessment:\")\n",
    "for regime, (obs_q, sim_q) in flow_stats.items():\n",
    "    bias_pct = 100 * (sim_q - obs_q) / obs_q\n",
    "    print(f\"   {regime}: Obs={obs_q:.1f}, Sim={sim_q:.1f} mÂ³/s ({bias_pct:+.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPREHENSIVE SEMI-DISTRIBUTED VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Creating semi-distributed evaluation visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Time series comparison (top left)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(obs_valid.index, obs_valid.values, 'b-',\n",
    "         label='WSC Observed', linewidth=1.5, alpha=0.8)\n",
    "ax1.plot(sim_valid.index, sim_valid.values, 'r-',\n",
    "         label=f'Semi-Distributed ({len(basins_gdf)} GRUs)', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('Discharge (mÂ³/s)', fontsize=11)\n",
    "ax1.set_title('Semi-Distributed Streamflow Comparison', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add performance metrics\n",
    "metrics_text = f'NSE: {nse:.3f}\\nKGE: {kge:.3f}\\nBias: {pbias:+.1f}%\\nGRUs: {len(basins_gdf)}'\n",
    "ax1.text(0.02, 0.95, metrics_text, transform=ax1.transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.8), fontsize=10, verticalalignment='top')\n",
    "\n",
    "# Scatter plot with routing emphasis (top right)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(obs_valid, sim_valid, alpha=0.5, c='green', s=20)\n",
    "max_val = max(obs_valid.max(), sim_valid.max())\n",
    "ax2.plot([0, max_val], [0, max_val], 'k--', label='1:1 line')\n",
    "ax2.set_xlabel('Observed (mÂ³/s)', fontsize=11)\n",
    "ax2.set_ylabel('Semi-Distributed (mÂ³/s)', fontsize=11)\n",
    "ax2.set_title('Obs vs Sim with Network Routing', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly climatology (bottom left)\n",
    "ax3 = axes[1, 0]\n",
    "monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "months = range(1, 13)\n",
    "month_names = ['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D']\n",
    "\n",
    "ax3.plot(months, monthly_obs.values, 'o-', label='Observed',\n",
    "         color='blue', linewidth=2, markersize=6)\n",
    "ax3.plot(months, monthly_sim.values, 's-', label='Semi-Distributed',\n",
    "         color='red', linewidth=2, markersize=6)\n",
    "\n",
    "ax3.set_xticks(months)\n",
    "ax3.set_xticklabels(month_names)\n",
    "ax3.set_ylabel('Mean Discharge (mÂ³/s)', fontsize=11)\n",
    "ax3.set_title('Seasonal Flow Regime', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Flow duration curve (bottom right)\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Calculate exceedance probabilities\n",
    "obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "\n",
    "ax4.semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "ax4.semilogy(sim_ranks, sim_sorted, 'r-', label='Semi-Distributed', linewidth=2)\n",
    "\n",
    "ax4.set_xlabel('Exceedance Probability (%)', fontsize=11)\n",
    "ax4.set_ylabel('Discharge (mÂ³/s)', fontsize=11)\n",
    "ax4.set_title('Flow Duration Curve', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Semi-Distributed Evaluation - {config_dict[\"DOMAIN_NAME\"]} ({len(basins_gdf)} GRUs)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Semi-Distributed Basin-Scale Modeling\n",
    "This tutorial successfully demonstrated the advancement from lumped to semi-distributed watershed modeling using CONFLUENCE. Through the enhanced Bow River at Banff case study, we illustrated how the same standardized workflow framework seamlessly scales from single-unit to multi-unit spatial representation while introducing explicit stream network routing and sub-basin connectivity, establishing the foundation for fully distributed hydrological modeling applications.\n",
    "\n",
    "## Key Methodological Achievements\n",
    "The tutorial established multi-unit spatial discretization through automated watershed delineation that creates connected sub-basins based on stream network topology and flow accumulation algorithms. Stream network routing integration was successfully implemented through mizuRoute coupling with SUMMA, enabling explicit representation of travel times and channel storage effects between connected GRUs. Intelligent data reuse capabilities were demonstrated through efficient adaptation of geospatial and forcing data from Tutorial 02a, showcasing CONFLUENCE's support for iterative model development and comparative analysis.\n",
    "\n",
    "## Scientific Process Understanding\n",
    "The evaluation demonstrated CONFLUENCE's ability to represent spatially-distributed watershed processes through multiple connected sub-basins that capture elevation gradients and heterogeneous runoff generation while maintaining integrated outlet response. Routing dynamics and timing effects were successfully simulated through explicit stream network connectivity that accounts for travel delays and channel storage in streamflow generation. Spatial process attribution capabilities were established through sub-basin-level analysis that enables identification of contributing areas and process patterns across the watershed network.\n",
    "\n",
    "## Framework Scalability Validation\n",
    "This tutorial confirmed CONFLUENCE's seamless complexity scaling by applying identical workflow principles from lumped through semi-distributed modeling without requiring fundamental architectural modifications. The model-agnostic preprocessing approach proved equally effective for multi-GRU spatial processing and routing network configuration, reinforcing the framework's broad applicability across modeling scales. Computational efficiency optimization was demonstrated through intelligent data reuse and workflow management that minimizes redundant processing while enabling rapid exploration of alternative spatial discretization strategies.\n",
    "This foundation in semi-distributed basin modeling establishes essential principles for managing spatial complexity and network connectivity while preparing for the fully distributed modeling approaches and large-scale applications in subsequent tutorials.\n",
    "\n",
    "### Next Focus: Distributed Watershed Modelling \n",
    "\n",
    "**Ready to explore Distributed basin simulations?** â†’ **[Tutorial 02c: Basin Scale - Distributed Watershed](./02c_basin_distributed.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
