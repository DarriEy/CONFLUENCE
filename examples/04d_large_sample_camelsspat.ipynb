{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMELS-SPAT Large Sample Experiment Tutorial\n",
    "\n",
    "This notebook demonstrates how to run CONFLUENCE over multiple watersheds from the CAMELS-SPAT dataset for large-sample hydrology analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the large sample experiment\n",
    "experiment_config = {\n",
    "    'dataset': 'camels-spat',  # CAMELS-SPAT dataset\n",
    "    'max_watersheds': 5,  # Number of watersheds to process\n",
    "    'dry_run': False,  # Set to True to test without submitting jobs\n",
    "    'experiment_name': 'camelsspat_tutorial',\n",
    "    'template_config': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/config_distributed_basin_template.yaml',\n",
    "    'config_dir': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/camels_spat',\n",
    "    'camelsspat_script': '/home/darri.eythorsson/code/CONFLUENCE/9_scripts/run_watersheds_camelsspat.py',\n",
    "    'camelsspat_dir': '/work/comphyd_lab/data/_to-be-moved/camels-spat-upload/shapefiles/meso-scale/shapes-distributed',\n",
    "    'metadata_csv': 'camels-spat-metadata.csv'\n",
    "}\n",
    "\n",
    "# Create experiment directory\n",
    "experiment_dir = Path(f\"./experiments/{experiment_config['experiment_name']}\")\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "with open(experiment_dir / 'experiment_config.yaml', 'w') as f:\n",
    "    yaml.dump(experiment_config, f)\n",
    "\n",
    "print(f\"Experiment configured: {experiment_config['experiment_name']}\")\n",
    "print(f\"Processing {experiment_config['max_watersheds']} watersheds from {experiment_config['dataset']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Watershed Information from CAMELS-SPAT Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function from the CAMELS-SPAT script to extract shapefile info\n",
    "sys.path.append(str(Path(experiment_config['camelsspat_script']).parent))\n",
    "from run_watersheds_camelsspat import extract_shapefile_info\n",
    "\n",
    "# Check if we already have watershed info cached\n",
    "watersheds_csv = experiment_dir / 'camelsspat_watersheds.csv'\n",
    "\n",
    "if watersheds_csv.exists():\n",
    "    print(f\"Loading existing watershed information from {watersheds_csv}\")\n",
    "    watersheds_df = pd.read_csv(watersheds_csv)\n",
    "else:\n",
    "    print(f\"Extracting watershed information from {experiment_config['camelsspat_dir']}...\")\n",
    "    watersheds_df = extract_shapefile_info(experiment_config['camelsspat_dir'])\n",
    "    watersheds_df.to_csv(watersheds_csv, index=False)\n",
    "    print(f\"Saved watershed information to {watersheds_csv}\")\n",
    "\n",
    "print(f\"\\nFound {len(watersheds_df)} watersheds\")\n",
    "print(\"\\nFirst 5 watersheds:\")\n",
    "print(watersheds_df.head()[['ID', 'Basin_File', 'River_File', 'Area_km2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Merge CAMELS-SPAT Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load CAMELS-SPAT metadata if available\n",
    "metadata_path = experiment_config['metadata_csv']\n",
    "\n",
    "if os.path.exists(metadata_path):\n",
    "    print(f\"Loading CAMELS-SPAT metadata from {metadata_path}\")\n",
    "    metadata_df = pd.read_csv(metadata_path)\n",
    "    \n",
    "    # Clean column names\n",
    "    metadata_df.columns = [col.strip() for col in metadata_df.columns]\n",
    "    print(f\"Found metadata with {len(metadata_df)} rows and columns: {metadata_df.columns.tolist()}\")\n",
    "    \n",
    "    # Create standardized ID column for merging\n",
    "    watersheds_df['Metadata_ID'] = watersheds_df['ID'].str.replace(r'^[A-Z]+_', '', regex=True)\n",
    "    \n",
    "    # Merge metadata with watershed information\n",
    "    print(\"\\nMerging shapefile information with metadata...\")\n",
    "    watersheds_merged = pd.merge(\n",
    "        watersheds_df, \n",
    "        metadata_df, \n",
    "        left_on='Metadata_ID',\n",
    "        right_on='ID',\n",
    "        how='left',\n",
    "        suffixes=('', '_metadata')\n",
    "    )\n",
    "    \n",
    "    # Save merged data\n",
    "    watersheds_merged.to_csv(experiment_dir / 'camelsspat_watersheds_merged.csv', index=False)\n",
    "    print(f\"Saved merged watershed information to {experiment_dir / 'camelsspat_watersheds_merged.csv'}\")\n",
    "    watersheds_df = watersheds_merged\n",
    "else:\n",
    "    print(f\"No metadata file found at {metadata_path}. Proceeding with shapefile information only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Watershed Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot watershed locations on a map\n",
    "if 'Lat' in watersheds_df.columns and 'Lon' in watersheds_df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Filter out any missing coordinates\n",
    "    valid_coords = watersheds_df.dropna(subset=['Lat', 'Lon'])\n",
    "    \n",
    "    # Color by country\n",
    "    countries = valid_coords['ID'].str.extract(r'^([A-Z]+)_')[0].unique()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(countries)))\n",
    "    \n",
    "    for country, color in zip(countries, colors):\n",
    "        country_data = valid_coords[valid_coords['ID'].str.startswith(country)]\n",
    "        ax.scatter(country_data['Lon'], country_data['Lat'], \n",
    "                  s=country_data.get('Area_km2', 100)/10, \n",
    "                  c=[color], alpha=0.6, label=country)\n",
    "    \n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('CAMELS-SPAT Watershed Locations')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No coordinate information available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launch CONFLUENCE for Multiple Watersheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the large sample experiment\n",
    "cmd = [\n",
    "    'python', experiment_config['camelsspat_script']\n",
    "]\n",
    "\n",
    "# Add command-line arguments\n",
    "if experiment_config['dry_run']:\n",
    "    cmd.extend(['--dry-run'])\n",
    "    print(\"DRY RUN MODE - No jobs will be submitted\")\n",
    "\n",
    "# Add max watersheds limit if specified\n",
    "if experiment_config['max_watersheds'] > 0:\n",
    "    cmd.extend(['--max-watersheds', str(experiment_config['max_watersheds'])])\n",
    "\n",
    "print(f\"Launching CONFLUENCE for {experiment_config['max_watersheds']} watersheds...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "\n",
    "# Execute\n",
    "result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(Path(experiment_config['camelsspat_script']).parent))\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(result.stdout[:1000] + \"...\" if len(result.stdout) > 1000 else result.stdout)\n",
    "\n",
    "# Save submission log\n",
    "with open(experiment_dir / 'submission.log', 'w') as f:\n",
    "    f.write(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Parse Job Submission Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the submission log to extract job IDs\n",
    "submission_log = experiment_dir / 'submission.log'\n",
    "submitted_jobs = []\n",
    "\n",
    "if submission_log.exists():\n",
    "    with open(submission_log, 'r') as f:\n",
    "        log_content = f.read()\n",
    "    \n",
    "    # Extract job submissions from log\n",
    "    import re\n",
    "    pattern = r'Domain: ([^,]+), Job ID: (\\d+)'\n",
    "    matches = re.findall(pattern, log_content)\n",
    "    \n",
    "    for domain, job_id in matches:\n",
    "        submitted_jobs.append({\n",
    "            'domain': domain,\n",
    "            'job_id': job_id\n",
    "        })\n",
    "    \n",
    "    if submitted_jobs:\n",
    "        jobs_df = pd.DataFrame(submitted_jobs)\n",
    "        print(\"Submitted Jobs:\")\n",
    "        print(jobs_df)\n",
    "        \n",
    "        # Save job information\n",
    "        jobs_df.to_csv(experiment_dir / 'submitted_jobs.csv', index=False)\n",
    "else:\n",
    "    print(\"No submission log found or no jobs submitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Monitor Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check SLURM job status\n",
    "def check_job_status(user=None):\n",
    "    user = user or os.environ.get('USER')\n",
    "    cmd = ['squeue', '-u', user]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return result.stdout\n",
    "\n",
    "print(\"Current jobs:\")\n",
    "print(check_job_status())\n",
    "\n",
    "# Check specific job IDs if we have them\n",
    "if submitted_jobs:\n",
    "    job_ids = [job['job_id'] for job in submitted_jobs]\n",
    "    cmd = ['squeue', '-j', ','.join(job_ids)]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(\"\\nStatus of submitted CAMELS-SPAT jobs:\")\n",
    "    print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Find Completed Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find completed watershed simulations\n",
    "confluence_data_dir = Path(\"/work/comphyd_lab/data/CONFLUENCE_data\")\n",
    "camelsspat_dir = confluence_data_dir / \"camels_spat\"\n",
    "\n",
    "completed = []\n",
    "if camelsspat_dir.exists():\n",
    "    # Look for domain directories\n",
    "    for domain_dir in camelsspat_dir.glob(\"domain_*\"):\n",
    "        watershed_id = domain_dir.name.replace('domain_', '')\n",
    "        sim_dir = domain_dir / \"simulations\"\n",
    "        \n",
    "        # Check if simulation files exist\n",
    "        if sim_dir.exists() and list(sim_dir.rglob(\"*.nc\")):\n",
    "            completed.append({\n",
    "                'watershed_id': watershed_id,\n",
    "                'domain_dir': domain_dir,\n",
    "                'sim_dir': sim_dir\n",
    "            })\n",
    "\n",
    "print(f\"Completed simulations: {len(completed)}\")\n",
    "for ws in completed:\n",
    "    print(f\"  - Watershed {ws['watershed_id']}\")\n",
    "\n",
    "# Save completed simulations info\n",
    "if completed:\n",
    "    completed_df = pd.DataFrame(completed)\n",
    "    completed_df.to_csv(experiment_dir / 'completed_simulations.csv', index=False)\n",
    "    print(f\"\\nSaved completed simulations info to {experiment_dir / 'completed_simulations.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Load and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load SUMMA output\n",
    "def load_summa_output(sim_dir, variable='scalarSWE'):\n",
    "    import xarray as xr\n",
    "    \n",
    "    # Look for SUMMA output files\n",
    "    summa_output_dir = sim_dir / 'run_1' / 'SUMMA'\n",
    "    if not summa_output_dir.exists():\n",
    "        return None\n",
    "        \n",
    "    output_files = list(summa_output_dir.glob(\"*timestep*.nc\"))\n",
    "    if output_files:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        if variable in ds.variables:\n",
    "            return pd.DataFrame({\n",
    "                'time': pd.to_datetime(ds.time.values),\n",
    "                'value': ds[variable].values.flatten()\n",
    "            })\n",
    "    return None\n",
    "\n",
    "# Plot results for completed watersheds\n",
    "if completed:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for ws in completed[:3]:  # Plot first 3\n",
    "        data = load_summa_output(ws['sim_dir'])\n",
    "        if data is not None:\n",
    "            ax.plot(data['time'], data['value'], \n",
    "                   label=f\"Watershed {ws['watershed_id']}\", \n",
    "                   linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Snow Water Equivalent (mm)')\n",
    "    ax.set_title('SWE Comparison - CAMELS-SPAT Watersheds')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No completed simulations found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Load and Compare Streamflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load mizuRoute output\n",
    "def load_streamflow(sim_dir):\n",
    "    import xarray as xr\n",
    "    \n",
    "    # Look for mizuRoute output\n",
    "    mizuroute_dir = sim_dir / 'run_1' / 'mizuRoute'\n",
    "    if not mizuroute_dir.exists():\n",
    "        return None\n",
    "        \n",
    "    output_files = list(mizuroute_dir.glob(\"*.nc\"))\n",
    "    if output_files:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        # Try different variable names for routed runoff\n",
    "        for var in ['IRFroutedRunoff', 'routedRunoff', 'discharge']:\n",
    "            if var in ds.variables:\n",
    "                return pd.DataFrame({\n",
    "                    'time': pd.to_datetime(ds.time.values),\n",
    "                    'simulated': ds[var].values.flatten()\n",
    "                })\n",
    "    return None\n",
    "\n",
    "# Function to load observed streamflow\n",
    "def load_observed_streamflow(domain_dir, watershed_id):\n",
    "    obs_dir = domain_dir / 'observations' / 'streamflow' / 'preprocessed'\n",
    "    obs_file = list(obs_dir.glob(f\"*{watershed_id}*streamflow*.csv\"))\n",
    "    \n",
    "    if obs_file:\n",
    "        obs_df = pd.read_csv(obs_file[0])\n",
    "        # Standardize column names\n",
    "        if 'datetime' in obs_df.columns:\n",
    "            obs_df['time'] = pd.to_datetime(obs_df['datetime'])\n",
    "        elif 'date' in obs_df.columns:\n",
    "            obs_df['time'] = pd.to_datetime(obs_df['date'])\n",
    "            \n",
    "        if 'discharge_m3s' in obs_df.columns:\n",
    "            obs_df['observed'] = obs_df['discharge_m3s']\n",
    "        elif 'streamflow' in obs_df.columns:\n",
    "            obs_df['observed'] = obs_df['streamflow']\n",
    "            \n",
    "        return obs_df[['time', 'observed']]\n",
    "    return None\n",
    "\n",
    "# Compare observed and simulated streamflow for completed watersheds\n",
    "if completed:\n",
    "    fig, axes = plt.subplots(min(3, len(completed)), 1, figsize=(12, 4*min(3, len(completed))))\n",
    "    if len(completed) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, ws in enumerate(completed[:3]):\n",
    "        sim_flow = load_streamflow(ws['sim_dir'])\n",
    "        obs_flow = load_observed_streamflow(ws['domain_dir'], ws['watershed_id'])\n",
    "        \n",
    "        if sim_flow is not None and obs_flow is not None:\n",
    "            # Merge on time\n",
    "            merged = pd.merge(obs_flow, sim_flow, on='time', how='inner')\n",
    "            \n",
    "            axes[i].plot(merged['time'], merged['observed'], label='Observed', color='blue', alpha=0.7)\n",
    "            axes[i].plot(merged['time'], merged['simulated'], label='Simulated', color='red', alpha=0.7)\n",
    "            axes[i].set_title(f'Streamflow Comparison - {ws[\"watershed_id\"]}')\n",
    "            axes[i].set_ylabel('Discharge (m³/s)')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No completed simulations found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "def calculate_metrics(obs, sim):\n",
    "    \"\"\"Calculate various performance metrics\"\"\"\n",
    "    # Remove NaN values\n",
    "    mask = ~(np.isnan(obs) | np.isnan(sim))\n",
    "    obs, sim = obs[mask], sim[mask]\n",
    "    \n",
    "    if len(obs) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # Nash-Sutcliffe Efficiency\n",
    "    nse = 1 - np.sum((obs - sim)**2) / np.sum((obs - np.mean(obs))**2)\n",
    "    \n",
    "    # RMSE\n",
    "    rmse = np.sqrt(np.mean((obs - sim)**2))\n",
    "    \n",
    "    # Percent Bias\n",
    "    pbias = 100 * np.sum(sim - obs) / np.sum(obs)\n",
    "    \n",
    "    # Correlation\n",
    "    corr = np.corrcoef(obs, sim)[0, 1]\n",
    "    \n",
    "    return {\n",
    "        'NSE': nse,\n",
    "        'RMSE': rmse,\n",
    "        'PBIAS': pbias,\n",
    "        'Correlation': corr\n",
    "    }\n",
    "\n",
    "# Calculate metrics for all completed watersheds\n",
    "metrics_list = []\n",
    "\n",
    "for ws in completed:\n",
    "    sim_flow = load_streamflow(ws['sim_dir'])\n",
    "    obs_flow = load_observed_streamflow(ws['domain_dir'], ws['watershed_id'])\n",
    "    \n",
    "    if sim_flow is not None and obs_flow is not None:\n",
    "        # Merge on time\n",
    "        merged = pd.merge(obs_flow, sim_flow, on='time', how='inner')\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(merged['observed'].values, merged['simulated'].values)\n",
    "        metrics['watershed_id'] = ws['watershed_id']\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "if metrics_list:\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    print(\"Performance Metrics:\")\n",
    "    print(metrics_df)\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_df.to_csv(experiment_dir / 'performance_metrics.csv', index=False)\n",
    "    \n",
    "    # Plot metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, metric in enumerate(['NSE', 'RMSE', 'PBIAS', 'Correlation']):\n",
    "        axes[i].bar(range(len(metrics_df)), metrics_df[metric])\n",
    "        axes[i].set_xlabel('Watershed')\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].set_title(f'{metric} by Watershed')\n",
    "        axes[i].set_xticks(range(len(metrics_df)))\n",
    "        axes[i].set_xticklabels(metrics_df['watershed_id'], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No metrics calculated yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Create Summary Report"
   ]
  }]}