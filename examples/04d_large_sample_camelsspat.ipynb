{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a5229d",
   "metadata": {},
   "source": [
    "# CAMELS-SPAT Large Sample Experiment Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c48153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the large sample experiment\n",
    "experiment_config = {\n",
    "    'dataset': 'camels-spat',\n",
    "    'max_watersheds': 5,\n",
    "    'dry_run': False,\n",
    "    'experiment_name': 'camelsspat_tutorial',\n",
    "    'template_config': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/config_distributed_basin_template.yaml',\n",
    "    'config_dir': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/camels_spat',\n",
    "    'camelsspat_script': '/home/darri.eythorsson/code/CONFLUENCE/9_scripts/run_watersheds_camelsspat.py',\n",
    "    'camelsspat_dir': '/work/comphyd_lab/data/_to-be-moved/camels-spat-upload/shapefiles/meso-scale/shapes-distributed',\n",
    "    'metadata_csv': 'camels-spat-metadata.csv'\n",
    "}\n",
    "\n",
    "# Create experiment directory\n",
    "experiment_dir = Path(f\"./experiments/{experiment_config['experiment_name']}\")\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "with open(experiment_dir / 'experiment_config.yaml', 'w') as f:\n",
    "    yaml.dump(experiment_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88550001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import function from the CAMELS-SPAT script to extract shapefile info\n",
    "sys.path.append(str(Path(experiment_config['camelsspat_script']).parent))\n",
    "from run_watersheds_camelsspat import extract_shapefile_info\n",
    "\n",
    "# Check if we already have watershed info cached\n",
    "watersheds_csv = experiment_dir / 'camelsspat_watersheds.csv'\n",
    "\n",
    "if watersheds_csv.exists():\n",
    "    print(f\"Loading existing watershed information\")\n",
    "    watersheds_df = pd.read_csv(watersheds_csv)\n",
    "else:\n",
    "    print(f\"Extracting watershed information...\")\n",
    "    watersheds_df = extract_shapefile_info(experiment_config['camelsspat_dir'])\n",
    "    watersheds_df.to_csv(watersheds_csv, index=False)\n",
    "\n",
    "print(f\"Found {len(watersheds_df)} watersheds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197fa216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CAMELS-SPAT metadata if available\n",
    "metadata_path = experiment_config['metadata_csv']\n",
    "\n",
    "if os.path.exists(metadata_path):\n",
    "    print(f\"Loading and merging metadata\")\n",
    "    metadata_df = pd.read_csv(metadata_path)\n",
    "    metadata_df.columns = [col.strip() for col in metadata_df.columns]\n",
    "    \n",
    "    watersheds_df['Metadata_ID'] = watersheds_df['ID'].str.replace(r'^[A-Z]+_', '', regex=True)\n",
    "    watersheds_merged = pd.merge(\n",
    "        watersheds_df, metadata_df, \n",
    "        left_on='Metadata_ID', right_on='ID',\n",
    "        how='left', suffixes=('', '_metadata')\n",
    "    )\n",
    "    watersheds_df = watersheds_merged\n",
    "else:\n",
    "    print(f\"No metadata file found. Proceeding with shapefile information only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c12ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Launch the large sample experiment\n",
    "cmd = ['python', experiment_config['camelsspat_script']]\n",
    "\n",
    "# Add command-line arguments\n",
    "if experiment_config['dry_run']:\n",
    "    cmd.extend(['--dry-run'])\n",
    "\n",
    "if experiment_config['max_watersheds'] > 0:\n",
    "    cmd.extend(['--max-watersheds', str(experiment_config['max_watersheds'])])\n",
    "\n",
    "print(f\"Launching CONFLUENCE for {experiment_config['max_watersheds']} watersheds\")\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "# Save submission log\n",
    "with open(experiment_dir / 'submission.log', 'w') as f:\n",
    "    f.write(result.stdout)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f76caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Parse submission log and check job status\n",
    "submission_log = experiment_dir / 'submission.log'\n",
    "submitted_jobs = []\n",
    "\n",
    "if submission_log.exists():\n",
    "    with open(submission_log, 'r') as f:\n",
    "        log_content = f.read()\n",
    "    \n",
    "    # Extract job submissions\n",
    "    import re\n",
    "    pattern = r'Domain: ([^,]+), Job ID: (\\d+)'\n",
    "    matches = re.findall(pattern, log_content)\n",
    "    for domain, job_id in matches:\n",
    "        submitted_jobs.append({'domain': domain, 'job_id': job_id})\n",
    "    \n",
    "    if submitted_jobs:\n",
    "        jobs_df = pd.DataFrame(submitted_jobs)\n",
    "        print(f\"Submitted {len(jobs_df)} jobs\")\n",
    "\n",
    "# Check job status\n",
    "def check_job_status(user=None):\n",
    "    user = user or os.environ.get('USER')\n",
    "    cmd = ['squeue', '-u', user]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return result.stdout\n",
    "\n",
    "print(\"\\nCurrent jobs:\")\n",
    "print(check_job_status())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aaf094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find completed watershed simulations\n",
    "confluence_data_dir = Path(\"/work/comphyd_lab/data/CONFLUENCE_data\")\n",
    "camelsspat_dir = confluence_data_dir / \"camels_spat\"\n",
    "\n",
    "completed = []\n",
    "if camelsspat_dir.exists():\n",
    "    for domain_dir in camelsspat_dir.glob(\"domain_*\"):\n",
    "        watershed_id = domain_dir.name.replace('domain_', '')\n",
    "        sim_dir = domain_dir / \"simulations\"\n",
    "        \n",
    "        if sim_dir.exists() and list(sim_dir.rglob(\"*.nc\")):\n",
    "            completed.append({\n",
    "                'watershed_id': watershed_id,\n",
    "                'domain_dir': domain_dir,\n",
    "                'sim_dir': sim_dir\n",
    "            })\n",
    "\n",
    "print(f\"Completed simulations: {len(completed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to load model outputs\n",
    "def load_summa_output(sim_dir, variable='scalarSWE'):\n",
    "    import xarray as xr\n",
    "    summa_output_dir = sim_dir / 'run_1' / 'SUMMA'\n",
    "    if not summa_output_dir.exists():\n",
    "        return None\n",
    "    output_files = list(summa_output_dir.glob(\"*timestep*.nc\"))\n",
    "    if output_files:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        if variable in ds.variables:\n",
    "            return pd.DataFrame({\n",
    "                'time': pd.to_datetime(ds.time.values),\n",
    "                'value': ds[variable].values.flatten()\n",
    "            })\n",
    "    return None\n",
    "\n",
    "def load_streamflow(sim_dir):\n",
    "    import xarray as xr\n",
    "    mizuroute_dir = sim_dir / 'run_1' / 'mizuRoute'\n",
    "    if not mizuroute_dir.exists():\n",
    "        print(f\"mizuRoute directory not found: {mizuroute_dir}\")\n",
    "        return None\n",
    "    \n",
    "    output_files = list(mizuroute_dir.glob(\"*.nc\"))\n",
    "    if not output_files:\n",
    "        print(f\"No netCDF files found in: {mizuroute_dir}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        \n",
    "        # Try to find streamflow variable\n",
    "        for var in ['IRFroutedRunoff', 'routedRunoff', 'discharge']:\n",
    "            if var in ds.variables:\n",
    "                # Check dimensions\n",
    "                var_dims = ds[var].dims\n",
    "                \n",
    "                if len(var_dims) == 1 and 'time' in var_dims:\n",
    "                    # Single dimension (time only)\n",
    "                    return pd.DataFrame({\n",
    "                        'time': pd.to_datetime(ds.time.values),\n",
    "                        'simulated': ds[var].values\n",
    "                    })\n",
    "                \n",
    "                elif len(var_dims) > 1:\n",
    "                    # Multiple dimensions (likely time and segments/reaches)\n",
    "                    time_dim = 'time'\n",
    "                    reach_dims = [d for d in var_dims if d != time_dim]\n",
    "                    \n",
    "                    if not reach_dims:\n",
    "                        print(f\"Unexpected dimensions in {var}: {var_dims}\")\n",
    "                        continue\n",
    "                    \n",
    "                    reach_dim = reach_dims[0]\n",
    "                    \n",
    "                    # Find the right reach/segment to use\n",
    "                    # If there's a single reach, use it\n",
    "                    if ds[reach_dim].size == 1:\n",
    "                        reach_idx = 0\n",
    "                    else:\n",
    "                        # TODO: Add logic to find the appropriate outlet reach\n",
    "                        # For now, use the last reach which is often the outlet\n",
    "                        reach_idx = ds[reach_dim].size - 1\n",
    "                    \n",
    "                    # Extract data for the selected reach\n",
    "                    flow_data = ds[var].isel({reach_dim: reach_idx}).values\n",
    "                    \n",
    "                    # Make sure lengths match\n",
    "                    if len(ds.time) == len(flow_data):\n",
    "                        return pd.DataFrame({\n",
    "                            'time': pd.to_datetime(ds.time.values),\n",
    "                            'simulated': flow_data\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"Length mismatch: time ({len(ds.time)}) vs flow ({len(flow_data)})\")\n",
    "        \n",
    "        print(f\"No suitable flow variable found in {output_files[0]}\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading streamflow data: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_observed_streamflow(domain_dir, watershed_id):\n",
    "    obs_dir = domain_dir / 'observations' / 'streamflow' / 'preprocessed'\n",
    "    obs_file = list(obs_dir.glob(f\"*{watershed_id}*streamflow*.csv\"))\n",
    "    \n",
    "    if obs_file:\n",
    "        obs_df = pd.read_csv(obs_file[0])\n",
    "        time_col = 'datetime' if 'datetime' in obs_df.columns else 'date'\n",
    "        flow_col = 'discharge_cms' if 'discharge_cms' in obs_df.columns else 'streamflow'\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'time': pd.to_datetime(obs_df[time_col]),\n",
    "            'observed': obs_df[flow_col]\n",
    "        })\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5d85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "def calculate_metrics(obs, sim):\n",
    "    mask = ~(np.isnan(obs) | np.isnan(sim))\n",
    "    obs, sim = obs[mask], sim[mask]\n",
    "    \n",
    "    if len(obs) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # Nash-Sutcliffe Efficiency\n",
    "    nse = 1 - np.sum((obs - sim)**2) / np.sum((obs - np.mean(obs))**2)\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(np.mean((obs - sim)**2))\n",
    "    # Percent Bias\n",
    "    pbias = 100 * np.sum(sim - obs) / np.sum(obs) if np.sum(obs) != 0 else np.nan\n",
    "    # Correlation\n",
    "    corr = np.corrcoef(obs, sim)[0, 1] if len(obs) > 1 else np.nan\n",
    "    \n",
    "    return {'NSE': nse, 'RMSE': rmse, 'PBIAS': pbias, 'Correlation': corr}\n",
    "\n",
    "# Calculate metrics for completed watersheds\n",
    "metrics_list = []\n",
    "for ws in completed:\n",
    "    sim_flow = load_streamflow(ws['sim_dir'])\n",
    "    obs_flow = load_observed_streamflow(ws['domain_dir'], ws['watershed_id'])\n",
    "    \n",
    "    if sim_flow is not None and obs_flow is not None:\n",
    "        merged = pd.merge(obs_flow, sim_flow, on='time', how='inner')\n",
    "        metrics = calculate_metrics(merged['observed'].values, merged['simulated'].values)\n",
    "        metrics['watershed_id'] = ws['watershed_id']\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "if metrics_list:\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    print(\"Performance Metrics:\")\n",
    "    print(metrics_df)\n",
    "    metrics_df.to_csv(experiment_dir / 'performance_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b417cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "if completed:\n",
    "    print(\"### CAMELS-SPAT Experiment Summary Report ###\")\n",
    "    print(f\"Experiment: {experiment_config['experiment_name']}\")\n",
    "    print(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Completed simulations: {len(completed)}\")\n",
    "    \n",
    "    if metrics_list:\n",
    "        print(\"\\nOverall Model Performance:\")\n",
    "        for metric in ['NSE', 'RMSE', 'PBIAS', 'Correlation']:\n",
    "            if metric in metrics_df.columns:\n",
    "                print(f\"  Average {metric}: {metrics_df[metric].mean():.3f}\")\n",
    "                \n",
    "    # Save report to file\n",
    "    report_path = experiment_dir / 'experiment_report.txt'\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(f\"CAMELS-SPAT Experiment Summary\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\\n\")\n",
    "        f.write(f\"Experiment: {experiment_config['experiment_name']}\\n\")\n",
    "    \n",
    "    print(f\"\\nSummary report saved to {report_path}\")\n",
    "else:\n",
    "    print(\"No completed simulations found yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
