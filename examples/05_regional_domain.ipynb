{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Regional Domain Modeling - Iceland\n",
    "\n",
    "This notebook demonstrates regional domain modeling using Iceland as an example. Unlike previous tutorials that focused on single watersheds, this example:\n",
    "\n",
    "1. **Delineates an entire region** (not just a single watershed)\n",
    "2. **Includes coastal watersheds** (watersheds that drain directly to the ocean)\n",
    "3. **Uses a bounding box** instead of a pour point\n",
    "\n",
    "## Key Differences from Previous Tutorials\n",
    "\n",
    "- **DELINEATE_BY_POURPOINT**: `False` - We're not focusing on a single outlet\n",
    "- **DELINEATE_COASTAL_WATERSHEDS**: `True` - Include watersheds draining to coast\n",
    "- **Regional scale**: Multiple independent watersheds\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand regional vs. watershed-scale modeling\n",
    "2. Learn how to delineate coastal watersheds\n",
    "3. Handle multiple independent drainage systems\n",
    "4. Work with national/regional scale domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working from: /home/darri.eythorsson/code/CONFLUENCE\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import contextily as cx\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import CONFLUENCE\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Working from: {confluence_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize CONFLUENCE\n",
    "First, let's set up our directories and load the configuration. We'll customize the Iceland configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing Iceland configuration. Loading it.\n",
      "19:37:53 - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,159 - confluence_general - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - CONFLUENCE Logging Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,160 - confluence_general - INFO - CONFLUENCE Logging Initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Domain: Iceland_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,162 - confluence_general - INFO - Domain: Iceland_tutorial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Experiment ID: tutorial_run_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,164 - confluence_general - INFO - Experiment ID: tutorial_run_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Log Level: INFO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,165 - confluence_general - INFO - Log Level: INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Log File: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/_workLog_Iceland_tutorial/confluence_general_Iceland_tutorial_20250511_193753.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,167 - confluence_general - INFO - Log File: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/_workLog_Iceland_tutorial/confluence_general_Iceland_tutorial_20250511_193753.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,169 - confluence_general - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Configuration logged to: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/_workLog_Iceland_tutorial/config_Iceland_tutorial_20250511_193753.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,197 - confluence_general - INFO - Configuration logged to: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/_workLog_Iceland_tutorial/config_Iceland_tutorial_20250511_193753.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Initializing CONFLUENCE system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,200 - confluence_general - INFO - Initializing CONFLUENCE system\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Configuration loaded from: /home/darri.eythorsson/code/CONFLUENCE/0_config_files/config_iceland_tutorial.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,202 - confluence_general - INFO - Configuration loaded from: /home/darri.eythorsson/code/CONFLUENCE/0_config_files/config_iceland_tutorial.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - Initializing VariableHandler for dataset: ERA5 and model: SUMMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,204 - confluence_general - INFO - Initializing VariableHandler for dataset: ERA5 and model: SUMMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:53 - INFO - CONFLUENCE system initialized successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:37:53,538 - confluence_general - INFO - CONFLUENCE system initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iceland Tutorial Configuration ===\n",
      "Domain Name: Iceland_tutorial\n",
      "Bounding Box: 66.56/-24.55/63.25/-13.5\n",
      "Delineate by Pour Point: False (Full region!)\n",
      "Include Coastal Watersheds: True\n",
      "Stream Threshold: 5000\n",
      "Domain Method: delineate\n",
      "\n",
      "Geographic extent:\n",
      "  North: 66.56Â°N\n",
      "  South: 63.25Â°N\n",
      "  West: -24.55Â°E\n",
      "  East: -13.5Â°E\n"
     ]
    }
   ],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # â† User should modify this path\n",
    "\n",
    "# Fallback to a local path if the default doesn't exist (for easier testing)\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    CONFLUENCE_DATA_DIR = Path('./data/CONFLUENCE_data')\n",
    "    print(f\"Using local data directory: {CONFLUENCE_DATA_DIR}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if Iceland config exists\n",
    "iceland_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_iceland.yaml'\n",
    "\n",
    "if not iceland_config_path.exists():\n",
    "    print(f\"Iceland configuration not found at {iceland_config_path}. Creating from template.\")\n",
    "    # Load template configuration as fallback\n",
    "    config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "    with open(config_template_path, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    \n",
    "    # Update with Iceland-specific settings\n",
    "    config_dict['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "    config_dict['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "    \n",
    "    # Set Iceland domain and region-specific settings\n",
    "    config_dict['DOMAIN_NAME'] = \"Iceland_region\"  \n",
    "    config_dict['EXPERIMENT_ID'] = \"regional_run_1\"\n",
    "    config_dict['EXPERIMENT_TIME_START'] = \"2018-01-01 01:00\"\n",
    "    config_dict['EXPERIMENT_TIME_END'] = \"2020-12-31 23:00\"\n",
    "    config_dict['SPATIAL_MODE'] = \"Distributed\"\n",
    "    \n",
    "    # Iceland regional domain settings\n",
    "    config_dict['BOUNDING_BOX_COORDS'] = \"66.56/-24.55/63.25/-13.5\"  # North/West/South/East\n",
    "    config_dict['POUR_POINT_COORDS'] = \"default\"  # Not needed for regional domain\n",
    "    config_dict['DELINEATE_BY_POURPOINT'] = False\n",
    "    config_dict['DELINEATE_COASTAL_WATERSHEDS'] = True\n",
    "    config_dict['DOMAIN_DEFINITION_METHOD'] = \"delineate_geofabric\" \n",
    "    config_dict['STREAM_THRESHOLD'] = 5000\n",
    "    config_dict['DOMAIN_DISCRETIZATION'] = \"GRUs\"\n",
    "    config_dict['MIN_GRU_SIZE'] = 10  # Larger minimum size for regional domain\n",
    "else:\n",
    "    print(f\"Found existing Iceland configuration. Loading it.\")\n",
    "    with open(iceland_config_path, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Create tutorial version with updated domain name\n",
    "config_dict['DOMAIN_NAME'] = \"Iceland_tutorial\"  \n",
    "config_dict['EXPERIMENT_ID'] = \"tutorial_run_1\"\n",
    "\n",
    "# Create config directory if it doesn't exist\n",
    "config_dir = CONFLUENCE_CODE_DIR / '0_config_files'\n",
    "config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write to tutorial config file\n",
    "tutorial_config_path = config_dir / 'config_iceland_tutorial.yaml'\n",
    "with open(tutorial_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f)\n",
    "\n",
    "try:\n",
    "    # Initialize CONFLUENCE with tutorial config\n",
    "    confluence = CONFLUENCE(tutorial_config_path)\n",
    "    \n",
    "    # Parse bounding box for visualization\n",
    "    bbox = config_dict['BOUNDING_BOX_COORDS'].split('/')\n",
    "    lat_max, lon_min, lat_min, lon_max = map(float, bbox)\n",
    "    \n",
    "    # Display configuration\n",
    "    print(\"=== Iceland Tutorial Configuration ===\")\n",
    "    print(f\"Domain Name: {confluence.config['DOMAIN_NAME']}\")\n",
    "    print(f\"Bounding Box: {confluence.config['BOUNDING_BOX_COORDS']}\")\n",
    "    print(f\"Delineate by Pour Point: {confluence.config['DELINEATE_BY_POURPOINT']} (Full region!)\")\n",
    "    print(f\"Include Coastal Watersheds: {confluence.config.get('DELINEATE_COASTAL_WATERSHEDS', True)}\")\n",
    "    print(f\"Stream Threshold: {confluence.config['STREAM_THRESHOLD']}\")\n",
    "    print(f\"Domain Method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "    \n",
    "    # Display geographic extent\n",
    "    print(f\"\\nGeographic extent:\")\n",
    "    print(f\"  North: {lat_max}Â°N\")\n",
    "    print(f\"  South: {lat_min}Â°N\")\n",
    "    print(f\"  West: {lon_min}Â°E\")\n",
    "    print(f\"  East: {lon_max}Â°E\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing CONFLUENCE: {str(e)}\")\n",
    "    print(\"Check that CONFLUENCE_DATA_DIR is correctly set and accessible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Project Setup\n",
    "The first step is to set up our project structure. Since we're doing a regional model, we need a different approach than for a single watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Project Initialization ===\n",
      "19:38:05 - INFO - Setting up project for domain: Iceland_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:05,067 - confluence_general - INFO - Setting up project for domain: Iceland_tutorial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:05 - INFO - Project directory created at: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:05,087 - confluence_general - INFO - Project directory created at: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial\n",
      "2025-05-11 19:38:05,107 - pyogrio._io - INFO - Created 1 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:05 - INFO - Pour point shapefile created successfully: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/pour_point/Iceland_tutorial_pourPoint.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:05,110 - confluence_general - INFO - Pour point shapefile created successfully: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/pour_point/Iceland_tutorial_pourPoint.shp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created directories:\n",
      "  ðŸ“ _workLog_Iceland_tutorial\n",
      "  ðŸ“ attributes\n",
      "  ðŸ“ documentation\n",
      "  ðŸ“ observations\n",
      "  ðŸ“ optimisation\n",
      "  ðŸ“ shapefiles\n",
      "Warning: Required directory 'forcing' not created\n",
      "Warning: Required directory 'simulations' not created\n",
      "Warning: Required directory 'evaluation' not created\n",
      "Warning: Required directory 'plots' not created\n",
      "\n",
      "Directory purposes:\n",
      "  ðŸ“ shapefiles: Domain geometry (multiple watersheds, river network)\n",
      "  ðŸ“ attributes: Static characteristics (elevation, soil, land cover)\n",
      "  ðŸ“ forcing: Meteorological inputs (precipitation, temperature)\n",
      "  ðŸ“ simulations: Model outputs\n",
      "  ðŸ“ evaluation: Performance metrics and comparisons\n",
      "  ðŸ“ plots: Visualizations\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Project Initialization\n",
    "print(\"=== Step 1: Project Initialization ===\")\n",
    "\n",
    "try:\n",
    "    # Setup project\n",
    "    project_dir = confluence.managers['project'].setup_project()    \n",
    "    pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "    # List created directories\n",
    "    print(\"\\nCreated directories:\")\n",
    "    created_dirs = []\n",
    "    for item in sorted(project_dir.iterdir()):\n",
    "        if item.is_dir():\n",
    "            created_dirs.append(item.name)\n",
    "            print(f\"  ðŸ“ {item.name}\")\n",
    "    \n",
    "    # Check if all required directories are created\n",
    "    required_dirs = ['shapefiles', 'attributes', 'forcing', 'simulations', 'evaluation', 'plots']\n",
    "    for dir_name in required_dirs:\n",
    "        if dir_name not in created_dirs:\n",
    "            print(f\"Warning: Required directory '{dir_name}' not created\")\n",
    "    \n",
    "    print(\"\\nDirectory purposes:\")\n",
    "    print(\"  ðŸ“ shapefiles: Domain geometry (multiple watersheds, river network)\")\n",
    "    print(\"  ðŸ“ attributes: Static characteristics (elevation, soil, land cover)\")\n",
    "    print(\"  ðŸ“ forcing: Meteorological inputs (precipitation, temperature)\")\n",
    "    print(\"  ðŸ“ simulations: Model outputs\")\n",
    "    print(\"  ðŸ“ evaluation: Performance metrics and comparisons\")\n",
    "    print(\"  ðŸ“ plots: Visualizations\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up project: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Geospatial Domain Definition and Analysis - Data Acquisition\n",
    "Before delineating the region, we need to acquire geospatial data (DEM, soil, land cover)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 2: Geospatial Domain Definition and Analysis ===\n",
      "Acquiring geospatial attributes (DEM, soil, land cover)...\n",
      "19:38:07 - INFO - Starting attribute acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:07,108 - confluence_general - INFO - Starting attribute acquisition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:07 - INFO - Acquiring elevation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:07,123 - confluence_general - INFO - Acquiring elevation data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract-gis.sh: WARNING! --account not provided, using `rpp-kshook` by default.\n",
      "(2025-05-12 01:38:10) merit_hydro.sh: processing MERIT-Hydro GeoTIFF(s)...\n",
      "(2025-05-12 01:38:10) merit_hydro.sh: creating cache directory under /work/comphyd_lab/users/darri/cache_Iceland_tutorial\n",
      "(2025-05-12 01:38:10) merit_hydro.sh: creating output directory under /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem\n",
      "(2025-05-12 01:38:10) merit_hydro.sh: untarring MERIT-Hydro variables under /work/comphyd_lab/users/darri/cache_Iceland_tutorial\n",
      "(2025-05-12 01:38:16) merit_hydro.sh: subsetting GeoTIFFs under /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜/home/darri.eythorsson/empty_dirâ€™: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025-05-12 01:38:21) merit_hydro.sh: deleting temporary files from /work/comphyd_lab/users/darri/cache_Iceland_tutorial\n",
      "(2025-05-12 01:38:21) merit_hydro.sh: temporary files from /work/comphyd_lab/users/darri/cache_Iceland_tutorial are removed\n",
      "(2025-05-12 01:38:21) merit_hydro.sh: results are produced under /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem\n",
      "19:38:21 - INFO - gistool completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:21,848 - confluence_general - INFO - gistool completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:21 - INFO - Geospatial data acquisition process completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:21,850 - confluence_general - INFO - Geospatial data acquisition process completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:21 - INFO - Acquiring land cover data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:21,852 - confluence_general - INFO - Acquiring land cover data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract-gis.sh: WARNING! --account not provided, using `rpp-kshook` by default.\n",
      "(2025-05-12 01:38:25) modis.sh: processing MODIS HDF(s)...\n",
      "(2025-05-12 01:38:25) modis.sh: creating cache directory under /work/comphyd_lab/users/darri/cache_Iceland_tutorial\n",
      "(2025-05-12 01:38:25) modis.sh: creating output directory under /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/landclass\n",
      "(2025-05-12 01:38:25) modis.sh: building virtual format (.vrt) of MODIS HDFs under /work/comphyd_lab/users/darri/cache_Iceland_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n",
      "ERROR 1: PROJ: sinu: Invalid latitude\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Acquire attributes\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAcquiring geospatial attributes (DEM, soil, land cover)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mconfluence\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanagers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Check if attributes were created\u001b[39;00m\n\u001b[32m     10\u001b[39m     dem_dir = project_dir / \u001b[33m'\u001b[39m\u001b[33mattributes\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33melevation\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mdem\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/CONFLUENCE/utils/data/data_manager.py:114\u001b[39m, in \u001b[36mDataManager.acquire_attributes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28mself\u001b[39m._acquire_elevation_data(gr, dem_dir, latlims, lonlims)\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Acquire land cover data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire_landcover_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlandclass_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatlims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlonlims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Acquire soil class data\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m._acquire_soilclass_data(gr, soilclass_dir, latlims, lonlims)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/CONFLUENCE/utils/data/data_manager.py:195\u001b[39m, in \u001b[36mDataManager._acquire_landcover_data\u001b[39m\u001b[34m(self, gistool_runner, output_dir, lat_lims, lon_lims)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# Create gistool command\u001b[39;00m\n\u001b[32m    186\u001b[39m gistool_command = gistool_runner.create_gistool_command(\n\u001b[32m    187\u001b[39m     dataset=\u001b[33m'\u001b[39m\u001b[33mMODIS\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    188\u001b[39m     output_dir=output_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     end_date=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-01-01\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    194\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[43mgistool_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_gistool_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgistool_command\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# Calculate mode if multiple years selected\u001b[39;00m\n\u001b[32m    198\u001b[39m land_name = \u001b[38;5;28mself\u001b[39m.config.get(\u001b[33m'\u001b[39m\u001b[33mLAND_CLASS_NAME\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/CONFLUENCE/utils/data/data_utils.py:972\u001b[39m, in \u001b[36mgistoolRunner.execute_gistool_command\u001b[39m\u001b[34m(self, gistool_command)\u001b[39m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_gistool_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, gistool_command):\n\u001b[32m    969\u001b[39m     \n\u001b[32m    970\u001b[39m     \u001b[38;5;66;03m#Run the gistool command\u001b[39;00m\n\u001b[32m    971\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m         \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgistool_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    973\u001b[39m         \u001b[38;5;28mself\u001b[39m.logger.info(\u001b[33m\"\u001b[39m\u001b[33mgistool completed successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/local/modules/spack/2024v5/core/__spack_path_placeholder__/__spack_path_placeholder__/__spack_path_placeholder/linux-rocky8-x86_64/gcc-14.2.0/python-3.11.7-kydrhvi3xotycebna2knxwhwha3ffygj/lib/python3.11/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/local/modules/spack/2024v5/core/__spack_path_placeholder__/__spack_path_placeholder__/__spack_path_placeholder/linux-rocky8-x86_64/gcc-14.2.0/python-3.11.7-kydrhvi3xotycebna2knxwhwha3ffygj/lib/python3.11/subprocess.py:1201\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1199\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1200\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/local/modules/spack/2024v5/core/__spack_path_placeholder__/__spack_path_placeholder__/__spack_path_placeholder/linux-rocky8-x86_64/gcc-14.2.0/python-3.11.7-kydrhvi3xotycebna2knxwhwha3ffygj/lib/python3.11/subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/local/modules/spack/2024v5/core/__spack_path_placeholder__/__spack_path_placeholder__/__spack_path_placeholder/linux-rocky8-x86_64/gcc-14.2.0/python-3.11.7-kydrhvi3xotycebna2knxwhwha3ffygj/lib/python3.11/subprocess.py:2046\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2044\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2045\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2046\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2047\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2048\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2049\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/local/modules/spack/2024v5/core/__spack_path_placeholder__/__spack_path_placeholder__/__spack_path_placeholder/linux-rocky8-x86_64/gcc-14.2.0/python-3.11.7-kydrhvi3xotycebna2knxwhwha3ffygj/lib/python3.11/subprocess.py:2004\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2002\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2004\u001b[39m     (pid, sts) = os.waitpid(\u001b[38;5;28mself\u001b[39m.pid, wait_flags)\n\u001b[32m   2005\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2006\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2007\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2008\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2009\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Step 2: Geospatial Domain Definition and Analysis\n",
    "print(\"=== Step 2: Geospatial Domain Definition and Analysis ===\")\n",
    "\n",
    "try:\n",
    "    # Acquire attributes\n",
    "    print(\"Acquiring geospatial attributes (DEM, soil, land cover)...\")\n",
    "    confluence.managers['data'].acquire_attributes()\n",
    "    \n",
    "    # Check if attributes were created\n",
    "    dem_dir = project_dir / 'attributes' / 'elevation' / 'dem'\n",
    "    soilclass_dir = project_dir / 'attributes' / 'soilclass'\n",
    "    landclass_dir = project_dir / 'attributes' / 'landclass'\n",
    "    \n",
    "    if dem_dir.exists() and any(dem_dir.glob('*.tif')):\n",
    "        print(\"âœ“ DEM data acquired successfully\")\n",
    "    else:\n",
    "        print(\"âš  DEM data acquisition may have failed\")\n",
    "        \n",
    "    if soilclass_dir.exists() and any(soilclass_dir.glob('*.tif')):\n",
    "        print(\"âœ“ Soil class data acquired successfully\")\n",
    "    else:\n",
    "        print(\"âš  Soil class data acquisition may have failed\")\n",
    "        \n",
    "    if landclass_dir.exists() and any(landclass_dir.glob('*.tif')):\n",
    "        print(\"âœ“ Land cover data acquired successfully\")\n",
    "    else:\n",
    "        print(\"âš  Land cover data acquisition may have failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error acquiring attributes: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regional Domain Delineation\n",
    "This is the critical step where we delineate the entire region, including coastal watersheds. This is different from the single-watershed approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delineating regional domain using method: delineate\n",
      "Delineate by pour point: False (Full region!)\n",
      "Include coastal watersheds: True\n",
      "Stream threshold: 5000\n",
      "\n",
      "This will create multiple independent drainage basins...\n",
      "19:38:33 - INFO - Domain definition workflow starting with: delineate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:33,344 - confluence_general - INFO - Domain definition workflow starting with: delineate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:33 - INFO - Starting geofabric delineation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:33,346 - confluence_general - INFO - Starting geofabric delineation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:33 - INFO - Geofabric delineation completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:33,348 - confluence_general - INFO - Geofabric delineation completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:33 - INFO - Starting geofabric delineation for Iceland_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:33,350 - confluence_general - INFO - Starting geofabric delineation for Iceland_tutorial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:33 - INFO - Created interim directory: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:33,363 - confluence_general - INFO - Created interim directory: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:33 - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/pitremove -z /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem/domain_Iceland_tutorial_elv.tif -fel /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:33,367 - confluence_general - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/pitremove -z /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem/domain_Iceland_tutorial_elv.tif -fel /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:45 - INFO - Command output: On input demfile: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem/domain_Iceland_tutorial_elv.tif\n",
      "On input newfile: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif\n",
      "Not Using mask file: N/A\n",
      "PitRemove version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem/domain_Iceland_tutorial_elv.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -9999.000000\n",
      "Nodata value recast to float used in partition raster: -9999.000000\n",
      "Header read\n",
      "Process: 0, totalX: 13260, totalY: 3972\n",
      "Process: 0, nx: 13260, ny: 3972\n",
      "Process: 0, xstart: 0, ystart: 0\n",
      "Data read\n",
      "Midpoint of partition: 0, nxm: 6630, nym: 1986, value: 969.400024\n",
      "Planchon grid initialized rank: 0\n",
      "Rank: 0, Stack size: 102\n",
      "Rank: 0, Stack size: 100102\n",
      "Rank: 0, Stack size: 200102\n",
      "Rank: 0, Stack size: 300102\n",
      "Rank: 0, Stack size: 400102\n",
      "Rank: 0, Stack size: 500102\n",
      "Rank: 0, Stack size: 600102\n",
      "Rank: 0, Stack size: 700102\n",
      "Rank: 0, Stack size: 800102\n",
      "Rank: 0, Stack size: 900102\n",
      "Rank: 0, Stack size: 1000102\n",
      "Rank: 0, Stack size: 1100102\n",
      "Rank: 0, Stack size: 1200102\n",
      "Rank: 0, Stack size: 1300102\n",
      "Rank: 0, Stack size: 1400102\n",
      "Rank: 0, Stack size: 1500102\n",
      "Rank: 0, Stack size: 1600102\n",
      "Rank: 0, Stack size: 1700102\n",
      "Rank: 0, Stack size: 1800102\n",
      "Rank: 0, Stack size: 1900102\n",
      "Rank: 0, Stack size: 2000102\n",
      "Rank: 0, Stack size: 2100102\n",
      "Rank: 0, Stack size: 2200102\n",
      "Rank: 0, Stack size: 2300102\n",
      "Rank: 0, Stack size: 2400102\n",
      "Rank: 0, Stack size: 2500102\n",
      "Rank: 0, Stack size: 2600102\n",
      "Rank: 0, Stack size: 2700102\n",
      "Rank: 0, Stack size: 2800102\n",
      "Rank: 0, Stack size: 2900102\n",
      "Rank: 0, Stack size: 3000102\n",
      "Rank: 0, Stack size: 3100102\n",
      "Rank: 0, Stack size: 3200102\n",
      "Rank: 0, Stack size: 3300102\n",
      "Rank: 0, Stack size: 3400102\n",
      "Rank: 0, Stack size: 3500102\n",
      "Rank: 0, Stack size: 3600102\n",
      "Rank: 0, Stack size: 3700102\n",
      "Rank: 0, Stack size: 3800102\n",
      "Rank: 0, Stack size: 3900102\n",
      "Rank: 0, Stack size: 4000102\n",
      "Rank: 0, Stack size: 4100102\n",
      "Rank: 0, Stack size: 4200102\n",
      "Rank: 0, Stack size: 4300102\n",
      "Rank: 0, Stack size: 4400102\n",
      "Rank: 0, Stack size: 4500102\n",
      "Rank: 0, Stack size: 4600102\n",
      "Rank: 0, Stack size: 4700102\n",
      "Rank: 0, Stack size: 4800102\n",
      "Rank: 0, Stack size: 4900102\n",
      "Rank: 0, Stack size: 5000102\n",
      "Rank: 0, Stack size: 5100102\n",
      "Rank: 0, Stack size: 5200102\n",
      "Rank: 0, Stack size: 5300102\n",
      "Rank: 0, Stack size: 5400102\n",
      "Rank: 0, Stack size: 5500102\n",
      "Rank: 0, Stack size: 5600102\n",
      "Rank: 0, Stack size: 5700102\n",
      "Rank: 0, Stack size: 5800102\n",
      "Rank: 0, Stack size: 5900102\n",
      "Rank: 0, Stack size: 6000102\n",
      "Rank: 0, Stack size: 6100102\n",
      "Rank: 0, Stack size: 6200102\n",
      "Rank: 0, Stack size: 6300102\n",
      "Rank: 0, Stack size: 6400102\n",
      "Rank: 0, Stack size: 6500102\n",
      "Rank: 0, Stack size: 6600102\n",
      "Rank: 0, Stack size: 6700102\n",
      "Rank: 0, Stack size: 6800102\n",
      "Rank: 0, Stack size: 6900102\n",
      "Rank: 0, Stack size: 7000102\n",
      "Rank: 0, Stack size: 7100102\n",
      "Rank: 0, Stack size: 7200102\n",
      "Rank: 0, Stack size: 7300102\n",
      "Rank: 0, Stack size: 7400102\n",
      "Rank: 0, Stack size: 7500102\n",
      "Rank: 0, Stack size: 7600102\n",
      "Rank: 0, Stack size: 7700102\n",
      "Rank: 0, Stack size: 7800102\n",
      "Rank: 0, Stack size: 7900102\n",
      "Rank: 0, Stack size: 8000102\n",
      "Rank: 0, Stack size: 8100102\n",
      "Rank: 0, Stack size: 8200102\n",
      "Rank: 0, Stack size: 8300102\n",
      "Rank: 0, Stack size: 8400102\n",
      "Rank: 0, Stack size: 8500102\n",
      "Rank: 0, Stack size: 8600102\n",
      "Rank: 0, Stack size: 8700102\n",
      "Rank: 0, Stack size: 8800102\n",
      "Rank: 0, Stack size: 8900102\n",
      "Rank: 0, Stack size: 9000102\n",
      "Rank: 0, Stack size: 9100102\n",
      "Rank: 0, Stack size: 9200102\n",
      "Rank: 0, Stack size: 9300102\n",
      "Rank: 0, Stack size: 9400102\n",
      "Rank: 0, Stack size: 9500102\n",
      "Rank: 0, Stack size: 9600102\n",
      "Rank: 0, Stack size: 9700102\n",
      "Rank: 0, Stack size: 9800102\n",
      "Rank: 0, Stack size: 9900102\n",
      "Rank: 0, Stack size: 10000102\n",
      "Rank: 0, Stack size: 10100102\n",
      "Rank: 0, Stack size: 10200102\n",
      "Rank: 0, Stack size: 10300102\n",
      "Rank: 0, Stack size: 10400102\n",
      "Rank: 0, Stack size: 10500102\n",
      "Rank: 0, Stack size: 10600102\n",
      "Rank: 0, Stack size: 10700102\n",
      "Rank: 0, Stack size: 10800102\n",
      "Rank: 0, Stack size: 10900102\n",
      "Rank: 0, Stack size: 11000102\n",
      "Rank: 0, Stack size: 11100102\n",
      "Rank: 0, Stack size: 11200102\n",
      "Rank: 0, Stack size: 11300102\n",
      "Rank: 0, Stack size: 11400102\n",
      "Rank: 0, Stack size: 11500102\n",
      "Rank: 0, Stack size: 11600102\n",
      "Rank: 0, Stack size: 11700102\n",
      "Rank: 0, Stack size: 11800102\n",
      "Rank: 0, Stack size: 11900102\n",
      "Rank: 0, Stack size: 12000102\n",
      "Rank: 0, Stack size: 12100102\n",
      "Rank: 0, Stack size: 12200102\n",
      "Rank: 0, Stack size: 12300102\n",
      "Rank: 0, Stack size: 12400102\n",
      "Rank: 0, Stack size: 12500102\n",
      "Rank: 0, Stack size: 12600102\n",
      "Rank: 0, Stack size: 12700102\n",
      "Rank: 0, Stack size: 12800102\n",
      "Rank: 0, Stack size: 12900102\n",
      "Rank: 0, Stack size: 13000102\n",
      "Rank: 0, Stack size: 13100102\n",
      "Rank: 0, Stack size: 13200102\n",
      "Rank: 0, Stack size: 13300102\n",
      "Rank: 0, Stack size: 13400102\n",
      "Rank: 0, Stack size: 13500102\n",
      "Rank: 0, Stack size: 13600102\n",
      "Rank: 0, Stack size: 13700102\n",
      "Rank: 0, Stack size: 13800102\n",
      "Rank: 0, Stack size: 13900102\n",
      "Rank: 0, Stack size: 14000102\n",
      "Rank: 0, Stack size: 14100102\n",
      "Rank: 0, Stack size: 14200102\n",
      "Rank: 0, Stack size: 14300102\n",
      "Rank: 0, Stack size: 14400102\n",
      "Rank: 0, Stack size: 14500102\n",
      "Rank: 0, Stack size: 14600102\n",
      "Rank: 0, Stack size: 14700102\n",
      "Rank: 0, Stack size: 14800102\n",
      "Rank: 0, Stack size: 14900102\n",
      "Rank: 0, Stack size: 15000102\n",
      "Rank: 0, Stack size: 15100102\n",
      "Rank: 0, Stack size: 15200102\n",
      "Rank: 0, Stack size: 15300102\n",
      "Rank: 0, Stack size: 15400102\n",
      "Rank: 0, Stack size: 15500102\n",
      "Rank: 0, Stack size: 15600102\n",
      "Rank: 0, Stack size: 15700102\n",
      "Rank: 0, Stack size: 15800102\n",
      "Rank: 0, Stack size: 15900102\n",
      "Rank: 0, Stack size: 16000102\n",
      "Rank: 0, Stack size: 16100102\n",
      "Rank: 0, Stack size: 16200102\n",
      "Rank: 0, Stack size: 16300102\n",
      "Rank: 0, Stack size: 16400102\n",
      "Rank: 0, Stack size: 16500102\n",
      "Rank: 0, Stack size: 16600102\n",
      "Rank: 0, Stack size: 16700102\n",
      "Rank: 0, Stack size: 16800102\n",
      "Rank: 0, Stack size: 16900102\n",
      "Rank: 0, Stack size: 17000102\n",
      "Rank: 0, Stack size: 17100102\n",
      "Rank: 0, Stack size: 17200102\n",
      "Rank: 0, Stack size: 17300102\n",
      "Rank: 0, Stack size: 17400102\n",
      "Rank: 0, Stack size: 17500102\n",
      "Rank: 0, Stack size: 17600102\n",
      "Rank: 0, Stack size: 17700102\n",
      "Rank: 0, Stack size: 17800102\n",
      "Rank: 0, Stack size: 17900102\n",
      "Rank: 0, Stack size: 18000102\n",
      "Rank: 0, Stack size: 18100102\n",
      "Rank: 0, Stack size: 18200102\n",
      "Rank: 0, Stack size: 18300102\n",
      "Rank: 0, Stack size: 18400102\n",
      "Rank: 0, Stack size: 18500102\n",
      "Rank: 0, Stack size: 18600102\n",
      "Rank: 0, Stack size: 18700102\n",
      "Rank: 0, Stack size: 18800102\n",
      "Rank: 0, Stack size: 18900102\n",
      "Rank: 0, Stack size: 19000102\n",
      "Rank: 0, Stack size: 19100102\n",
      "Rank: 0, Stack size: 19200102\n",
      "Rank: 0, Stack size: 19300102\n",
      "Rank: 0, Stack size: 19400102\n",
      "Rank: 0, Stack size: 19500102\n",
      "Rank: 0, Stack size: 19600102\n",
      "Rank: 0, Stack size: 19700102\n",
      "Rank: 0, Stack size: 19800102\n",
      "Rank: 0, Stack size: 19900102\n",
      "Rank: 0, Stack size: 20000102\n",
      "Rank: 0, Stack size: 20100102\n",
      "Rank: 0, Stack size: 20200102\n",
      "Rank: 0, Stack size: 20300102\n",
      "Rank: 0, Stack size: 20400102\n",
      "Rank: 0, Stack size: 20500102\n",
      "Rank: 0, Stack size: 20600102\n",
      "Rank: 0, Stack size: 20700102\n",
      "Rank: 0, Stack size: 20800102\n",
      "Rank: 0, Stack size: 20900102\n",
      "Rank: 0, Stack size: 21000102\n",
      "Rank: 0, Stack size: 21100102\n",
      "Rank: 0, Stack size: 21200102\n",
      "Rank: 0, Stack size: 21300102\n",
      "Rank: 0, Stack size: 21400102\n",
      "Rank: 0, Stack size: 21500102\n",
      "Rank: 0, Stack size: 21600102\n",
      "Rank: 0, Stack size: 21700102\n",
      "Rank: 0, Stack size: 21800102\n",
      "Rank: 0, Stack size: 21900102\n",
      "Rank: 0, Stack size: 22000102\n",
      "Rank: 0, Stack size: 22100102\n",
      "Rank: 0, Stack size: 22200102\n",
      "Rank: 0, Stack size: 22300102\n",
      "Rank: 0, Stack size: 22400102\n",
      "Rank: 0, Stack size: 22500102\n",
      "Rank: 0, Stack size: 22600102\n",
      "Rank: 0, Stack size: 22700102\n",
      "Rank: 0, Stack size: 22800102\n",
      "Rank: 0, Stack size: 22900102\n",
      "Rank: 0, Stack size: 23000102\n",
      "Rank: 0, Stack size: 23100102\n",
      "Rank: 0, Stack size: 23200102\n",
      "Rank: 0, Stack size: 23300102\n",
      "Rank: 0, Stack size: 23400102\n",
      "Rank: 0, Stack size: 23500102\n",
      "Rank: 0, Stack size: 23600102\n",
      "Rank: 0, Stack size: 23700102\n",
      "Rank: 0, Stack size: 23800102\n",
      "Rank: 0, Stack size: 23900102\n",
      "Rank: 0, Stack size: 24000102\n",
      "Rank: 0, Stack size: 24100102\n",
      "Rank: 0, Stack size: 24200102\n",
      "Rank: 0, Stack size: 24300102\n",
      "Rank: 0, Stack size: 24400102\n",
      "Rank: 0, Stack size: 24500102\n",
      "Rank: 0, Stack size: 24600102\n",
      "Rank: 0, Stack size: 24700102\n",
      "Rank: 0, Stack size: 24800102\n",
      "Rank: 0, Stack size: 24900102\n",
      "Rank: 0, Stack size: 25000102\n",
      "Rank: 0, Stack size: 25100102\n",
      "Rank: 0, Stack size: 25200102\n",
      "Rank: 0, Stack size: 25300102\n",
      "Rank: 0, Stack size: 25400102\n",
      "Rank: 0, Stack size: 25500102\n",
      "Rank: 0, Stack size: 25600102\n",
      "Rank: 0, Stack size: 25700102\n",
      "Rank: 0, Stack size: 25800102\n",
      "Rank: 0, Stack size: 25900102\n",
      "Rank: 0, Stack size: 26000102\n",
      "Rank: 0, Stack size: 26100102\n",
      "Rank: 0, Stack size: 26200102\n",
      "Rank: 0, Stack size: 26300102\n",
      "Rank: 0, Stack size: 26400102\n",
      "Rank: 0, Stack size: 26500102\n",
      "Rank: 0, Stack size: 26600102\n",
      "Rank: 0, Stack size: 26700102\n",
      "Process: 0, Pass: 1, Remaining: 26762824\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Rank: 0, Stack 2 size: 900102\n",
      "Rank: 0, Stack 2 size: 1000102\n",
      "Rank: 0, Stack 2 size: 1100102\n",
      "Rank: 0, Stack 2 size: 1200102\n",
      "Rank: 0, Stack 2 size: 1300102\n",
      "Rank: 0, Stack 2 size: 1400102\n",
      "Rank: 0, Stack 2 size: 1500102\n",
      "Rank: 0, Stack 2 size: 1600102\n",
      "Rank: 0, Stack 2 size: 1700102\n",
      "Rank: 0, Stack 2 size: 1800102\n",
      "Rank: 0, Stack 2 size: 1900102\n",
      "Rank: 0, Stack 2 size: 2000102\n",
      "Rank: 0, Stack 2 size: 2100102\n",
      "Rank: 0, Stack 2 size: 2200102\n",
      "Rank: 0, Stack 2 size: 2300102\n",
      "Rank: 0, Stack 2 size: 2400102\n",
      "Rank: 0, Stack 2 size: 2500102\n",
      "Rank: 0, Stack 2 size: 2600102\n",
      "Rank: 0, Stack 2 size: 2700102\n",
      "Rank: 0, Stack 2 size: 2800102\n",
      "Rank: 0, Stack 2 size: 2900102\n",
      "Rank: 0, Stack 2 size: 3000102\n",
      "Rank: 0, Stack 2 size: 3100102\n",
      "Rank: 0, Stack 2 size: 3200102\n",
      "Rank: 0, Stack 2 size: 3300102\n",
      "Rank: 0, Stack 2 size: 3400102\n",
      "Rank: 0, Stack 2 size: 3500102\n",
      "Rank: 0, Stack 2 size: 3600102\n",
      "Rank: 0, Stack 2 size: 3700102\n",
      "Rank: 0, Stack 2 size: 3800102\n",
      "Rank: 0, Stack 2 size: 3900102\n",
      "Rank: 0, Stack 2 size: 4000102\n",
      "Rank: 0, Stack 2 size: 4100102\n",
      "Rank: 0, Stack 2 size: 4200102\n",
      "Rank: 0, Stack 2 size: 4300102\n",
      "Rank: 0, Stack 2 size: 4400102\n",
      "Rank: 0, Stack 2 size: 4500102\n",
      "Rank: 0, Stack 2 size: 4600102\n",
      "Rank: 0, Stack 2 size: 4700102\n",
      "Rank: 0, Stack 2 size: 4800102\n",
      "Rank: 0, Stack 2 size: 4900102\n",
      "Rank: 0, Stack 2 size: 5000102\n",
      "Rank: 0, Stack 2 size: 5100102\n",
      "Rank: 0, Stack 2 size: 5200102\n",
      "Rank: 0, Stack 2 size: 5300102\n",
      "Rank: 0, Stack 2 size: 5400102\n",
      "Rank: 0, Stack 2 size: 5500102\n",
      "Rank: 0, Stack 2 size: 5600102\n",
      "Rank: 0, Stack 2 size: 5700102\n",
      "Rank: 0, Stack 2 size: 5800102\n",
      "Rank: 0, Stack 2 size: 5900102\n",
      "Rank: 0, Stack 2 size: 6000102\n",
      "Rank: 0, Stack 2 size: 6100102\n",
      "Rank: 0, Stack 2 size: 6200102\n",
      "Rank: 0, Stack 2 size: 6300102\n",
      "Rank: 0, Stack 2 size: 6400102\n",
      "Rank: 0, Stack 2 size: 6500102\n",
      "Rank: 0, Stack 2 size: 6600102\n",
      "Rank: 0, Stack 2 size: 6700102\n",
      "Rank: 0, Stack 2 size: 6800102\n",
      "Rank: 0, Stack 2 size: 6900102\n",
      "Rank: 0, Stack 2 size: 7000102\n",
      "Rank: 0, Stack 2 size: 7100102\n",
      "Rank: 0, Stack 2 size: 7200102\n",
      "Rank: 0, Stack 2 size: 7300102\n",
      "Rank: 0, Stack 2 size: 7400102\n",
      "Rank: 0, Stack 2 size: 7500102\n",
      "Rank: 0, Stack 2 size: 7600102\n",
      "Rank: 0, Stack 2 size: 7700102\n",
      "Rank: 0, Stack 2 size: 7800102\n",
      "Process: 0, Pass: 2, Remaining: 7858970\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Rank: 0, Stack 1 size: 700102\n",
      "Rank: 0, Stack 1 size: 800102\n",
      "Rank: 0, Stack 1 size: 900102\n",
      "Rank: 0, Stack 1 size: 1000102\n",
      "Rank: 0, Stack 1 size: 1100102\n",
      "Rank: 0, Stack 1 size: 1200102\n",
      "Rank: 0, Stack 1 size: 1300102\n",
      "Rank: 0, Stack 1 size: 1400102\n",
      "Rank: 0, Stack 1 size: 1500102\n",
      "Rank: 0, Stack 1 size: 1600102\n",
      "Rank: 0, Stack 1 size: 1700102\n",
      "Rank: 0, Stack 1 size: 1800102\n",
      "Rank: 0, Stack 1 size: 1900102\n",
      "Rank: 0, Stack 1 size: 2000102\n",
      "Rank: 0, Stack 1 size: 2100102\n",
      "Rank: 0, Stack 1 size: 2200102\n",
      "Rank: 0, Stack 1 size: 2300102\n",
      "Rank: 0, Stack 1 size: 2400102\n",
      "Rank: 0, Stack 1 size: 2500102\n",
      "Rank: 0, Stack 1 size: 2600102\n",
      "Rank: 0, Stack 1 size: 2700102\n",
      "Rank: 0, Stack 1 size: 2800102\n",
      "Rank: 0, Stack 1 size: 2900102\n",
      "Rank: 0, Stack 1 size: 3000102\n",
      "Rank: 0, Stack 1 size: 3100102\n",
      "Rank: 0, Stack 1 size: 3200102\n",
      "Rank: 0, Stack 1 size: 3300102\n",
      "Rank: 0, Stack 1 size: 3400102\n",
      "Rank: 0, Stack 1 size: 3500102\n",
      "Rank: 0, Stack 1 size: 3600102\n",
      "Rank: 0, Stack 1 size: 3700102\n",
      "Rank: 0, Stack 1 size: 3800102\n",
      "Process: 0, Pass: 3, Remaining: 3868986\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Rank: 0, Stack 2 size: 900102\n",
      "Rank: 0, Stack 2 size: 1000102\n",
      "Rank: 0, Stack 2 size: 1100102\n",
      "Rank: 0, Stack 2 size: 1200102\n",
      "Rank: 0, Stack 2 size: 1300102\n",
      "Rank: 0, Stack 2 size: 1400102\n",
      "Rank: 0, Stack 2 size: 1500102\n",
      "Rank: 0, Stack 2 size: 1600102\n",
      "Rank: 0, Stack 2 size: 1700102\n",
      "Rank: 0, Stack 2 size: 1800102\n",
      "Rank: 0, Stack 2 size: 1900102\n",
      "Rank: 0, Stack 2 size: 2000102\n",
      "Rank: 0, Stack 2 size: 2100102\n",
      "Rank: 0, Stack 2 size: 2200102\n",
      "Rank: 0, Stack 2 size: 2300102\n",
      "Rank: 0, Stack 2 size: 2400102\n",
      "Process: 0, Pass: 4, Remaining: 2463702\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Rank: 0, Stack 1 size: 700102\n",
      "Rank: 0, Stack 1 size: 800102\n",
      "Rank: 0, Stack 1 size: 900102\n",
      "Rank: 0, Stack 1 size: 1000102\n",
      "Rank: 0, Stack 1 size: 1100102\n",
      "Rank: 0, Stack 1 size: 1200102\n",
      "Rank: 0, Stack 1 size: 1300102\n",
      "Rank: 0, Stack 1 size: 1400102\n",
      "Rank: 0, Stack 1 size: 1500102\n",
      "Rank: 0, Stack 1 size: 1600102\n",
      "Rank: 0, Stack 1 size: 1700102\n",
      "Process: 0, Pass: 5, Remaining: 1747540\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Rank: 0, Stack 2 size: 900102\n",
      "Rank: 0, Stack 2 size: 1000102\n",
      "Rank: 0, Stack 2 size: 1100102\n",
      "Rank: 0, Stack 2 size: 1200102\n",
      "Rank: 0, Stack 2 size: 1300102\n",
      "Process: 0, Pass: 6, Remaining: 1306050\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Rank: 0, Stack 1 size: 700102\n",
      "Rank: 0, Stack 1 size: 800102\n",
      "Rank: 0, Stack 1 size: 900102\n",
      "Rank: 0, Stack 1 size: 1000102\n",
      "Process: 0, Pass: 7, Remaining: 1025366\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Process: 0, Pass: 8, Remaining: 840956\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Process: 0, Pass: 9, Remaining: 697894\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Process: 0, Pass: 10, Remaining: 595484\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Process: 0, Pass: 11, Remaining: 510794\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Process: 0, Pass: 12, Remaining: 446002\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Process: 0, Pass: 13, Remaining: 391650\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Process: 0, Pass: 14, Remaining: 347902\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Process: 0, Pass: 15, Remaining: 311300\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Process: 0, Pass: 16, Remaining: 277160\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Process: 0, Pass: 17, Remaining: 229184\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 18, Remaining: 198154\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Process: 0, Pass: 19, Remaining: 175220\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 20, Remaining: 160444\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Process: 0, Pass: 21, Remaining: 145214\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 22, Remaining: 134382\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Process: 0, Pass: 23, Remaining: 122868\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 24, Remaining: 112044\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 25, Remaining: 98666\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 26, Remaining: 89316\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 27, Remaining: 80750\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 28, Remaining: 73674\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 29, Remaining: 66732\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 30, Remaining: 60662\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 31, Remaining: 56094\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 32, Remaining: 52686\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 33, Remaining: 47384\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 34, Remaining: 43306\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 35, Remaining: 38454\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 36, Remaining: 36586\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 37, Remaining: 34644\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 38, Remaining: 33040\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 39, Remaining: 31492\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 40, Remaining: 29594\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 41, Remaining: 27662\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 42, Remaining: 26334\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 43, Remaining: 19356\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 44, Remaining: 18492\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 45, Remaining: 17454\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 46, Remaining: 16616\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 47, Remaining: 15682\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 48, Remaining: 14586\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 49, Remaining: 12968\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 50, Remaining: 11954\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 51, Remaining: 11248\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 52, Remaining: 10490\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 53, Remaining: 10084\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 54, Remaining: 9852\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 55, Remaining: 9704\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 56, Remaining: 8228\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 57, Remaining: 6138\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 58, Remaining: 3354\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 59, Remaining: 1170\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 60, Remaining: 1106\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 61, Remaining: 1014\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 62, Remaining: 822\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 63, Remaining: 650\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 64, Remaining: 574\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 65, Remaining: 486\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 66, Remaining: 352\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 67, Remaining: 226\n",
      "Process: 0, Pass: 68, Remaining: 74\n",
      "Process: 0, Pass: 69, Remaining: 32\n",
      "Process: 0, Pass: 70, Remaining: 28\n",
      "Process: 0, Pass: 71, Remaining: 14\n",
      "Process: 0, Pass: 72, Remaining: 10\n",
      "Process: 0, Pass: 73, Remaining: 4\n",
      "Process: 0, Pass: 74, Remaining: 0\n",
      "Process: 0, Pass: 75, Remaining: 0\n",
      "About to write\n",
      "Result midpoint of partition: 0, nxm: 6630, nym: 1986, value: 969.400024\n",
      "Partition: 0, written\n",
      "Processes: 1\n",
      "Header read time: 0.248803\n",
      "Data read time: 0.795047\n",
      "Compute time: 7.189317\n",
      "Write time: 2.941426\n",
      "Total time: 11.174593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:45,087 - confluence_general - INFO - Command output: On input demfile: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem/domain_Iceland_tutorial_elv.tif\n",
      "On input newfile: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif\n",
      "Not Using mask file: N/A\n",
      "PitRemove version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/attributes/elevation/dem/domain_Iceland_tutorial_elv.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -9999.000000\n",
      "Nodata value recast to float used in partition raster: -9999.000000\n",
      "Header read\n",
      "Process: 0, totalX: 13260, totalY: 3972\n",
      "Process: 0, nx: 13260, ny: 3972\n",
      "Process: 0, xstart: 0, ystart: 0\n",
      "Data read\n",
      "Midpoint of partition: 0, nxm: 6630, nym: 1986, value: 969.400024\n",
      "Planchon grid initialized rank: 0\n",
      "Rank: 0, Stack size: 102\n",
      "Rank: 0, Stack size: 100102\n",
      "Rank: 0, Stack size: 200102\n",
      "Rank: 0, Stack size: 300102\n",
      "Rank: 0, Stack size: 400102\n",
      "Rank: 0, Stack size: 500102\n",
      "Rank: 0, Stack size: 600102\n",
      "Rank: 0, Stack size: 700102\n",
      "Rank: 0, Stack size: 800102\n",
      "Rank: 0, Stack size: 900102\n",
      "Rank: 0, Stack size: 1000102\n",
      "Rank: 0, Stack size: 1100102\n",
      "Rank: 0, Stack size: 1200102\n",
      "Rank: 0, Stack size: 1300102\n",
      "Rank: 0, Stack size: 1400102\n",
      "Rank: 0, Stack size: 1500102\n",
      "Rank: 0, Stack size: 1600102\n",
      "Rank: 0, Stack size: 1700102\n",
      "Rank: 0, Stack size: 1800102\n",
      "Rank: 0, Stack size: 1900102\n",
      "Rank: 0, Stack size: 2000102\n",
      "Rank: 0, Stack size: 2100102\n",
      "Rank: 0, Stack size: 2200102\n",
      "Rank: 0, Stack size: 2300102\n",
      "Rank: 0, Stack size: 2400102\n",
      "Rank: 0, Stack size: 2500102\n",
      "Rank: 0, Stack size: 2600102\n",
      "Rank: 0, Stack size: 2700102\n",
      "Rank: 0, Stack size: 2800102\n",
      "Rank: 0, Stack size: 2900102\n",
      "Rank: 0, Stack size: 3000102\n",
      "Rank: 0, Stack size: 3100102\n",
      "Rank: 0, Stack size: 3200102\n",
      "Rank: 0, Stack size: 3300102\n",
      "Rank: 0, Stack size: 3400102\n",
      "Rank: 0, Stack size: 3500102\n",
      "Rank: 0, Stack size: 3600102\n",
      "Rank: 0, Stack size: 3700102\n",
      "Rank: 0, Stack size: 3800102\n",
      "Rank: 0, Stack size: 3900102\n",
      "Rank: 0, Stack size: 4000102\n",
      "Rank: 0, Stack size: 4100102\n",
      "Rank: 0, Stack size: 4200102\n",
      "Rank: 0, Stack size: 4300102\n",
      "Rank: 0, Stack size: 4400102\n",
      "Rank: 0, Stack size: 4500102\n",
      "Rank: 0, Stack size: 4600102\n",
      "Rank: 0, Stack size: 4700102\n",
      "Rank: 0, Stack size: 4800102\n",
      "Rank: 0, Stack size: 4900102\n",
      "Rank: 0, Stack size: 5000102\n",
      "Rank: 0, Stack size: 5100102\n",
      "Rank: 0, Stack size: 5200102\n",
      "Rank: 0, Stack size: 5300102\n",
      "Rank: 0, Stack size: 5400102\n",
      "Rank: 0, Stack size: 5500102\n",
      "Rank: 0, Stack size: 5600102\n",
      "Rank: 0, Stack size: 5700102\n",
      "Rank: 0, Stack size: 5800102\n",
      "Rank: 0, Stack size: 5900102\n",
      "Rank: 0, Stack size: 6000102\n",
      "Rank: 0, Stack size: 6100102\n",
      "Rank: 0, Stack size: 6200102\n",
      "Rank: 0, Stack size: 6300102\n",
      "Rank: 0, Stack size: 6400102\n",
      "Rank: 0, Stack size: 6500102\n",
      "Rank: 0, Stack size: 6600102\n",
      "Rank: 0, Stack size: 6700102\n",
      "Rank: 0, Stack size: 6800102\n",
      "Rank: 0, Stack size: 6900102\n",
      "Rank: 0, Stack size: 7000102\n",
      "Rank: 0, Stack size: 7100102\n",
      "Rank: 0, Stack size: 7200102\n",
      "Rank: 0, Stack size: 7300102\n",
      "Rank: 0, Stack size: 7400102\n",
      "Rank: 0, Stack size: 7500102\n",
      "Rank: 0, Stack size: 7600102\n",
      "Rank: 0, Stack size: 7700102\n",
      "Rank: 0, Stack size: 7800102\n",
      "Rank: 0, Stack size: 7900102\n",
      "Rank: 0, Stack size: 8000102\n",
      "Rank: 0, Stack size: 8100102\n",
      "Rank: 0, Stack size: 8200102\n",
      "Rank: 0, Stack size: 8300102\n",
      "Rank: 0, Stack size: 8400102\n",
      "Rank: 0, Stack size: 8500102\n",
      "Rank: 0, Stack size: 8600102\n",
      "Rank: 0, Stack size: 8700102\n",
      "Rank: 0, Stack size: 8800102\n",
      "Rank: 0, Stack size: 8900102\n",
      "Rank: 0, Stack size: 9000102\n",
      "Rank: 0, Stack size: 9100102\n",
      "Rank: 0, Stack size: 9200102\n",
      "Rank: 0, Stack size: 9300102\n",
      "Rank: 0, Stack size: 9400102\n",
      "Rank: 0, Stack size: 9500102\n",
      "Rank: 0, Stack size: 9600102\n",
      "Rank: 0, Stack size: 9700102\n",
      "Rank: 0, Stack size: 9800102\n",
      "Rank: 0, Stack size: 9900102\n",
      "Rank: 0, Stack size: 10000102\n",
      "Rank: 0, Stack size: 10100102\n",
      "Rank: 0, Stack size: 10200102\n",
      "Rank: 0, Stack size: 10300102\n",
      "Rank: 0, Stack size: 10400102\n",
      "Rank: 0, Stack size: 10500102\n",
      "Rank: 0, Stack size: 10600102\n",
      "Rank: 0, Stack size: 10700102\n",
      "Rank: 0, Stack size: 10800102\n",
      "Rank: 0, Stack size: 10900102\n",
      "Rank: 0, Stack size: 11000102\n",
      "Rank: 0, Stack size: 11100102\n",
      "Rank: 0, Stack size: 11200102\n",
      "Rank: 0, Stack size: 11300102\n",
      "Rank: 0, Stack size: 11400102\n",
      "Rank: 0, Stack size: 11500102\n",
      "Rank: 0, Stack size: 11600102\n",
      "Rank: 0, Stack size: 11700102\n",
      "Rank: 0, Stack size: 11800102\n",
      "Rank: 0, Stack size: 11900102\n",
      "Rank: 0, Stack size: 12000102\n",
      "Rank: 0, Stack size: 12100102\n",
      "Rank: 0, Stack size: 12200102\n",
      "Rank: 0, Stack size: 12300102\n",
      "Rank: 0, Stack size: 12400102\n",
      "Rank: 0, Stack size: 12500102\n",
      "Rank: 0, Stack size: 12600102\n",
      "Rank: 0, Stack size: 12700102\n",
      "Rank: 0, Stack size: 12800102\n",
      "Rank: 0, Stack size: 12900102\n",
      "Rank: 0, Stack size: 13000102\n",
      "Rank: 0, Stack size: 13100102\n",
      "Rank: 0, Stack size: 13200102\n",
      "Rank: 0, Stack size: 13300102\n",
      "Rank: 0, Stack size: 13400102\n",
      "Rank: 0, Stack size: 13500102\n",
      "Rank: 0, Stack size: 13600102\n",
      "Rank: 0, Stack size: 13700102\n",
      "Rank: 0, Stack size: 13800102\n",
      "Rank: 0, Stack size: 13900102\n",
      "Rank: 0, Stack size: 14000102\n",
      "Rank: 0, Stack size: 14100102\n",
      "Rank: 0, Stack size: 14200102\n",
      "Rank: 0, Stack size: 14300102\n",
      "Rank: 0, Stack size: 14400102\n",
      "Rank: 0, Stack size: 14500102\n",
      "Rank: 0, Stack size: 14600102\n",
      "Rank: 0, Stack size: 14700102\n",
      "Rank: 0, Stack size: 14800102\n",
      "Rank: 0, Stack size: 14900102\n",
      "Rank: 0, Stack size: 15000102\n",
      "Rank: 0, Stack size: 15100102\n",
      "Rank: 0, Stack size: 15200102\n",
      "Rank: 0, Stack size: 15300102\n",
      "Rank: 0, Stack size: 15400102\n",
      "Rank: 0, Stack size: 15500102\n",
      "Rank: 0, Stack size: 15600102\n",
      "Rank: 0, Stack size: 15700102\n",
      "Rank: 0, Stack size: 15800102\n",
      "Rank: 0, Stack size: 15900102\n",
      "Rank: 0, Stack size: 16000102\n",
      "Rank: 0, Stack size: 16100102\n",
      "Rank: 0, Stack size: 16200102\n",
      "Rank: 0, Stack size: 16300102\n",
      "Rank: 0, Stack size: 16400102\n",
      "Rank: 0, Stack size: 16500102\n",
      "Rank: 0, Stack size: 16600102\n",
      "Rank: 0, Stack size: 16700102\n",
      "Rank: 0, Stack size: 16800102\n",
      "Rank: 0, Stack size: 16900102\n",
      "Rank: 0, Stack size: 17000102\n",
      "Rank: 0, Stack size: 17100102\n",
      "Rank: 0, Stack size: 17200102\n",
      "Rank: 0, Stack size: 17300102\n",
      "Rank: 0, Stack size: 17400102\n",
      "Rank: 0, Stack size: 17500102\n",
      "Rank: 0, Stack size: 17600102\n",
      "Rank: 0, Stack size: 17700102\n",
      "Rank: 0, Stack size: 17800102\n",
      "Rank: 0, Stack size: 17900102\n",
      "Rank: 0, Stack size: 18000102\n",
      "Rank: 0, Stack size: 18100102\n",
      "Rank: 0, Stack size: 18200102\n",
      "Rank: 0, Stack size: 18300102\n",
      "Rank: 0, Stack size: 18400102\n",
      "Rank: 0, Stack size: 18500102\n",
      "Rank: 0, Stack size: 18600102\n",
      "Rank: 0, Stack size: 18700102\n",
      "Rank: 0, Stack size: 18800102\n",
      "Rank: 0, Stack size: 18900102\n",
      "Rank: 0, Stack size: 19000102\n",
      "Rank: 0, Stack size: 19100102\n",
      "Rank: 0, Stack size: 19200102\n",
      "Rank: 0, Stack size: 19300102\n",
      "Rank: 0, Stack size: 19400102\n",
      "Rank: 0, Stack size: 19500102\n",
      "Rank: 0, Stack size: 19600102\n",
      "Rank: 0, Stack size: 19700102\n",
      "Rank: 0, Stack size: 19800102\n",
      "Rank: 0, Stack size: 19900102\n",
      "Rank: 0, Stack size: 20000102\n",
      "Rank: 0, Stack size: 20100102\n",
      "Rank: 0, Stack size: 20200102\n",
      "Rank: 0, Stack size: 20300102\n",
      "Rank: 0, Stack size: 20400102\n",
      "Rank: 0, Stack size: 20500102\n",
      "Rank: 0, Stack size: 20600102\n",
      "Rank: 0, Stack size: 20700102\n",
      "Rank: 0, Stack size: 20800102\n",
      "Rank: 0, Stack size: 20900102\n",
      "Rank: 0, Stack size: 21000102\n",
      "Rank: 0, Stack size: 21100102\n",
      "Rank: 0, Stack size: 21200102\n",
      "Rank: 0, Stack size: 21300102\n",
      "Rank: 0, Stack size: 21400102\n",
      "Rank: 0, Stack size: 21500102\n",
      "Rank: 0, Stack size: 21600102\n",
      "Rank: 0, Stack size: 21700102\n",
      "Rank: 0, Stack size: 21800102\n",
      "Rank: 0, Stack size: 21900102\n",
      "Rank: 0, Stack size: 22000102\n",
      "Rank: 0, Stack size: 22100102\n",
      "Rank: 0, Stack size: 22200102\n",
      "Rank: 0, Stack size: 22300102\n",
      "Rank: 0, Stack size: 22400102\n",
      "Rank: 0, Stack size: 22500102\n",
      "Rank: 0, Stack size: 22600102\n",
      "Rank: 0, Stack size: 22700102\n",
      "Rank: 0, Stack size: 22800102\n",
      "Rank: 0, Stack size: 22900102\n",
      "Rank: 0, Stack size: 23000102\n",
      "Rank: 0, Stack size: 23100102\n",
      "Rank: 0, Stack size: 23200102\n",
      "Rank: 0, Stack size: 23300102\n",
      "Rank: 0, Stack size: 23400102\n",
      "Rank: 0, Stack size: 23500102\n",
      "Rank: 0, Stack size: 23600102\n",
      "Rank: 0, Stack size: 23700102\n",
      "Rank: 0, Stack size: 23800102\n",
      "Rank: 0, Stack size: 23900102\n",
      "Rank: 0, Stack size: 24000102\n",
      "Rank: 0, Stack size: 24100102\n",
      "Rank: 0, Stack size: 24200102\n",
      "Rank: 0, Stack size: 24300102\n",
      "Rank: 0, Stack size: 24400102\n",
      "Rank: 0, Stack size: 24500102\n",
      "Rank: 0, Stack size: 24600102\n",
      "Rank: 0, Stack size: 24700102\n",
      "Rank: 0, Stack size: 24800102\n",
      "Rank: 0, Stack size: 24900102\n",
      "Rank: 0, Stack size: 25000102\n",
      "Rank: 0, Stack size: 25100102\n",
      "Rank: 0, Stack size: 25200102\n",
      "Rank: 0, Stack size: 25300102\n",
      "Rank: 0, Stack size: 25400102\n",
      "Rank: 0, Stack size: 25500102\n",
      "Rank: 0, Stack size: 25600102\n",
      "Rank: 0, Stack size: 25700102\n",
      "Rank: 0, Stack size: 25800102\n",
      "Rank: 0, Stack size: 25900102\n",
      "Rank: 0, Stack size: 26000102\n",
      "Rank: 0, Stack size: 26100102\n",
      "Rank: 0, Stack size: 26200102\n",
      "Rank: 0, Stack size: 26300102\n",
      "Rank: 0, Stack size: 26400102\n",
      "Rank: 0, Stack size: 26500102\n",
      "Rank: 0, Stack size: 26600102\n",
      "Rank: 0, Stack size: 26700102\n",
      "Process: 0, Pass: 1, Remaining: 26762824\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Rank: 0, Stack 2 size: 900102\n",
      "Rank: 0, Stack 2 size: 1000102\n",
      "Rank: 0, Stack 2 size: 1100102\n",
      "Rank: 0, Stack 2 size: 1200102\n",
      "Rank: 0, Stack 2 size: 1300102\n",
      "Rank: 0, Stack 2 size: 1400102\n",
      "Rank: 0, Stack 2 size: 1500102\n",
      "Rank: 0, Stack 2 size: 1600102\n",
      "Rank: 0, Stack 2 size: 1700102\n",
      "Rank: 0, Stack 2 size: 1800102\n",
      "Rank: 0, Stack 2 size: 1900102\n",
      "Rank: 0, Stack 2 size: 2000102\n",
      "Rank: 0, Stack 2 size: 2100102\n",
      "Rank: 0, Stack 2 size: 2200102\n",
      "Rank: 0, Stack 2 size: 2300102\n",
      "Rank: 0, Stack 2 size: 2400102\n",
      "Rank: 0, Stack 2 size: 2500102\n",
      "Rank: 0, Stack 2 size: 2600102\n",
      "Rank: 0, Stack 2 size: 2700102\n",
      "Rank: 0, Stack 2 size: 2800102\n",
      "Rank: 0, Stack 2 size: 2900102\n",
      "Rank: 0, Stack 2 size: 3000102\n",
      "Rank: 0, Stack 2 size: 3100102\n",
      "Rank: 0, Stack 2 size: 3200102\n",
      "Rank: 0, Stack 2 size: 3300102\n",
      "Rank: 0, Stack 2 size: 3400102\n",
      "Rank: 0, Stack 2 size: 3500102\n",
      "Rank: 0, Stack 2 size: 3600102\n",
      "Rank: 0, Stack 2 size: 3700102\n",
      "Rank: 0, Stack 2 size: 3800102\n",
      "Rank: 0, Stack 2 size: 3900102\n",
      "Rank: 0, Stack 2 size: 4000102\n",
      "Rank: 0, Stack 2 size: 4100102\n",
      "Rank: 0, Stack 2 size: 4200102\n",
      "Rank: 0, Stack 2 size: 4300102\n",
      "Rank: 0, Stack 2 size: 4400102\n",
      "Rank: 0, Stack 2 size: 4500102\n",
      "Rank: 0, Stack 2 size: 4600102\n",
      "Rank: 0, Stack 2 size: 4700102\n",
      "Rank: 0, Stack 2 size: 4800102\n",
      "Rank: 0, Stack 2 size: 4900102\n",
      "Rank: 0, Stack 2 size: 5000102\n",
      "Rank: 0, Stack 2 size: 5100102\n",
      "Rank: 0, Stack 2 size: 5200102\n",
      "Rank: 0, Stack 2 size: 5300102\n",
      "Rank: 0, Stack 2 size: 5400102\n",
      "Rank: 0, Stack 2 size: 5500102\n",
      "Rank: 0, Stack 2 size: 5600102\n",
      "Rank: 0, Stack 2 size: 5700102\n",
      "Rank: 0, Stack 2 size: 5800102\n",
      "Rank: 0, Stack 2 size: 5900102\n",
      "Rank: 0, Stack 2 size: 6000102\n",
      "Rank: 0, Stack 2 size: 6100102\n",
      "Rank: 0, Stack 2 size: 6200102\n",
      "Rank: 0, Stack 2 size: 6300102\n",
      "Rank: 0, Stack 2 size: 6400102\n",
      "Rank: 0, Stack 2 size: 6500102\n",
      "Rank: 0, Stack 2 size: 6600102\n",
      "Rank: 0, Stack 2 size: 6700102\n",
      "Rank: 0, Stack 2 size: 6800102\n",
      "Rank: 0, Stack 2 size: 6900102\n",
      "Rank: 0, Stack 2 size: 7000102\n",
      "Rank: 0, Stack 2 size: 7100102\n",
      "Rank: 0, Stack 2 size: 7200102\n",
      "Rank: 0, Stack 2 size: 7300102\n",
      "Rank: 0, Stack 2 size: 7400102\n",
      "Rank: 0, Stack 2 size: 7500102\n",
      "Rank: 0, Stack 2 size: 7600102\n",
      "Rank: 0, Stack 2 size: 7700102\n",
      "Rank: 0, Stack 2 size: 7800102\n",
      "Process: 0, Pass: 2, Remaining: 7858970\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Rank: 0, Stack 1 size: 700102\n",
      "Rank: 0, Stack 1 size: 800102\n",
      "Rank: 0, Stack 1 size: 900102\n",
      "Rank: 0, Stack 1 size: 1000102\n",
      "Rank: 0, Stack 1 size: 1100102\n",
      "Rank: 0, Stack 1 size: 1200102\n",
      "Rank: 0, Stack 1 size: 1300102\n",
      "Rank: 0, Stack 1 size: 1400102\n",
      "Rank: 0, Stack 1 size: 1500102\n",
      "Rank: 0, Stack 1 size: 1600102\n",
      "Rank: 0, Stack 1 size: 1700102\n",
      "Rank: 0, Stack 1 size: 1800102\n",
      "Rank: 0, Stack 1 size: 1900102\n",
      "Rank: 0, Stack 1 size: 2000102\n",
      "Rank: 0, Stack 1 size: 2100102\n",
      "Rank: 0, Stack 1 size: 2200102\n",
      "Rank: 0, Stack 1 size: 2300102\n",
      "Rank: 0, Stack 1 size: 2400102\n",
      "Rank: 0, Stack 1 size: 2500102\n",
      "Rank: 0, Stack 1 size: 2600102\n",
      "Rank: 0, Stack 1 size: 2700102\n",
      "Rank: 0, Stack 1 size: 2800102\n",
      "Rank: 0, Stack 1 size: 2900102\n",
      "Rank: 0, Stack 1 size: 3000102\n",
      "Rank: 0, Stack 1 size: 3100102\n",
      "Rank: 0, Stack 1 size: 3200102\n",
      "Rank: 0, Stack 1 size: 3300102\n",
      "Rank: 0, Stack 1 size: 3400102\n",
      "Rank: 0, Stack 1 size: 3500102\n",
      "Rank: 0, Stack 1 size: 3600102\n",
      "Rank: 0, Stack 1 size: 3700102\n",
      "Rank: 0, Stack 1 size: 3800102\n",
      "Process: 0, Pass: 3, Remaining: 3868986\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Rank: 0, Stack 2 size: 900102\n",
      "Rank: 0, Stack 2 size: 1000102\n",
      "Rank: 0, Stack 2 size: 1100102\n",
      "Rank: 0, Stack 2 size: 1200102\n",
      "Rank: 0, Stack 2 size: 1300102\n",
      "Rank: 0, Stack 2 size: 1400102\n",
      "Rank: 0, Stack 2 size: 1500102\n",
      "Rank: 0, Stack 2 size: 1600102\n",
      "Rank: 0, Stack 2 size: 1700102\n",
      "Rank: 0, Stack 2 size: 1800102\n",
      "Rank: 0, Stack 2 size: 1900102\n",
      "Rank: 0, Stack 2 size: 2000102\n",
      "Rank: 0, Stack 2 size: 2100102\n",
      "Rank: 0, Stack 2 size: 2200102\n",
      "Rank: 0, Stack 2 size: 2300102\n",
      "Rank: 0, Stack 2 size: 2400102\n",
      "Process: 0, Pass: 4, Remaining: 2463702\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Rank: 0, Stack 1 size: 700102\n",
      "Rank: 0, Stack 1 size: 800102\n",
      "Rank: 0, Stack 1 size: 900102\n",
      "Rank: 0, Stack 1 size: 1000102\n",
      "Rank: 0, Stack 1 size: 1100102\n",
      "Rank: 0, Stack 1 size: 1200102\n",
      "Rank: 0, Stack 1 size: 1300102\n",
      "Rank: 0, Stack 1 size: 1400102\n",
      "Rank: 0, Stack 1 size: 1500102\n",
      "Rank: 0, Stack 1 size: 1600102\n",
      "Rank: 0, Stack 1 size: 1700102\n",
      "Process: 0, Pass: 5, Remaining: 1747540\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Rank: 0, Stack 2 size: 900102\n",
      "Rank: 0, Stack 2 size: 1000102\n",
      "Rank: 0, Stack 2 size: 1100102\n",
      "Rank: 0, Stack 2 size: 1200102\n",
      "Rank: 0, Stack 2 size: 1300102\n",
      "Process: 0, Pass: 6, Remaining: 1306050\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Rank: 0, Stack 1 size: 700102\n",
      "Rank: 0, Stack 1 size: 800102\n",
      "Rank: 0, Stack 1 size: 900102\n",
      "Rank: 0, Stack 1 size: 1000102\n",
      "Process: 0, Pass: 7, Remaining: 1025366\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Rank: 0, Stack 2 size: 600102\n",
      "Rank: 0, Stack 2 size: 700102\n",
      "Rank: 0, Stack 2 size: 800102\n",
      "Process: 0, Pass: 8, Remaining: 840956\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Rank: 0, Stack 1 size: 600102\n",
      "Process: 0, Pass: 9, Remaining: 697894\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Rank: 0, Stack 2 size: 500102\n",
      "Process: 0, Pass: 10, Remaining: 595484\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Rank: 0, Stack 1 size: 400102\n",
      "Rank: 0, Stack 1 size: 500102\n",
      "Process: 0, Pass: 11, Remaining: 510794\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Rank: 0, Stack 2 size: 400102\n",
      "Process: 0, Pass: 12, Remaining: 446002\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Process: 0, Pass: 13, Remaining: 391650\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Rank: 0, Stack 2 size: 300102\n",
      "Process: 0, Pass: 14, Remaining: 347902\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Rank: 0, Stack 1 size: 300102\n",
      "Process: 0, Pass: 15, Remaining: 311300\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Rank: 0, Stack 2 size: 200102\n",
      "Process: 0, Pass: 16, Remaining: 277160\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Rank: 0, Stack 1 size: 200102\n",
      "Process: 0, Pass: 17, Remaining: 229184\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 18, Remaining: 198154\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Process: 0, Pass: 19, Remaining: 175220\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 20, Remaining: 160444\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Process: 0, Pass: 21, Remaining: 145214\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 22, Remaining: 134382\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Rank: 0, Stack 1 size: 100102\n",
      "Process: 0, Pass: 23, Remaining: 122868\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Rank: 0, Stack 2 size: 100102\n",
      "Process: 0, Pass: 24, Remaining: 112044\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 25, Remaining: 98666\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 26, Remaining: 89316\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 27, Remaining: 80750\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 28, Remaining: 73674\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 29, Remaining: 66732\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 30, Remaining: 60662\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 31, Remaining: 56094\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 32, Remaining: 52686\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 33, Remaining: 47384\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 34, Remaining: 43306\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 35, Remaining: 38454\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 36, Remaining: 36586\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 37, Remaining: 34644\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 38, Remaining: 33040\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 39, Remaining: 31492\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 40, Remaining: 29594\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 41, Remaining: 27662\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 42, Remaining: 26334\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 43, Remaining: 19356\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 44, Remaining: 18492\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 45, Remaining: 17454\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 46, Remaining: 16616\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 47, Remaining: 15682\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 48, Remaining: 14586\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 49, Remaining: 12968\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 50, Remaining: 11954\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 51, Remaining: 11248\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 52, Remaining: 10490\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 53, Remaining: 10084\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 54, Remaining: 9852\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 55, Remaining: 9704\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 56, Remaining: 8228\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 57, Remaining: 6138\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 58, Remaining: 3354\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 59, Remaining: 1170\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 60, Remaining: 1106\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 61, Remaining: 1014\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 62, Remaining: 822\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 63, Remaining: 650\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 64, Remaining: 574\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 65, Remaining: 486\n",
      "Rank: 0, Stack 2 size: 102\n",
      "Process: 0, Pass: 66, Remaining: 352\n",
      "Rank: 0, Stack 1 size: 102\n",
      "Process: 0, Pass: 67, Remaining: 226\n",
      "Process: 0, Pass: 68, Remaining: 74\n",
      "Process: 0, Pass: 69, Remaining: 32\n",
      "Process: 0, Pass: 70, Remaining: 28\n",
      "Process: 0, Pass: 71, Remaining: 14\n",
      "Process: 0, Pass: 72, Remaining: 10\n",
      "Process: 0, Pass: 73, Remaining: 4\n",
      "Process: 0, Pass: 74, Remaining: 0\n",
      "Process: 0, Pass: 75, Remaining: 0\n",
      "About to write\n",
      "Result midpoint of partition: 0, nxm: 6630, nym: 1986, value: 969.400024\n",
      "Partition: 0, written\n",
      "Processes: 1\n",
      "Header read time: 0.248803\n",
      "Data read time: 0.795047\n",
      "Compute time: 7.189317\n",
      "Write time: 2.941426\n",
      "Total time: 11.174593\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:45 - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:45,089 - confluence_general - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:38:45 - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/d8flowdir -fel /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif -sd8 /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-sd8.tif -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:38:45,091 - confluence_general - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/d8flowdir -fel /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif -sd8 /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-sd8.tif -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:43:59 - INFO - Command output: D8FlowDir version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -300000000549775575777803994281145270272.000000\n",
      "Nodata value recast to float used in partition raster: -300000000549775575777803994281145270272.000000\n",
      "Processors: 1\n",
      "Header read time: 0.252176\n",
      "Data read time: 0.931026\n",
      "Compute Slope time: 7.503084\n",
      "Write Slope time: 2.946450\n",
      "Resolve Flat time: 301.425318\n",
      "Write Flat time: 1.041619\n",
      "Total time: 314.099672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:43:59,647 - confluence_general - INFO - Command output: D8FlowDir version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -300000000549775575777803994281145270272.000000\n",
      "Nodata value recast to float used in partition raster: -300000000549775575777803994281145270272.000000\n",
      "Processors: 1\n",
      "Header read time: 0.252176\n",
      "Data read time: 0.931026\n",
      "Compute Slope time: 7.503084\n",
      "Write Slope time: 2.946450\n",
      "Resolve Flat time: 301.425318\n",
      "Write Flat time: 1.041619\n",
      "Total time: 314.099672\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:43:59 - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:43:59,649 - confluence_general - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:43:59 - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/aread8 -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -ad8 /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif -nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:43:59,652 - confluence_general - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/aread8 -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -ad8 /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif -nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:12 - INFO - Command output: AreaD8 version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Number of Processes: 1\n",
      "Read time: 0.516960\n",
      "Compute time: 9.575595\n",
      "Write time: 2.041456\n",
      "Total time: 12.134011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:12,427 - confluence_general - INFO - Command output: AreaD8 version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Number of Processes: 1\n",
      "Read time: 0.516960\n",
      "Compute time: 9.575595\n",
      "Write time: 2.041456\n",
      "Total time: 12.134011\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:12 - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:12,429 - confluence_general - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:12 - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/gridnet -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -plen /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-plen.tif -tlen /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-tlen.tif -gord /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-gord.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:12,431 - confluence_general - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/gridnet -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -plen /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-plen.tif -tlen /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-tlen.tif -gord /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-gord.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:32 - INFO - Command output: GridNet version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Processors: 1\n",
      "Read time: 0.737596\n",
      "Compute time: 12.261408\n",
      "Write time: 6.470273\n",
      "Total time: 19.469277\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:32,378 - confluence_general - INFO - Command output: GridNet version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Processors: 1\n",
      "Read time: 0.737596\n",
      "Compute time: 12.261408\n",
      "Write time: 6.470273\n",
      "Total time: 19.469277\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:32 - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:32,380 - confluence_general - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:32 - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/threshold -ssa /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif -src /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif -thresh 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:32,382 - confluence_general - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/threshold -ssa /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif -src /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif -thresh 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:35 - INFO - Command output: Threshold version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -1.000000\n",
      "Nodata value recast to float used in partition raster: -1.000000\n",
      "Compute time: 0.611380\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:35,024 - confluence_general - INFO - Command output: Threshold version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -1.000000\n",
      "Nodata value recast to float used in partition raster: -1.000000\n",
      "Compute time: 0.611380\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:35 - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:35,026 - confluence_general - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:35 - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/moveoutletstostrm -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -src /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif -o /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/pour_point/Iceland_tutorial_pourPoint.shp -om /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/gauges.shp -md 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:35,028 - confluence_general - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/moveoutletstostrm -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -src /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif -o /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/pour_point/Iceland_tutorial_pourPoint.shp -om /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/gauges.shp -md 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:36 - INFO - Command output: MoveOutletsToStreams version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "gauges Total time: 0.893248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:36,379 - confluence_general - INFO - Command output: MoveOutletsToStreams version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "gauges Total time: 0.893248\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:36 - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:36,381 - confluence_general - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:36 - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/streamnet -fel /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -ad8 /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif -src /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif -ord /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ord.tif -tree /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-tree.dat -coord /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-coord.dat -net /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-streams.shp -o /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/gauges.shp -w /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-watersheds.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:36,383 - confluence_general - INFO - Running command: mpirun -n 1 /work/comphyd_lab/data/CONFLUENCE_data/installs/TauDEM/bin/streamnet -fel /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif -p /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif -ad8 /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif -src /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif -ord /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ord.tif -tree /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-tree.dat -coord /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-coord.dat -net /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-streams.shp -o /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/gauges.shp -w /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-watersheds.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:56 - INFO - Command output: StreamNet version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -1.000000\n",
      "Nodata value recast to float used in partition raster: -1.000000\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -300000000549775575777803994281145270272.000000\n",
      "Nodata value recast to float used in partition raster: -300000000549775575777803994281145270272.000000\n",
      "basin-streams Processors: 1\n",
      "Read time: 3.472497\n",
      "Length compute time: 0.635137\n",
      "Link compute time: 3.767585\n",
      "Link write time: 1.256479\n",
      "Watershed compute time: 7.491902\n",
      "Write time: 3.233643\n",
      "Total time: 19.857244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:56,725 - confluence_general - INFO - Command output: StreamNet version 5.3.9\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-src.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fdir.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -32768.000000\n",
      "Nodata value recast to int16_t used in partition raster: -32768\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-ad8.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -1.000000\n",
      "Nodata value recast to float used in partition raster: -1.000000\n",
      "Input file /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/elv-fel.tif has geographic coordinate system.\n",
      "Nodata value input to create partition from file: -300000000549775575777803994281145270272.000000\n",
      "Nodata value recast to float used in partition raster: -300000000549775575777803994281145270272.000000\n",
      "basin-streams Processors: 1\n",
      "Read time: 3.472497\n",
      "Length compute time: 0.635137\n",
      "Link compute time: 3.767585\n",
      "Link write time: 1.256479\n",
      "Watershed compute time: 7.491902\n",
      "Write time: 3.233643\n",
      "Total time: 19.857244\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:56 - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:56,727 - confluence_general - INFO - Completed TauDEM step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:59 - INFO - Completed GDAL polygonization using direct method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:59,279 - confluence_general - INFO - Completed GDAL polygonization using direct method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:44:59 - WARNING - CRS is not defined for /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-watersheds.shp. Setting to EPSG:4326.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:44:59,482 - confluence_general - WARNING - CRS is not defined for /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files/d8/basin-watersheds.shp. Setting to EPSG:4326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:45:00 - INFO - Found 997 rows with duplicate GRU_ID values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:45:00,147 - confluence_general - INFO - Found 997 rows with duplicate GRU_ID values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:45:00 - INFO - Removed 997 duplicate GRU_IDs, keeping the largest area for each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:45:00,153 - confluence_general - INFO - Removed 997 duplicate GRU_IDs, keeping the largest area for each\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:45:00 - INFO - Remaining GRUs: 2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:45:00,155 - confluence_general - INFO - Remaining GRUs: 2682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:45:00 - INFO - Starting GRU merging process (minimum size: 10 kmÂ²)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:45:00,158 - confluence_general - INFO - Starting GRU merging process (minimum size: 10 kmÂ²)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - ERROR - Error during geofabric subsetting: One of the arguments is of incorrect type. Please provide only Geometry objects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,751 - confluence_general - ERROR - Error during geofabric subsetting: One of the arguments is of incorrect type. Please provide only Geometry objects.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Cleaned up intermediate files: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,834 - confluence_general - INFO - Cleaned up intermediate files: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/taudem-interim-files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Geofabric delineation completed for Iceland_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,836 - confluence_general - INFO - Geofabric delineation completed for Iceland_tutorial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Starting coastal delineation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,837 - confluence_general - INFO - Starting coastal delineation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Starting coastal watershed delineation for Iceland_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,839 - confluence_general - INFO - Starting coastal watershed delineation for Iceland_tutorial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - ERROR - River basins or network files not found. Run delineate_geofabric first.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,854 - confluence_general - ERROR - River basins or network files not found. Run delineate_geofabric first.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Coastal delineation completed: (None, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,855 - confluence_general - INFO - Coastal delineation completed: (None, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Domain definition completed using method: delineate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,857 - confluence_general - INFO - Domain definition completed using method: delineate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Creating domain visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,858 - confluence_general - INFO - Creating domain visualization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - ERROR - Error in plot_domain: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/river_basins/Iceland_tutorial_riverBasins_delineate.shp: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,864 - confluence_general - ERROR - Error in plot_domain: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/river_basins/Iceland_tutorial_riverBasins_delineate.shp: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - ERROR - Traceback (most recent call last):\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/reporting/reporting_utils.py\", line 828, in plot_domain\n",
      "    catchment_gdf = gpd.read_file(catchment_path)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 294, in _read_file\n",
      "    return _read_file_pyogrio(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 547, in _read_file_pyogrio\n",
      "    return pyogrio.read_dataframe(path_or_bytes, bbox=bbox, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/geopandas.py\", line 265, in read_dataframe\n",
      "    result = read_func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/raw.py\", line 198, in read\n",
      "    return ogr_read(\n",
      "           ^^^^^^^^^\n",
      "  File \"pyogrio/_io.pyx\", line 1240, in pyogrio._io.ogr_read\n",
      "  File \"pyogrio/_io.pyx\", line 220, in pyogrio._io.ogr_open\n",
      "pyogrio.errors.DataSourceError: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/river_basins/Iceland_tutorial_riverBasins_delineate.shp: No such file or directory\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,868 - confluence_general - ERROR - Traceback (most recent call last):\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/reporting/reporting_utils.py\", line 828, in plot_domain\n",
      "    catchment_gdf = gpd.read_file(catchment_path)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 294, in _read_file\n",
      "    return _read_file_pyogrio(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 547, in _read_file_pyogrio\n",
      "    return pyogrio.read_dataframe(path_or_bytes, bbox=bbox, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/geopandas.py\", line 265, in read_dataframe\n",
      "    result = read_func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/raw.py\", line 198, in read\n",
      "    return ogr_read(\n",
      "           ^^^^^^^^^\n",
      "  File \"pyogrio/_io.pyx\", line 1240, in pyogrio._io.ogr_read\n",
      "  File \"pyogrio/_io.pyx\", line 220, in pyogrio._io.ogr_open\n",
      "pyogrio.errors.DataSourceError: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_tutorial/shapefiles/river_basins/Iceland_tutorial_riverBasins_delineate.shp: No such file or directory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - WARNING - Could not create domain visualization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,870 - confluence_general - WARNING - Could not create domain visualization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:46:15 - INFO - Domain definition workflow finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:46:15,872 - confluence_general - INFO - Domain definition workflow finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  No basin shapefiles found. Domain delineation may have failed.\n",
      "âš  No river network shapefiles found. Stream delineation may have failed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Define domain\n",
    "    print(f\"Delineating regional domain using method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "    print(f\"Delineate by pour point: {confluence.config['DELINEATE_BY_POURPOINT']} (Full region!)\")\n",
    "    print(f\"Include coastal watersheds: {confluence.config.get('DELINEATE_COASTAL_WATERSHEDS', True)}\")\n",
    "    print(f\"Stream threshold: {confluence.config['STREAM_THRESHOLD']}\")\n",
    "    print(\"\\nThis will create multiple independent drainage basins...\")\n",
    "    \n",
    "    watershed_path = confluence.managers['domain'].define_domain()\n",
    "    \n",
    "    # Check results\n",
    "    basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "    network_path = project_dir / 'shapefiles' / 'river_network'\n",
    "    \n",
    "    basin_count = 0\n",
    "    basin_files = []\n",
    "    basins = None\n",
    "    if basin_path.exists():\n",
    "        basin_files = list(basin_path.glob('*.shp'))\n",
    "        if basin_files:\n",
    "            try:\n",
    "                basins = gpd.read_file(basin_files[0])\n",
    "                basin_count = len(basins)\n",
    "                print(f\"\\nâœ“ Created {basin_count} watersheds\")\n",
    "                print(f\"Total area: {basins.geometry.area.sum() / 1e6:.0f} kmÂ²\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading basin shapefile: {str(e)}\")\n",
    "    \n",
    "    network_count = 0\n",
    "    network_files = []\n",
    "    rivers = None\n",
    "    if network_path.exists():\n",
    "        network_files = list(network_path.glob('*.shp'))\n",
    "        if network_files:\n",
    "            try:\n",
    "                rivers = gpd.read_file(network_files[0])\n",
    "                network_count = len(rivers)\n",
    "                print(f\"âœ“ Created river network with {network_count} segments\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading river network shapefile: {str(e)}\")\n",
    "                \n",
    "    if not basin_files:\n",
    "        print(\"âš  No basin shapefiles found. Domain delineation may have failed.\")\n",
    "    if not network_files:\n",
    "        print(\"âš  No river network shapefiles found. Stream delineation may have failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during domain delineation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Watershed Discretization\n",
    "Now we need to discretize our domain into GRUs (Grouped Response Units) and HRUs (Hydrologic Response Units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HRUs using method: GRUs\n",
      "19:29:55 - INFO - Discretizing domain using method: GRUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:29:55,928 - confluence_general - INFO - Discretizing domain using method: GRUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:55 - INFO - Starting domain discretization using method: grus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:29:55,953 - confluence_general - INFO - Starting domain discretization using method: grus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:55 - INFO - Step 1/2: Running discretization method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:29:55,956 - confluence_general - INFO - Step 1/2: Running discretization method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:55 - INFO - config domain name Iceland_region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:29:55,959 - confluence_general - INFO - config domain name Iceland_region\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:55 - ERROR - Error reading shapefile /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:29:55,962 - confluence_general - ERROR - Error reading shapefile /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:55 - ERROR - Error during domain discretization: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:29:55,964 - confluence_general - ERROR - Error during domain discretization: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:55 - ERROR - Traceback (most recent call last):\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/domain_manager.py\", line 101, in discretize_domain\n",
      "    hru_shapefile = self.domain_discretizer.discretize_domain()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/discretization_utils.py\", line 163, in discretize_domain\n",
      "    method_map[discretization_method]()\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/discretization_utils.py\", line 194, in _use_grus_as_hrus\n",
      "    gru_gdf = self._read_shapefile(gru_shapefile)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/discretization_utils.py\", line 853, in _read_shapefile\n",
      "    gdf = gpd.read_file(shapefile_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 294, in _read_file\n",
      "    return _read_file_pyogrio(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 547, in _read_file_pyogrio\n",
      "    return pyogrio.read_dataframe(path_or_bytes, bbox=bbox, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/geopandas.py\", line 265, in read_dataframe\n",
      "    result = read_func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/raw.py\", line 198, in read\n",
      "    return ogr_read(\n",
      "           ^^^^^^^^^\n",
      "  File \"pyogrio/_io.pyx\", line 1240, in pyogrio._io.ogr_read\n",
      "  File \"pyogrio/_io.pyx\", line 220, in pyogrio._io.ogr_open\n",
      "pyogrio.errors.DataSourceError: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: No such file or directory\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:29:55,968 - confluence_general - ERROR - Traceback (most recent call last):\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/domain_manager.py\", line 101, in discretize_domain\n",
      "    hru_shapefile = self.domain_discretizer.discretize_domain()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/discretization_utils.py\", line 163, in discretize_domain\n",
      "    method_map[discretization_method]()\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/discretization_utils.py\", line 194, in _use_grus_as_hrus\n",
      "    gru_gdf = self._read_shapefile(gru_shapefile)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/darri.eythorsson/code/CONFLUENCE/utils/geospatial/discretization_utils.py\", line 853, in _read_shapefile\n",
      "    gdf = gpd.read_file(shapefile_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 294, in _read_file\n",
      "    return _read_file_pyogrio(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 547, in _read_file_pyogrio\n",
      "    return pyogrio.read_dataframe(path_or_bytes, bbox=bbox, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/geopandas.py\", line 265, in read_dataframe\n",
      "    result = read_func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/pyogrio/raw.py\", line 198, in read\n",
      "    return ogr_read(\n",
      "           ^^^^^^^^^\n",
      "  File \"pyogrio/_io.pyx\", line 1240, in pyogrio._io.ogr_read\n",
      "  File \"pyogrio/_io.pyx\", line 220, in pyogrio._io.ogr_open\n",
      "pyogrio.errors.DataSourceError: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: No such file or directory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during domain discretization: /work/comphyd_lab/data/CONFLUENCE_data/domain_Iceland_region/shapefiles/river_basins/Iceland_region_riverBasins_with_coastal.shp: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Discretize domain\n",
    "    print(f\"Creating HRUs using method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "    hru_path = confluence.managers['domain'].discretize_domain()\n",
    "    \n",
    "    # Check results\n",
    "    hru_path = project_dir / 'shapefiles' / 'catchment'\n",
    "    hru_gdf = None\n",
    "    if hru_path.exists():\n",
    "        hru_files = list(hru_path.glob('*.shp'))\n",
    "        if hru_files:\n",
    "            try:\n",
    "                hru_gdf = gpd.read_file(hru_files[0])\n",
    "                \n",
    "                print(f\"\\nâœ“ Created {len(hru_gdf)} HRUs\")\n",
    "                print(f\"Number of GRUs: {hru_gdf['GRU_ID'].nunique()}\")\n",
    "                \n",
    "                # Show some statistics\n",
    "                hru_stats = hru_gdf.groupby('GRU_ID').size()\n",
    "                print(f\"\\nHRU distribution:\")\n",
    "                print(f\"  Min HRUs per GRU: {hru_stats.min()}\")\n",
    "                print(f\"  Max HRUs per GRU: {hru_stats.max()}\")\n",
    "                print(f\"  Avg HRUs per GRU: {hru_stats.mean():.1f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading HRU shapefile: {str(e)}\")\n",
    "        else:\n",
    "            print(\"âš  No HRU shapefiles found. Domain discretization may have failed.\")\n",
    "    else:\n",
    "        print(\"âš  Catchment directory not found. Domain discretization may have failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during domain discretization: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Regional Domain\n",
    "Let's visualize what our regional domain looks like with all delineated watersheds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating regional domain visualization...\n",
      "plot_domain method not available - using custom visualization instead\n",
      "Cannot create visualization: Basin data not available\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create CONFLUENCE domain visualization\n",
    "    print(\"Creating regional domain visualization...\")\n",
    "    if hasattr(confluence.managers['domain'], 'plot_domain'):\n",
    "        plot_paths = confluence.managers['domain'].plot_domain()\n",
    "    else:\n",
    "        print(\"plot_domain method not available - using custom visualization instead\")\n",
    "    \n",
    "    # Create custom visualization\n",
    "    if basin_path.exists() and basin_files and basins is not None:\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        # Plot watersheds\n",
    "        if 'GRU_ID' in basins.columns:\n",
    "            basins.plot(ax=ax, column='GRU_ID', cmap='tab20', \n",
    "                       edgecolor='black', linewidth=0.5, legend=False)\n",
    "        else:\n",
    "            basins.plot(ax=ax, cmap='tab20', \n",
    "                       edgecolor='black', linewidth=0.5, legend=False)\n",
    "        \n",
    "        # Plot river network if available\n",
    "        if network_path.exists() and network_files and rivers is not None:\n",
    "            rivers.plot(ax=ax, color='blue', linewidth=1)\n",
    "        \n",
    "        ax.set_title(f'Iceland Regional Domain - {basin_count} Watersheds', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        \n",
    "        # Add annotation about coastal watersheds\n",
    "        ax.text(0.02, 0.98, f'Including coastal watersheds\\nTotal watersheds: {basin_count}',\n",
    "                transform=ax.transAxes, va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Cannot create visualization: Basin data not available\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating domain visualization: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyze Regional Characteristics\n",
    "Let's analyze the characteristics of our regional watersheds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE (HPC Modules)",
   "language": "python",
   "name": "conf-env-hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
