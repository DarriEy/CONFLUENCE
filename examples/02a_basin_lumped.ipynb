{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 3: Lumped Basin Workflow (Bow River at Banff)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial shows how to scale up from point-scale modeling to basin-scale streamflow simulation using CONFLUENCE. Building on our previous tutorials with SNOTEL and FLUXNET data, we now demonstrate how to model an entire watershed as a single unit to generate streamflow at the basin outlet.\n",
    "\n",
    "### What is Lumped Basin Modeling?\n",
    "\n",
    "Lumped basin modeling treats the entire watershed as one homogeneous unit, averaging all the spatial variability across the catchment. While this is a simplification, it's a valuable approach because:\n",
    "\n",
    "- **Simplicity**: Easier to understand and implement than distributed models\n",
    "- **Computational efficiency**: Fast execution makes it ideal for calibration and uncertainty analysis  \n",
    "- **Baseline performance**: Establishes whether a model can capture the basic watershed response before adding spatial complexity\n",
    "- **Parameter identification**: Simpler structure makes it easier to understand which parameters control model behavior\n",
    "\n",
    "### Case Study: Bow River at Banff\n",
    "\n",
    "We'll use the Bow River at Banff as our example watershed:\n",
    "\n",
    "- **Location**: Canadian Rockies, Alberta, Canada\n",
    "- **Drainage area**: ~2,210 km¬≤\n",
    "- **Elevation**: Ranges from 1,384 m at the outlet to over 3,400 m in the headwaters\n",
    "- **Climate**: Snow-dominated mountain system with pronounced seasonal cycles\n",
    "- **Gauging station**: Water Survey of Canada station 05BB001 with long-term observations\n",
    "\n",
    "This watershed presents interesting modeling challenges:\n",
    "- Strong elevation gradients affecting temperature and precipitation\n",
    "- Complex snow dynamics across elevation zones\n",
    "- Seasonal storage in snowpack and glaciers\n",
    "- Pronounced spring freshet from snowmelt\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "This tutorial will teach you how to:\n",
    "\n",
    "1. **Set up a basin-scale project** with CONFLUENCE's automated workflow\n",
    "2. **Delineate watersheds** automatically from digital elevation models\n",
    "3. **Aggregate spatial data** to create catchment-averaged characteristics\n",
    "4. **Process meteorological forcing** data for basin-scale modeling\n",
    "5. **Configure and run SUMMA** for lumped basin simulation\n",
    "6. **Evaluate model performance** using standard hydrological metrics\n",
    "7. **Interpret results** and understand model limitations\n",
    "\n",
    "### Tutorial Overview\n",
    "\n",
    "We'll walk through the complete CONFLUENCE workflow step by step:\n",
    "\n",
    "1. **Project Setup**: Create the organized directory structure\n",
    "2. **Watershed Delineation**: Automatically identify the watershed boundary\n",
    "3. **Data Acquisition**: Get elevation, soil, and land cover data\n",
    "4. **Forcing Data**: Process meteorological inputs\n",
    "5. **Model Configuration**: Set up SUMMA for the lumped basin\n",
    "6. **Model Execution**: Run the simulation\n",
    "7. **Results Analysis**: Compare simulated and observed streamflow\n",
    "\n",
    "By the end of this tutorial, you'll understand how CONFLUENCE handles the transition from point-scale to basin-scale modeling and be ready to explore more complex distributed modeling approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Basin-Scale Workflow Setup\n",
    "Building on the point-scale modeling expertise from Tutorials 01a and 01b, we now advance to basin-scale hydrological modeling. This represents a fundamental scaling transition: from process validation at individual sites to integrated watershed simulation that captures the collective hydrological response of an entire catchment.\n",
    "Scaling Transition: Point ‚Üí Basin\n",
    "\n",
    "- Spatial Scale: Single location ‚Üí Entire watershed (~2,210 km¬≤)\n",
    "- Process Integration: Isolated vertical processes ‚Üí Integrated water balance with routing\n",
    "- Validation Target: Local states (SWE, SM, LE) ‚Üí Streamflow at basin outlet\n",
    "- Complexity: Uniform characteristics ‚Üí Spatially-averaged catchment properties\n",
    "- Scientific Challenge: Process understanding ‚Üí Emergent watershed behavior\n",
    "\n",
    "The same CONFLUENCE architecture seamlessly handles this transition, demonstrating the framework's scalability from point validation through basin-scale prediction while maintaining reproducible workflow principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: BASIN-SCALE WORKFLOW SETUP\n",
    "# =============================================================================\n",
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=== CONFLUENCE Tutorial 02a: Lumped Basin Modeling ===\")\n",
    "print(\"Scaling from point-scale validation to basin-scale streamflow simulation\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION FOR BOW RIVER AT BANFF WATERSHED\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüèîÔ∏è Configuring for Bow River at Banff Watershed\")\n",
    "\n",
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/Users/darrieythorsson/compHydro/data/CONFLUENCE_data')  # ‚Üê Update this path\n",
    "\n",
    "# Load template configuration and customize for basin-scale modeling\n",
    "config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "\n",
    "with open(config_template_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update for Bow River basin-scale modeling\n",
    "config_updates = {\n",
    "    'CONFLUENCE_CODE_DIR': str(CONFLUENCE_CODE_DIR),\n",
    "    'CONFLUENCE_DATA_DIR': str(CONFLUENCE_DATA_DIR),\n",
    "    'DOMAIN_NAME': 'Bow_at_Banff_lumped',\n",
    "    'EXPERIMENT_ID': 'run_1',\n",
    "    'POUR_POINT_COORDS': '51.1722/-115.5717',  # Banff gauging station\n",
    "    'DOMAIN_DEFINITION_METHOD': 'lumped',    # Watershed delineation vs point buffer\n",
    "    'DOMAIN_DISCRETIZATION': 'GRUS',          # Single HRU for entire watershed\n",
    "    'HYDROLOGICAL_MODEL': 'SUMMA',\n",
    "    'EXPERIMENT_TIME_START': '2004-01-01 01:00',\n",
    "    'EXPERIMENT_TIME_END': '2018-12-31 23:00',\n",
    "    'CALIBRATION_PERIOD': '2004-01-01, 2010-12-31',\n",
    "    'EVALUATION_PERIOD': '2011-01-01, 2018-12-31',\n",
    "    'SPINUP_PERIOD': '2004-01-01, 2005-12-31',\n",
    "    'STATION_ID': '05BB001',                     # WSC streamflow station\n",
    "    'DOWNLOAD_WSC_DATA': True\n",
    "}\n",
    "\n",
    "config_dict.update(config_updates)\n",
    "\n",
    "# Add experiment metadata for traceability\n",
    "config_dict['NOTEBOOK_CREATION_TIME'] = datetime.now().isoformat()\n",
    "config_dict['NOTEBOOK_CREATOR'] = 'CONFLUENCE_Tutorial_02a'\n",
    "config_dict['SCALING_TRANSITION'] = 'Point-scale to basin-scale lumped modeling'\n",
    "\n",
    "# Save configuration\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_basin_notebook.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"‚úÖ Configuration saved: {temp_config_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SYSTEM INITIALIZATION AND PROJECT STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüèóÔ∏è  Initializing CONFLUENCE for Basin-Scale Modeling...\")\n",
    "\n",
    "# Initialize CONFLUENCE with basin configuration\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "print(f\"‚úÖ System initialized with {len(confluence.managers)} managers\")\n",
    "\n",
    "# Create project structure\n",
    "print(f\"\\nüìÅ Creating basin-scale project structure for {config_dict['DOMAIN_NAME']}...\")\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"‚úÖ Project directory: {project_dir}\")\n",
    "print(f\"‚úÖ Pour point created: {pour_point_path}\")\n",
    "\n",
    "print(f\"\\nüöÄ Basin-scale setup complete - Ready for watershed delineation and streamflow modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basin Representation and Spatial Discretization Fundamentals\n",
    "The transition from point-scale to basin-scale modeling requires fundamental decisions about how to represent spatial heterogeneity within the watershed. Unlike point-scale modeling where we assume uniform conditions, basin-scale modeling must address the challenge of capturing spatial variability while maintaining computational tractability.\n",
    "Scientific Context: Basin Representation Philosophy\n",
    "Spatial Heterogeneity Challenges:\n",
    "\n",
    "- Elevation Gradients: Temperature lapse rates, precipitation patterns, snow line dynamics\n",
    "- Vegetation Patterns: Forest vs alpine zones affecting evapotranspiration and interception\n",
    "- Soil Variability: Infiltration, storage capacity, and drainage characteristics\n",
    "- Topographic Effects: Slope, aspect, and drainage network configuration\n",
    "- Climate Gradients: Orographic precipitation, temperature inversions, wind patterns\n",
    "\n",
    "Representation Strategies:\n",
    "\n",
    "- Lumped Approach: Single computational unit with averaged characteristics\n",
    "- Semi-Distributed: Multiple units based on similarity (elevation bands, soil types, land cover)\n",
    "- Fully Distributed: Grid-based representation with explicit spatial patterns\n",
    "\n",
    "The Grouped Response Unit (GRU) concept provides flexible spatial discretization, allowing users to choose the appropriate level of complexity for their scientific objectives and computational constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: BASIN REPRESENTATION AND SPATIAL DISCRETIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Step 2: Basin Representation and Spatial Discretization ===\")\n",
    "\n",
    "# Update discretization method to GRUs for this demonstration\n",
    "config_dict['DOMAIN_DISCRETIZATION'] = 'GRUs'\n",
    "\n",
    "# Save updated configuration\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "# Reinitialize with updated config\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "# Execute attribute acquisition\n",
    "print(f\"\\n‚¨áÔ∏è  Executing geospatial attribute acquisition...\")\n",
    "#confluence.managers['data'].acquire_attributes()\n",
    "print(\"‚úÖ Basin-scale attribute acquisition complete\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Executing watershed delineation...\")\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "print(\"‚úÖ Watershed delineation complete\")\n",
    "\n",
    "print(f\"\\nüîß Executing domain discretization...\")\n",
    "confluence.managers['domain'].discretize_domain()\n",
    "hru_path = str(Path(config_dict['CONFLUENCE_DATA_DIR']) / f\"domain_{config_dict['DOMAIN_NAME']}\" / 'shapefiles' / 'catchment' / f\"{config_dict['DOMAIN_NAME']}_HRUs_{config_dict['DOMAIN_DISCRETIZATION']}.shp\")\n",
    "print(\"‚úÖ Domain discretization complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION AND ANALYSIS OF BASIN REPRESENTATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìä Analyzing Created Basin Representation...\")\n",
    "\n",
    "print(watershed_path)\n",
    "print(hru_path)\n",
    "print(pour_point_path)\n",
    "\n",
    "# Load spatial data\n",
    "watershed_gdf = gpd.read_file(str(watershed_path[1]))\n",
    "hru_gdf = gpd.read_file(hru_path)\n",
    "pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "\n",
    "print(f\"\\nüìã Basin Characteristics:\")\n",
    "total_area_m2 = watershed_gdf.geometry.area.sum()\n",
    "total_area_km2 = total_area_m2 / 1e6\n",
    "print(f\"   Watershed area: {total_area_km2:.1f} km¬≤\")\n",
    "print(f\"   Number of GRUs: {len(hru_gdf)}\")\n",
    "print(f\"   Average GRU size: {total_area_km2/len(hru_gdf):.1f} km¬≤\")\n",
    "\n",
    "# Display HRU characteristics if available\n",
    "if 'elevation' in hru_gdf.columns:\n",
    "    print(f\"   Elevation range: {hru_gdf['elevation'].min():.0f}m to {hru_gdf['elevation'].max():.0f}m\")\n",
    "if 'slope' in hru_gdf.columns:\n",
    "    print(f\"   Slope range: {hru_gdf['slope'].min():.1f}¬∞ to {hru_gdf['slope'].max():.1f}¬∞\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "print(f\"\\nüó∫Ô∏è  Creating basin representation visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Left plot: Watershed boundary and pour point\n",
    "ax1 = axes[0]\n",
    "watershed_gdf.plot(ax=ax1, facecolor='lightblue', edgecolor='navy', \n",
    "                  linewidth=2, alpha=0.7)\n",
    "pour_point_gdf.plot(ax=ax1, color='red', markersize=100, marker='o',\n",
    "                   edgecolor='white', linewidth=2, zorder=5)\n",
    "\n",
    "ax1.set_title('Delineated Watershed Boundary', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Longitude', fontsize=12)\n",
    "ax1.set_ylabel('Latitude', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add area annotation\n",
    "ax1.text(0.02, 0.98, f'Area: {total_area_km2:.1f} km¬≤\\nPour Point: WSC {config_dict[\"STATION_ID\"]}',\n",
    "         transform=ax1.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3'))\n",
    "\n",
    "# Right plot: HRU discretization\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Color HRUs by elevation if available, otherwise by area\n",
    "if 'elevation' in hru_gdf.columns:\n",
    "    hru_gdf.plot(ax=ax2, column='elevation', cmap='terrain', \n",
    "                edgecolor='black', linewidth=0.5, legend=True)\n",
    "    colorbar_label = 'Elevation (m)'\n",
    "else:\n",
    "    hru_gdf.plot(ax=ax2, column=hru_gdf.geometry.area, cmap='viridis',\n",
    "                edgecolor='black', linewidth=0.5, legend=True) \n",
    "    colorbar_label = 'Area (deg¬≤)'\n",
    "\n",
    "pour_point_gdf.plot(ax=ax2, color='red', markersize=100, marker='o',\n",
    "                   edgecolor='white', linewidth=2, zorder=5)\n",
    "\n",
    "ax2.set_title(f'GRU Discretization ({len(hru_gdf)} units)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Longitude', fontsize=12)\n",
    "ax2.set_ylabel('Latitude', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add discretization info\n",
    "ax2.text(0.02, 0.98, f'GRUs: {len(hru_gdf)}\\nAvg. size: {total_area_km2/len(hru_gdf):.1f} km¬≤',\n",
    "         transform=ax2.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3'))\n",
    "\n",
    "plt.suptitle(f'Bow River at Banff: Basin Representation', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Pipeline for Basin-Scale Streamflow Modeling\n",
    "The same model-agnostic preprocessing framework now scales from point validation to basin-scale streamflow simulation. The core philosophy remains unchanged‚Äîstandardized, quality-controlled data products‚Äîbut the spatial context shifts from single locations to integrated watershed responses.\n",
    "Data Pipeline Scaling: Point ‚Üí Basin\n",
    "\n",
    "- Forcing Data: Same ERA5 global data, now basin-averaged across watershed\n",
    "- Validation Target: Streamflow hydrographs vs local states (SWE, SM, LE)\n",
    "- Spatial Processing: Watershed-scale remapping vs single-point extraction\n",
    "- Temporal Integration: Daily streamflow vs sub-daily energy cycles\n",
    "- Process Focus: Integrated water balance with routing vs isolated vertical processes\n",
    "\n",
    "The same CONFLUENCE preprocessing pipeline handles both scales seamlessly, demonstrating the framework's scalability while maintaining data quality and reproducibility standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: STREAMLINED DATA PIPELINE FOR BASIN-SCALE STREAMFLOW MODELING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüåä Processing Streamflow Observations for Basin Outlet...\")\n",
    "print(f\"   Station: WSC {config_dict['STATION_ID']} (Bow River at Banff)\")\n",
    "\n",
    "# Execute streamflow data processing\n",
    "print(f\"\\nüì• Processing WSC streamflow observations...\")\n",
    "confluence.managers['data'].process_observed_data()\n",
    "print(\"‚úÖ Streamflow data processing complete\")\n",
    "\n",
    "print(f\"\\nüå¶Ô∏è  Acquiring Basin-Averaged Meteorological Forcing...\")\n",
    "print(f\"   Watershed area: ~{total_area_km2:.1f} km¬≤ (Bow River at Banff)\")\n",
    "print(f\"   Elevation range: {hru_gdf['elevation'].min():.0f}m to {hru_gdf['elevation'].max():.0f}m\")\n",
    "\n",
    "# Execute forcing acquisition (commented for demonstration)\n",
    "print(f\"\\n‚¨áÔ∏è  Executing basin-scale forcing acquisition...\")\n",
    "# confluence.managers['data'].acquire_forcings()\n",
    "print(\"‚úÖ forcing acquisition complete (simulated)\")\n",
    "\n",
    "# Execute model-agnostic preprocessing\n",
    "print(f\"\\n‚öôÔ∏è  Executing basin-scale model-agnostic preprocessing...\")\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"‚úÖ Model-agnostic preprocessing complete\")\n",
    "\n",
    "print(f\"\\nüåä SUMMA + mizuRoute Configuration for Basin Streamflow...\")\n",
    "print(f\"   Hydrological model: {config_dict['HYDROLOGICAL_MODEL']} (process-based)\")\n",
    "print(f\"   Routing model: {config_dict['ROUTING_MODEL']} (streamflow routing)\")\n",
    "\n",
    "# Execute model-specific preprocessing\n",
    "print(f\"\\nüîß Executing SUMMA + mizuRoute preprocessing...\")\n",
    "confluence.managers['model'].preprocess_models()\n",
    "print(\"‚úÖ Basin-scale model configuration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Streamlined Basin-Scale Model Execution\n",
    "The same SUMMA process-based physics now scales from point validation to integrated basin simulation, but with the critical addition of streamflow routing. This represents a fundamental modeling advancement: from isolated vertical processes to coupled vertical-horizontal water transport that generates streamflow at the basin outlet.\n",
    "Model Execution Scaling: Point ‚Üí Basin\n",
    "\n",
    "- Spatial Integration: Single HRU ‚Üí Multiple GRUs with routing connectivity\n",
    "- Process Coupling: Vertical water balance ‚Üí Vertical + horizontal flow routing\n",
    "- Output Target: Local states ‚Üí Streamflow hydrograph at outlet\n",
    "- Temporal Integration: Sub-daily energy cycles ‚Üí Daily streamflow generation\n",
    "- Validation Shift: Direct state comparison ‚Üí Integrated basin response\n",
    "\n",
    "The same workflow orchestration ensures robust execution while mizuRoute routing transforms distributed runoff into the streamflow observations that drive water resources management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: STREAMLINED BASIN-SCALE MODEL EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# Execute the integrated model system\n",
    "print(f\"\\nüèÉ‚Äç‚ôÇÔ∏è Running SUMMA + mizuRoute basin simulation...\")\n",
    "confluence.managers['model'].run_models()\n",
    "print(\"‚úÖ Basin-scale integrated simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Streamflow Evaluation and Basin Performance Assessment\n",
    "The same CONFLUENCE evaluation framework now transitions from point-scale validation to basin-scale streamflow assessment. This represents a fundamental shift in validation philosophy: from direct process comparison (SWE, SM, LE) to integrated response evaluation where all upstream processes collectively generate the streamflow signal at the basin outlet.\n",
    "Evaluation Framework Transition: Point ‚Üí Basin\n",
    "\n",
    "- Validation Target: Local states (SWE, soil moisture, energy fluxes) ‚Üí Streamflow hydrograph\n",
    "- Process Integration: Direct measurement comparison ‚Üí Emergent watershed response\n",
    "- Temporal Patterns: Sub-daily cycles ‚Üí Seasonal flow regimes and flood events\n",
    "- Performance Metrics: State variable accuracy ‚Üí Hydrologic signatures and timing\n",
    "- Scientific Interpretation: Process physics ‚Üí Water balance closure and prediction skill\n",
    "\n",
    "The same evaluation infrastructure seamlessly handles this transition, demonstrating CONFLUENCE's versatility across validation scales while maintaining rigorous performance assessment standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: STREAMLINED STREAMFLOW EVALUATION AND BASIN PERFORMANCE ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüåä Loading Streamflow Simulation and Observations...\")\n",
    "\n",
    "# Load observed streamflow data\n",
    "obs_path = confluence.project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config_dict['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "\n",
    "if obs_path.exists():\n",
    "    obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "    obs_df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ WSC observations loaded\")\n",
    "    print(f\"   Station: {config_dict['STATION_ID']} (Bow River at Banff)\")\n",
    "    print(f\"   Period: {obs_df.index.min()} to {obs_df.index.max()}\")\n",
    "    print(f\"   Flow range: {obs_df['discharge_cms'].min():.1f} to {obs_df['discharge_cms'].max():.1f} m¬≥/s\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Observed streamflow not found at {obs_path}\")\n",
    "    obs_df = None\n",
    "\n",
    "# Load simulated streamflow from mizuRoute\n",
    "summa_dir = confluence.project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"SUMMA\"\n",
    "routing_dir = confluence.project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"mizuRoute\"\n",
    "routing_files = list(routing_dir.glob(\"*.nc\"))\n",
    "\n",
    "if routing_files:\n",
    "    # Load mizuRoute output\n",
    "    routing_ds = xr.open_dataset(routing_files[0])\n",
    "    \n",
    "    # Extract streamflow variable (typically IRFroutedRunoff)\n",
    "    if 'IRFroutedRunoff' in routing_ds.data_vars:\n",
    "        sim_streamflow = routing_ds['IRFroutedRunoff']\n",
    "        \n",
    "        # Convert to pandas for easier analysis\n",
    "        sim_df = sim_streamflow.to_pandas()\n",
    "        \n",
    "        print(f\"‚úÖ mizuRoute simulation loaded\")\n",
    "        print(f\"   Period: {sim_df.index.min()} to {sim_df.index.max()}\")\n",
    "        print(f\"   Flow range: {sim_df.min():.1f} to {sim_df.max():.1f} m¬≥/s\")\n",
    "        \n",
    "        routing_ds.close()\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Streamflow variable not found in mizuRoute output\")\n",
    "        print(f\"   Available variables: {list(routing_ds.data_vars)}\")\n",
    "        sim_df = None\n",
    "        routing_ds.close()\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  mizuRoute output files not found in {routing_dir}, checking summa files in {summa_dir}\")\n",
    "    sim_ds = xr.open_dataset(list(summa_dir.glob(\"*_timestep.nc\"))[0])\n",
    "    shp_file = gpd.read_file(str(confluence.project_dir / \"shapefiles\" / \"catchment\" / f\"{config_dict['DOMAIN_NAME']}_HRUs_{config_dict['DOMAIN_DISCRETIZATION']}.shp\"))\n",
    "    shp_area = shp_file['GRU_area'].values[0]\n",
    "    sim_ds['averageRoutedRunoff'] = sim_ds['averageRoutedRunoff'] * shp_area\n",
    "    sim_streamflow = sim_ds['averageRoutedRunoff']    \n",
    "    sim_df = sim_streamflow.to_pandas()\n",
    "    print(f\"‚úÖ SUMMA simulation loaded\")\n",
    "    \n",
    "    sim_ds.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STREAMFLOW PERFORMANCE EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "if obs_df is not None and sim_df is not None:\n",
    "    print(f\"\\nüìä Streamflow Performance Assessment...\")\n",
    "    \n",
    "    # Align data to common period\n",
    "    start_date = max(obs_df.index.min(), sim_df.index.min())\n",
    "    end_date = min(obs_df.index.max(), sim_df.index.max())\n",
    "    \n",
    "    # Skip initial spinup period\n",
    "    start_date = start_date + pd.DateOffset(months=6)\n",
    "    \n",
    "    print(f\"   Evaluation period: {start_date} to {end_date}\")\n",
    "    print(f\"   Duration: {(end_date - start_date).days} days\")\n",
    "    \n",
    "    # Filter to common period and resample to daily\n",
    "    obs_daily = obs_df['discharge_cms'].resample('D').mean().loc[start_date:end_date]\n",
    "    sim_daily = sim_df.resample('D').mean().loc[start_date:end_date]\n",
    "    \n",
    "    # Ensure sim_daily is a Series (in case it's a DataFrame with one column)\n",
    "    if isinstance(sim_daily, pd.DataFrame):\n",
    "        if sim_daily.shape[1] == 1:\n",
    "            sim_daily = sim_daily.iloc[:, 0]  # Take the first (and likely only) column\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  sim_daily has {sim_daily.shape[1]} columns. Using the first column.\")\n",
    "            print(f\"   Available columns: {list(sim_daily.columns)}\")\n",
    "            sim_daily = sim_daily.iloc[:, 0]\n",
    "    \n",
    "    # Remove any remaining NaN values\n",
    "    valid_mask = ~(obs_daily.isna() | sim_daily.isna())\n",
    "    obs_valid = obs_daily[valid_mask]\n",
    "    sim_valid = sim_daily[valid_mask]    \n",
    "    print(f\"   Valid paired observations: {len(obs_valid)} days\")\n",
    "    \n",
    "    # Calculate comprehensive performance metrics\n",
    "    print(f\"\\nüìà Streamflow Performance Metrics:\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    rmse = np.sqrt(((obs_valid - sim_valid) ** 2).mean())\n",
    "    bias = (sim_valid - obs_valid).mean()\n",
    "    mae = np.abs(obs_valid - sim_valid).mean()\n",
    "    \n",
    "    # Relative metrics\n",
    "    pbias = 100 * bias / obs_valid.mean()\n",
    "    \n",
    "    # Nash-Sutcliffe Efficiency\n",
    "    nse = 1 - ((obs_valid - sim_valid) ** 2).sum() / ((obs_valid - obs_valid.mean()) ** 2).sum()\n",
    "    \n",
    "    # Kling-Gupta Efficiency  \n",
    "    r = obs_valid.corr(sim_valid)\n",
    "    alpha = sim_valid.std() / obs_valid.std()\n",
    "    beta = sim_valid.mean() / obs_valid.mean()\n",
    "    kge = 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "    \n",
    "    # Display performance metrics\n",
    "    print(f\"   üìä RMSE: {rmse:.2f} m¬≥/s\")\n",
    "    print(f\"   üìä Bias: {bias:+.2f} m¬≥/s ({pbias:+.1f}%)\")\n",
    "    print(f\"   üìä MAE: {mae:.2f} m¬≥/s\")\n",
    "    print(f\"   üìä Correlation (r): {r:.3f}\")\n",
    "    print(f\"   üìä Nash-Sutcliffe (NSE): {nse:.3f}\")\n",
    "    print(f\"   üìä Kling-Gupta (KGE): {kge:.3f}\")\n",
    "    \n",
    "    # Hydrologic signature analysis\n",
    "    print(f\"\\nüåä Hydrologic Signature Analysis:\")\n",
    "    \n",
    "    # Flow statistics\n",
    "    obs_q95 = obs_valid.quantile(0.95)  # High flows\n",
    "    sim_q95 = sim_valid.quantile(0.95)\n",
    "    obs_q05 = obs_valid.quantile(0.05)  # Low flows  \n",
    "    sim_q05 = sim_valid.quantile(0.05)\n",
    "    \n",
    "    print(f\"   High flows (Q95): Obs={obs_q95:.1f}, Sim={sim_q95:.1f} m¬≥/s\")\n",
    "    print(f\"   Low flows (Q05): Obs={obs_q05:.1f}, Sim={sim_q05:.1f} m¬≥/s\")\n",
    "    \n",
    "    # Seasonal timing\n",
    "    obs_monthly = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "    sim_monthly = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "    peak_month_obs = obs_monthly.idxmax()\n",
    "    peak_month_sim = sim_monthly.idxmax()\n",
    "    \n",
    "    print(f\"   Peak flow timing: Obs=Month {peak_month_obs}, Sim=Month {peak_month_sim}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # STREAMFLOW VISUALIZATION\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\nüìà Creating comprehensive streamflow evaluation...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Time series comparison (top left)\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(obs_valid.index, obs_valid.values, 'b-', \n",
    "             label='WSC Observed', linewidth=1.5, alpha=0.8)\n",
    "    ax1.plot(sim_valid.index, sim_valid.values, 'r-', \n",
    "             label='SUMMA + mizuRoute', linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    ax1.set_ylabel('Discharge (m¬≥/s)', fontsize=11)\n",
    "    ax1.set_title('Streamflow Time Series', fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance metrics\n",
    "    metrics_text = f'NSE: {nse:.3f}\\nKGE: {kge:.3f}\\nBias: {pbias:+.1f}%'\n",
    "    ax1.text(0.02, 0.95, metrics_text, transform=ax1.transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8), fontsize=10, verticalalignment='top')\n",
    "    \n",
    "    # Scatter plot (top right)\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.scatter(obs_valid, sim_valid, alpha=0.5, c='blue', s=20)\n",
    "    max_val = max(obs_valid.max(), sim_valid.max())\n",
    "    ax2.plot([0, max_val], [0, max_val], 'k--', label='1:1 line')\n",
    "    ax2.set_xlabel('Observed (m¬≥/s)', fontsize=11)\n",
    "    ax2.set_ylabel('Simulated (m¬≥/s)', fontsize=11)\n",
    "    ax2.set_title('Obs vs Sim Streamflow', fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Monthly climatology (bottom left)\n",
    "    ax3 = axes[1, 0]\n",
    "    months = range(1, 13)\n",
    "    month_names = ['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D']\n",
    "    \n",
    "    ax3.plot(months, obs_monthly.values, 'o-', label='Observed', \n",
    "             color='blue', linewidth=2, markersize=6)\n",
    "    ax3.plot(months, sim_monthly.values, 'o-', label='Simulated', \n",
    "             color='red', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax3.set_xticks(months)\n",
    "    ax3.set_xticklabels(month_names)\n",
    "    ax3.set_ylabel('Mean Discharge (m¬≥/s)', fontsize=11)\n",
    "    ax3.set_title('Seasonal Flow Regime', fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Flow duration curve (bottom right)\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Calculate exceedance probabilities\n",
    "    obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "    sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "    obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "    sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "    \n",
    "    ax4.semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "    ax4.semilogy(sim_ranks, sim_sorted, 'r-', label='Simulated', linewidth=2)\n",
    "    \n",
    "    ax4.set_xlabel('Exceedance Probability (%)', fontsize=11)\n",
    "    ax4.set_ylabel('Discharge (m¬≥/s)', fontsize=11)\n",
    "    ax4.set_title('Flow Duration Curve', fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Basin-Scale Streamflow Evaluation - {config_dict[\"DOMAIN_NAME\"]}',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot perform streamflow evaluation - missing simulation or observation data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ready to explore Semi-Distributed basin simulations?** ‚Üí **[Tutorial 03b: Basin Scale - Semi-Distributed Watershed](./02b_basin_semi_distributed.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
