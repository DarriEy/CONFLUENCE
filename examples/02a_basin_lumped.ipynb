{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 3: Lumped Basin Workflow (Bow River at Banff)\n",
    "\n",
    "## Introduction\n",
    "This tutorial demonstrates the scaling transition from point-scale validation to basin-scale streamflow simulation using CONFLUENCE. Building on our previous tutorials with SNOTEL and FLUXNET data validation, we now advance to modeling an entire watershed as a single computational unit to generate streamflow predictions at the basin outlet, establishing the foundation for distributed hydrological modeling applications.\n",
    "\n",
    "## Lumped Basin Modeling Philosophy\n",
    "Lumped basin modeling treats the entire watershed as one homogeneous computational unit, spatially averaging all variability across the catchment. While this represents a simplification of complex spatial heterogeneity, lumped modeling provides exceptional scientific value through its computational simplicity that enables efficient implementation and rapid execution ideal for calibration and uncertainty analysis. This approach establishes baseline performance by determining whether a model can capture fundamental watershed response before adding spatial complexity, while its simplified parameter structure facilitates clear understanding of which parameters control model behavior and hydrological processes.\n",
    "\n",
    "## Case Study: Bow River at Banff\n",
    "Our demonstration focuses on the Bow River at Banff watershed, located in the Canadian Rockies of Alberta, Canada. This watershed encompasses approximately 2,210 km¬≤ with elevations ranging from 1,384 m at the outlet to over 3,400 m in the headwaters, representing a snow-dominated mountain system with pronounced seasonal cycles. The basin is monitored by Water Survey of Canada station 05BB001, which provides long-term streamflow observations essential for model validation.\n",
    "\n",
    "This watershed presents compelling modeling challenges through strong elevation gradients that affect temperature and precipitation patterns, complex snow dynamics across multiple elevation zones, seasonal water storage in snowpack and glacial systems, and pronounced spring freshet periods driven by snowmelt processes. These characteristics make it an ideal testbed for demonstrating CONFLUENCE's capabilities in mountain hydrology and snow-dominated basin modeling.\n",
    "\n",
    "## Learning Objectives and Workflow\n",
    "Through this tutorial, you will master basin-scale project setup using CONFLUENCE's automated workflow management, understand automated watershed delineation from digital elevation models, learn spatial data aggregation techniques for creating catchment-averaged characteristics, process meteorological forcing data for basin-scale applications, configure and execute SUMMA for lumped basin simulation, evaluate model performance using standard hydrological metrics, and interpret results within the context of model limitations and watershed processes.\n",
    "\n",
    "The tutorial follows the complete CONFLUENCE workflow through systematic project setup and organized directory structure creation, automated watershed delineation to identify basin boundaries, comprehensive data acquisition including elevation, soil, and land cover characteristics, meteorological forcing data processing and spatial averaging, SUMMA model configuration for lumped basin representation, integrated model execution with streamflow routing, and comprehensive results analysis comparing simulated and observed streamflow patterns. By completing this tutorial, you will understand how CONFLUENCE manages the critical transition from point-scale process validation to basin-scale integrated modeling, preparing you for more complex distributed modeling approaches in subsequent tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Basin-Scale Workflow Setup\n",
    "Building on the point-scale modeling expertise from Tutorials 01a and 01b, we now advance to basin-scale hydrological modeling. This represents a scaling transition from process validation at individual sites to integrated watershed simulation that captures the collective hydrological response of an entire catchment.\n",
    "\n",
    "The same CONFLUENCE architecture seamlessly handles this transition, demonstrating the framework's scalability from point validation through basin-scale prediction while maintaining reproducible workflow principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll need in this notebook\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION FOR BOW RIVER AT BANFF WATERSHED\n",
    "# =============================================================================\n",
    "\n",
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/Users/darrieythorsson/compHydro/data/CONFLUENCE_data')  \n",
    "#CONFLUENCE_DATA_DIR = Path('/path/to/your/CONFLUENCE_data') \n",
    "\n",
    "# Load template configuration and customize for basin-scale modeling\n",
    "config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "\n",
    "with open(config_template_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update for Bow River basin-scale modeling\n",
    "config_updates = {\n",
    "    'CONFLUENCE_CODE_DIR': str(CONFLUENCE_CODE_DIR),\n",
    "    'CONFLUENCE_DATA_DIR': str(CONFLUENCE_DATA_DIR),\n",
    "    'DOMAIN_NAME': 'Bow_at_Banff_lumped',\n",
    "    'EXPERIMENT_ID': 'run_1',\n",
    "    'POUR_POINT_COORDS': '51.1722/-115.5717',  # Banff gauging station\n",
    "    'DOMAIN_DEFINITION_METHOD': 'lumped',    # Watershed delineation vs point buffer\n",
    "    'DOMAIN_DISCRETIZATION': 'GRUS',          # Single HRU for entire watershed\n",
    "    'HYDROLOGICAL_MODEL': 'SUMMA',\n",
    "    'EXPERIMENT_TIME_START': '2004-01-01 01:00',\n",
    "    'EXPERIMENT_TIME_END': '2018-12-31 23:00',\n",
    "    'CALIBRATION_PERIOD': '2004-01-01, 2010-12-31',\n",
    "    'EVALUATION_PERIOD': '2011-01-01, 2018-12-31',\n",
    "    'SPINUP_PERIOD': '2004-01-01, 2005-12-31',\n",
    "    'STATION_ID': '05BB001',                     # WSC streamflow station\n",
    "    'DOWNLOAD_WSC_DATA': True\n",
    "}\n",
    "\n",
    "config_dict.update(config_updates)\n",
    "\n",
    "# Save configuration\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_basin_notebook.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"‚úÖ Configuration saved: {temp_config_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SYSTEM INITIALIZATION AND PROJECT STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize CONFLUENCE with basin configuration\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "# Create project structure\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"\\n Basin-scale setup complete - Ready for watershed delineation and streamflow modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basin Representation and Spatial Discretization Fundamentals\n",
    "The transition from point-scale to basin-scale modeling requires fundamental decisions about how to represent spatial heterogeneity within the watershed. Unlike point-scale modeling where we assume uniform conditions, basin-scale modeling must address the challenge of capturing spatial variability while maintaining computational tractability and scientific interpretability.\n",
    "\n",
    "### Scientific Context: Basin Representation Philosophy\n",
    "Basin-scale hydrological modeling confronts significant spatial heterogeneity challenges that profoundly influence water cycling processes. Elevation gradients create complex patterns in temperature lapse rates, precipitation distributions, and snow line dynamics that control seasonal water storage and release. Vegetation patterns ranging from dense forest to alpine zones fundamentally alter evapotranspiration rates and interception processes. Soil variability across the landscape affects infiltration capacity, water storage potential, and drainage characteristics that determine runoff generation mechanisms. Topographic effects including slope, aspect, and drainage network configuration control flow routing and energy balance processes. Climate gradients manifest through orographic precipitation enhancement, temperature inversions, and wind pattern modifications that create substantial spatial variability in hydrological drivers.\n",
    "\n",
    "### Representation Strategies and Discretization Approaches\n",
    "Hydrological modeling addresses these spatial complexities through three primary representation strategies, each offering distinct advantages and computational trade-offs. The lumped approach treats the entire watershed as a single computational unit with spatially-averaged characteristics, providing computational efficiency and parameter interpretability while sacrificing spatial detail. Semi-distributed strategies create multiple computational units based on landscape similarity criteria such as elevation bands, soil types, or land cover classes, balancing spatial representation with computational tractability. Fully distributed approaches employ grid-based representation with explicit spatial patterns, capturing detailed heterogeneity at the cost of increased computational demands and parameter complexity.\n",
    "\n",
    "The Grouped Response Unit (GRU) concept provides flexible spatial discretization that allows users to choose the appropriate level of complexity for their scientific objectives and computational constraints. This framework enables seamless transitions from lumped representations through increasingly detailed semi-distributed configurations, ensuring that model complexity aligns with both scientific questions and available computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute attribute acquisition\n",
    "#confluence.managers['data'].acquire_attributes()\n",
    "print(\"‚úÖ Basin-scale attribute acquisition complete\")\n",
    "\n",
    "# Execute watershed delineation\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "print(\"‚úÖ Watershed delineation complete\")\n",
    "\n",
    "# Execute domain discretization\n",
    "confluence.managers['domain'].discretize_domain()\n",
    "print(\"‚úÖ Domain discretization complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION AND ANALYSIS OF BASIN REPRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spatial data\n",
    "hru_path = str(Path(config_dict['CONFLUENCE_DATA_DIR']) / f\"domain_{config_dict['DOMAIN_NAME']}\" / 'shapefiles' / 'catchment' / f\"{config_dict['DOMAIN_NAME']}_HRUs_{config_dict['DOMAIN_DISCRETIZATION']}.shp\")\n",
    "watershed_gdf = gpd.read_file(str(watershed_path[1]))\n",
    "hru_gdf = gpd.read_file(hru_path)\n",
    "pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "\n",
    "# Project to appropriate CRS for area calculations\n",
    "# For Bow River at Banff (Alberta), UTM Zone 11N is appropriate\n",
    "target_crs = 'EPSG:32611'  # UTM Zone 11N\n",
    "watershed_projected = watershed_gdf.to_crs(target_crs)\n",
    "hru_projected = hru_gdf.to_crs(target_crs)\n",
    "\n",
    "print(f\"\\nüìã Basin Characteristics:\")\n",
    "total_area_m2 = watershed_projected.geometry.area.sum()\n",
    "total_area_km2 = total_area_m2 / 1e6\n",
    "print(f\"   Watershed area: {total_area_km2:.1f} km¬≤\")\n",
    "print(f\"   Number of GRUs: {len(hru_gdf)}\")\n",
    "print(f\"   Average GRU size: {total_area_km2/len(hru_gdf):.1f} km¬≤\")\n",
    "\n",
    "# Display HRU characteristics if available\n",
    "if 'elevation' in hru_gdf.columns:\n",
    "    print(f\"   Elevation range: {hru_gdf['elevation'].min():.0f}m to {hru_gdf['elevation'].max():.0f}m\")\n",
    "if 'slope' in hru_gdf.columns:\n",
    "    print(f\"   Slope range: {hru_gdf['slope'].min():.1f}¬∞ to {hru_gdf['slope'].max():.1f}¬∞\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "print(f\"\\nüó∫Ô∏è  Creating basin representation visualization...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Left plot: Watershed boundary and pour point (use original CRS for plotting)\n",
    "ax1 = axes[0]\n",
    "watershed_gdf.plot(ax=ax1, facecolor='lightblue', edgecolor='navy', \n",
    "                  linewidth=2, alpha=0.7)\n",
    "pour_point_gdf.plot(ax=ax1, color='red', markersize=100, marker='o',\n",
    "                   edgecolor='white', linewidth=2, zorder=5)\n",
    "ax1.set_title('Delineated Watershed Boundary', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Longitude', fontsize=12)\n",
    "ax1.set_ylabel('Latitude', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add area annotation\n",
    "ax1.text(0.02, 0.98, f'Area: {total_area_km2:.1f} km¬≤\\nPour Point: WSC {config_dict[\"STATION_ID\"]}',\n",
    "         transform=ax1.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3'))\n",
    "\n",
    "# Right plot: HRU discretization\n",
    "ax2 = axes[1]\n",
    "# Color HRUs by elevation if available, otherwise by area (using projected areas)\n",
    "if 'elevation' in hru_gdf.columns:\n",
    "    hru_gdf.plot(ax=ax2, column='elevation', cmap='terrain', \n",
    "                edgecolor='black', linewidth=0.5, legend=True)\n",
    "    colorbar_label = 'Elevation (m)'\n",
    "else:\n",
    "    # Use projected geometries for area calculation\n",
    "    hru_areas_km2 = hru_projected.geometry.area / 1e6\n",
    "    hru_gdf.plot(ax=ax2, column=hru_areas_km2, cmap='viridis',\n",
    "                edgecolor='black', linewidth=0.5, legend=True) \n",
    "    colorbar_label = 'Area (km¬≤)'\n",
    "\n",
    "pour_point_gdf.plot(ax=ax2, color='red', markersize=100, marker='o',\n",
    "                   edgecolor='white', linewidth=2, zorder=5)\n",
    "ax2.set_title(f'GRU Discretization ({len(hru_gdf)} units)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Longitude', fontsize=12)\n",
    "ax2.set_ylabel('Latitude', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add discretization info\n",
    "ax2.text(0.02, 0.98, f'GRUs: {len(hru_gdf)}\\nAvg. size: {total_area_km2/len(hru_gdf):.1f} km¬≤',\n",
    "         transform=ax2.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3'))\n",
    "\n",
    "plt.suptitle(f'Bow River at Banff: Basin Representation', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Pipeline for Basin-Scale Streamflow Modeling\n",
    "The same model-agnostic preprocessing framework now scales from point validation to basin-scale streamflow simulation. The core philosophy remains unchanged‚Äîstandardized, quality-controlled data products‚Äîbut the spatial context shifts from single locations to integrated watershed responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute streamflow data processing\n",
    "confluence.managers['data'].process_observed_data()\n",
    "print(\"‚úÖ Streamflow data processing complete\")\n",
    "\n",
    "# Execute forcing acquisition (commented for demonstration)\n",
    "# confluence.managers['data'].acquire_forcings()\n",
    "print(\"‚úÖ forcing acquisition complete (simulated)\")\n",
    "\n",
    "# Execute model-agnostic preprocessing\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"‚úÖ Model-agnostic preprocessing complete\")\n",
    "\n",
    "# Execute model-specific preprocessing\n",
    "confluence.managers['model'].preprocess_models()\n",
    "print(\"‚úÖ Basin-scale model configuration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Streamlined Basin-Scale Model Execution\n",
    "The same SUMMA process-based physics now scales from point validation to integrated basin simulation, but with the critical addition of streamflow routing. This represents a fundamental modeling advancement: from isolated vertical processes to coupled vertical-horizontal water transport that generates streamflow at the basin outlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute the integrated model system\n",
    "confluence.managers['model'].run_models()\n",
    "print(\"‚úÖ Basin-scale integrated simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Streamflow Evaluation and Basin Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load observed streamflow data\n",
    "obs_path = confluence.project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config_dict['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "    \n",
    "# Load simulated streamflow from mizuRoute\n",
    "summa_dir = confluence.project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"SUMMA\"\n",
    "routing_dir = confluence.project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"mizuRoute\"\n",
    "routing_files = list(routing_dir.glob(\"*.nc\"))\n",
    "\n",
    "if routing_files:\n",
    "    # Load mizuRoute output\n",
    "    routing_ds = xr.open_dataset(routing_files[0])\n",
    "    \n",
    "    # Extract streamflow variable (typically IRFroutedRunoff)\n",
    "    sim_streamflow = routing_ds['IRFroutedRunoff']\n",
    "    sim_df = sim_streamflow.to_pandas()    \n",
    "    routing_ds.close()\n",
    "\n",
    "else:\n",
    "    sim_ds = xr.open_dataset(list(summa_dir.glob(\"*_timestep.nc\"))[0])\n",
    "    shp_file = gpd.read_file(str(confluence.project_dir / \"shapefiles\" / \"catchment\" / f\"{config_dict['DOMAIN_NAME']}_HRUs_{config_dict['DOMAIN_DISCRETIZATION']}.shp\"))\n",
    "    shp_area = shp_file['GRU_area'].values[0]\n",
    "    sim_ds['averageRoutedRunoff'] = sim_ds['averageRoutedRunoff'] * shp_area\n",
    "    sim_streamflow = sim_ds['averageRoutedRunoff']    \n",
    "    sim_df = sim_streamflow.to_pandas()\n",
    "    \n",
    "    sim_ds.close()\n",
    "\n",
    "# =============================================================================\n",
    "# STREAMFLOW PERFORMANCE EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n Streamflow Performance Assessment...\")\n",
    "\n",
    "# Align data to common period\n",
    "start_date = max(obs_df.index.min(), sim_df.index.min())\n",
    "end_date = min(obs_df.index.max(), sim_df.index.max())\n",
    "\n",
    "# Skip initial spinup period\n",
    "start_date = start_date + pd.DateOffset(months=6)\n",
    "\n",
    "print(f\"   Evaluation period: {start_date} to {end_date}\")\n",
    "print(f\"   Duration: {(end_date - start_date).days} days\")\n",
    "\n",
    "# Filter to common period and resample to daily\n",
    "obs_daily = obs_df['discharge_cms'].resample('D').mean().loc[start_date:end_date]\n",
    "sim_daily = sim_df.resample('D').mean().loc[start_date:end_date]\n",
    "\n",
    "# Ensure sim_daily is a Series (in case it's a DataFrame with one column)\n",
    "if isinstance(sim_daily, pd.DataFrame):\n",
    "    if sim_daily.shape[1] == 1:\n",
    "        sim_daily = sim_daily.iloc[:, 0]  # Take the first (and likely only) column\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  sim_daily has {sim_daily.shape[1]} columns. Using the first column.\")\n",
    "        print(f\"   Available columns: {list(sim_daily.columns)}\")\n",
    "        sim_daily = sim_daily.iloc[:, 0]\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "valid_mask = ~(obs_daily.isna() | sim_daily.isna())\n",
    "obs_valid = obs_daily[valid_mask]\n",
    "sim_valid = sim_daily[valid_mask]    \n",
    "print(f\"   Valid paired observations: {len(obs_valid)} days\")\n",
    "\n",
    "# Calculate comprehensive performance metrics\n",
    "print(f\"\\nüìà Streamflow Performance Metrics:\")\n",
    "\n",
    "# Basic statistics\n",
    "rmse = np.sqrt(((obs_valid - sim_valid) ** 2).mean())\n",
    "bias = (sim_valid - obs_valid).mean()\n",
    "mae = np.abs(obs_valid - sim_valid).mean()\n",
    "\n",
    "# Relative metrics\n",
    "pbias = 100 * bias / obs_valid.mean()\n",
    "\n",
    "# Nash-Sutcliffe Efficiency\n",
    "nse = 1 - ((obs_valid - sim_valid) ** 2).sum() / ((obs_valid - obs_valid.mean()) ** 2).sum()\n",
    "\n",
    "# Kling-Gupta Efficiency  \n",
    "r = obs_valid.corr(sim_valid)\n",
    "alpha = sim_valid.std() / obs_valid.std()\n",
    "beta = sim_valid.mean() / obs_valid.mean()\n",
    "kge = 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "# Display performance metrics\n",
    "print(f\"   üìä RMSE: {rmse:.2f} m¬≥/s\")\n",
    "print(f\"   üìä Bias: {bias:+.2f} m¬≥/s ({pbias:+.1f}%)\")\n",
    "print(f\"   üìä MAE: {mae:.2f} m¬≥/s\")\n",
    "print(f\"   üìä Correlation (r): {r:.3f}\")\n",
    "print(f\"   üìä Nash-Sutcliffe (NSE): {nse:.3f}\")\n",
    "print(f\"   üìä Kling-Gupta (KGE): {kge:.3f}\")\n",
    "\n",
    "# Hydrologic signature analysis\n",
    "print(f\"\\nüåä Hydrologic Signature Analysis:\")\n",
    "\n",
    "# Flow statistics\n",
    "obs_q95 = obs_valid.quantile(0.95)  # High flows\n",
    "sim_q95 = sim_valid.quantile(0.95)\n",
    "obs_q05 = obs_valid.quantile(0.05)  # Low flows  \n",
    "sim_q05 = sim_valid.quantile(0.05)\n",
    "\n",
    "print(f\"   High flows (Q95): Obs={obs_q95:.1f}, Sim={sim_q95:.1f} m¬≥/s\")\n",
    "print(f\"   Low flows (Q05): Obs={obs_q05:.1f}, Sim={sim_q05:.1f} m¬≥/s\")\n",
    "\n",
    "# Seasonal timing\n",
    "obs_monthly = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "sim_monthly = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "peak_month_obs = obs_monthly.idxmax()\n",
    "peak_month_sim = sim_monthly.idxmax()\n",
    "\n",
    "print(f\"   Peak flow timing: Obs=Month {peak_month_obs}, Sim=Month {peak_month_sim}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STREAMFLOW VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Time series comparison (top left)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(obs_valid.index, obs_valid.values, 'b-', \n",
    "         label='WSC Observed', linewidth=1.5, alpha=0.8)\n",
    "ax1.plot(sim_valid.index, sim_valid.values, 'r-', \n",
    "         label='SUMMA + mizuRoute', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('Discharge (m¬≥/s)', fontsize=11)\n",
    "ax1.set_title('Streamflow Time Series', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add performance metrics\n",
    "metrics_text = f'NSE: {nse:.3f}\\nKGE: {kge:.3f}\\nBias: {pbias:+.1f}%'\n",
    "ax1.text(0.02, 0.95, metrics_text, transform=ax1.transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.8), fontsize=10, verticalalignment='top')\n",
    "\n",
    "# Scatter plot (top right)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(obs_valid, sim_valid, alpha=0.5, c='blue', s=20)\n",
    "max_val = max(obs_valid.max(), sim_valid.max())\n",
    "ax2.plot([0, max_val], [0, max_val], 'k--', label='1:1 line')\n",
    "ax2.set_xlabel('Observed (m¬≥/s)', fontsize=11)\n",
    "ax2.set_ylabel('Simulated (m¬≥/s)', fontsize=11)\n",
    "ax2.set_title('Obs vs Sim Streamflow', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly climatology (bottom left)\n",
    "ax3 = axes[1, 0]\n",
    "months = range(1, 13)\n",
    "month_names = ['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D']\n",
    "\n",
    "ax3.plot(months, obs_monthly.values, 'o-', label='Observed', \n",
    "         color='blue', linewidth=2, markersize=6)\n",
    "ax3.plot(months, sim_monthly.values, 'o-', label='Simulated', \n",
    "         color='red', linewidth=2, markersize=6)\n",
    "\n",
    "ax3.set_xticks(months)\n",
    "ax3.set_xticklabels(month_names)\n",
    "ax3.set_ylabel('Mean Discharge (m¬≥/s)', fontsize=11)\n",
    "ax3.set_title('Seasonal Flow Regime', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Flow duration curve (bottom right)\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Calculate exceedance probabilities\n",
    "obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "\n",
    "ax4.semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "ax4.semilogy(sim_ranks, sim_sorted, 'r-', label='Simulated', linewidth=2)\n",
    "\n",
    "ax4.set_xlabel('Exceedance Probability (%)', fontsize=11)\n",
    "ax4.set_ylabel('Discharge (m¬≥/s)', fontsize=11)\n",
    "ax4.set_title('Flow Duration Curve', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Basin-Scale Streamflow Evaluation - {config_dict[\"DOMAIN_NAME\"]}',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Lumped Basin-Scale Streamflow Simulation\n",
    "This tutorial successfully demonstrated the critical scaling transition from point-scale process validation to basin-scale integrated streamflow simulation using CONFLUENCE. Through the Bow River at Banff case study, we illustrated how the same standardized workflow framework seamlessly scales from individual site validation to watershed-scale prediction while maintaining scientific rigor and computational efficiency.\n",
    "\n",
    "## Key Methodological Achievements\n",
    "The tutorial established watershed-scale modeling capabilities by successfully transitioning from point measurements to integrated basin response through automated watershed delineation and lumped representation strategies. Spatial aggregation techniques were demonstrated through catchment-averaged characteristic development that captures essential watershed properties while maintaining computational tractability. Integrated process simulation was achieved by coupling SUMMA's process-based physics with mizuRoute streamflow routing to transform distributed runoff generation into streamflow predictions at the basin outlet.\n",
    "\n",
    "## Scientific Process Understanding\n",
    "The evaluation demonstrated CONFLUENCE's ability to simulate integrated watershed response through the successful representation of snow accumulation, melt, and runoff generation processes across elevation gradients in a mountain environment. Seasonal flow regime capture was validated through comparison with long-term Water Survey of Canada observations, showing the model's capability to represent pronounced spring freshet patterns and low-flow periods. Water balance closure was maintained through conservation of mass principles while scaling from point processes to basin-integrated streamflow generation.\n",
    "\n",
    "## Framework Scalability Validation\n",
    "This tutorial confirmed CONFLUENCE's seamless scaling capabilities by applying identical workflow principles from point validation through basin-scale prediction without requiring fundamental architectural changes. The model-agnostic preprocessing approach proved equally effective for basin-averaged forcing and validation data preparation, reinforcing the framework's broad applicability. Computational efficiency was demonstrated through lumped representation strategies that enable rapid execution suitable for calibration, uncertainty analysis, and operational applications while maintaining process-based physical realism.\n",
    "\n",
    "This foundation in lumped basin modeling establishes the essential principles for understanding watershed-scale hydrological behavior and \n",
    "prepares for the spatial complexity introduced in semi-distributed and fully distributed modeling approaches in subsequent tutorials.\n",
    "\n",
    "### Next Focus: Semi-Distributed Watershed Modelling \n",
    "\n",
    "**Ready to explore Semi-Distributed basin simulations?** ‚Üí **[Tutorial 02b: Basin Scale - Semi-Distributed Watershed](./02b_basin_semi_distributed.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
