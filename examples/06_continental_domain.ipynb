{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Continental-Scale Modeling - North America\n",
    "\n",
    "This notebook demonstrates how to set up a continental-scale SUMMA model for North America. We'll move quickly through the workflow, focusing on the scale differences from previous tutorials.\n",
    "\n",
    "## Key Points\n",
    "- **Scale**: From country (Iceland) to continent (North America)\n",
    "- **Computational considerations**: Much larger domain\n",
    "- **Simplified approach**: Quick setup for demonstration\n",
    "- **High-performance computing**: Required for continental modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgpd\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/pyplot.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcycler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolorbar\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/colorbar.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmartist\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpatches\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/collections.py:1582\u001b[39m\n\u001b[32m   1578\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Draw a collection of regular stars with *numsides* points.\"\"\"\u001b[39;00m\n\u001b[32m   1579\u001b[39m     _path_generator = mpath.Path.unit_regular_star\n\u001b[32m-> \u001b[39m\u001b[32m1582\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mAsteriskPolygonCollection\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mRegularPolyCollection\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1583\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"Draw a collection of regular asterisks with *numsides* points.\"\"\"\u001b[39;49;00m\n\u001b[32m   1584\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_path_generator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m.\u001b[49m\u001b[43munit_regular_asterisk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/artist.py:149\u001b[39m, in \u001b[36mArtist.__init_subclass__\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mcls\u001b[39m.set.\u001b[34m__name__\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28mcls\u001b[39m.set.\u001b[34m__qualname__\u001b[39m = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_set_signature_and_docstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/artist.py:177\u001b[39m, in \u001b[36mArtist._update_set_signature_and_docstring\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28mcls\u001b[39m.set.__signature__ = Signature(\n\u001b[32m    168\u001b[39m     [Parameter(\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m, Parameter.POSITIONAL_OR_KEYWORD),\n\u001b[32m    169\u001b[39m      *[Parameter(prop, Parameter.KEYWORD_ONLY, default=_UNSET)\n\u001b[32m    170\u001b[39m        \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m ArtistInspector(\u001b[38;5;28mcls\u001b[39m).get_setters()\n\u001b[32m    171\u001b[39m        \u001b[38;5;28;01mif\u001b[39;00m prop \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m Artist._PROPERTIES_EXCLUDED_FROM_SET]])\n\u001b[32m    172\u001b[39m \u001b[38;5;28mcls\u001b[39m.set._autogenerated_signature = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;28mcls\u001b[39m.set.\u001b[34m__doc__\u001b[39m = (\n\u001b[32m    175\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSet multiple properties at once.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSupported properties are\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     + \u001b[43mkwdoc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/artist.py:1851\u001b[39m, in \u001b[36mkwdoc\u001b[39m\u001b[34m(artist)\u001b[39m\n\u001b[32m   1833\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1834\u001b[39m \u001b[33;03mInspect an `~matplotlib.artist.Artist` class (using `.ArtistInspector`) and\u001b[39;00m\n\u001b[32m   1835\u001b[39m \u001b[33;03mreturn information about its settable properties and their current values.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1846\u001b[39m \u001b[33;03m    use in Sphinx) if it is True.\u001b[39;00m\n\u001b[32m   1847\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1848\u001b[39m ai = ArtistInspector(artist)\n\u001b[32m   1849\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join(ai.pprint_setters_rest(leadingspace=\u001b[32m4\u001b[39m))\n\u001b[32m   1850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mdocstring.hardcopy\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1851\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mProperties:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join(\u001b[43mai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpprint_setters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleadingspace\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/artist.py:1613\u001b[39m, in \u001b[36mArtistInspector.pprint_setters\u001b[39m\u001b[34m(self, prop, leadingspace)\u001b[39m\n\u001b[32m   1611\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_setters()):\n\u001b[32m   1612\u001b[39m     accepts = \u001b[38;5;28mself\u001b[39m.get_valid_values(prop)\n\u001b[32m-> \u001b[39m\u001b[32m1613\u001b[39m     name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maliased_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1614\u001b[39m     lines.append(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccepts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m   1615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/conf-env/lib/python3.11/site-packages/matplotlib/artist.py:1557\u001b[39m, in \u001b[36mArtistInspector.aliased_name\u001b[39m\u001b[34m(self, s)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maliased_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[32m   1550\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1551\u001b[39m \u001b[33;03m    Return 'PROPNAME or alias' if *s* has an alias, else return 'PROPNAME'.\u001b[39;00m\n\u001b[32m   1552\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1555\u001b[39m \u001b[33;03m    property, which does not, return 'transform'.\u001b[39;00m\n\u001b[32m   1556\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1557\u001b[39m     aliases = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m.aliasd.get(s, [])))\n\u001b[32m   1558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s + aliases\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import contextily as cx\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import CONFLUENCE\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Working from: {confluence_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize CONFLUENCE for Continental Domain\n",
    "We'll configure CONFLUENCE for a continental-scale domain with appropriate settings for North America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # ← User should modify this path\n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load template configuration\n",
    "config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "with open(config_template_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update with North America-specific settings\n",
    "config_dict['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config_dict['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "\n",
    "# Set North America domain and continental-specific settings\n",
    "config_dict['DOMAIN_NAME'] = \"North_America_continent\"  \n",
    "config_dict['EXPERIMENT_ID'] = \"continental_run_1\"\n",
    "config_dict['EXPERIMENT_TIME_START'] = \"2018-01-01 01:00\"\n",
    "config_dict['EXPERIMENT_TIME_END'] = \"2019-12-31 23:00\"  # Shorter period for demonstration\n",
    "config_dict['SPATIAL_MODE'] = \"Distributed\"\n",
    "\n",
    "# North America continent regional domain settings\n",
    "config_dict['BOUNDING_BOX_COORDS'] = \"83.0/-170.0/5.0/-50.0\"  # North/West/South/East\n",
    "config_dict['POUR_POINT_COORDS'] = \"n/a\"  # Not needed for continental domain\n",
    "config_dict['DELINEATE_BY_POURPOINT'] = False\n",
    "config_dict['DELINEATE_COASTAL_WATERSHEDS'] = True\n",
    "config_dict['DOMAIN_DEFINITION_METHOD'] = \"delineate_geofabric\" \n",
    "config_dict['STREAM_THRESHOLD'] = 7500  # Larger threshold for continental scale\n",
    "config_dict['DOMAIN_DISCRETIZATION'] = \"GRUs\"\n",
    "config_dict['MIN_GRU_SIZE'] = 50  # Larger minimum size for continental domain\n",
    "config_dict['MPI_PROCESSES'] = 40  # Higher for parallel processing\n",
    "\n",
    "# Write to temporary config file\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_north_america.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f)\n",
    "\n",
    "# Initialize CONFLUENCE\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "# Parse bounding box for visualization\n",
    "bbox = config_dict['BOUNDING_BOX_COORDS'].split('/')\n",
    "lat_max, lon_min, lat_min, lon_max = map(float, bbox)\n",
    "\n",
    "# Display configuration\n",
    "print(\"=== North America Continental Configuration ===\")\n",
    "print(f\"Domain Name: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Bounding Box: {confluence.config['BOUNDING_BOX_COORDS']}\")\n",
    "print(f\"Delineate by Pour Point: {confluence.config['DELINEATE_BY_POURPOINT']} (Full continent!)\")\n",
    "print(f\"Include Coastal Watersheds: {confluence.config['DELINEATE_COASTAL_WATERSHEDS']}\")\n",
    "print(f\"Stream Threshold: {confluence.config['STREAM_THRESHOLD']} (larger for continental scale)\")\n",
    "print(f\"Min GRU Size: {confluence.config['MIN_GRU_SIZE']} km²\")\n",
    "print(f\"MPI Processes: {confluence.config['MPI_PROCESSES']} (high for parallel processing)\")\n",
    "\n",
    "# Display geographic extent\n",
    "print(f\"\\nGeographic extent:\")\n",
    "print(f\"  North: {lat_max}°N (Arctic)\")\n",
    "print(f\"  South: {lat_min}°N (Central America)\")\n",
    "print(f\"  West: {lon_min}°E (Pacific)\")\n",
    "print(f\"  East: {lon_max}°E (Atlantic)\")\n",
    "print(f\"  Extent: {abs(lat_max - lat_min):.1f}° latitude × {abs(lon_max - lon_min):.1f}° longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Continental Domain\n",
    "Let's visualize the North America domain to understand the scale we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of North America's extent\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Create bounding box\n",
    "na_box = box(lon_min, lat_min, lon_max, lat_max)\n",
    "na_bbox = gpd.GeoDataFrame({'geometry': [na_box]}, crs='EPSG:4326')\n",
    "\n",
    "# Plot bounding box\n",
    "na_bbox.boundary.plot(ax=ax, color='red', linewidth=2, label='Study Area')\n",
    "\n",
    "# Add some context\n",
    "ax.set_xlim(lon_min - 5, lon_max + 5)\n",
    "ax.set_ylim(lat_min - 5, lat_max + 5)\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('North America Continental Domain', fontsize=16, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotation\n",
    "ax.text(0.5, 0.95, 'Continental-scale domain with coastal watersheds',\n",
    "        ha='center', va='top', transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "        fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create scale comparison visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define area scales for comparison\n",
    "scales = {\n",
    "    'Bow River at Banff': 2_210,\n",
    "    'Iceland': 103_000,\n",
    "    'North America': 24_700_000\n",
    "}\n",
    "\n",
    "# Create logarithmic scale bar chart\n",
    "ax.bar(scales.keys(), np.log10(list(scales.values())), color=['lightblue', 'lightgreen', 'coral'])\n",
    "ax.set_ylabel('Area (log₁₀ km²)', fontsize=12)\n",
    "ax.set_title('Scale Comparison: Watershed to Continent', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add area labels\n",
    "for i, (domain, area) in enumerate(scales.items()):\n",
    "    ax.text(i, np.log10(area) + 0.1, f'{area:,} km²', ha='center', fontsize=10)\n",
    "\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Project Setup - Continental Scale\n",
    "Let's set up our continental-scale project structure. This will be similar to the regional domain but will need to handle much larger data volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Project Initialization\n",
    "print(\"=== Step 1: Project Initialization ===\")\n",
    "print(\"Setting up continental project...\")\n",
    "\n",
    "# Setup project\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# Note: We skip pour point creation for continental domains\n",
    "print(\"Pour point creation skipped (continental domain)\")\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  📁 {item.name}\")\n",
    "\n",
    "print(\"\\nDirectory purposes:\")\n",
    "print(\"  📁 shapefiles: Domain geometry (thousands of watersheds, river networks)\")\n",
    "print(\"  📁 attributes: Static characteristics (elevation, soil, land cover)\")\n",
    "print(\"  📁 forcing: Meteorological inputs (precipitation, temperature)\")\n",
    "print(\"  📁 simulations: Model outputs\")\n",
    "print(\"  📁 evaluation: Performance metrics and comparisons\")\n",
    "print(\"  📁 plots: Visualizations\")\n",
    "\n",
    "print(\"\\n⚠️ Note: Continental scale will require much more disk space!\")\n",
    "print(\"   Expected total storage requirement: 100s of GB to multiple TB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Geospatial Domain Definition - Continental Data Acquisition\n",
    "We need to acquire continental-scale geospatial data, which will be much larger than for regional domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Geospatial Domain Definition and Analysis\n",
    "print(\"=== Step 2: Geospatial Domain Definition and Analysis ===\")\n",
    "\n",
    "# Acquire attributes\n",
    "print(\"Acquiring continental-scale attributes (DEM, soil, land cover)...\")\n",
    "print(\"Note: This downloads LARGE datasets\")\n",
    "print(\"Expected data size: Several GB\")\n",
    "confluence.managers['data'].acquire_attributes()\n",
    "print(\"✓ Continental attributes acquired\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Continental Domain Delineation\n",
    "Now we'll delineate the entire continent, creating thousands of watersheds. This is computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define continental domain\n",
    "print(\"Delineating continental domain...\")\n",
    "print(f\"Method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "print(f\"Stream threshold: {confluence.config['STREAM_THRESHOLD']} (high for continent)\")\n",
    "print(f\"MPI processes: {confluence.config['MPI_PROCESSES']} (parallel processing)\")\n",
    "print(\"This creates thousands of watersheds across North America...\")\n",
    "print(\"⚠️ Warning: This step may take several hours on high-performance computing resources\")\n",
    "\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "\n",
    "# Check results\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "network_path = project_dir / 'shapefiles' / 'river_network'\n",
    "\n",
    "basin_count = 0\n",
    "if basin_path.exists():\n",
    "    basin_files = list(basin_path.glob('*.shp'))\n",
    "    if basin_files:\n",
    "        basins = gpd.read_file(basin_files[0])\n",
    "        basin_count = len(basins)\n",
    "        print(f\"\\n✓ Created {basin_count} watersheds across North America\")\n",
    "        print(f\"Total area: {basins.geometry.area.sum() / 1e6:.0f} km²\")\n",
    "\n",
    "network_count = 0\n",
    "if network_path.exists():\n",
    "    network_files = list(network_path.glob('*.shp'))\n",
    "    if network_files:\n",
    "        rivers = gpd.read_file(network_files[0])\n",
    "        network_count = len(rivers)\n",
    "        print(f\"✓ Created river network with {network_count} segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Continental Watershed Discretization\n",
    "Now we need to discretize our continental domain into GRUs and HRUs, which will create tens of thousands of computational units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize continental domain\n",
    "print(f\"Creating continental HRUs using method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "print(\"⚠️ Warning: This step may take many hours and require significant memory\")\n",
    "print(f\"Minimum GRU size: {confluence.config['MIN_GRU_SIZE']} km² (larger than regional domain)\")\n",
    "\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "# Check results\n",
    "hru_path = project_dir / 'shapefiles' / 'catchment'\n",
    "if hru_path.exists():\n",
    "    hru_files = list(hru_path.glob('*.shp'))\n",
    "    if hru_files:\n",
    "        # Note: For continental scale, we might not want to load all HRUs at once\n",
    "        print(\"\\n⚠️ Continental HRU file may be very large. Loading sample statistics instead.\")\n",
    "        \n",
    "        # Get basic file stats without loading entire shapefile\n",
    "        hru_file_size = hru_files[0].stat().st_size / (1024**2)  # Size in MB\n",
    "        print(f\"HRU shapefile size: {hru_file_size:.1f} MB\")\n",
    "        \n",
    "        # Option to load a small sample of HRUs for statistics\n",
    "        print(\"Loading small sample of HRUs for statistics...\")\n",
    "        sample_size = min(1000, basin_count)  # Limit sample size\n",
    "        hru_sample = gpd.read_file(hru_files[0], rows=slice(0, sample_size))\n",
    "        \n",
    "        print(f\"Sample contains {len(hru_sample)} HRUs\")\n",
    "        sample_grus = hru_sample['GRU_ID'].nunique()\n",
    "        print(f\"GRUs in sample: {sample_grus}\")\n",
    "        \n",
    "        # Estimate total counts\n",
    "        if basin_count > 0 and sample_grus > 0:\n",
    "            est_hru_total = len(hru_sample) * (basin_count / sample_grus)\n",
    "            print(f\"Estimated total HRUs: ~{est_hru_total:.0f} (based on sample)\")\n",
    "        \n",
    "        print(\"\\nContinental statistics:\")\n",
    "        print(f\"  - Total watersheds (GRUs): ~{basin_count}\")\n",
    "        print(f\"  - Computational units (HRUs): Tens to hundreds of thousands\")\n",
    "        print(f\"  - Domain extent: {abs(lat_max - lat_min):.1f}° latitude × {abs(lon_max - lon_min):.1f}° longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Agnostic Processing - Continental Forcing Data\n",
    "For continental domains, forcing data acquisition and processing is particularly data-intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Agnostic Data Pre-Processing\n",
    "print(\"=== Step 3: Model Agnostic Data Pre-Processing ===\")\n",
    "\n",
    "# Process observed data\n",
    "print(\"Processing observed streamflow data...\")\n",
    "print(\"Note: For continental modeling, we often use a subset of gauged watersheds for evaluation\")\n",
    "confluence.managers['data'].process_observed_data()\n",
    "\n",
    "# Acquire continental-scale forcings\n",
    "print(f\"\\nAcquiring continental forcing data: {confluence.config['FORCING_DATASET']}\")\n",
    "print(\"Expected data size: 10s to 100s of GB\")\n",
    "print(f\"Period: {confluence.config['EXPERIMENT_TIME_START']} to {confluence.config['EXPERIMENT_TIME_END']}\")\n",
    "print(\"⚠️ Warning: This step will take several hours and require significant storage\")\n",
    "confluence.managers['data'].acquire_forcings()\n",
    "\n",
    "# Run model-agnostic preprocessing\n",
    "print(\"\\nRunning continental-scale model-agnostic preprocessing...\")\n",
    "print(\"This step remaps climate data to tens of thousands of HRUs\")\n",
    "print(\"⚠️ Warning: High memory requirements (10s of GB)\")\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model-Specific Preprocessing for Continental Domain\n",
    "Preparing model input files for continental-scale modeling presents unique challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Specific Processing and Initialization\n",
    "print(\"=== Step 4: Model Specific Processing and Initialization ===\")\n",
    "\n",
    "# Preprocess models\n",
    "print(f\"Preparing continental-scale {confluence.config['HYDROLOGICAL_MODEL']} input files...\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Routing: {confluence.config['ROUTING_MODEL']}\")\n",
    "print(\"⚠️ Warning: This will create very large input files\")\n",
    "print(\"Expected file sizes: Several GB per input file\")\n",
    "confluence.managers['model'].preprocess_models()\n",
    "\n",
    "print(\"\\n=== Continental Model Configuration Complete ===\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Domain: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Number of GRUs: ~{basin_count}\")\n",
    "print(\"Number of HRUs: Tens to hundreds of thousands\")\n",
    "print(\"\\nModel is now ready for execution with high-performance computing resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Continental Model Running Considerations\n",
    "For demonstration, we'll discuss running a continental model without actually running it, as it would require significant computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We don't actually run the continental model here\n",
    "print(\"=== Continental Model Execution Considerations ===\")\n",
    "print(\"Running a continental-scale model requires significant HPC resources.\")\n",
    "print(\"\\nTo run the model (when adequate resources are available):\")\n",
    "print(\"  confluence.managers['model'].run_models()\")\n",
    "\n",
    "print(\"\\nTypical resource requirements:\")\n",
    "print(\"  - Memory: 100+ GB RAM\")\n",
    "print(\"  - CPU: 40+ cores for parallel processing\")\n",
    "print(\"  - Storage: 1+ TB for inputs/outputs\")\n",
    "print(\"  - Runtime: Days to weeks\")\n",
    "\n",
    "print(\"\\nCommon execution strategies:\")\n",
    "print(\"  1. Break continent into regions and run separately\")\n",
    "print(\"  2. Use MPI for massive parallelization\")\n",
    "print(\"  3. Run shorter test periods before full simulation\")\n",
    "print(\"  4. Use HPC job scheduling for long-running simulations\")\n",
    "\n",
    "print(\"\\nFor this tutorial, we've completed the continental model setup\")\n",
    "print(\"without running the full model due to computational constraints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Continental-Scale Considerations\n",
    "\n",
    "### Computational Requirements\n",
    "- **Memory**: 100+ GB for data processing\n",
    "- **Storage**: 1+ TB for inputs/outputs\n",
    "- **CPU**: High parallelization (40+ cores)\n",
    "- **Runtime**: Days to weeks for full simulations\n",
    "\n",
    "### Key Configuration Differences\n",
    "```yaml\n",
    "STREAM_THRESHOLD: 7500        # Higher for continental scale\n",
    "MPI_PROCESSES: 40            # More parallel processes\n",
    "MIN_GRU_SIZE: 50             # Larger minimum size to manage computational load\n",
    "FORCING_DATASET: ERA5        # Global reanalysis data\n",
    "```\n",
    "\n",
    "### Challenges at Continental Scale\n",
    "1. **Data Volume**: TB of input/output data\n",
    "2. **Heterogeneity**: Diverse climates, terrains, vegetation\n",
    "3. **Calibration**: How to calibrate thousands of watersheds?\n",
    "4. **Validation**: Limited observations for many basins\n",
    "5. **Computation**: Requires HPC resources\n",
    "\n",
    "### Use Cases\n",
    "- Climate change impact assessment\n",
    "- Continental water balance\n",
    "- Large-scale flood forecasting\n",
    "- Water resources planning\n",
    "- Earth system modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "Let's summarize what we've accomplished with our continental-scale setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== Continental Model Setup Complete ===\\n\")\n",
    "print(f\"Domain: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Scale: Continental (~24.7 million km²)\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Status: Ready for simulation\")\n",
    "\n",
    "print(\"\\nScale progression in tutorials:\")\n",
    "print(\"  1. Watershed: Bow at Banff (~2,200 km²)\")\n",
    "print(\"  2. Country: Iceland (~103,000 km²)\")\n",
    "print(\"  3. Continent: North America (~24,700,000 km²)\")\n",
    "\n",
    "print(\"\\nKey output locations:\")\n",
    "print(f\"  - Basin shapefiles: {basin_path}\")\n",
    "print(f\"  - River network: {network_path}\")\n",
    "print(f\"  - HRU shapefiles: {hru_path}\")\n",
    "print(f\"  - Model settings: {project_dir}/settings/{confluence.config['HYDROLOGICAL_MODEL']}/\")\n",
    "print(f\"  - Future simulation results: {project_dir}/simulations/{confluence.config['EXPERIMENT_ID']}/\")\n",
    "\n",
    "print(\"\\n🎉 You've successfully scaled from watershed to continent!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE (HPC Modules)",
   "language": "python",
   "name": "conf-env-hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
