{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Building on the foundational CONFLUENCE workflow management and point-scale modeling principles established in Tutorial 01a, this notebook extends our analysis to focus on energy balance and evapotranspiration processes. While the previous SNOTEL tutorial emphasized snow dynamics and soil moisture in mountain environments, this example demonstrates CONFLUENCE's capabilities for simulating land-atmosphere interactions using eddy covariance flux tower observations from the global FLUXNET network.\n",
    "\n",
    "## FLUXNET: Global Energy and Carbon Flux Observations\n",
    "The FLUXNET network represents one of the most comprehensive global observational frameworks for studying land-atmosphere interactions, providing continuous measurements of energy, water, and carbon fluxes using the eddy covariance technique. These towers offer exceptional advantages for hydrological model evaluation through direct flux measurements that serve as validation targets for land surface energy balance models, high temporal resolution data that captures diurnal cycles and rapid environmental responses, multi-year records that enable assessment of seasonal dynamics and interannual variability, and ecosystem diversity spanning major biomes for process-based model evaluation across diverse vegetation types and climatic conditions.\n",
    "\n",
    "## Scientific Importance of Energy Balance Modeling\n",
    "Accurate representation of land-atmosphere energy exchanges forms the foundation of hydrological modeling through several critical processes. Evapotranspiration partitioning requires understanding the relative contributions of soil evaporation, plant transpiration, and canopy interception to total water loss. Energy balance processes directly influence soil moisture dynamics through evapotranspiration demand and soil-plant-atmosphere feedback mechanisms. Vegetation stress responses depend on accurate simulation of plant water stress and stomatal response to environmental conditions. These land-atmosphere interactions represent key feedback mechanisms in climate variability and change, making their accurate representation essential for robust hydrological predictions.\n",
    "\n",
    "## Case Study: CA-NS7 Boreal Forest Site\n",
    "This tutorial focuses on the CA-NS7 FLUXNET site located in the boreal forest of Saskatchewan, Canada (56.6358Â°N, 99.9483Â°W). This site presents distinct scientific challenges compared to the mountain snow environment of the previous tutorial. The site represents a mature boreal forest dominated by black spruce (Picea mariana) under a continental boreal climate regime with pronounced seasonal temperature variations. Located at 260 m elevation, the site features organic-rich soils with seasonal freezing and variable drainage conditions, typical of boreal landscapes.\n",
    "\n",
    "## Learning Objectives\n",
    "In this tutorial, you will extend CONFLUENCE applications to energy balance modeling and flux tower validation, understand ecosystem-specific modeling approaches for boreal forest conditions and vegetation parameterizations, evaluate energy balance processes by comparing simulated and observed evapotranspiration and sensible heat flux using established metrics, interpret land-atmosphere interactions through analysis of physical drivers underlying model-observation discrepancies in energy partitioning, and connect point-scale measurements to ecosystem scales by understanding how flux tower footprints relate to model grid cell assumptions.\n",
    "\n",
    "This tutorial follows the established CONFLUENCE workflow while emphasizing energy balance processes through configuration adaptation for boreal forest conditions, integration of FLUXNET observations with meteorological forcing, SUMMA execution and flux evaluation comparing simulated and observed energy balance components, and detailed process analysis interpreting results within the context of boreal ecosystem dynamics. By completing this tutorial, you will develop understanding of energy balance modeling that complements the snow and soil moisture focus of the previous example, providing a comprehensive foundation for distributed hydrological modeling applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Rapid Workflow Setup for FLUXNET Energy Balance Modeling\n",
    "Building on the CONFLUENCE fundamentals established in Tutorial 01a, we can now streamline the initial workflow setup. This step efficiently configures the system for energy balance validation at the CA-NS7 boreal forest FLUXNET site, leveraging the same reproducible framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll need in this notebook\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION FOR CA-NS7 BOREAL FOREST SITE\n",
    "# =============================================================================\n",
    "\n",
    "# Set directory paths \n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/Users/darrieythorsson/compHydro/data/CONFLUENCE_data') \n",
    "#CONFLUENCE_DATA_DIR = Path('/path/to/your/CONFLUENCE_data') \n",
    "\n",
    "# Load template configuration and customize for FLUXNET site\n",
    "config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_point_template.yaml'\n",
    "\n",
    "with open(config_template_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update for CA-NS7 boreal forest site\n",
    "config_updates = {\n",
    "    'CONFLUENCE_CODE_DIR': str(CONFLUENCE_CODE_DIR),\n",
    "    'CONFLUENCE_DATA_DIR': str(CONFLUENCE_DATA_DIR),\n",
    "    'DOMAIN_NAME': 'CA-NS7',\n",
    "    'POUR_POINT_COORDS': '56.6358/-99.9483',  # CA-NS7 coordinates\n",
    "    'DOWNLOAD_FLUXNET': 'true',\n",
    "    'FLUXNET_STATION': 'CA-NS7',\n",
    "    'EXPERIMENT_TIME_START': '2001-01-01 01:00',  # FLUXNET data availability\n",
    "    'EXPERIMENT_TIME_END': '2005-12-31 23:00',\n",
    "    'CALIBRATION_PERIOD': '2002-01-01, 2003-12-31',\n",
    "    'EVALUATION_PERIOD': '2004-01-01, 2005-12-31',\n",
    "    'SPINUP_PERIOD': '2001-01-01, 2001-12-31'\n",
    "}\n",
    "\n",
    "config_dict.update(config_updates)\n",
    "\n",
    "# Save configuration\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_fluxnet_notebook.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"âœ… Configuration saved: {temp_config_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SYSTEM INITIALIZATION AND PROJECT STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize CONFLUENCE with FLUXNET configuration\n",
    "confluence = CONFLUENCE(temp_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Geospatial Domain Setup \n",
    "Having established the geospatial domain definition principles in Tutorial 01a, we can now efficiently configure the spatial framework for our boreal forest FLUXNET site. The same point-scale approach applies and the same CONFLUENCE spatial framework handles both environments seamlessly, demonstrating the transferability of the modeling approach across diverse ecosystems while capturing site-specific physical characteristics through the attribute acquisition process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ATTRIBUTE ACQUISITION \n",
    "# =============================================================================\n",
    "\n",
    "# confluence.managers['data'].acquire_attributes()\n",
    "\n",
    "print(\"âœ… Attribute acquisition complete\")    \n",
    "\n",
    "# =============================================================================\n",
    "# DOMAIN DELINEATION AND DISCRETIZATION FOR POINT-SCALE FLUX TOWER\n",
    "# =============================================================================\n",
    "\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "\n",
    "# Domain discretization (single HRU for energy balance modeling)  \n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "print(f\"âœ… Spatial domain configuration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Pipeline\n",
    "Leveraging the model-agnostic preprocessing concepts established in Tutorial 01a, we can now efficiently prepare the data pipeline for boreal forest energy balance modeling. The same standardized framework seamlessly handles the transition, demonstrating CONFLUENCE's versatility across diverse validation objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute observational data processing\n",
    "confluence.managers['data'].process_observed_data()\n",
    "print(\"âœ… Observed Data processing complete\")\n",
    "\n",
    "# Execute forcing acquisition \n",
    "# confluence.managers['data'].acquire_forcings()\n",
    "print(\"âœ… Forcing acquisition complete (simulated)\")\n",
    "\n",
    "# Execute model-agnostic preprocessing\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"âœ… Model-agnostic preprocessing complete\")\n",
    "\n",
    "# Execute model-specific preprocessing\n",
    "confluence.managers['model'].preprocess_models()\n",
    "print(\"âœ… SUMMA configuration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Execution \n",
    "Building on the detailed model instantiation concepts from Tutorial 01a, we can now efficiently execute the energy balance simulation. The same SUMMA process-based physics applies, but with emphasis on land-atmosphere energy exchange rather than snow accumulation and soil moisture dynamics.\n",
    "\n",
    "\n",
    "The same workflow orchestration ensures reproducible and comparable simulations across both applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute the model\n",
    "confluence.managers['model'].run_models()\n",
    "print(\"âœ… SUMMA simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: ET Process Validation\n",
    "Building on the comprehensive evaluation framework established in Tutorial 01a, we now focus on energy flux validation using FLUXNET observations. The same scientific evaluation principles apply, but with emphasis on land-atmosphere energy exchange rather than snow/soil state variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_fluxnet_data_inline(domain_name, data_dir):\n",
    "    \"\"\"Process raw FLUXNET data into standardized format for CONFLUENCE \"\"\"\n",
    "    \n",
    "    # Set up paths\n",
    "    data_dir = Path(data_dir)\n",
    "    domain_dir = data_dir / f\"domain_{domain_name}\"\n",
    "    raw_fluxnet_dir = domain_dir / \"observations\" / \"fluxnet\" / \"raw_data\"\n",
    "    processed_dir = domain_dir / \"observations\" / \"energy_fluxes\" / \"fluxnet\" / \"processed\"\n",
    "    \n",
    "    # Create processed directory if it doesn't exist\n",
    "    processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    # Find FLUXNET files\n",
    "    fluxnet_files = list(raw_fluxnet_dir.glob(f\"FLX_{domain_name}_FLUXNET2015_FULLSET_*.csv\"))\n",
    "    \n",
    "    if not fluxnet_files:\n",
    "        print(f\"âŒ No FLUXNET files found in {raw_fluxnet_dir}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"   Found {len(fluxnet_files)} FLUXNET files\")\n",
    "    \n",
    "    # Process halfhourly data (most detailed for energy balance)\n",
    "    hh_files = [f for f in fluxnet_files if \"_HH_\" in f.name]\n",
    "    \n",
    "    if not hh_files:\n",
    "        print(\"âŒ No halfhourly (_HH_) files found\")\n",
    "        return False\n",
    "    \n",
    "    file_path = hh_files[0]  # Use first halfhourly file\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"   Loaded {len(df)} rows, {len(df.columns)} columns\")\n",
    "        \n",
    "        # Create timestamp from TIMESTAMP_START\n",
    "        df['timestamp'] = pd.to_datetime(df['TIMESTAMP_START'].astype(str), format='%Y%m%d%H%M', errors='coerce')\n",
    "        df = df.dropna(subset=['timestamp'])\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print(\"âŒ No valid timestamps found\")\n",
    "            return False\n",
    "            \n",
    "        # Key FLUXNET variables for energy balance\n",
    "        key_variables = {\n",
    "            'LE_F_MDS': 'Latent heat flux (gap-filled)',\n",
    "            'H_F_MDS': 'Sensible heat flux (gap-filled)', \n",
    "            'RNET': 'Net radiation',\n",
    "            'G_F_MDS': 'Ground heat flux (gap-filled)',\n",
    "            'LE_F_MDS_QC': 'LE quality flag',\n",
    "            'H_F_MDS_QC': 'H quality flag',\n",
    "            'TA_F_MDS': 'Air temperature (gap-filled)',\n",
    "            'PA_F': 'Atmospheric pressure',\n",
    "            'WS_F': 'Wind speed',\n",
    "            'RH': 'Relative humidity',\n",
    "            'VPD_F_MDS': 'Vapor pressure deficit (gap-filled)',\n",
    "            'SW_IN_F_MDS': 'Incoming shortwave radiation (gap-filled)',\n",
    "            'P_F': 'Precipitation (gap-filled)',\n",
    "        }\n",
    "        \n",
    "        # Select available variables\n",
    "        available_vars = ['timestamp']\n",
    "        for var in key_variables.keys():\n",
    "            if var in df.columns:\n",
    "                available_vars.append(var)\n",
    "                \n",
    "        # Create subset with available variables\n",
    "        processed_df = df[available_vars].copy()\n",
    "        \n",
    "        # Replace FLUXNET missing value codes with NaN\n",
    "        missing_value_codes = [-9999, -9999.0, -6999, -6999.0]\n",
    "        for code in missing_value_codes:\n",
    "            processed_df = processed_df.replace(code, np.nan)\n",
    "        \n",
    "        # Convert LE (W/mÂ²) to ET (mm/day)\n",
    "        if 'LE_F_MDS' in processed_df.columns:\n",
    "            processed_df['ET_from_LE_mm_per_day'] = processed_df['LE_F_MDS'] * 0.0353\n",
    "         \n",
    "        # Calculate energy balance closure if components available\n",
    "        energy_components = ['LE_F_MDS', 'H_F_MDS', 'G_F_MDS', 'RNET']\n",
    "        if all(var in processed_df.columns for var in energy_components):\n",
    "            processed_df['ENERGY_CLOSURE'] = (processed_df['LE_F_MDS'] + processed_df['H_F_MDS']) / (processed_df['RNET'] - processed_df['G_F_MDS'])\n",
    "         \n",
    "        # Save processed data\n",
    "        output_file = processed_dir / f\"{domain_name}_fluxnet_processed.csv\"\n",
    "        processed_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Print data quality summary\n",
    "        if 'LE_F_MDS' in processed_df.columns:\n",
    "            valid_le = processed_df['LE_F_MDS'].notna().sum()\n",
    "        \n",
    "        if 'ET_from_LE_mm_per_day' in processed_df.columns:\n",
    "            et_stats = processed_df['ET_from_LE_mm_per_day'].describe()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing {file_path.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# CHECK AND PROCESS FLUXNET DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nðŸ”§ Checking and Processing FLUXNET Data...\")\n",
    "\n",
    "# Check if processed FLUXNET data exists\n",
    "fluxnet_processed_path = confluence.project_dir / \"observations\" / \"energy_fluxes\" / \"fluxnet\" / \"processed\" / f\"{config_dict['DOMAIN_NAME']}_fluxnet_processed.csv\"\n",
    "\n",
    "if not fluxnet_processed_path.exists():\n",
    "    print(\"âš ï¸  Processed FLUXNET data not found. Processing raw data...\")\n",
    "    \n",
    "    # Process the data using our inline function\n",
    "    success = process_fluxnet_data_inline(config_dict['DOMAIN_NAME'], str(CONFLUENCE_DATA_DIR))\n",
    "\n",
    "# =============================================================================\n",
    "# SIMULATION DATA LOADING \n",
    "# =============================================================================\n",
    "\n",
    "# Load simulation data with proper filtering\n",
    "sim_dir = confluence.project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"SUMMA\"\n",
    "sim_file = sim_dir / f\"{config_dict['EXPERIMENT_ID']}_day.nc\"\n",
    "ds = xr.open_dataset(sim_file)\n",
    "\n",
    "# Filter to experiment period\n",
    "start_date = pd.to_datetime(config_dict['EXPERIMENT_TIME_START'])\n",
    "end_date = pd.to_datetime(config_dict['EXPERIMENT_TIME_END'])\n",
    "\n",
    "time_mask = (ds.time >= start_date) & (ds.time <= end_date)\n",
    "evaluation_data = ds.isel(time=time_mask)\n",
    "        \n",
    "# Identify available energy balance variables\n",
    "energy_variables = {\n",
    "    'scalarLatHeatTotal': 'Latent heat flux (LE) - Evapotranspiration energy',\n",
    "    'scalarSenHeatTotal': 'Sensible heat flux (H) - Convective energy transfer',\n",
    "    'scalarNetRadiation': 'Net radiation (Rn) - Available energy',\n",
    "    'scalarGroundHeatFlux': 'Ground heat flux (G) - Soil energy storage'\n",
    "}\n",
    "\n",
    "available_energy_vars = {var: desc for var, desc in energy_variables.items() \n",
    "                       if var in evaluation_data.data_vars}\n",
    "\n",
    "# ET component variables for detailed analysis\n",
    "et_components = {\n",
    "    'scalarTotalET': 'Total evapotranspiration',\n",
    "    'scalarCanopyTranspiration': 'Plant transpiration',\n",
    "    'scalarCanopyEvaporation': 'Canopy interception evaporation', \n",
    "    'scalarGroundEvaporation': 'Soil surface evaporation',\n",
    "    'scalarCanopySublimation': 'Canopy sublimation',\n",
    "    'scalarSnowSublimation': 'Snow sublimation'\n",
    "}\n",
    "\n",
    "available_et_components = {var: desc for var, desc in et_components.items()\n",
    "                         if var in evaluation_data.data_vars}\n",
    "\n",
    "# =============================================================================\n",
    "# FLUXNET OBSERVATION DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "# Load processed FLUXNET data\n",
    "if fluxnet_processed_path.exists():\n",
    "    fluxnet_df = pd.read_csv(fluxnet_processed_path)\n",
    "    fluxnet_df['timestamp'] = pd.to_datetime(fluxnet_df['timestamp'])\n",
    "    fluxnet_df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Show key available variables (excluding QC flags)\n",
    "    key_vars = [col for col in fluxnet_df.columns if not col.endswith('_QC') and col in \n",
    "                ['LE_F_MDS', 'H_F_MDS', 'RNET', 'G_F_MDS', 'ET_from_LE_mm_per_day', 'TA_F_MDS', 'VPD_F_MDS']]\n",
    "    \n",
    "    # Check data quality\n",
    "    if 'ET_from_LE_mm_per_day' in fluxnet_df.columns:\n",
    "        et_valid = fluxnet_df['ET_from_LE_mm_per_day'].notna().sum()\n",
    "        \n",
    "        et_stats = fluxnet_df['ET_from_LE_mm_per_day'].describe()\n",
    "    \n",
    "# =============================================================================\n",
    "# ENERGY BALANCE EVALUATION: LATENT HEAT FLUX (ET)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Check for ET data in simulation\n",
    "et_var = None\n",
    "conversion_factor = None\n",
    "\n",
    "if 'scalarLatHeatTotal' in evaluation_data.data_vars:\n",
    "    et_var = 'scalarLatHeatTotal'\n",
    "    conversion_factor = 0.0353  # W/mÂ² to mm/day\n",
    "elif 'scalarTotalET' in evaluation_data.data_vars:\n",
    "    et_var = 'scalarTotalET'\n",
    "    conversion_factor = 86400  # kg m-2 s-1 to mm/day  \n",
    "\n",
    "if et_var and fluxnet_df is not None and 'ET_from_LE_mm_per_day' in fluxnet_df.columns:\n",
    "    \n",
    "    # Extract simulated ET and convert units\n",
    "    sim_et_xr = evaluation_data[et_var]\n",
    "    \n",
    "    # If multi-dimensional, take spatial mean first\n",
    "    if len(sim_et_xr.dims) > 1:\n",
    "        spatial_dims = [dim for dim in sim_et_xr.dims if dim != 'time']\n",
    "        sim_et_xr = sim_et_xr.mean(dim=spatial_dims)\n",
    "    \n",
    "    # Convert to pandas Series\n",
    "    sim_et_raw = sim_et_xr.to_pandas()\n",
    "    \n",
    "    # Handle negative values (SUMMA convention: negative = leaving system)\n",
    "    median_val = sim_et_raw.median()\n",
    "    if median_val < 0:\n",
    "        sim_et_raw = -sim_et_raw\n",
    "        print(f\"   âš¡ Inverted sign for {et_var} (negative values indicate water leaving system)\")\n",
    "    \n",
    "    sim_et_mm_day = sim_et_raw * conversion_factor\n",
    "        \n",
    "    # Find common period and align data\n",
    "    common_start = max(fluxnet_df.index.min(), sim_et_mm_day.index.min())\n",
    "    common_end = min(fluxnet_df.index.max(), sim_et_mm_day.index.max())\n",
    "    \n",
    "    # Resample to daily and filter to common period\n",
    "    obs_daily = fluxnet_df['ET_from_LE_mm_per_day'].resample('D').mean().loc[common_start:common_end]\n",
    "    sim_daily = sim_et_mm_day.resample('D').mean().loc[common_start:common_end]\n",
    "    \n",
    "    # Remove NaN values for metrics calculation\n",
    "    valid_mask = ~(obs_daily.isna() | sim_daily.isna())\n",
    "    obs_valid = obs_daily[valid_mask]\n",
    "    sim_valid = sim_daily[valid_mask]\n",
    "    \n",
    "    if len(obs_valid) > 10:  # Need minimum data for meaningful analysis\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        print(f\"\\nðŸ“Š Evapotranspiration Performance Metrics:\")\n",
    "        \n",
    "        rmse = np.sqrt(((obs_valid - sim_valid) ** 2).mean())\n",
    "        bias = (sim_valid - obs_valid).mean()\n",
    "        mae = np.abs(obs_valid - sim_valid).mean()\n",
    "        \n",
    "        # Handle correlation calculation\n",
    "        try:\n",
    "            corr = obs_valid.corr(sim_valid)\n",
    "            if pd.isna(corr):\n",
    "                corr = 0.0\n",
    "        except:\n",
    "            corr = 0.0\n",
    "        \n",
    "        # Nash-Sutcliffe Efficiency\n",
    "        if obs_valid.var() > 0:\n",
    "            nse = 1 - ((obs_valid - sim_valid) ** 2).sum() / ((obs_valid - obs_valid.mean()) ** 2).sum()\n",
    "        else:\n",
    "            nse = np.nan\n",
    "        \n",
    "        print(f\"   RMSE: {rmse:.2f} mm/day\")\n",
    "        print(f\"   Bias: {bias:+.2f} mm/day\")\n",
    "        print(f\"   MAE: {mae:.2f} mm/day\") \n",
    "        print(f\"   Correlation: {corr:.3f}\")\n",
    "        print(f\"   Nash-Sutcliffe Efficiency: {nse:.3f}\")\n",
    "        \n",
    "        # Seasonal analysis\n",
    "        print(f\"\\nðŸ—“ï¸ Seasonal ET Performance:\")\n",
    "        seasonal_data = pd.DataFrame({\n",
    "            'obs': obs_valid,\n",
    "            'sim': sim_valid,\n",
    "            'month': obs_valid.index.month\n",
    "        })\n",
    "        \n",
    "        seasonal_stats = seasonal_data.groupby('month').apply(\n",
    "            lambda x: pd.Series({\n",
    "                'obs_mean': x['obs'].mean(),\n",
    "                'sim_mean': x['sim'].mean(),\n",
    "                'bias': x['sim'].mean() - x['obs'].mean(),\n",
    "                'corr': x['obs'].corr(x['sim']) if len(x) > 3 else np.nan\n",
    "            })\n",
    "        )\n",
    "        \n",
    "        seasons = [(12, 'Winter'), (3, 'Spring'), (6, 'Summer'), (9, 'Fall')]\n",
    "        for month, label in seasons:\n",
    "            if month in seasonal_stats.index:\n",
    "                stats = seasonal_stats.loc[month]\n",
    "                print(f\"   {label:6s}: Obs={stats['obs_mean']:.2f}, Sim={stats['sim_mean']:.2f} mm/day, \"\n",
    "                      f\"Bias={stats['bias']:+.2f}, r={stats['corr']:.3f}\")\n",
    "        \n",
    "        # Create comprehensive ET visualization\n",
    "        print(f\"\\nðŸ“ˆ Creating ET comparison visualization...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Time series comparison\n",
    "        ax1 = axes[0, 0]\n",
    "        obs_plot = obs_daily.dropna()\n",
    "        sim_plot = sim_daily.dropna()\n",
    "        \n",
    "        ax1.plot(obs_plot.index, obs_plot.values, 'o-', label='FLUXNET ET', \n",
    "                 color='blue', alpha=0.7, markersize=1, linewidth=1)\n",
    "        ax1.plot(sim_plot.index, sim_plot.values, '-', label='SUMMA ET', \n",
    "                 color='red', linewidth=2)\n",
    "        ax1.set_title('Evapotranspiration Time Series', fontweight='bold')\n",
    "        ax1.set_ylabel('ET (mm/day)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.scatter(obs_valid, sim_valid, alpha=0.6, c='green', s=20)\n",
    "        max_val = max(obs_valid.max(), sim_valid.max())\n",
    "        min_val = min(obs_valid.min(), sim_valid.min())\n",
    "        ax2.plot([min_val, max_val], [min_val, max_val], 'k--', label='1:1 line')\n",
    "        ax2.set_xlabel('FLUXNET ET (mm/day)')\n",
    "        ax2.set_ylabel('SUMMA ET (mm/day)')\n",
    "        ax2.set_title('Observed vs. Simulated ET', fontweight='bold')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add metrics text\n",
    "        metrics_text = f'r = {corr:.3f}\\\\nRMSE = {rmse:.2f}\\\\nBias = {bias:+.2f}'\n",
    "        ax2.text(0.05, 0.95, metrics_text, transform=ax2.transAxes,\n",
    "                 bbox=dict(facecolor='white', alpha=0.8), fontsize=10, verticalalignment='top')\n",
    "        \n",
    "        # Monthly climatology\n",
    "        ax3 = axes[1, 0]\n",
    "        monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "        monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "        months = range(1, 13)\n",
    "        month_names = ['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D']\n",
    "        \n",
    "        # Ensure we have data for plotting\n",
    "        full_monthly_obs = pd.Series(index=months, dtype=float)\n",
    "        full_monthly_sim = pd.Series(index=months, dtype=float)\n",
    "        \n",
    "        for month in months:\n",
    "            if month in monthly_obs.index:\n",
    "                full_monthly_obs[month] = monthly_obs[month]\n",
    "            if month in monthly_sim.index:\n",
    "                full_monthly_sim[month] = monthly_sim[month]\n",
    "        \n",
    "        ax3.plot(months, full_monthly_obs, 'o-', label='FLUXNET', color='blue', linewidth=2)\n",
    "        ax3.plot(months, full_monthly_sim, 'o-', label='SUMMA', color='red', linewidth=2)\n",
    "        ax3.set_xticks(months)\n",
    "        ax3.set_xticklabels(month_names)\n",
    "        ax3.set_ylabel('ET (mm/day)')\n",
    "        ax3.set_title('Monthly ET Climatology', fontweight='bold')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Residuals\n",
    "        ax4 = axes[1, 1]\n",
    "        residuals = sim_valid - obs_valid\n",
    "        ax4.scatter(obs_valid.index, residuals, alpha=0.6, c='purple', s=15)\n",
    "        ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        if residuals.std() > 0:\n",
    "            ax4.axhline(y=residuals.std(), color='red', linestyle='--', alpha=0.5, label='+1Ïƒ')\n",
    "            ax4.axhline(y=-residuals.std(), color='red', linestyle='--', alpha=0.5, label='-1Ïƒ')\n",
    "            ax4.legend()\n",
    "        ax4.set_ylabel('Residuals (mm/day)')\n",
    "        ax4.set_title('Model Residuals', fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle(f'Evapotranspiration Evaluation - {config_dict[\"DOMAIN_NAME\"]} Boreal Forest', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "# =============================================================================\n",
    "# ET COMPONENT ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Extract and convert ET components\n",
    "et_comp_data = {}\n",
    "for comp_var, description in available_et_components.items():\n",
    "    comp_xr = evaluation_data[comp_var]\n",
    "    \n",
    "    # If multi-dimensional, take spatial mean first\n",
    "    if len(comp_xr.dims) > 1:\n",
    "        spatial_dims = [dim for dim in comp_xr.dims if dim != 'time']\n",
    "        comp_xr = comp_xr.mean(dim=spatial_dims)\n",
    "    \n",
    "    # Convert to pandas Series\n",
    "    comp_ts = comp_xr.to_pandas()\n",
    "    \n",
    "    # Handle negative values\n",
    "    median_val = comp_ts.median()\n",
    "    if median_val < 0:\n",
    "        comp_ts = -comp_ts\n",
    "    \n",
    "    # Convert from kg m-2 s-1 to mm/day\n",
    "    comp_ts_mm_day = comp_ts * 86400\n",
    "    et_comp_data[comp_var] = comp_ts_mm_day\n",
    "    \n",
    "    print(f\"   ðŸŒ± {comp_var}: {comp_ts_mm_day.mean():.3f} Â± {comp_ts_mm_day.std():.3f} mm/day\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Component time series (monthly means)\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.Set2.colors\n",
    "\n",
    "for i, (comp_var, comp_data) in enumerate(et_comp_data.items()):\n",
    "    if comp_var != 'scalarTotalET':  # Skip total for component plot\n",
    "        monthly_comp = comp_data.resample('ME').mean()\n",
    "        ax1.plot(monthly_comp.index, monthly_comp.values, \n",
    "                label=comp_var.replace('scalar', '').replace('Canopy', 'Can.').replace('Ground', 'Grd.'), \n",
    "                color=colors[i % len(colors)], linewidth=2, marker='o', markersize=3)\n",
    "\n",
    "ax1.set_title('SUMMA ET Components - Monthly Means (Boreal Forest)', fontweight='bold')\n",
    "ax1.set_ylabel('ET Component (mm/day)')\n",
    "ax1.legend(loc='upper right', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Component seasonal climatology\n",
    "ax2 = axes[1]\n",
    "months = range(1, 13)\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "for i, (comp_var, comp_data) in enumerate(et_comp_data.items()):\n",
    "    if comp_var != 'scalarTotalET':\n",
    "        monthly_mean = comp_data.groupby(comp_data.index.month).mean()\n",
    "        \n",
    "        # Ensure all months are represented\n",
    "        full_monthly = pd.Series(index=months, dtype=float)\n",
    "        for month in months:\n",
    "            if month in monthly_mean.index:\n",
    "                full_monthly[month] = monthly_mean[month]\n",
    "            else:\n",
    "                full_monthly[month] = 0.0\n",
    "        \n",
    "        ax2.plot(months, full_monthly.values, 'o-', linewidth=2,\n",
    "                label=comp_var.replace('scalar', '').replace('Canopy', 'Can.').replace('Ground', 'Grd.'), \n",
    "                color=colors[i % len(colors)])\n",
    "\n",
    "ax2.set_title('ET Component Seasonal Climatology (Boreal Forest)', fontweight='bold')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('ET Component (mm/day)')\n",
    "ax2.set_xticks(months)\n",
    "ax2.set_xticklabels(month_names)\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate component contributions\n",
    "print(f\"\\nðŸ“Š Annual ET Component Contributions:\")\n",
    "annual_totals = {}\n",
    "for comp_var, comp_data in et_comp_data.items():\n",
    "    if comp_var != 'scalarTotalET':\n",
    "        annual_total = comp_data.resample('YE').sum().mean()  # Average annual total\n",
    "        annual_totals[comp_var] = annual_total\n",
    "\n",
    "\n",
    "\n",
    "total_annual = sum(annual_totals.values())\n",
    "for comp_var, annual_total in annual_totals.items():\n",
    "    percentage = (annual_total / total_annual) * 100 if total_annual > 0 else 0\n",
    "    print(f\"   ðŸŒ¿ {comp_var.replace('scalar', '')}: {annual_total:.1f} mm/yr ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Summary\n",
    "### Point-Scale Energy Balance Validation\n",
    "This tutorial successfully demonstrated CONFLUENCE's versatility by extending the established workflow framework from snow and soil moisture validation to comprehensive energy balance modeling using FLUXNET observations. Through the CA-NS7 boreal forest case study, we illustrated how the same standardized preprocessing pipeline and model execution framework seamlessly adapts across diverse ecosystems and validation objectives while maintaining scientific rigor and reproducibility.\n",
    "\n",
    "### Key Methodological Advances\n",
    "The tutorial showcased process-specific model configuration by adapting CONFLUENCE for boreal forest energy balance processes while maintaining the same underlying workflow structure. Multi-flux validation was achieved through comprehensive evaluation of evapotranspiration against direct eddy covariance measurements, demonstrating quantitative performance assessment across temporal scales from sub-daily to seasonal dynamics. Process component analysis revealed the relative contributions of different evapotranspiration pathways including transpiration, canopy evaporation, and soil evaporation, providing insights into boreal forest water cycling mechanisms.\n",
    "\n",
    "### Scientific Process Understanding\n",
    "The evaluation demonstrated CONFLUENCE's capability to simulate land-atmosphere energy exchange processes with explicit representation of stomatal conductance, canopy interception, and soil-plant-atmosphere feedback mechanisms. Seasonal energy dynamics were successfully captured, showing the model's ability to represent pronounced boreal forest phenological cycles and temperature-driven evapotranspiration patterns. Energy balance closure analysis provided direct validation of fundamental thermodynamic principles in the model physics.\n",
    "\n",
    "### Framework Scalability Demonstration\n",
    "This tutorial reinforced CONFLUENCE's transferable methodology by applying identical workflow principles across contrasting environments from mountain snow zones to boreal forests. The model-agnostic preprocessing approach proved equally effective for both snow/soil validation and energy flux evaluation, confirming the framework's broad applicability. Comparative process validation established the foundation for multi-site energy balance studies and ecosystem-specific model benchmarking that will be essential for larger-scale applications in subsequent tutorials.\n",
    "\n",
    "### Next Focus: Watershed Simulations and Basin-Scale Processes\n",
    "**Ready to explore Basin Scale simulations?** â†’ **[Tutorial 02a: Basin Scale - Lumped Watershed](./02a_basin_lumped.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
