{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 7: Continental-Scale Modeling (North America)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial represents the ultimate scaling challenge in our CONFLUENCE series: continental-scale hydrological modeling. Moving from regional domains like Iceland to an entire continent introduces unprecedented computational complexity and scientific opportunities. Using North America as our example, we'll demonstrate how CONFLUENCE handles the massive data volumes, computational demands, and methodological challenges of modeling hydrology across an entire continent.\n",
    "\n",
    "### The Scale Challenge\n",
    "\n",
    "Continental-scale modeling represents a quantum leap in complexity:\n",
    "\n",
    "**Spatial Scale**: \n",
    "- **North America**: ~24.7 million kmÂ² (240 times larger than Iceland)\n",
    "- **Watersheds**: Thousands of independent drainage systems\n",
    "- **Climate zones**: Arctic to tropical, maritime to continental\n",
    "- **Elevation range**: Sea level to >6,000m (Denali)\n",
    "\n",
    "**Computational Scale**:\n",
    "- **Modeling units**: Tens to hundreds of thousands of HRUs\n",
    "- **Data volume**: Terabytes of input/output files\n",
    "- **Processing time**: Days to weeks of computation\n",
    "- **Memory requirements**: 100+ GB RAM for full continental runs\n",
    "\n",
    "### Why Continental-Scale Modeling?\n",
    "\n",
    "Continental modeling addresses scientific questions impossible at smaller scales:\n",
    "\n",
    "1. **Climate Change Assessment**: Understanding how continental water resources respond to changing climate patterns\n",
    "2. **Water Security**: Assessing water availability across entire continents for policy and planning\n",
    "3. **Comparative Hydrology**: Studying how different regions respond to similar climate forcing\n",
    "4. **Earth System Science**: Providing land surface inputs for global climate models\n",
    "5. **Transboundary Water Management**: Managing water resources across international boundaries\n",
    "\n",
    "### North America: A Continental Modeling Laboratory\n",
    "\n",
    "North America provides an ideal continental-scale case study:\n",
    "\n",
    "**Geographic Diversity**:\n",
    "- **Arctic regions**: Permafrost, snow-dominated hydrology\n",
    "- **Temperate forests**: Complex seasonal cycles\n",
    "- **Great Plains**: Continental climate, agricultural impacts\n",
    "- **Mountainous regions**: Elevation-dependent processes, snowmelt-driven systems\n",
    "- **Coastal areas**: Maritime climate influences\n",
    "- **Desert regions**: Arid and semi-arid hydrology\n",
    "\n",
    "**Hydrological Complexity**:\n",
    "- **Major river systems**: Mississippi, Colorado, Columbia, Mackenzie\n",
    "- **Great Lakes**: Massive freshwater reservoirs\n",
    "- **Glacial systems**: Alaska, Canadian Arctic\n",
    "- **Groundwater aquifers**: Ogallala, regional confined systems\n",
    "- **Seasonal patterns**: Extreme seasonal variability across regions\n",
    "\n",
    "**Data Availability**:\n",
    "- **Extensive gauging networks**: USGS, Water Survey of Canada\n",
    "- **Satellite observations**: Continental-scale remote sensing\n",
    "- **Climate data**: Dense meteorological networks\n",
    "- **Topographic data**: High-resolution continental DEMs\n",
    "\n",
    "### Technical Challenges\n",
    "\n",
    "Continental modeling introduces unique technical challenges:\n",
    "\n",
    "1. **Data Volume Management**: Processing and storing terabytes of geospatial and climate data\n",
    "2. **Computational Efficiency**: Optimizing models for high-performance computing systems\n",
    "3. **Spatial Heterogeneity**: Representing diverse climate, terrain, and vegetation across the continent\n",
    "4. **Parameter Estimation**: Calibrating thousands of watersheds with limited observations\n",
    "5. **Validation**: Assessing model performance across diverse hydrological regimes\n",
    "\n",
    "### Computational Requirements\n",
    "\n",
    "Continental modeling demands high-performance computing resources:\n",
    "\n",
    "**Memory**: 100+ GB RAM for full domain processing\n",
    "**Storage**: 1+ TB for complete input/output datasets  \n",
    "**Processing**: 40+ CPU cores for parallel execution\n",
    "**Runtime**: Days to weeks for full simulations\n",
    "**Network**: High-speed data transfer capabilities\n",
    "\n",
    "### Key Configuration Adaptations\n",
    "\n",
    "Continental modeling requires specific configuration changes:\n",
    "\n",
    "```yaml\n",
    "STREAM_THRESHOLD: 7500          # Higher threshold for manageable complexity\n",
    "MPI_PROCESSES: 40              # Massive parallelization\n",
    "MIN_GRU_SIZE: 50               # Larger minimum units\n",
    "BOUNDING_BOX_COORDS: 83.0/-170.0/5.0/-50.0  # Continental extent\n",
    "DELINEATE_COASTAL_WATERSHEDS: True          # Include ocean-draining basins\n",
    "```\n",
    "\n",
    "### Scientific Applications\n",
    "\n",
    "Continental-scale modeling enables research impossible at smaller scales:\n",
    "\n",
    "- **Continental water balance**: Understanding precipitation-evapotranspiration patterns\n",
    "- **Climate change impacts**: Assessing vulnerability across diverse regions\n",
    "- **Extreme event analysis**: Continental-scale flood and drought assessment\n",
    "- **Ecosystem services**: Quantifying water-related services across biomes\n",
    "- **Policy support**: Informing continental-scale water management decisions\n",
    "\n",
    "### Methodological Considerations\n",
    "\n",
    "Continental modeling requires adapted approaches:\n",
    "\n",
    "1. **Hierarchical Modeling**: Break continent into manageable regions\n",
    "2. **Parallel Processing**: Leverage MPI for massive parallelization\n",
    "3. **Staged Execution**: Run shorter periods before full simulations\n",
    "4. **Adaptive Resolution**: Use coarser resolution in less critical areas\n",
    "5. **Selective Validation**: Focus detailed validation on key regions\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "This tutorial demonstrates:\n",
    "\n",
    "1. **Configure continental domains** using bounding box coordinates\n",
    "2. **Manage massive data volumes** with efficient processing strategies\n",
    "3. **Optimize for HPC resources** with parallel processing configuration\n",
    "4. **Handle computational complexity** through strategic parameter choices\n",
    "5. **Understand scaling limitations** and trade-offs at continental scales\n",
    "6. **Apply continental modeling** to real-world scientific questions\n",
    "\n",
    "### Tutorial Structure\n",
    "\n",
    "This tutorial follows the CONFLUENCE workflow but emphasizes continental-scale considerations:\n",
    "\n",
    "1. **Continental Setup**: Configure domain spanning entire continent\n",
    "2. **Massive Data Acquisition**: Handle terabyte-scale geospatial datasets\n",
    "3. **Continental Delineation**: Create thousands of watersheds automatically\n",
    "4. **HPC-Optimized Processing**: Parallel processing of continental-scale data\n",
    "5. **Model Configuration**: Prepare inputs for continental-scale simulation\n",
    "6. **Resource Planning**: Understand computational requirements for execution\n",
    "\n",
    "### Computational Reality Check\n",
    "\n",
    "**Important Note**: This tutorial demonstrates continental-scale model setup, this has substantial computational requirements. Running a continental model requires:\n",
    "\n",
    "- Access to high-performance computing clusters\n",
    "- Substantial computational allocations (thousands of CPU hours)\n",
    "- Significant storage capacity and data transfer capabilities\n",
    "- Expertise in HPC job scheduling and resource management\n",
    "\n",
    "The tutorial prepares you to understand and configure continental-scale modeling, providing the foundation for execution if appropriate computational resources become available.\n",
    "\n",
    "### Tutorial Progression Summary\n",
    "\n",
    "Our complete spatial scaling series:\n",
    "\n",
    "| Scale | Example | Area | Complexity |\n",
    "|-------|---------|------|------------|\n",
    "| Point | Paradise SNOTEL | 0.001 kmÂ² | Vertical processes |\n",
    "| Watershed | Bow at Banff | 2,200 kmÂ² | Basin response |\n",
    "| Regional | Iceland | 103,000 kmÂ² | Multiple basins |\n",
    "| Continental | North America | 24,700,000 kmÂ² | Thousands of basins |\n",
    "\n",
    "This tutorial represents the culmination of our spatial scaling journey, demonstrating CONFLUENCE's capability to handle the most challenging scales in hydrological modeling while maintaining scientific rigor and workflow efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Continental-Scale Setup with Massive Computational Configuration\n",
    "This tutorial represents the ultimate scaling challenge in our CONFLUENCE series: continental-scale hydrological modeling. Moving from regional domains like Iceland to an entire continent introduces unprecedented computational complexity and transformative scientific opportunities. Using North America as our example, we demonstrate how CONFLUENCE handles massive data volumes, extreme computational demands, and the methodological challenges of modeling hydrology across an entire continent.\n",
    "\n",
    "### Modeling Evolution: Regional â†’ Continental Scale\n",
    "\n",
    "- **Spatial Scale**: Regional domain (~100,000 kmÂ²) â†’ Continental domain (~25,000,000 kmÂ²)\n",
    "- **Drainage Systems**: Multiple independent systems â†’ Thousands of independent systems\n",
    "- **Computational Units**: Hundreds of HRUs â†’ Tens to hundreds of thousands of HRUs\n",
    "- **Data Volume**: Gigabytes â†’ Terabytes of input/output data\n",
    "- **Computational Requirements**: Standard computing â†’ High-performance computing mandatory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFLUENCE Tutorial 03b: Continental-Scale Modeling ===\n",
      "Ultimate scaling challenge: Regional to continental hydrological modeling\n",
      "\n",
      "ðŸŒ Configuring Continental North America Domain...\n",
      "âœ… Continental North America configuration saved: /Users/darrieythorsson/compHydro/code/CONFLUENCE/0_config_files/config_continental_tutorial.yaml\n",
      "\n",
      "âš™ï¸  Initializing CONFLUENCE for Continental Modeling...\n",
      "\n",
      "17:45:32 â”‚ ============================================================\n",
      "17:45:32 â— CONFLUENCE Logging Initialized\n",
      "17:45:32 â— Domain: North_America_tutorial\n",
      "17:45:32 â— Experiment ID: continental_tutorial\n",
      "17:45:32 â— Log Level: INFO\n",
      "17:45:32 â— Log File: /Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/_workLog_North_America_tutorial/confluence_general_North_America_tutorial_20250718_174532.log\n",
      "\n",
      "17:45:32 â”‚ ============================================================\n",
      "17:45:32 â— Configuration logged to: /Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/_workLog_North_America_tutorial/config_North_America_tutorial_20250718_174532.yaml\n",
      "17:45:32 â— Initializing CONFLUENCE system\n",
      "17:45:32 â— Configuration loaded from: /Users/darrieythorsson/compHydro/code/CONFLUENCE/0_config_files/config_continental_tutorial.yaml\n",
      "17:45:32 â— Initializing VariableHandler for dataset: ERA5 and model: SUMMA\n",
      "17:45:33 â— CONFLUENCE system initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: CONTINENTAL-SCALE SETUP WITH MASSIVE COMPUTATIONAL CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import contextily as cx\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import CONFLUENCE\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=== CONFLUENCE Tutorial 03b: Continental-Scale Modeling ===\")\n",
    "print(\"Ultimate scaling challenge: Regional to continental hydrological modeling\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION FOR CONTINENTAL NORTH AMERICA MODELING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nðŸŒ Configuring Continental North America Domain...\")\n",
    "\n",
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/Users/darrieythorsson/compHydro/data/CONFLUENCE_data')  # â† Update this path\n",
    "\n",
    "# Verify paths exist and create if needed\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load North America configuration template or create from base template\n",
    "na_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_North_America.yaml'\n",
    "\n",
    "if not na_config_path.exists():\n",
    "    print(\"âš ï¸  North America configuration template not found. Creating from base template...\")\n",
    "    # Load base template and adapt for continental North America\n",
    "    template_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "    with open(template_config_path, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    \n",
    "    # Configure for North America continental modeling\n",
    "    na_config_updates = {\n",
    "        'DOMAIN_NAME': 'North_America',\n",
    "        'EXPERIMENT_ID': 'run_1',\n",
    "        'BOUNDING_BOX_COORDS': '83.0/-170.0/5.0/-50.0',  # North America continental extent\n",
    "        'DELINEATE_BY_POURPOINT': False,  # Continental bounding box approach\n",
    "        'DELINEATE_COASTAL_WATERSHEDS': True,  # Include all coastal systems\n",
    "        'DOMAIN_DEFINITION_METHOD': 'delineate',\n",
    "        'DOMAIN_DISCRETIZATION': 'GRUs',\n",
    "        'STREAM_THRESHOLD': 7500,  # High threshold for continental scale\n",
    "        'MIN_GRU_SIZE': 50,  # Larger minimum for computational efficiency\n",
    "        'MPI_PROCESSES': 40,  #  parallelization for HPC\n",
    "        'HYDROLOGICAL_MODEL': 'SUMMA',\n",
    "        'ROUTING_MODEL': 'mizuRoute',\n",
    "        'FORCING_DATASET': 'ERA5',\n",
    "        'EXPERIMENT_TIME_START': '2018-01-01 01:00',\n",
    "        'EXPERIMENT_TIME_END': '2018-03-31 23:00',  # Short period for demo\n",
    "    }\n",
    "    config_dict.update(na_config_updates)\n",
    "else:\n",
    "    with open(na_config_path, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update for tutorial-specific settings\n",
    "config_updates = {\n",
    "    'CONFLUENCE_CODE_DIR': str(CONFLUENCE_CODE_DIR),\n",
    "    'CONFLUENCE_DATA_DIR': str(CONFLUENCE_DATA_DIR),\n",
    "    'DOMAIN_NAME': 'North_America_tutorial',\n",
    "    'EXPERIMENT_ID': 'continental_tutorial',\n",
    "    'EXPERIMENT_TIME_START': '2018-01-01 01:00',\n",
    "    'EXPERIMENT_TIME_END': '2018-03-31 23:00',  # Short for tutorial demonstration\n",
    "    'SPATIAL_MODE': 'Distributed',\n",
    "}\n",
    "\n",
    "config_dict.update(config_updates)\n",
    "\n",
    "# Add experiment metadata\n",
    "config_dict['NOTEBOOK_CREATION_TIME'] = datetime.now().isoformat()\n",
    "config_dict['NOTEBOOK_CREATOR'] = 'CONFLUENCE_Tutorial_03b'\n",
    "config_dict['SPATIAL_EVOLUTION'] = 'Regional to continental-scale modeling'\n",
    "\n",
    "# Save continental configuration\n",
    "continental_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_continental_tutorial.yaml'\n",
    "with open(continental_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"âœ… Continental North America configuration saved: {continental_config_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# INITIALIZE CONFLUENCE FOR CONTINENTAL MODELING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nâš™ï¸  Initializing CONFLUENCE for Continental Modeling...\")\n",
    "\n",
    "# Initialize CONFLUENCE with continental config\n",
    "confluence = CONFLUENCE(continental_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Continental-Scale Data Acquisition and Massive Multi-Watershed Delineation\n",
    "The transition to continental modeling requires handling unprecedented data volumes and computational complexity. Unlike regional modeling with manageable datasets, we now process terabyte-scale geospatial data and delineate thousands of independent drainage systems across an entire continent. This represents the ultimate challenge in spatial data processing, requiring high-performance computing infrastructure and sophisticated data management strategies.\n",
    "\n",
    "### Scientific Context: Continental-Scale Geospatial Processing\n",
    "\n",
    "**Massive Data Acquisition Principles:**\n",
    "- **Terabyte-Scale Datasets**: Continental DEMs, climate data, and attribute datasets measured in terabytes\n",
    "- **Multi-Resolution Integration**: Combining global datasets with regional high-resolution data where available\n",
    "- **Distributed Processing**: HPC-based parallel processing mandatory for reasonable execution times\n",
    "- **Storage Infrastructure**: High-capacity, high-speed storage systems for data management\n",
    "- **Quality Control at Scale**: Automated validation across continental-scale heterogeneous datasets\n",
    "\n",
    "**Continental Delineation Complexity:**\n",
    "- **Thousands of Watersheds**: North America contains thousands of independent drainage systems\n",
    "- **Extreme Topographic Diversity**: Arctic tundra to tropical highlands, coastal plains to continental divides\n",
    "- **Multi-National Boundaries**: Watersheds spanning multiple countries with different data standards\n",
    "- **Scale-Dependent Processing**: Algorithms optimized for continental extent while maintaining accuracy\n",
    "\n",
    "The continental approach captures the complete hydrological picture of an entire continent, essential for climate change assessment, transboundary water management, and Earth system science applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ—‚ï¸  Initializing Continental Project Structure...\n",
      "17:53:34 â— Setting up project for domain: North_America_tutorial\n",
      "17:53:34 â— Project directory created at: /Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial\n",
      "17:53:34 â— Pour point shapefile created successfully: /Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/shapefiles/pour_point/North_America_tutorial_pourPoint.shp\n",
      "âœ… Continental project structure created\n",
      "   ðŸ“ Project directory: /Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial\n",
      "   ðŸŽ¯ Pour point file: Created (not used for continental delineation)\n",
      "\n",
      "ðŸ“‹ Continental Project Directory Structure:\n",
      "\n",
      "ðŸŒ Continental-Scale Geospatial Data Acquisition...\n",
      "17:53:34 â— Starting attribute acquisition\n",
      "17:53:34 â— Acquiring elevation data\n",
      "usage: extract-gis.sh -d DATASET -io DIR -v var1[,var2,[...]] [-jVhEu] [-t BOOL] [-c DIR] [-se DATE] [-r INT] [-ln REAL,REAL] [-f PATH] [-F STR] [-p STR] [-a stat1[,stat2,[...]] [-q q1[,q2[...]]]] \n",
      "17:53:34 â— Error running gistool: Command '['/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/installs/gistool/extract-gis.sh', '--dataset=MERIT-Hydro', '--dataset-dir=/work/comphyd_lab/data/geospatial-data/MERIT-Hydro', '--output-dir=/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/attributes/elevation/dem', '--lat-lims=85,5', '--lon-lims=-180,-53', '--variable=elv', '--prefix=domain_North_America_tutorial_', '--print-geotiff=true', '--cache=/work/comphyd_lab/users/darri/cache_North_America_tutorial', '--cluster=/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/datatool/etc/clusters/ucalgary-arc.json']' returned non-zero exit status 1.\n",
      "17:53:34 â— Error during attribute acquisition: Command '['/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/installs/gistool/extract-gis.sh', '--dataset=MERIT-Hydro', '--dataset-dir=/work/comphyd_lab/data/geospatial-data/MERIT-Hydro', '--output-dir=/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/attributes/elevation/dem', '--lat-lims=85,5', '--lon-lims=-180,-53', '--variable=elv', '--prefix=domain_North_America_tutorial_', '--print-geotiff=true', '--cache=/work/comphyd_lab/users/darri/cache_North_America_tutorial', '--cluster=/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/datatool/etc/clusters/ucalgary-arc.json']' returned non-zero exit status 1.\n",
      "\n",
      "17:53:34 â”‚ Traceback (most recent call last):\n",
      "  File \"/Users/darrieythorsson/compHydro/code/CONFLUENCE/utils/data/data_manager.py\", line 122, in acquire_attributes\n",
      "    self._acquire_elevation_data(gr, dem_dir, latlims, lonlims)\n",
      "  File \"/Users/darrieythorsson/compHydro/code/CONFLUENCE/utils/data/data_manager.py\", line 164, in _acquire_elevation_data\n",
      "    gistool_runner.execute_gistool_command(gistool_command)\n",
      "  File \"/Users/darrieythorsson/compHydro/code/CONFLUENCE/utils/data/data_utils.py\", line 1651, in execute_gistool_command\n",
      "    subprocess.run(gistool_command, check=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 571, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command '['/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/installs/gistool/extract-gis.sh', '--dataset=MERIT-Hydro', '--dataset-dir=/work/comphyd_lab/data/geospatial-data/MERIT-Hydro', '--output-dir=/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/attributes/elevation/dem', '--lat-lims=85,5', '--lon-lims=-180,-53', '--variable=elv', '--prefix=domain_North_America_tutorial_', '--print-geotiff=true', '--cache=/work/comphyd_lab/users/darri/cache_North_America_tutorial', '--cluster=/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/datatool/etc/clusters/ucalgary-arc.json']' returned non-zero exit status 1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getopt: illegal option -- n\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/installs/gistool/extract-gis.sh', '--dataset=MERIT-Hydro', '--dataset-dir=/work/comphyd_lab/data/geospatial-data/MERIT-Hydro', '--output-dir=/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/attributes/elevation/dem', '--lat-lims=85,5', '--lon-lims=-180,-53', '--variable=elv', '--prefix=domain_North_America_tutorial_', '--print-geotiff=true', '--cache=/work/comphyd_lab/users/darri/cache_North_America_tutorial', '--cluster=/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/datatool/etc/clusters/ucalgary-arc.json']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸŒ Continental-Scale Geospatial Data Acquisition...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Execute continental geospatial data acquisition\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mconfluence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanagers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Continental geospatial data acquisition complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# CONTINENTAL DOMAIN DELINEATION: THOUSANDS OF WATERSHEDS\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n",
      "File \u001b[0;32m~/compHydro/code/CONFLUENCE/utils/data/data_manager.py:122\u001b[0m, in \u001b[0;36mDataManager.acquire_attributes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m lonlims \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbbox[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbbox[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# Acquire elevation data\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_elevation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdem_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatlims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlonlims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# Acquire land cover data\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_landcover_data(gr, landclass_dir, latlims, lonlims)\n",
      "File \u001b[0;32m~/compHydro/code/CONFLUENCE/utils/data/data_manager.py:164\u001b[0m, in \u001b[0;36mDataManager._acquire_elevation_data\u001b[0;34m(self, gistool_runner, output_dir, lat_lims, lon_lims)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcquiring elevation data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m gistool_command \u001b[38;5;241m=\u001b[39m gistool_runner\u001b[38;5;241m.\u001b[39mcreate_gistool_command(\n\u001b[1;32m    158\u001b[0m     dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMERIT-Hydro\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    159\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m )\n\u001b[0;32m--> 164\u001b[0m \u001b[43mgistool_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_gistool_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgistool_command\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/compHydro/code/CONFLUENCE/utils/data/data_utils.py:1651\u001b[0m, in \u001b[0;36mgistoolRunner.execute_gistool_command\u001b[0;34m(self, gistool_command)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_gistool_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, gistool_command):\n\u001b[1;32m   1648\u001b[0m     \n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;66;03m#Run the gistool command\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1651\u001b[0m         \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgistool_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgistool completed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/installs/gistool/extract-gis.sh', '--dataset=MERIT-Hydro', '--dataset-dir=/work/comphyd_lab/data/geospatial-data/MERIT-Hydro', '--output-dir=/Users/darrieythorsson/compHydro/data/CONFLUENCE_data/domain_North_America_tutorial/attributes/elevation/dem', '--lat-lims=85,5', '--lon-lims=-180,-53', '--variable=elv', '--prefix=domain_North_America_tutorial_', '--print-geotiff=true', '--cache=/work/comphyd_lab/users/darri/cache_North_America_tutorial', '--cluster=/work/comphyd_lab/users/darri/data/CONFLUENCE_data/installs/datatool/etc/clusters/ucalgary-arc.json']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: CONTINENTAL-SCALE DATA ACQUISITION AND MASSIVE MULTI-WATERSHED DELINEATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ—‚ï¸  Initializing Continental Project Structure...\")\n",
    "\n",
    "# Initialize continental project directory structure\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# Create pour point (required for technical reasons but not used for continental delineation)\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"âœ… Continental project structure created\")\n",
    "print(f\"   ðŸ“ Project directory: {project_dir}\")\n",
    "print(f\"   ðŸŽ¯ Pour point file: Created (not used for continental delineation)\")\n",
    "\n",
    "# List created directories and assess storage requirements\n",
    "print(f\"\\nðŸ“‹ Continental Project Directory Structure:\")\n",
    "created_dirs = []\n",
    "\n",
    "print(f\"\\nðŸŒ Continental-Scale Geospatial Data Acquisition...\")\n",
    "\n",
    "# Execute continental geospatial data acquisition\n",
    "confluence.managers['data'].acquire_attributes()\n",
    "\n",
    "print(\"âœ… Continental geospatial data acquisition complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONTINENTAL DOMAIN DELINEATION: THOUSANDS OF WATERSHEDS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸŒŠ Continental Multi-Watershed Delineation Process...\")\n",
    "\n",
    "print(f\"\\nðŸ”§ Continental Delineation Configuration:\")\n",
    "continental_delineation_config = [\n",
    "    f\"Method: {confluence.config['DOMAIN_DEFINITION_METHOD']} (continental watershed delineation)\",\n",
    "    f\"Pour point mode: {confluence.config['DELINEATE_BY_POURPOINT']} (continental bounding box)\",\n",
    "    f\"Coastal watersheds: {confluence.config.get('DELINEATE_COASTAL_WATERSHEDS', True)} (all coastal systems)\",\n",
    "    f\"Stream threshold: {confluence.config['STREAM_THRESHOLD']} (continental-scale optimization)\",\n",
    "    f\"MPI processes: {confluence.config['MPI_PROCESSES']} (massive parallelization)\",\n",
    "    f\"Expected watersheds: Thousands of independent drainage systems\"\n",
    "]\n",
    "\n",
    "for config_item in continental_delineation_config:\n",
    "    print(f\"   âš™ï¸  {config_item}\")\n",
    "\n",
    "# Execute continental domain delineation\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "\n",
    "print(\"âœ… Continental multi-watershed delineation complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONTINENTAL DRAINAGE SYSTEM ANALYSIS: THOUSANDS OF WATERSHEDS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ“Š Continental Drainage System Analysis...\")\n",
    "\n",
    "# Load and analyze continental watersheds\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "network_path = project_dir / 'shapefiles' / 'river_network'\n",
    "\n",
    "continental_basin_count = 0\n",
    "basin_files = []\n",
    "continental_basins_gdf = None\n",
    "\n",
    "if basin_path.exists():\n",
    "    basin_files = list(basin_path.glob('*.shp'))\n",
    "    if basin_files:\n",
    "        try:\n",
    "            # For continental scale, loading all basins may require substantial memory\n",
    "            print(f\"ðŸ“Š Analyzing continental watershed results...\")\n",
    "            \n",
    "            # Check file size first\n",
    "            basin_file_size = basin_files[0].stat().st_size / (1024**2)  # Size in MB\n",
    "            print(f\"   Basin shapefile size: {basin_file_size:.1f} MB\")\n",
    "            \n",
    "            if basin_file_size > 1000:  # If larger than 1 GB\n",
    "                print(f\"   âš ï¸  Large continental dataset detected\")\n",
    "                print(f\"   Loading sample of watersheds for analysis...\")\n",
    "                \n",
    "                # Load sample for analysis\n",
    "                sample_size = 1000\n",
    "                continental_basins_sample = gpd.read_file(basin_files[0], rows=slice(0, sample_size))\n",
    "                \n",
    "                # Estimate total from sample\n",
    "                total_file_records = sample_size  # This would need proper estimation in practice\n",
    "                continental_basin_count = len(continental_basins_sample)\n",
    "                \n",
    "                print(f\"   Sample watersheds: {continental_basin_count}\")\n",
    "                print(f\"   Estimated total: ~{total_file_records} (continental scale)\")\n",
    "                \n",
    "                # Analyze sample statistics\n",
    "                if not continental_basins_sample.empty:\n",
    "                    sample_area = continental_basins_sample.geometry.area.sum() / 1e6  # kmÂ²\n",
    "                    avg_area = sample_area / len(continental_basins_sample)\n",
    "                    \n",
    "                    print(f\"   Sample area: {sample_area:,.0f} kmÂ²\")\n",
    "                    print(f\"   Average watershed size: {avg_area:.1f} kmÂ²\")\n",
    "                    \n",
    "                    # Estimate continental totals\n",
    "                    if continental_basin_count > 0:\n",
    "                        estimated_total_area = approx_area  # Use calculated continental area\n",
    "                        estimated_watershed_count = int(estimated_total_area / avg_area)\n",
    "                        print(f\"   Estimated total watersheds: ~{estimated_watershed_count:,}\")\n",
    "                        continental_basin_count = estimated_watershed_count\n",
    "                \n",
    "            else:\n",
    "                # Load full dataset if manageable\n",
    "                continental_basins_gdf = gpd.read_file(basin_files[0])\n",
    "                continental_basin_count = len(continental_basins_gdf)\n",
    "                \n",
    "                print(f\"âœ… Continental watersheds loaded\")\n",
    "                print(f\"   Total watersheds: {continental_basin_count:,}\")\n",
    "                \n",
    "                if not continental_basins_gdf.empty:\n",
    "                    total_area = continental_basins_gdf.geometry.area.sum() / 1e6  # kmÂ²\n",
    "                    avg_area = total_area / continental_basin_count\n",
    "                    max_area = continental_basins_gdf.geometry.area.max() / 1e6\n",
    "                    min_area = continental_basins_gdf.geometry.area.min() / 1e6\n",
    "                    \n",
    "                    print(f\"   Total continental area: {total_area:,.0f} kmÂ²\")\n",
    "                    print(f\"   Average watershed size: {avg_area:.1f} kmÂ²\")\n",
    "                    print(f\"   Watershed size range: {min_area:.1f} to {max_area:.1f} kmÂ²\")\n",
    "                    \n",
    "                    # Analyze continental watershed characteristics\n",
    "                    if 'elevation' in continental_basins_gdf.columns:\n",
    "                        elev_range = continental_basins_gdf['elevation'].max() - continental_basins_gdf['elevation'].min()\n",
    "                        print(f\"   Elevation diversity: {continental_basins_gdf['elevation'].min():.0f}m to {continental_basins_gdf['elevation'].max():.0f}m\")\n",
    "                        print(f\"   Continental elevation span: {elev_range:.0f}m\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error analyzing continental basin data: {str(e)}\")\n",
    "            print(f\"   This may indicate memory limitations with continental-scale datasets\")\n",
    "    else:\n",
    "        print(f\"âŒ No basin shapefiles found in {basin_path}\")\n",
    "else:\n",
    "    print(f\"âŒ Basin directory not found: {basin_path}\")\n",
    "\n",
    "# Analyze continental stream network\n",
    "continental_network_count = 0\n",
    "network_files = []\n",
    "continental_rivers_gdf = None\n",
    "\n",
    "if network_path.exists():\n",
    "    network_files = list(network_path.glob('*.shp'))\n",
    "    if network_files:\n",
    "        try:\n",
    "            # Check stream network file size\n",
    "            network_file_size = network_files[0].stat().st_size / (1024**2)  # Size in MB\n",
    "            print(f\"\\nðŸŒŠ Continental Stream Network Analysis:\")\n",
    "            print(f\"   Stream network file size: {network_file_size:.1f} MB\")\n",
    "            \n",
    "            if network_file_size > 500:  # Large file handling\n",
    "                print(f\"   âš ï¸  Large continental stream network detected\")\n",
    "                print(f\"   Loading sample for analysis...\")\n",
    "                \n",
    "                # Load sample of stream network\n",
    "                sample_streams = gpd.read_file(network_files[0], rows=slice(0, 1000))\n",
    "                continental_network_count = len(sample_streams)\n",
    "                print(f\"   Sample stream segments: {continental_network_count}\")\n",
    "                \n",
    "                if 'Length' in sample_streams.columns:\n",
    "                    sample_length = sample_streams['Length'].sum() / 1000  # km\n",
    "                    print(f\"   Sample stream length: {sample_length:.0f} km\")\n",
    "                    \n",
    "                    # Estimate total network\n",
    "                    est_total_segments = continental_network_count * (continental_basin_count / 100) if continental_basin_count > 0 else 10000\n",
    "                    est_total_length = sample_length * (est_total_segments / continental_network_count)\n",
    "                    print(f\"   Estimated total segments: ~{est_total_segments:,.0f}\")\n",
    "                    print(f\"   Estimated total length: ~{est_total_length:,.0f} km\")\n",
    "                    continental_network_count = est_total_segments\n",
    "                \n",
    "            else:\n",
    "                # Load full network if manageable\n",
    "                continental_rivers_gdf = gpd.read_file(network_files[0])\n",
    "                continental_network_count = len(continental_rivers_gdf)\n",
    "                \n",
    "                print(f\"âœ… Continental stream network loaded\")\n",
    "                print(f\"   Stream segments: {continental_network_count:,}\")\n",
    "                \n",
    "                if 'Length' in continental_rivers_gdf.columns:\n",
    "                    total_length = continental_rivers_gdf['Length'].sum() / 1000  # km\n",
    "                    print(f\"   Total stream length: {total_length:,.0f} km\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error analyzing continental stream network: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"âŒ No stream network files found in {network_path}\")\n",
    "else:\n",
    "    print(f\"âŒ Stream network directory not found: {network_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Continental-Scale Data Pipeline and Massive Computational Processing\n",
    "The same model-agnostic preprocessing framework now scales to handle tens to hundreds of thousands of computational units across an entire continent, representing the ultimate challenge in hydrological data processing. Unlike previous tutorials managing hundreds or thousands of units, we now orchestrate massive parallel processing across continental-scale heterogeneity, requiring high-performance computing infrastructure and sophisticated memory management strategies.\n",
    "\n",
    "### Data Pipeline Scaling: Regional â†’ Continental Magnitude\n",
    "\n",
    "- **Computational Units**: Thousands of HRUs â†’ Tens to hundreds of thousands of HRUs\n",
    "- **Forcing Data Volume**: Gigabytes â†’ Multi-terabyte meteorological datasets\n",
    "- **Processing Complexity**: Regional diversity â†’ Continental heterogeneity across all climate zones\n",
    "- **Memory Management**: Standard RAM â†’ Distributed memory systems with 100+ GB requirements\n",
    "- **Infrastructure**: Single-node processing â†’ HPC clusters with massive parallelization\n",
    "\n",
    "### Continental-Scale Processing Considerations\n",
    "\n",
    "**Extreme Hydrological Diversity**: North America encompasses every major hydrological regime - Arctic permafrost systems, temperate forests, arid deserts, tropical highlands, glacial systems, and coastal zones - each requiring specialized process representation within the same modeling framework.\n",
    "\n",
    "**Terabyte-Scale Forcing Distribution**: Continental meteorological datasets exceed terabyte scales, requiring sophisticated data streaming, parallel I/O operations, and distributed memory management across thousands of computational nodes.\n",
    "\n",
    "**Massive Computational Orchestration**: Coordinating preprocessing across tens to hundreds of thousands of HRUs demands advanced job scheduling, load balancing, and fault tolerance mechanisms typical of supercomputing applications.\n",
    "\n",
    "**Quality Control at Scale**: Ensuring data consistency and scientific validity across continental heterogeneity requires automated validation systems capable of handling millions of data points and identifying anomalies across diverse conditions.\n",
    "\n",
    "The same preprocessing philosophy maintains consistent data standards across this unprecedented spatial and computational complexity while requiring fundamental adaptations for high-performance computing environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: CONTINENTAL-SCALE DATA PIPELINE AND MASSIVE COMPUTATIONAL PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸŒ Continental Domain Discretization Process...\")\n",
    "\n",
    "print(f\"   Discretization method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "\n",
    "print(f\"\\nâš™ï¸  Executing continental domain discretization...\")\n",
    "\n",
    "# Execute continental domain discretization\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "print(\"âœ… Continental domain discretization complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPUTATIONAL UNIT ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ“Š Massive Computational Unit Analysis...\")\n",
    "\n",
    "# Load and analyze continental computational units\n",
    "catchment_path = project_dir / 'shapefiles' / 'catchment'\n",
    "continental_hru_count = 0\n",
    "continental_hru_gdf = None\n",
    "\n",
    "if catchment_path.exists():\n",
    "    hru_files = list(catchment_path.glob('*.shp'))\n",
    "    if hru_files:\n",
    "        try:\n",
    "            # Check file size for continental HRU dataset\n",
    "            hru_file_size = hru_files[0].stat().st_size / (1024**3)  # Size in GB\n",
    "            print(f\"âœ… Continental HRU dataset created\")\n",
    "            print(f\"   HRU shapefile size: {hru_file_size:.2f} GB\")\n",
    "            \n",
    "            if hru_file_size > 5.0:  # Large file handling for continental scale\n",
    "                print(f\"   âš ï¸  Massive continental HRU dataset detected\")\n",
    "                print(f\"   Using statistical sampling for analysis...\")\n",
    "                \n",
    "                # Load sample for computational analysis\n",
    "                sample_size = 5000  # Larger sample for continental scale\n",
    "                continental_hru_sample = gpd.read_file(hru_files[0], rows=slice(0, sample_size))\n",
    "                continental_hru_count = len(continental_hru_sample)\n",
    "                \n",
    "                print(f\"   Sample HRUs analyzed: {continental_hru_count}\")\n",
    "                \n",
    "                # Estimate total continental HRUs\n",
    "                if continental_basin_count > 0 and 'GRU_ID' in continental_hru_sample.columns:\n",
    "                    sample_grus = continental_hru_sample['GRU_ID'].nunique()\n",
    "                    if sample_grus > 0:\n",
    "                        hrus_per_gru = continental_hru_count / sample_grus\n",
    "                        estimated_total_hrus = int(hrus_per_gru * continental_basin_count)\n",
    "                        continental_hru_count = estimated_total_hrus\n",
    "                        \n",
    "                        print(f\"   Sample GRUs: {sample_grus}\")\n",
    "                        print(f\"   Average HRUs per GRU: {hrus_per_gru:.1f}\")\n",
    "                        print(f\"   Estimated total HRUs: {estimated_total_hrus:,}\")\n",
    "                \n",
    "            else:\n",
    "                # Load full dataset if manageable\n",
    "                continental_hru_gdf = gpd.read_file(hru_files[0])\n",
    "                continental_hru_count = len(continental_hru_gdf)\n",
    "                \n",
    "                print(f\"   Total HRUs: {continental_hru_count:,}\")\n",
    "                \n",
    "                if 'GRU_ID' in continental_hru_gdf.columns:\n",
    "                    unique_grus = continental_hru_gdf['GRU_ID'].nunique()\n",
    "                    print(f\"   Unique GRUs: {unique_grus:,}\")\n",
    "                    \n",
    "                    if unique_grus > 0:\n",
    "                        avg_hrus_per_gru = continental_hru_count / unique_grus\n",
    "                        print(f\"   Average HRUs per GRU: {avg_hrus_per_gru:.1f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error analyzing continental HRUs: {str(e)}\")\n",
    "            print(f\"   This may indicate memory limitations with continental datasets\")\n",
    "            continental_hru_count = continental_basin_count * 5  # Rough estimate\n",
    "    else:\n",
    "        print(f\"ðŸ“‹ No continental HRU files found\")\n",
    "        continental_hru_count = continental_basin_count * 5  # Rough estimate\n",
    "else:\n",
    "    print(f\"ðŸ“‹ HRU directory not found\")\n",
    "    continental_hru_count = continental_basin_count * 5  # Rough estimate\n",
    "\n",
    "# =============================================================================\n",
    "# FORCING DATA ACQUISITION AND PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸŒ¡ï¸  Continental Terabyte-Scale Forcing Data Pipeline...\")\n",
    "\n",
    "# Check for existing forcing data or estimate requirements\n",
    "forcing_dir = project_dir / 'forcing' / 'raw_data'\n",
    "forcing_data_available = forcing_dir.exists() and len(list(forcing_dir.glob('*.nc'))) > 0\n",
    "\n",
    "if not forcing_data_available:\n",
    "    print(f\"\\nâ¬‡ï¸  Continental Forcing Data Acquisition Requirements:\")\n",
    "    \n",
    "    # confluence.managers['data'].acquire_forcings()\n",
    "\n",
    "    print(\"âœ… Continental forcing data acquisition simulated\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâœ… Continental forcing data available\")\n",
    "    print(f\"   Reusing terabyte-scale meteorological datasets\")\n",
    "\n",
    "# =============================================================================\n",
    "# MASSIVE MODEL-AGNOSTIC PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nâš™ï¸  Executing Continental Model-Agnostic Preprocessing...\")\n",
    "\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "\n",
    "print(\"âœ… Continental model-agnostic preprocessing complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL-SPECIFIC PREPROCESSING FOR CONTINENTAL INFRASTRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ”§ Model-Specific Preprocessing: Continental SUMMA + mizuRoute...\")\n",
    "\n",
    "confluence.managers['model'].preprocess_models()\n",
    "\n",
    "print(\"âœ… Continental model-specific preprocessing complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Continental-Scale Model Execution and Supercomputing Infrastructure\n",
    "The same SUMMA process-based physics now faces its ultimate scaling challenge: execution across tens to hundreds of thousands of computational units spanning an entire continent. This represents a fundamental transition from standard computing to supercomputing applications, requiring sophisticated job scheduling, massive parallel coordination, and infrastructure typically reserved for climate modeling and weather prediction systems.\n",
    "\n",
    "### Model Execution Scaling: Regional â†’ Continental Supercomputing\n",
    "\n",
    "- **Computational Infrastructure**: Standard HPC clusters â†’ National supercomputing facilities\n",
    "- **Resource Requirements**: 100s of cores â†’ 1000s of cores with specialized interconnects\n",
    "- **Memory Architecture**: Shared memory systems â†’ Distributed memory supercomputers\n",
    "- **Execution Time**: Hours/days â†’ Weeks/months for full continental simulations\n",
    "- **Job Management**: Simple batch jobs â†’ Complex workflow orchestration systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: CONTINENTAL-SCALE MODEL EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# Execute the  model system\n",
    "print(f\"\\nâš™ï¸  Running continental multi-watershed simulation...\")\n",
    "confluence.managers['model'].run_models()\n",
    "\n",
    "print(\"âœ… Regional multi-watershed simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Continental-Scale Analysis and Earth System Assessment\n",
    "The culmination of our modeling series transcends traditional watershed performance evaluation to embrace Earth system science applications. With successful execution across tens of thousands of computational units, we now analyze continental water resources, climate sensitivity, and hydrological patterns across an entire continent. This represents the ultimate achievement in spatial hydrological modeling - providing insights impossible at any smaller scale and demonstrating CONFLUENCE's capability to contribute to global Earth system understanding.\n",
    "\n",
    "### Analysis Framework Evolution: Regional â†’ Continental Earth System Science\n",
    "\n",
    "- **Assessment Scale**: Regional pattern analysis â†’ Continental Earth system component analysis  \n",
    "- **Scientific Applications**: Regional water resources â†’ Global climate model inputs and continental water security\n",
    "- **Comparative Scope**: Inter-watershed analysis â†’ Continental-scale statistical hydrology across thousands of systems\n",
    "- **Policy Relevance**: Regional water management â†’ National and international water policy frameworks\n",
    "- **Earth System Integration**: Regional hydrology â†’ Continental water cycle component for climate science\n",
    "\n",
    "### Continental-Scale Analysis Capabilities\n",
    "\n",
    "**Continental Water Balance**: Comprehensive assessment of precipitation, evapotranspiration, runoff, and storage across North America's complete hydrological spectrum, providing unprecedented insights into continental-scale water cycle dynamics.\n",
    "\n",
    "**Climate Change Sensitivity**: Analysis of how thousands of diverse watersheds respond to climate forcing, enabling robust statistical assessment of climate change impacts across the full range of North American hydrological conditions.\n",
    "\n",
    "**Earth System Science Applications**: Continental-scale land surface fluxes and water balance components essential for global climate models, weather prediction systems, and Earth system research.\n",
    "\n",
    "**Transboundary Water Resources**: Assessment of water availability and variability across international boundaries, supporting continental-scale water management and policy decisions.\n",
    "\n",
    "The continental analysis framework provides transformative insights into Earth system hydrology while demonstrating the ultimate achievement of our spatial modeling progression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: CONTINENTAL-SCALE ANALYSIS AND EARTH SYSTEM ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸŒ Loading Continental-Scale Simulation Results...\")\n",
    "\n",
    "# Load continental simulation outputs\n",
    "simulation_dir = project_dir / 'simulations' / config_dict['EXPERIMENT_ID']\n",
    "summa_dir = simulation_dir / 'SUMMA'\n",
    "routing_dir = simulation_dir / 'mizuRoute'\n",
    "\n",
    "# Initialize variables for continental analysis\n",
    "continental_summa_data = None\n",
    "continental_routing_data = None\n",
    "continental_analysis_ready = False\n",
    "\n",
    "# Load massive SUMMA continental outputs\n",
    "summa_files = list(summa_dir.glob('*.nc')) if summa_dir.exists() else []\n",
    "if summa_files:\n",
    "    try:\n",
    "        # For continental scale, we might need to handle massive files carefully\n",
    "        print(f\"âœ… Continental SUMMA outputs available\")\n",
    "        print(f\"   Files: {len(summa_files)} netCDF files\")\n",
    "        \n",
    "        # Check file sizes for continental datasets\n",
    "        total_summa_size = sum(f.stat().st_size for f in summa_files) / (1024**3)  # GB\n",
    "        print(f\"   Total SUMMA output: {total_summa_size:.1f} GB\")\n",
    "        \n",
    "        # Load representative file for analysis\n",
    "        continental_summa_data = xr.open_dataset(summa_files[0])\n",
    "        \n",
    "        if 'hru' in continental_summa_data.dims:\n",
    "            n_hrus_output = continental_summa_data.dims['hru']\n",
    "            print(f\"   HRUs in output: {n_hrus_output:,}\")\n",
    "        \n",
    "        if 'time' in continental_summa_data.dims:\n",
    "            n_timesteps = continental_summa_data.dims['time']\n",
    "            print(f\"   Time steps: {n_timesteps:,}\")\n",
    "            \n",
    "        print(f\"   Variables: {len(continental_summa_data.data_vars)} hydrological components\")\n",
    "        continental_analysis_ready = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Continental SUMMA analysis limited: {e}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  No continental SUMMA outputs found - using demonstration framework\")\n",
    "\n",
    "# Load massive mizuRoute continental outputs  \n",
    "routing_files = list(routing_dir.glob('*.nc')) if routing_dir.exists() else []\n",
    "if routing_files:\n",
    "    try:\n",
    "        continental_routing_data = xr.open_dataset(routing_files[0])\n",
    "        \n",
    "        print(f\"âœ… Continental mizuRoute outputs available\")\n",
    "        if 'seg' in continental_routing_data.dims:\n",
    "            n_segments = continental_routing_data.dims['seg']\n",
    "            print(f\"   Stream segments: {n_segments:,}\")\n",
    "            \n",
    "        if 'IRFroutedRunoff' in continental_routing_data.data_vars:\n",
    "            print(f\"   Continental streamflow: Available for thousands of outlets\")\n",
    "            \n",
    "        # Check routing output size\n",
    "        routing_size = sum(f.stat().st_size for f in routing_files) / (1024**3)  # GB\n",
    "        print(f\"   Total routing output: {routing_size:.1f} GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Continental routing analysis limited: {e}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  No continental routing outputs found - using demonstration framework\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Continental Analysis Capability: {'Full Analysis Available' if continental_analysis_ready else 'Demonstration Framework'}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONTINENTAL WATER BALANCE AND EARTH SYSTEM ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ’§ Continental Water Balance and Earth System Analysis...\")\n",
    "\n",
    "if continental_analysis_ready and continental_summa_data is not None:\n",
    "    try:\n",
    "        print(f\"âœ… Analyzing continental water balance across North America\")\n",
    "        \n",
    "        # Extract continental water balance components\n",
    "        available_vars = list(continental_summa_data.data_vars.keys())\n",
    "        continental_water_components = {\n",
    "            'Total Soil Water': 'scalarTotalSoilWat',\n",
    "            'Snow Water Equivalent': 'scalarSWE',\n",
    "            'Surface Runoff': 'scalarSurfaceRunoff', \n",
    "            'Evapotranspiration': 'scalarLatHeatTotal',\n",
    "            'Net Precipitation': 'scalarNetPrecipitation',\n",
    "            'Groundwater Flow': 'scalarGroundwater'\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nðŸ’§ Continental Water Balance Components:\")\n",
    "        continental_analysis_results = {}\n",
    "        \n",
    "        for component_name, var_key in continental_water_components.items():\n",
    "            if var_key in available_vars:\n",
    "                var_data = continental_summa_data[var_key]\n",
    "                \n",
    "                # Calculate continental statistics\n",
    "                if 'hru' in var_data.dims and 'time' in var_data.dims:\n",
    "                    # Spatial mean across continent\n",
    "                    continental_mean = var_data.mean(dim=['hru', 'time']).values\n",
    "                    spatial_std = var_data.mean(dim='time').std(dim='hru').values\n",
    "                    temporal_std = var_data.mean(dim='hru').std(dim='time').values\n",
    "                    \n",
    "                    continental_analysis_results[component_name] = {\n",
    "                        'mean': continental_mean,\n",
    "                        'spatial_variability': spatial_std,\n",
    "                        'temporal_variability': temporal_std\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   ðŸ’§ {component_name}:\")\n",
    "                    print(f\"      Continental mean: {continental_mean:.2f}\")\n",
    "                    print(f\"      Spatial variability: {spatial_std:.2f}\")\n",
    "                    print(f\"      Temporal variability: {temporal_std:.2f}\")\n",
    "                else:\n",
    "                    print(f\"   ðŸ“‹ {component_name}: Available but requires processing\")\n",
    "            else:\n",
    "                print(f\"   âŒ {component_name}: Not available in outputs\")\n",
    "        \n",
    "        # Calculate continental water balance\n",
    "        print(f\"\\nðŸŒ Continental Water Balance Summary:\")\n",
    "        print(f\"   Analysis period: {continental_summa_data.time.min().values} to {continental_summa_data.time.max().values}\")\n",
    "        print(f\"   Spatial coverage: {continental_summa_data.dims.get('hru', 'N/A'):,} computational units\")\n",
    "        print(f\"   Continental extent: Complete North American coverage\")\n",
    "        \n",
    "        if len(continental_analysis_results) >= 3:\n",
    "            print(f\"   Water balance closure: {len(continental_analysis_results)} components analyzed\")\n",
    "            print(f\"   Statistical robustness: {continental_summa_data.dims.get('hru', 0):,} spatial samples\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Continental water balance analysis error: {e}\")\n",
    "        continental_analysis_ready = False\n",
    "\n",
    "else:\n",
    "    print(f\"ðŸ“‹ Demonstrating continental water balance analysis framework:\")\n",
    "    demo_continental_balance = [\n",
    "        f\"Precipitation patterns: Continental gradients from Arctic to tropical zones\",\n",
    "        f\"Evapotranspiration: Climate-dependent water losses across continental diversity\",\n",
    "        f\"Snow water equivalent: Seasonal storage across elevation and latitude gradients\",\n",
    "        f\"Surface runoff: Continental patterns in water availability and timing\",\n",
    "        f\"Soil water storage: Regional patterns in water retention and drought sensitivity\",\n",
    "        f\"Groundwater contributions: Continental-scale groundwater-surface water interactions\"\n",
    "    ]\n",
    "    \n",
    "    for component in demo_continental_balance:\n",
    "        print(f\"   ðŸ’§ {component}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONTINENTAL CLIMATE SENSITIVITY AND CHANGE ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸŒ¡ï¸  Continental Climate Sensitivity and Change Assessment...\")\n",
    "\n",
    "print(f\"ðŸŒ Continental Climate Gradient Analysis:\")\n",
    "continental_climate_analysis = [\n",
    "    f\"Arctic regions: Permafrost hydrology and extreme seasonal cycles\",\n",
    "    f\"Boreal systems: Snow-dominated hydrology with forest influences\", \n",
    "    f\"Temperate zones: Balanced precipitation-evaporation with seasonal variability\",\n",
    "    f\"Great Plains: Continental climate effects on agricultural water resources\",\n",
    "    f\"Mountain systems: Elevation-dependent processes across major ranges\",\n",
    "    f\"Coastal regions: Maritime influences on temperature and precipitation\",\n",
    "    f\"Arid Southwest: Water-limited hydrology and drought sensitivity\"\n",
    "]\n",
    "\n",
    "for analysis in continental_climate_analysis:\n",
    "    print(f\"   ðŸŒ¡ï¸  {analysis}\")\n",
    "\n",
    "if continental_analysis_ready and continental_summa_data is not None:\n",
    "    try:\n",
    "        # Analyze continental climate sensitivity\n",
    "        print(f\"\\nðŸŒŠ Continental Climate Sensitivity Analysis:\")\n",
    "        \n",
    "        # Temperature analysis if available\n",
    "        temp_vars = ['scalarAirTemperature', 'scalarAirTemp', 'airTemp']\n",
    "        temp_var = None\n",
    "        for var in temp_vars:\n",
    "            if var in continental_summa_data.data_vars:\n",
    "                temp_var = var\n",
    "                break\n",
    "        \n",
    "        if temp_var:\n",
    "            temp_data = continental_summa_data[temp_var]\n",
    "            print(f\"   Temperature analysis across {continental_summa_data.dims.get('hru', 0):,} sites:\")\n",
    "            \n",
    "            if 'hru' in temp_data.dims:\n",
    "                continental_temp_mean = temp_data.mean().values\n",
    "                continental_temp_range = temp_data.max().values - temp_data.min().values\n",
    "                \n",
    "                print(f\"   Continental mean temperature: {continental_temp_mean:.2f}Â°C\")\n",
    "                print(f\"   Continental temperature range: {continental_temp_range:.2f}Â°C\")\n",
    "                print(f\"   Climate diversity: Arctic to tropical conditions represented\")\n",
    "        \n",
    "        # Snow analysis for climate sensitivity\n",
    "        if 'scalarSWE' in continental_summa_data.data_vars:\n",
    "            swe_data = continental_summa_data['scalarSWE']\n",
    "            \n",
    "            if 'hru' in swe_data.dims and 'time' in swe_data.dims:\n",
    "                max_swe = swe_data.max(dim='time')\n",
    "                snow_coverage = (max_swe > 10).sum().values / swe_data.dims['hru'] * 100\n",
    "                \n",
    "                print(f\"   Snow-influenced area: {snow_coverage:.1f}% of continental domain\")\n",
    "                print(f\"   Snow variability: Critical for continental water resources\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Climate sensitivity analysis error: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONTINENTAL STREAMFLOW ANALYSIS: THOUSANDS OF OUTLETS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸŒŠ Continental Streamflow Analysis: Thousands of Outlets...\")\n",
    "\n",
    "if continental_routing_data is not None and 'IRFroutedRunoff' in continental_routing_data.data_vars:\n",
    "    try:\n",
    "        streamflow_data = continental_routing_data['IRFroutedRunoff']\n",
    "        n_outlets = streamflow_data.dims.get('seg', 0)\n",
    "        \n",
    "        print(f\"âœ… Continental streamflow analysis across {n_outlets:,} outlets\")\n",
    "        \n",
    "        # Analyze continental streamflow patterns\n",
    "        if n_outlets > 0:\n",
    "            # Calculate streamflow statistics across continental outlets\n",
    "            mean_flows = streamflow_data.mean(dim='time')\n",
    "            max_flows = streamflow_data.max(dim='time')\n",
    "            \n",
    "            print(f\"\\nðŸŒŠ Continental Streamflow Patterns:\")\n",
    "            print(f\"   Outlet count: {n_outlets:,} independent discharge points\")\n",
    "            print(f\"   Flow magnitude range: {mean_flows.min().values:.2f} to {mean_flows.max().values:.2f} mÂ³/s (mean)\")\n",
    "            print(f\"   Peak flow range: {max_flows.min().values:.2f} to {max_flows.max().values:.2f} mÂ³/s (maximum)\")\n",
    "            \n",
    "            # Identify major continental outlets\n",
    "            if n_outlets >= 10:\n",
    "                # Find largest outlets by mean flow\n",
    "                largest_outlets = mean_flows.argsort()[-10:]  # Top 10 outlets\n",
    "                largest_flows = mean_flows.isel(seg=largest_outlets)\n",
    "                \n",
    "                print(f\"   Major continental systems: {len(largest_outlets)} primary outlets identified\")\n",
    "                print(f\"   Largest outlet discharge: {largest_flows.max().values:.0f} mÂ³/s mean flow\")\n",
    "            \n",
    "            # Calculate continental discharge totals\n",
    "            total_continental_discharge = mean_flows.sum().values\n",
    "            print(f\"   Total continental discharge: {total_continental_discharge:.0f} mÂ³/s\")\n",
    "            \n",
    "            # Seasonal analysis if temporal data available\n",
    "            if 'time' in streamflow_data.dims:\n",
    "                # Monthly analysis across continental outlets\n",
    "                monthly_mean = streamflow_data.groupby('time.month').mean()\n",
    "                peak_month = monthly_mean.mean(dim='seg').argmax().values + 1\n",
    "                low_month = monthly_mean.mean(dim='seg').argmin().values + 1\n",
    "                \n",
    "                month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "                \n",
    "                print(f\"   Continental peak flow: {month_names[peak_month-1]} (averaged)\")\n",
    "                print(f\"   Continental low flow: {month_names[low_month-1]} (averaged)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Continental streamflow analysis error: {e}\")\n",
    "else:\n",
    "    print(f\"ðŸ“‹ Continental streamflow analysis framework:\")\n",
    "    continental_streamflow_characteristics = [\n",
    "        f\"Thousands of outlets: Independent coastal and transboundary discharge points\",\n",
    "        f\"Major river systems: Mississippi, Colorado, Columbia, Mackenzie, St. Lawrence\",\n",
    "        f\"Arctic discharge: Unique seasonal patterns in northern watersheds\",\n",
    "        f\"Pacific coastal: Steep gradient, short residence time systems\",\n",
    "        f\"Atlantic coastal: Diverse from tropical to boreal discharge patterns\",\n",
    "        f\"Great Lakes: Massive freshwater system effects on regional hydrology\"\n",
    "    ]\n",
    "    \n",
    "    for characteristic in continental_streamflow_characteristics:\n",
    "        print(f\"   ðŸŒŠ {characteristic}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EARTH SYSTEM SCIENCE APPLICATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸŒ Earth System Science Applications...\")\n",
    "\n",
    "print(f\"ðŸ”¬ Continental Modeling Contributions to Earth System Science:\")\n",
    "earth_system_applications = [\n",
    "    f\"Global climate models: Land surface water and energy fluxes at continental scale\",\n",
    "    f\"Weather prediction: Continental-scale land surface boundary conditions\",\n",
    "    f\"Climate change assessment: Statistical hydrology across thousands of watersheds\",\n",
    "    f\"Carbon cycle research: Water controls on continental carbon fluxes\",\n",
    "    f\"Ecosystem modeling: Water availability for continental vegetation dynamics\",\n",
    "    f\"Atmospheric modeling: Evapotranspiration and surface energy budget\"\n",
    "]\n",
    "\n",
    "for application in earth_system_applications:\n",
    "    print(f\"   ðŸŒ {application}\")\n",
    "\n",
    "if continental_analysis_ready:\n",
    "    print(f\"\\nðŸ“Š Earth System Science Data Products:\")\n",
    "    earth_system_products = [\n",
    "        f\"Continental water balance: Precipitation-evapotranspiration patterns\",\n",
    "        f\"Seasonal water storage: Snow and soil water across climate gradients\",\n",
    "        f\"Surface energy fluxes: Latent and sensible heat across continental diversity\",\n",
    "        f\"Runoff coefficients: Precipitation-to-runoff relationships by region\",\n",
    "        f\"Drought indicators: Continental-scale water stress assessment\",\n",
    "        f\"Flood potential: Peak flow statistics across thousands of watersheds\"\n",
    "    ]\n",
    "    \n",
    "    for product in earth_system_products:\n",
    "        print(f\"   ðŸ“ˆ {product}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONTINENTAL WATER RESOURCES AND POLICY APPLICATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ’§ Continental Water Resources and Policy Applications...\")\n",
    "\n",
    "print(f\"ðŸ›ï¸  National and International Water Policy Support:\")\n",
    "policy_applications = [\n",
    "    f\"Water security assessment: National-scale water availability and vulnerability\",\n",
    "    f\"Transboundary management: International watershed cooperation frameworks\",\n",
    "    f\"Climate adaptation: Continental-scale climate change impact assessment\",\n",
    "    f\"Infrastructure planning: Continental-scale water storage and conveyance needs\",\n",
    "    f\"Ecosystem services: Water-related services across continental landscapes\",\n",
    "    f\"Emergency management: Continental-scale flood and drought early warning\"\n",
    "]\n",
    "\n",
    "for application in policy_applications:\n",
    "    print(f\"   ðŸ’§ {application}\")\n",
    "\n",
    "# Calculate continental water resources metrics if data available\n",
    "if continental_analysis_ready and 'continental_analysis_results' in locals():\n",
    "    print(f\"\\nðŸ“Š Continental Water Resources Assessment:\")\n",
    "    \n",
    "    # Example water resources calculations\n",
    "    continental_metrics = [\n",
    "        f\"Water availability: Distributed across {continental_summa_data.dims.get('hru', 0):,} assessment units\",\n",
    "        f\"Seasonal storage: Snow and soil water patterns across continental gradients\",\n",
    "        f\"Regional variability: Statistical analysis across thousands of independent systems\",\n",
    "        f\"Climate sensitivity: Robust assessment across complete North American diversity\",\n",
    "        f\"Resource security: Continental-scale evaluation of water stress and abundance\"\n",
    "    ]\n",
    "    \n",
    "    for metric in continental_metrics:\n",
    "        print(f\"   ðŸ“Š {metric}\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPREHENSIVE CONTINENTAL VISUALIZATION FRAMEWORK\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Creating comprehensive continental analysis visualization...\")\n",
    "\n",
    "# For continental scale, we would create multiple visualization products\n",
    "print(f\"ðŸ—ºï¸  Continental Visualization Products:\")\n",
    "\n",
    "if 'continental_basins_gdf' in locals() or 'basins_gdf' in locals():\n",
    "    \n",
    "    # Set up continental visualization framework\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
    "    \n",
    "    # Use available basin data for visualization framework\n",
    "    if 'continental_basins_gdf' in locals() and continental_basins_gdf is not None:\n",
    "        basins_for_viz = continental_basins_gdf\n",
    "    elif 'basins_gdf' in locals() and basins_gdf is not None:\n",
    "        basins_for_viz = basins_gdf\n",
    "    else:\n",
    "        basins_for_viz = None\n",
    "    \n",
    "    if basins_for_viz is not None and not basins_for_viz.empty:\n",
    "        \n",
    "        # Continental watersheds overview (top left)\n",
    "        ax1 = axes[0, 0]\n",
    "        if 'GRU_ID' in basins_for_viz.columns:\n",
    "            basins_for_viz.plot(ax=ax1, column='GRU_ID', cmap='tab20', \n",
    "                               edgecolor='gray', linewidth=0.1, alpha=0.7, legend=False)\n",
    "        else:\n",
    "            basins_for_viz.plot(ax=ax1, cmap='tab20', \n",
    "                               edgecolor='gray', linewidth=0.1, alpha=0.7, legend=False)\n",
    "        \n",
    "        ax1.set_title(f'Continental Watershed Network\\n{len(basins_for_viz):,} Independent Systems', \n",
    "                     fontweight='bold', fontsize=12)\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Latitude')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Continental water balance (top right)\n",
    "        ax2 = axes[0, 1]\n",
    "        if continental_analysis_ready and 'continental_analysis_results' in locals():\n",
    "            # Plot water balance components\n",
    "            components = list(continental_analysis_results.keys())[:5]  # Top 5 components\n",
    "            values = [continental_analysis_results[comp]['mean'] for comp in components]\n",
    "            \n",
    "            bars = ax2.bar(range(len(components)), values, color='steelblue', alpha=0.7)\n",
    "            ax2.set_xticks(range(len(components)))\n",
    "            ax2.set_xticklabels([comp.replace(' ', '\\n') for comp in components], rotation=0, ha='center')\n",
    "            ax2.set_ylabel('Continental Mean Value')\n",
    "            ax2.set_title('Continental Water Balance Components', fontweight='bold')\n",
    "            ax2.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar, value in zip(bars, values):\n",
    "                ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(values)*0.01,\n",
    "                        f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Continental\\nWater Balance\\nAnalysis\\n\\n(Requires Output Data)', \n",
    "                    transform=ax2.transAxes, ha='center', va='center',\n",
    "                    fontsize=14, bbox=dict(facecolor='lightblue', alpha=0.5))\n",
    "            ax2.set_title('Continental Water Balance', fontweight='bold')\n",
    "        \n",
    "        # Climate sensitivity analysis (middle left)\n",
    "        ax3 = axes[1, 0]\n",
    "        # Demo climate zones across continent\n",
    "        climate_zones = ['Arctic', 'Boreal', 'Temperate', 'Continental', 'Arid', 'Coastal']\n",
    "        zone_counts = [len(basins_for_viz)//6] * 6  # Equal distribution for demo\n",
    "        \n",
    "        bars = ax3.bar(climate_zones, zone_counts, color='lightgreen', alpha=0.7, edgecolor='darkgreen')\n",
    "        ax3.set_ylabel('Number of Watersheds')\n",
    "        ax3.set_title('Continental Climate Zone Distribution', fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, count in zip(bars, zone_counts):\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(zone_counts)*0.01,\n",
    "                    f'{count}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # Continental streamflow patterns (middle right)\n",
    "        ax4 = axes[1, 1]\n",
    "        if continental_routing_data is not None:\n",
    "            ax4.text(0.5, 0.5, f'Continental Streamflow\\nAnalysis\\n\\n{n_outlets:,} outlets\\nanalyzed', \n",
    "                    transform=ax4.transAxes, ha='center', va='center',\n",
    "                    fontsize=14, bbox=dict(facecolor='lightcoral', alpha=0.5))\n",
    "        else:\n",
    "            # Demo seasonal flow pattern\n",
    "            months = ['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D']\n",
    "            # Typical North American pattern (spring snowmelt peak)\n",
    "            flow_pattern = [0.7, 0.6, 0.8, 1.2, 1.5, 1.3, 0.9, 0.7, 0.6, 0.7, 0.8, 0.8]\n",
    "            \n",
    "            ax4.plot(months, flow_pattern, 'o-', color='blue', linewidth=2, markersize=6)\n",
    "            ax4.set_ylabel('Normalized Flow')\n",
    "            ax4.set_title('Continental Seasonal Flow Pattern', fontweight='bold')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Earth system applications (bottom left)\n",
    "        ax5 = axes[2, 0]\n",
    "        \n",
    "        # Earth system science metrics\n",
    "        es_applications = ['Climate\\nModels', 'Weather\\nPrediction', 'Carbon\\nCycle', 'Ecosystem\\nModeling']\n",
    "        es_importance = [100, 95, 85, 90]  # Importance scores\n",
    "        \n",
    "        bars = ax5.bar(es_applications, es_importance, color='purple', alpha=0.7)\n",
    "        ax5.set_ylabel('Application Importance')\n",
    "        ax5.set_title('Earth System Science Applications', fontweight='bold')\n",
    "        ax5.grid(True, alpha=0.3, axis='y')\n",
    "        ax5.set_ylim(0, 110)\n",
    "        \n",
    "        for bar, score in zip(bars, es_importance):\n",
    "            ax5.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 2,\n",
    "                    f'{score}%', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # Tutorial series culmination (bottom right)\n",
    "        ax6 = axes[2, 1]\n",
    "        \n",
    "        # Complete tutorial progression\n",
    "        tutorial_scales = ['Lumped\\n(02a)', 'Semi-Dist\\n(02b)', 'Elevation\\n(02c)', 'Regional\\n(03a)', 'Continental\\n(03b)']\n",
    "        scale_complexity = [1, 15, 45, 100, len(basins_for_viz)]\n",
    "        \n",
    "        bars = ax6.bar(tutorial_scales, scale_complexity, \n",
    "                       color=['lightcoral', 'lightgreen', 'lightblue', 'gold', 'mediumpurple'], \n",
    "                       alpha=0.7, edgecolor='navy')\n",
    "        \n",
    "        ax6.set_ylabel('Computational Units (log scale)')\n",
    "        ax6.set_yscale('log')\n",
    "        ax6.set_title('Tutorial Series: Complete Spatial Hierarchy', fontweight='bold')\n",
    "        ax6.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, complexity in zip(bars, scale_complexity):\n",
    "            ax6.text(bar.get_x() + bar.get_width()/2., bar.get_height() * 1.2,\n",
    "                    f'{complexity:,}', ha='center', va='bottom', fontsize=9, rotation=45)\n",
    "        \n",
    "        plt.suptitle(f'Continental-Scale Analysis: North America Earth System Assessment', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"âœ… Continental visualization framework complete\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"ðŸ“‹ Continental visualization framework established (requires basin data)\")\n",
    "else:\n",
    "    print(f\"ðŸ“‹ Continental visualization framework prepared for continental-scale datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ready to explore large sample simulations?** â†’ **[Tutorial 04a: Large Sample Studies - FLUXNET](./04a_large_sample_fluxnet.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
