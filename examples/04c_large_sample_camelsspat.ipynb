{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a5229d",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 10: CAMELS Large Sample Study (Multi-Basin Streamflow Analysis)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial represents the culmination of our CONFLUENCE large sample studies series: systematic streamflow modeling across hundreds of watersheds using the CAMELS spat dataset (Knoben et al., 2025). While our previous large sample tutorials focused on point-scale processes (FLUXNET energy fluxes, NorSWE snow dynamics), this tutorial demonstrates watershed-scale analysis of the most fundamental hydrological variable: streamflow. This represents the classic application of hydrological modeling and the ultimate test of CONFLUENCE's capabilities across diverse watersheds.\n",
    "\n",
    "### CAMELS Spat: The Gold Standard for Large Sample Hydrology\n",
    "\n",
    "The CAMELS Spat dataset was specifically designed to revolutionize hydrological science through large sample studies:\n",
    "\n",
    "**Comprehensive Coverage**:\n",
    "- **CAMELS-US**: 671 watersheds across the contiguous United States\n",
    "- **Global Extensions**: CAMELS-GB, CAMELS-BR, CAMELS-CL, CAMELS-AUS, CAMELS-FR\n",
    "- **Climate Diversity**: Arid to humid, tropical to continental, coastal to mountainous\n",
    "- **Scale Range**: 4 to 25,000 kmÂ² watersheds\n",
    "\n",
    "**Standardized Framework**:\n",
    "- **Meteorological Forcing**: Gridded precipitation and temperature data\n",
    "- **Streamflow Observations**: Quality-controlled daily discharge time series\n",
    "- **Catchment Attributes**: Topographic, geologic, soil, and vegetation characteristics\n",
    "- **Minimal Human Impact**: Focus on near-natural watersheds\n",
    "\n",
    "**Research Impact**:\n",
    "- **Benchmark Studies**: Standard dataset for model comparison\n",
    "- **Process Understanding**: Systematic analysis of hydrological controls\n",
    "- **Machine Learning**: Training data for data-driven approaches\n",
    "- **Climate Studies**: Assessment of climate change impacts on hydrology\n",
    "\n",
    "### Streamflow: The Integrative Hydrological Variable\n",
    "\n",
    "Streamflow represents the integrated response of all watershed processes:\n",
    "\n",
    "**Process Integration**:\n",
    "- **Precipitation Processing**: Interception, infiltration, and runoff generation\n",
    "- **Evapotranspiration**: Plant water use and soil moisture dynamics\n",
    "- **Groundwater Interactions**: Baseflow contributions and storage dynamics\n",
    "- **Routing Processes**: Travel time and channel hydraulics\n",
    "- **Snow Processes**: Seasonal storage and release in cold regions\n",
    "\n",
    "**Observational Advantages**:\n",
    "- **Direct Measurement**: Streamflow is directly observable at gauging stations\n",
    "- **Integrative Nature**: Represents the integrated watershed response\n",
    "- **Long Records**: Many sites have decades of continuous observations\n",
    "- **Management Relevance**: Direct connection to water resources applications\n",
    "\n",
    "### Scientific Importance of Multi-Basin Streamflow Analysis\n",
    "\n",
    "Large sample streamflow studies address fundamental questions in hydrology:\n",
    "\n",
    "**Hydrological Controls**:\n",
    "- **Climate vs. Landscape**: Relative importance of meteorological vs. physical controls\n",
    "- **Scale Dependencies**: How hydrological processes scale from hillslopes to watersheds\n",
    "- **Threshold Behaviors**: Nonlinear responses to climate and landscape characteristics\n",
    "- **Regional Patterns**: Systematic variations across physiographic regions\n",
    "\n",
    "**Model Evaluation**:\n",
    "- **Process Representation**: Which model components are most important?\n",
    "- **Parameter Transferability**: Can parameters be regionalized effectively?\n",
    "- **Uncertainty Quantification**: How does model uncertainty vary across environments?\n",
    "- **Structural Adequacy**: Are current model structures sufficient?\n",
    "\n",
    "### CAMELS vs. Previous Large Sample Studies\n",
    "\n",
    "This tutorial complements our previous large sample analyses:\n",
    "\n",
    "| Dataset | Scale | Focus | Validation | Complexity |\n",
    "|---------|-------|-------|------------|------------|\n",
    "| **FLUXNET** | Point | Energy/carbon fluxes | Flux measurements | Ecosystem interactions |\n",
    "| **NorSWE** | Point | Snow dynamics | State variables | Phase change physics |\n",
    "| **CAMELS** | Watershed | Streamflow | Discharge observations | Process integration |\n",
    "\n",
    "### Unique Challenges of Multi-Basin Streamflow Modeling\n",
    "\n",
    "Watershed-scale streamflow modeling presents distinct challenges:\n",
    "\n",
    "**Spatial Heterogeneity**:\n",
    "- **Landscape Diversity**: Elevation, slope, soil, and vegetation gradients\n",
    "- **Climate Variability**: Precipitation and temperature patterns within watersheds\n",
    "- **Geological Controls**: Subsurface heterogeneity and groundwater systems\n",
    "- **Scale Interactions**: Processes operating at different spatial scales\n",
    "\n",
    "**Temporal Dynamics**:\n",
    "- **Multiple Timescales**: Event response, seasonal cycles, and long-term trends\n",
    "- **Memory Effects**: Antecedent conditions and storage dynamics\n",
    "- **Extreme Events**: Floods, droughts, and their watershed-scale impacts\n",
    "- **Climate Variability**: Interannual and decadal variations\n",
    "\n",
    "### CONFLUENCE's Advantages for Multi-Basin Studies\n",
    "\n",
    "CONFLUENCE's design provides unique advantages for large sample streamflow analysis:\n",
    "\n",
    "**Consistent Methodology**:\n",
    "- **Standardized Workflow**: Same modeling approach across all watersheds\n",
    "- **Automated Processing**: Efficient setup and execution for hundreds of basins\n",
    "- **Reproducible Science**: Complete documentation of modeling decisions\n",
    "- **Quality Control**: Systematic evaluation of model performance\n",
    "\n",
    "**Physical Realism**:\n",
    "- **Process-Based Models**: Explicit representation of hydrological processes\n",
    "- **Flexible Structure**: Adaptable to different watershed characteristics\n",
    "- **Multi-Model Capability**: Compare different model structures\n",
    "- **Uncertainty Assessment**: Quantify parameter and structural uncertainty\n",
    "\n",
    "### Research Questions for Multi-Basin Analysis\n",
    "\n",
    "Large sample streamflow studies enable investigation of fundamental hydrological questions:\n",
    "\n",
    "1. **Process Controls**: What are the dominant controls on streamflow generation across different environments?\n",
    "2. **Model Performance**: How does model performance vary with climate, topography, and soil characteristics?\n",
    "3. **Parameter Patterns**: Are there systematic patterns in optimal parameter values across watersheds?\n",
    "4. **Prediction Capability**: Can models trained in one region predict streamflow in another?\n",
    "5. **Climate Sensitivity**: How sensitive is streamflow to climate variability and change?\n",
    "\n",
    "### Expected Outcomes\n",
    "\n",
    "This tutorial demonstrates several key capabilities for multi-basin streamflow analysis:\n",
    "\n",
    "1. **Watershed-Scale Configuration**: Adapt CONFLUENCE for diverse watershed characteristics\n",
    "2. **Streamflow Validation**: Compare simulated and observed hydrographs across sites\n",
    "3. **Performance Analysis**: Evaluate model performance using multiple metrics\n",
    "4. **Regional Patterns**: Identify systematic variations in model performance\n",
    "5. **Process Diagnostics**: Understand reasons for model success and failure\n",
    "\n",
    "### Methodological Framework\n",
    "\n",
    "Multi-basin streamflow studies require sophisticated analytical approaches:\n",
    "\n",
    "**Site Selection**:\n",
    "- **Climate Gradients**: Represent aridity, temperature, and seasonality gradients\n",
    "- **Physiographic Diversity**: Include different geological and topographic settings\n",
    "- **Scale Representation**: Cover the range of watershed sizes\n",
    "- **Data Quality**: Ensure reliable streamflow and meteorological data\n",
    "\n",
    "**Model Evaluation**:\n",
    "- **Multiple Metrics**: Nash-Sutcliffe efficiency, Kling-Gupta efficiency, bias\n",
    "- **Flow Components**: Evaluate high flows, low flows, and timing\n",
    "- **Seasonal Performance**: Assess model performance across different seasons\n",
    "- **Extreme Events**: Evaluate performance during floods and droughts\n",
    "\n",
    "### Tutorial Structure\n",
    "\n",
    "This tutorial follows the established large sample framework while emphasizing streamflow-specific aspects:\n",
    "\n",
    "1. **CAMELS Site Selection**: Choose representative watersheds across environmental gradients\n",
    "2. **Watershed Configuration**: Adapt CONFLUENCE for diverse basin characteristics\n",
    "3. **Streamflow-Focused Setup**: Configure for discharge validation and routing\n",
    "4. **Batch Processing**: Execute CONFLUENCE across multiple watersheds\n",
    "5. **Hydrograph Analysis**: Collect and analyze streamflow time series\n",
    "6. **Performance Assessment**: Evaluate model performance across sites\n",
    "7. **Regional Synthesis**: Identify patterns and controls on model performance\n",
    "\n",
    "### Scientific Impact\n",
    "\n",
    "Multi-basin streamflow studies contribute to advancing hydrological science:\n",
    "\n",
    "- **Process Understanding**: Identify universal vs. regional hydrological controls\n",
    "- **Model Development**: Improve model structure and parameterization\n",
    "- **Water Resources**: Enhance streamflow prediction for management applications\n",
    "- **Climate Applications**: Improve projections of streamflow under changing climate\n",
    "- **Ungauged Basins**: Develop approaches for prediction in ungauged watersheds\n",
    "\n",
    "### Tutorial Series Culmination\n",
    "\n",
    "This tutorial represents the ultimate demonstration of CONFLUENCE's capabilities:\n",
    "\n",
    "**Complete Skill Integration**:\n",
    "- **Point-scale understanding**: Foundation in individual processes\n",
    "- **Spatial scaling**: Watershed-scale process integration\n",
    "- **Large sample methods**: Systematic multi-site analysis\n",
    "- **Workflow automation**: Efficient processing of hundreds of sites\n",
    "\n",
    "**Hydrological Scope**:\n",
    "- **Process diversity**: Energy balance, snow dynamics, and streamflow\n",
    "- **Scale range**: Points to watersheds to continental domains\n",
    "- **Temporal coverage**: Event-scale to multi-decadal analysis\n",
    "- **Environmental gradients**: Complete range of hydroclimatic conditions\n",
    "\n",
    "**Methodological Sophistication**:\n",
    "- **Model complexity**: From simple to sophisticated process representations\n",
    "- **Uncertainty quantification**: Parameter and structural uncertainty assessment\n",
    "- **Comparative analysis**: Systematic evaluation across multiple sites\n",
    "- **Reproducible science**: Complete workflow documentation and automation\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "The skills developed in this tutorial have immediate practical applications:\n",
    "\n",
    "- **Water Resources Management**: Streamflow prediction for reservoir operations\n",
    "- **Flood Forecasting**: Improved understanding of extreme event generation\n",
    "- **Climate Change Assessment**: Quantifying future streamflow changes\n",
    "- **Ecological Applications**: Instream flow requirements and habitat assessment\n",
    "- **Policy Support**: Science-based water allocation and management decisions\n",
    "\n",
    "By completing this tutorial, you'll have mastered the complete spectrum of CONFLUENCE applications, from individual process understanding to large sample comparative analysis. This represents the cutting edge of hydrological science, where systematic multi-site analysis drives both theoretical advances and practical applications in water resources management.\n",
    "\n",
    "The combination of CONFLUENCE's workflow efficiency with CAMELS' comprehensive watershed database provides an unparalleled framework for advancing our understanding of how watersheds function across Earth's diverse hydroclimatic environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19e562-d16c-4257-909b-f6dbe7ff9483",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d212f-06e1-49b5-9441-ed14e9c1e99a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: LARGE SAMPLE MULTI-BASIN STREAMFLOW STUDY EXPERIMENTAL DESIGN\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Set up plotting style for watershed visualization\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=== CONFLUENCE Tutorial 04c: CAMELS-SPAT Large Sample Streamflow Study ===\")\n",
    "print(\"Watershed hydrology scaling: Single basins to systematic multi-basin streamflow analysis\")\n",
    "\n",
    "# =============================================================================\n",
    "# LARGE SAMPLE STREAMFLOW EXPERIMENTAL DESIGN CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nðï¸ Large Sample Streamflow Experimental Design Configuration...\")\n",
    "\n",
    "# Define the large sample streamflow experiment parameters\n",
    "streamflow_sample_config = {\n",
    "    # Experiment identification\n",
    "    'experiment_name': 'camelsspat_large_sample_tutorial',\n",
    "    'experiment_type': 'multi_basin_streamflow_validation',\n",
    "    'analysis_scale': 'continental_watershed_gradients',\n",
    "    \n",
    "    # Site selection criteria specific to streamflow hydrology\n",
    "    'max_watersheds': 15,  # Manageable number for tutorial demonstration\n",
    "    'site_selection_strategy': 'climate_scale_diversity',\n",
    "    'scales_to_include': ['meso', 'macro', 'headwater'],  # Multi-scale analysis\n",
    "    'min_data_years': 5,   # Minimum streamflow record length\n",
    "    'area_range': (10, 10000),  # Watershed area range (kmÂ²)\n",
    "    \n",
    "    # Data and processing configuration\n",
    "    'spatial_scheme': 'lumped',  # Use lumped basin representation\n",
    "    'camelsspat_base_path': '/home/x-deythorsson/data/camels-spat-upload/shapefiles',\n",
    "    'template_config': '../CONFLUENCE/0_config_files/config_Bow_lumped.yaml',\n",
    "    'config_output_dir': '../CONFLUENCE/0_config_files/camels_spat',\n",
    "    'camelsspat_script': './run_watersheds_camelsspat-3.py',\n",
    "    'metadata_csv': 'camels-spat-metadata.csv',\n",
    "    'base_data_path': '/anvil/scratch/x-deythorsson/CONFLUENCE_data/camels_spat',\n",
    "    \n",
    "    # Temporal configuration for streamflow analysis\n",
    "    'start_year': 2005,\n",
    "    'end_year': 2015,\n",
    "    'calibration_years': 5,  # Years for calibration period\n",
    "    'validation_years': 5,   # Years for validation period\n",
    "    \n",
    "    # Processing options\n",
    "    'batch_processing': True,\n",
    "    'parallel_execution': True,\n",
    "    'dry_run_mode': False,  # Set to True for testing without job submission\n",
    "    \n",
    "    # Streamflow-specific analysis objectives\n",
    "    'primary_variables': ['streamflow', 'baseflow', 'peak_flows', 'low_flows'],\n",
    "    'comparison_metrics': ['nse', 'kge', 'rmse', 'pbias', 'correlation'],\n",
    "    'flow_signatures': ['mean_flow', 'flow_variability', 'timing', 'duration_curves'],\n",
    "    'regional_analysis': ['climate_controls', 'landscape_controls', 'scale_effects']\n",
    "}\n",
    "\n",
    "print(f\"â Streamflow experimental design configured\")\n",
    "print(f\"   ðï¸ Experiment: {streamflow_sample_config['experiment_name']}\")\n",
    "print(f\"   ð Scale: {streamflow_sample_config['analysis_scale']}\")\n",
    "print(f\"   ð Strategy: {streamflow_sample_config['site_selection_strategy']}\")\n",
    "print(f\"   ð¯ Max watersheds: {streamflow_sample_config['max_watersheds']}\")\n",
    "print(f\"   ð Period: {streamflow_sample_config['start_year']}-{streamflow_sample_config['end_year']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE STREAMFLOW EXPERIMENT DIRECTORY STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð Creating Streamflow Experiment Directory Structure...\")\n",
    "\n",
    "# Create main experiment directory\n",
    "experiment_dir = Path(f\"./experiments/{streamflow_sample_config['experiment_name']}\")\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create subdirectories for streamflow analysis organization\n",
    "subdirs = {\n",
    "    'configs': 'Generated CONFLUENCE configuration files for watersheds',\n",
    "    'logs': 'Streamflow modeling execution logs and monitoring',\n",
    "    'results': 'Aggregated streamflow validation results and analysis outputs',\n",
    "    'plots': 'Streamflow visualization outputs and performance maps',\n",
    "    'reports': 'Multi-basin streamflow validation summary reports',\n",
    "    'watershed_data': 'Processed CAMELS-SPAT watershed metadata and characteristics'\n",
    "}\n",
    "\n",
    "for subdir, description in subdirs.items():\n",
    "    (experiment_dir / subdir).mkdir(exist_ok=True)\n",
    "    print(f\"   ð {subdir}/: {description}\")\n",
    "\n",
    "# Save experiment configuration\n",
    "config_file = experiment_dir / 'streamflow_experiment_config.yaml'\n",
    "with open(config_file, 'w') as f:\n",
    "    yaml.dump(streamflow_sample_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"â Streamflow experiment directory structure created: {experiment_dir}\")\n",
    "print(f\"   ð Configuration saved: {config_file}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXPLORE CAMELS-SPAT MULTI-SCALE DATASET STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð Exploring CAMELS-SPAT Multi-Scale Dataset Structure...\")\n",
    "\n",
    "# Check CAMELS-SPAT data availability across scales\n",
    "scales_info = {}\n",
    "spatial_scheme = streamflow_sample_config['spatial_scheme']\n",
    "\n",
    "for scale in streamflow_sample_config['scales_to_include']:\n",
    "    scale_path = Path(streamflow_sample_config['camelsspat_base_path']) / f\"{scale}-scale\" / f\"shapes-{spatial_scheme}\"\n",
    "    \n",
    "    if scale_path.exists():\n",
    "        # Count watersheds in this scale\n",
    "        watershed_dirs = [d for d in scale_path.iterdir() if d.is_dir()]\n",
    "        scales_info[scale] = {\n",
    "            'path': scale_path,\n",
    "            'num_watersheds': len(watershed_dirs),\n",
    "            'available': True\n",
    "        }\n",
    "        print(f\"   ðï¸ {scale.capitalize()} scale: {len(watershed_dirs)} watersheds available\")\n",
    "        print(f\"      Path: {scale_path}\")\n",
    "    else:\n",
    "        scales_info[scale] = {\n",
    "            'path': scale_path,\n",
    "            'num_watersheds': 0,\n",
    "            'available': False\n",
    "        }\n",
    "        print(f\"   â {scale.capitalize()} scale: Path not found - {scale_path}\")\n",
    "\n",
    "# Check for metadata file\n",
    "metadata_path = Path(streamflow_sample_config['metadata_csv'])\n",
    "if metadata_path.exists():\n",
    "    print(f\"\\nð CAMELS-SPAT Metadata File Found: {metadata_path}\")\n",
    "    try:\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        metadata_df.columns = [col.strip() for col in metadata_df.columns]\n",
    "        \n",
    "        print(f\"   â Loaded metadata: {len(metadata_df)} watersheds\")\n",
    "        print(f\"   ð Key metadata columns:\")\n",
    "        for i, col in enumerate(metadata_df.columns[:10]):  # Show first 10 columns\n",
    "            print(f\"      {i+1:2d}. {col}\")\n",
    "        if len(metadata_df.columns) > 10:\n",
    "            print(f\"      ... and {len(metadata_df.columns) - 10} more columns\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   â Error loading metadata: {e}\")\n",
    "        metadata_df = None\n",
    "else:\n",
    "    print(f\"\\nâ ï¸ CAMELS-SPAT metadata file not found: {metadata_path}\")\n",
    "    metadata_df = None\n",
    "\n",
    "# =============================================================================\n",
    "# EXTRACT WATERSHED INFORMATION FROM MULTI-SCALE SHAPEFILES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð Extracting Watershed Information from Multi-Scale Shapefiles...\")\n",
    "\n",
    "# Import the shapefile extraction function\n",
    "sys.path.append(str(Path(streamflow_sample_config['camelsspat_script']).parent))\n",
    "\n",
    "try:\n",
    "    from run_watersheds_camelsspat import extract_shapefile_info\n",
    "    \n",
    "    # Extract information from all available scales\n",
    "    all_watersheds = []\n",
    "    \n",
    "    for scale, scale_info in scales_info.items():\n",
    "        if scale_info['available']:\n",
    "            print(f\"   ð Processing {scale} scale watersheds...\")\n",
    "            \n",
    "            try:\n",
    "                scale_watersheds = extract_shapefile_info(str(scale_info['path']), scale)\n",
    "                print(f\"      â Extracted {len(scale_watersheds)} {scale} watersheds\")\n",
    "                all_watersheds.append(scale_watersheds)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      â Error extracting {scale} watersheds: {e}\")\n",
    "    \n",
    "    # Combine all scales\n",
    "    if all_watersheds:\n",
    "        watersheds_df = pd.concat(all_watersheds, ignore_index=True)\n",
    "        print(f\"\\nâ Combined watershed data: {len(watersheds_df)} total watersheds\")\n",
    "        \n",
    "        # Display scale distribution\n",
    "        if 'Scale' in watersheds_df.columns:\n",
    "            scale_counts = watersheds_df['Scale'].value_counts()\n",
    "            print(f\"   ð Watershed distribution by scale:\")\n",
    "            for scale, count in scale_counts.items():\n",
    "                print(f\"      {scale.capitalize()}: {count} watersheds\")\n",
    "    else:\n",
    "        print(f\"\\nâ No watershed data extracted from any scale\")\n",
    "        watersheds_df = pd.DataFrame()\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"   â Could not import extraction function: {e}\")\n",
    "    print(f\"   Creating demonstration dataset...\")\n",
    "    \n",
    "    # Create demonstration data\n",
    "    demo_watersheds = []\n",
    "    for i, scale in enumerate(['meso', 'macro', 'headwater']):\n",
    "        for j in range(5):  # 5 watersheds per scale for demo\n",
    "            demo_watersheds.append({\n",
    "                'ID': f'DEMO_{scale.upper()}_{j+1:03d}',\n",
    "                'Scale': scale,\n",
    "                'Area_km2': np.random.uniform(50, 2000),\n",
    "                'Lat': np.random.uniform(35, 50),\n",
    "                'Lon': np.random.uniform(-120, -80),\n",
    "                'Basin_File': f'demo_{scale}_{j+1}.shp',\n",
    "                'Available_Columns': \"['OBJECTID', 'geometry']\"\n",
    "            })\n",
    "    \n",
    "    watersheds_df = pd.DataFrame(demo_watersheds)\n",
    "    print(f\"   ð Created demonstration dataset: {len(watersheds_df)} watersheds\")\n",
    "\n",
    "# =============================================================================\n",
    "# MERGE WITH CAMELS-SPAT METADATA\n",
    "# =============================================================================\n",
    "\n",
    "if metadata_df is not None and len(watersheds_df) > 0:\n",
    "    print(f\"\\nð Merging Shapefile Data with CAMELS-SPAT Metadata...\")\n",
    "    \n",
    "    try:\n",
    "        # Create standardized ID for merging\n",
    "        watersheds_df['Metadata_ID'] = watersheds_df['ID'].str.replace(r'^[A-Z]+_', '', regex=True)\n",
    "        \n",
    "        # Handle scale suffixes\n",
    "        scale_suffixes = ['_meso', '_macro', '_headwater']\n",
    "        for suffix in scale_suffixes:\n",
    "            watersheds_df['Metadata_ID'] = watersheds_df['Metadata_ID'].str.replace(suffix, '', regex=False)\n",
    "        \n",
    "        print(f\"   ð Merging on standardized IDs...\")\n",
    "        print(f\"      Shapefile records: {len(watersheds_df)}\")\n",
    "        print(f\"      Metadata records: {len(metadata_df)}\")\n",
    "        \n",
    "        # Merge datasets\n",
    "        merged_watersheds = pd.merge(\n",
    "            watersheds_df, \n",
    "            metadata_df, \n",
    "            left_on='Metadata_ID',\n",
    "            right_on='Station_id',\n",
    "            how='left',\n",
    "            suffixes=('', '_metadata')\n",
    "        )\n",
    "        \n",
    "        # Count successful merges\n",
    "        successful_merges = merged_watersheds['Station_id'].notna().sum()\n",
    "        print(f\"      Successful merges: {successful_merges}/{len(watersheds_df)}\")\n",
    "        \n",
    "        # Add metadata-derived columns\n",
    "        if 'Station_name' in merged_watersheds.columns:\n",
    "            merged_watersheds['Watershed_Name'] = merged_watersheds['Station_name']\n",
    "        \n",
    "        if 'Station_lat' in merged_watersheds.columns and 'Station_lon' in merged_watersheds.columns:\n",
    "            merged_watersheds['POUR_POINT_COORDS'] = (\n",
    "                merged_watersheds['Station_lat'].astype(str) + '/' + \n",
    "                merged_watersheds['Station_lon'].astype(str)\n",
    "            )\n",
    "        \n",
    "        watersheds_df = merged_watersheds\n",
    "        print(f\"   â Metadata merge complete\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   â Error merging metadata: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "# =============================================================================\n",
    "# STREAMFLOW-SPECIFIC ENVIRONMENTAL GRADIENT ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð Streamflow-Specific Environmental Gradient Analysis...\")\n",
    "\n",
    "# Analyze environmental diversity for streamflow modeling\n",
    "streamflow_environmental_summary = {}\n",
    "\n",
    "# Watershed area distribution analysis (critical for streamflow)\n",
    "if 'Area_km2' in watersheds_df.columns:\n",
    "    area_stats = watersheds_df['Area_km2'].describe()\n",
    "    streamflow_environmental_summary['area_range'] = (area_stats['min'], area_stats['max'])\n",
    "    print(f\"   ðï¸ Watershed area diversity: {area_stats['min']:.1f} to {area_stats['max']:.1f} kmÂ²\")\n",
    "    print(f\"      Mean area: {area_stats['mean']:.1f} kmÂ²\")\n",
    "    print(f\"      Area quartiles: Q1={area_stats['25%']:.1f}, Q3={area_stats['75%']:.1f} kmÂ²\")\n",
    "\n",
    "# Geographic distribution (streamflow climate controls)\n",
    "if 'Lat' in watersheds_df.columns and 'Lon' in watersheds_df.columns:\n",
    "    lat_stats = watersheds_df['Lat'].describe()\n",
    "    lon_stats = watersheds_df['Lon'].describe()\n",
    "    streamflow_environmental_summary['lat_range'] = (lat_stats['min'], lat_stats['max'])\n",
    "    streamflow_environmental_summary['lon_range'] = (lon_stats['min'], lon_stats['max'])\n",
    "    print(f\"   ð Latitude range: {lat_stats['min']:.1f}Â° to {lat_stats['max']:.1f}Â°N\")\n",
    "    print(f\"   ð Longitude range: {lon_stats['min']:.1f}Â° to {lon_stats['max']:.1f}Â°W\")\n",
    "\n",
    "# Scale distribution analysis (multi-scale streamflow modeling)\n",
    "if 'Scale' in watersheds_df.columns:\n",
    "    scale_counts = watersheds_df['Scale'].value_counts()\n",
    "    streamflow_environmental_summary['scale_diversity'] = len(scale_counts)\n",
    "    print(f\"   ð Scale diversity: {len(scale_counts)} different watershed scales\")\n",
    "    for scale, count in scale_counts.items():\n",
    "        print(f\"      {scale.capitalize()}: {count} watersheds\")\n",
    "\n",
    "# Climate characteristics if available in metadata\n",
    "climate_vars = ['MAP', 'MAT', 'Aridity', 'Seasonality']\n",
    "available_climate = [var for var in climate_vars if var in watersheds_df.columns]\n",
    "\n",
    "if available_climate:\n",
    "    print(f\"   ð¡ï¸ Available climate characteristics: {', '.join(available_climate)}\")\n",
    "    for var in available_climate:\n",
    "        var_stats = watersheds_df[var].describe()\n",
    "        print(f\"      {var}: {var_stats['min']:.2f} to {var_stats['max']:.2f} (mean: {var_stats['mean']:.2f})\")\n",
    "\n",
    "# Landscape characteristics if available\n",
    "landscape_vars = ['Elevation', 'Slope', 'Forest_frac', 'Soil_depth']\n",
    "available_landscape = [var for var in landscape_vars if var in watersheds_df.columns]\n",
    "\n",
    "if available_landscape:\n",
    "    print(f\"   ðï¸ Available landscape characteristics: {', '.join(available_landscape)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STRATEGIC WATERSHED SITE SELECTION FOR STREAMFLOW ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð¯ Strategic Watershed Site Selection for Large Sample Streamflow Analysis...\")\n",
    "\n",
    "# Implement streamflow-specific site selection strategy\n",
    "selection_strategy = streamflow_sample_config['site_selection_strategy']\n",
    "max_watersheds = streamflow_sample_config['max_watersheds']\n",
    "min_data_years = streamflow_sample_config['min_data_years']\n",
    "area_range = streamflow_sample_config['area_range']\n",
    "\n",
    "print(f\"   Strategy: {selection_strategy}\")\n",
    "print(f\"   Target watersheds: {max_watersheds}\")\n",
    "print(f\"   Area range: {area_range[0]}-{area_range[1]} kmÂ²\")\n",
    "print(f\"   Minimum data years: {min_data_years}\")\n",
    "\n",
    "# Apply quality and criteria filters\n",
    "if len(watersheds_df) > 0:\n",
    "    quality_filtered = watersheds_df.copy()\n",
    "    \n",
    "    # Apply area filter\n",
    "    if 'Area_km2' in quality_filtered.columns:\n",
    "        area_mask = ((quality_filtered['Area_km2'] >= area_range[0]) & \n",
    "                    (quality_filtered['Area_km2'] <= area_range[1]))\n",
    "        quality_filtered = quality_filtered[area_mask]\n",
    "        print(f\"   ð Area filtering: {len(quality_filtered)}/{len(watersheds_df)} watersheds remain\")\n",
    "    \n",
    "    # Apply data quality filter (if metadata available)\n",
    "    if 'Streamflow_years' in quality_filtered.columns:\n",
    "        data_mask = quality_filtered['Streamflow_years'] >= min_data_years\n",
    "        quality_filtered = quality_filtered[data_mask]\n",
    "        print(f\"   ð Data quality filtering: {len(quality_filtered)} watersheds with â¥{min_data_years} years\")\n",
    "    \n",
    "    # Apply geographic filter (focus on contiguous regions)\n",
    "    if 'Lat' in quality_filtered.columns:\n",
    "        # Remove outliers for focused analysis\n",
    "        lat_q1 = quality_filtered['Lat'].quantile(0.1)\n",
    "        lat_q9 = quality_filtered['Lat'].quantile(0.9)\n",
    "        geo_mask = ((quality_filtered['Lat'] >= lat_q1) & \n",
    "                   (quality_filtered['Lat'] <= lat_q9))\n",
    "        quality_filtered = quality_filtered[geo_mask]\n",
    "        print(f\"   ðºï¸ Geographic filtering: {len(quality_filtered)} watersheds in core region\")\n",
    "\n",
    "else:\n",
    "    quality_filtered = pd.DataFrame()\n",
    "    print(f\"   â ï¸ No watershed data available for filtering\")\n",
    "\n",
    "# Implement selection strategy\n",
    "if len(quality_filtered) > 0:\n",
    "    if selection_strategy == 'climate_scale_diversity':\n",
    "        # Strategy: Maximize climate and scale diversity for streamflow modeling\n",
    "        selected_sites = []\n",
    "        \n",
    "        # If we have scale information, sample across scales\n",
    "        if 'Scale' in quality_filtered.columns:\n",
    "            available_scales = quality_filtered['Scale'].unique()\n",
    "            sites_per_scale = max(1, max_watersheds // len(available_scales))\n",
    "            \n",
    "            print(f\"   ðï¸ Multi-scale sampling strategy:\")\n",
    "            print(f\"      Available scales: {', '.join(available_scales)}\")\n",
    "            print(f\"      Target sites per scale: ~{sites_per_scale}\")\n",
    "            \n",
    "            for scale in available_scales:\n",
    "                scale_watersheds = quality_filtered[quality_filtered['Scale'] == scale]\n",
    "                \n",
    "                if len(scale_watersheds) > 0:\n",
    "                    # Prioritize by area diversity within scale\n",
    "                    if 'Area_km2' in scale_watersheds.columns:\n",
    "                        scale_watersheds = scale_watersheds.sort_values('Area_km2')\n",
    "                    \n",
    "                    # Sample up to sites_per_scale from this scale\n",
    "                    n_sample = min(sites_per_scale, len(scale_watersheds))\n",
    "                    \n",
    "                    # Systematic sampling for diversity\n",
    "                    if n_sample < len(scale_watersheds):\n",
    "                        step = len(scale_watersheds) // n_sample\n",
    "                        indices = range(0, len(scale_watersheds), step)[:n_sample]\n",
    "                        sampled = scale_watersheds.iloc[indices]\n",
    "                    else:\n",
    "                        sampled = scale_watersheds\n",
    "                    \n",
    "                    selected_sites.extend(sampled.index.tolist())\n",
    "                    print(f\"      {scale.capitalize()}: {len(sampled)}/{len(scale_watersheds)} watersheds selected\")\n",
    "                    \n",
    "                    if len(selected_sites) >= max_watersheds:\n",
    "                        break\n",
    "        else:\n",
    "            # No scale information - use area-based selection\n",
    "            if 'Area_km2' in quality_filtered.columns:\n",
    "                # Sort by area and select diverse sizes\n",
    "                quality_filtered = quality_filtered.sort_values('Area_km2')\n",
    "                step = len(quality_filtered) // max_watersheds\n",
    "                indices = range(0, len(quality_filtered), step)[:max_watersheds]\n",
    "                selected_sites = quality_filtered.iloc[indices].index.tolist()\n",
    "            else:\n",
    "                # Random selection as fallback\n",
    "                selected_sites = quality_filtered.sample(n=min(max_watersheds, len(quality_filtered)), \n",
    "                                                        random_state=42).index.tolist()\n",
    "        \n",
    "        # Trim to exact number if over\n",
    "        if len(selected_sites) > max_watersheds:\n",
    "            selected_sites = selected_sites[:max_watersheds]\n",
    "        \n",
    "        selected_df = quality_filtered.loc[selected_sites].copy()\n",
    "\n",
    "    else:\n",
    "        # Default: use highest quality sites\n",
    "        if 'Area_km2' in quality_filtered.columns:\n",
    "            selected_df = quality_filtered.sort_values('Area_km2', ascending=False).head(max_watersheds).copy()\n",
    "        else:\n",
    "            selected_df = quality_filtered.head(max_watersheds).copy()\n",
    "\n",
    "    print(f\"â Watershed site selection complete: {len(selected_df)} watersheds selected\")\n",
    "\n",
    "else:\n",
    "    print(f\"â No watersheds available after quality filtering\")\n",
    "    selected_df = pd.DataFrame()\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATE STREAMFLOW MODELING TEMPLATE CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð Validating Streamflow Modeling Template Configuration...\")\n",
    "\n",
    "template_path = Path(streamflow_sample_config['template_config'])\n",
    "\n",
    "if template_path.exists():\n",
    "    print(f\"â Streamflow template configuration found: {template_path}\")\n",
    "    \n",
    "    # Load and verify template structure\n",
    "    try:\n",
    "        with open(template_path, 'r') as f:\n",
    "            template_config = yaml.safe_load(f)\n",
    "        \n",
    "        # Check key template parameters for streamflow modeling\n",
    "        required_keys = ['DOMAIN_NAME', 'POUR_POINT_COORDS', 'BOUNDING_BOX_COORDS', \n",
    "                        'HYDROLOGICAL_MODEL', 'EXPERIMENT_TIME_START', 'EXPERIMENT_TIME_END']\n",
    "        \n",
    "        missing_keys = [key for key in required_keys if key not in template_config]\n",
    "        \n",
    "        if not missing_keys:\n",
    "            print(f\"â Streamflow template validation successful\")\n",
    "            print(f\"   ð Template contains all required parameters for streamflow modeling\")\n",
    "            \n",
    "            # Check streamflow-specific settings if available\n",
    "            if 'HYDROLOGICAL_MODEL' in template_config:\n",
    "                model = template_config['HYDROLOGICAL_MODEL']\n",
    "                print(f\"   ð Hydrological model: {model}\")\n",
    "                \n",
    "                if model.upper() == 'SUMMA':\n",
    "                    print(f\"      â SUMMA selected - excellent for process-based streamflow modeling\")\n",
    "                    print(f\"      ðï¸ SUMMA capabilities: Distributed hydrology, routing, multi-physics options\")\n",
    "            \n",
    "            # Check for routing configuration\n",
    "            routing_vars = ['ROUTING_MODEL', 'mizuRoute', 'ROUTING_TIMESTEP']\n",
    "            routing_found = [var for var in routing_vars if var in template_config]\n",
    "            if routing_found:\n",
    "                print(f\"   ð Routing configuration found: {', '.join(routing_found)}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"â ï¸  Streamflow template missing required keys: {missing_keys}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"â Streamflow template validation failed: {e}\")\n",
    "else:\n",
    "    print(f\"â Streamflow template configuration not found: {template_path}\")\n",
    "    print(f\"   Please ensure the streamflow modeling template file exists\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPREHENSIVE STREAMFLOW SITE SELECTION VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð Creating Comprehensive Streamflow Site Selection Visualization...\")\n",
    "\n",
    "if len(selected_df) > 0:\n",
    "    # Create comprehensive streamflow site selection visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    # Map 1: Geographic distribution with area coloring (top left)\n",
    "    ax1 = axes[0, 0]\n",
    "    if len(watersheds_df) > 0:\n",
    "        ax1.scatter(watersheds_df['Lon'], watersheds_df['Lat'], \n",
    "                   c='lightgray', alpha=0.3, s=15, label='Available watersheds')\n",
    "    \n",
    "    if 'Area_km2' in selected_df.columns:\n",
    "        scatter1 = ax1.scatter(selected_df['Lon'], selected_df['Lat'], \n",
    "                              c=selected_df['Area_km2'], cmap='viridis', s=80, \n",
    "                              edgecolors='black', linewidth=0.5, label='Selected watersheds')\n",
    "        \n",
    "        # Add colorbar for area\n",
    "        cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "        cbar1.set_label('Watershed Area (kmÂ²)')\n",
    "    else:\n",
    "        ax1.scatter(selected_df['Lon'], selected_df['Lat'], \n",
    "                   c='red', s=80, edgecolors='black', linewidth=0.5, label='Selected watersheds')\n",
    "    \n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.set_title(f'Streamflow Site Selection: Geographic Distribution\\\\n{len(selected_df)} of {len(watersheds_df)} watersheds')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Map 2: Area distribution by scale (top middle)\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'Scale' in selected_df.columns and 'Area_km2' in selected_df.columns:\n",
    "        scales = selected_df['Scale'].unique()\n",
    "        colors = plt.cm.Set3.colors[:len(scales)]\n",
    "        \n",
    "        for i, scale in enumerate(scales):\n",
    "            scale_data = selected_df[selected_df['Scale'] == scale]\n",
    "            ax2.scatter(scale_data['Area_km2'], [i] * len(scale_data), \n",
    "                       c=[colors[i]], s=60, alpha=0.7, label=scale.capitalize(),\n",
    "                       edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        ax2.set_xlabel('Watershed Area (kmÂ²)')\n",
    "        ax2.set_ylabel('Scale')\n",
    "        ax2.set_yticks(range(len(scales)))\n",
    "        ax2.set_yticklabels([s.capitalize() for s in scales])\n",
    "        ax2.set_title('Area Distribution by Scale')\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Scale/Area data\\nnot available', \n",
    "                ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Area Distribution by Scale')\n",
    "    \n",
    "    # Map 3: Climate characteristics if available (top right)\n",
    "    ax3 = axes[0, 2]\n",
    "    climate_vars = ['MAP', 'MAT', 'Aridity'] if 'MAP' in selected_df.columns else None\n",
    "    \n",
    "    if climate_vars and all(var in selected_df.columns for var in climate_vars[:2]):\n",
    "        scatter3 = ax3.scatter(selected_df['MAP'], selected_df['MAT'], \n",
    "                              c=selected_df.get('Aridity', 'blue'), \n",
    "                              cmap='RdYlBu', s=80, alpha=0.7,\n",
    "                              edgecolors='black', linewidth=0.5)\n",
    "        ax3.set_xlabel('Mean Annual Precipitation (mm)')\n",
    "        ax3.set_ylabel('Mean Annual Temperature (Â°C)')\n",
    "        ax3.set_title('Climate Space Coverage')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        if 'Aridity' in selected_df.columns:\n",
    "            cbar3 = plt.colorbar(scatter3, ax=ax3)\n",
    "            cbar3.set_label('Aridity Index')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'Climate data\\nnot available', \n",
    "                ha='center', va='center', transform=ax3.transAxes)\n",
    "        ax3.set_title('Climate Space Coverage')\n",
    "    \n",
    "    # Map 4: Scale distribution (bottom left)\n",
    "    ax4 = axes[1, 0]\n",
    "    if 'Scale' in selected_df.columns:\n",
    "        scale_counts = selected_df['Scale'].value_counts()\n",
    "        bars = ax4.bar(scale_counts.index, scale_counts.values, \n",
    "                      color=['skyblue', 'lightgreen', 'orange'][:len(scale_counts)], \n",
    "                      alpha=0.7, edgecolor='black')\n",
    "        ax4.set_xlabel('Watershed Scale')\n",
    "        ax4.set_ylabel('Number of Watersheds')\n",
    "        ax4.set_title('Selected Watersheds by Scale')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars, scale_counts.values):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.1,\n",
    "                    str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'Scale data\\nnot available', \n",
    "                ha='center', va='center', transform=ax4.transAxes)\n",
    "        ax4.set_title('Selected Watersheds by Scale')\n",
    "    \n",
    "    # Map 5: Area histogram (bottom middle)\n",
    "    ax5 = axes[1, 1]\n",
    "    if 'Area_km2' in selected_df.columns:\n",
    "        ax5.hist(selected_df['Area_km2'], bins=10, color='lightcoral', \n",
    "                alpha=0.7, edgecolor='black')\n",
    "        ax5.set_xlabel('Watershed Area (kmÂ²)')\n",
    "        ax5.set_ylabel('Number of Watersheds')\n",
    "        ax5.set_title('Area Distribution (Selected Sites)')\n",
    "        ax5.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add statistics\n",
    "        area_stats = selected_df['Area_km2'].describe()\n",
    "        stats_text = f\"Mean: {area_stats['mean']:.0f} kmÂ²\\nMedian: {area_stats['50%']:.0f} kmÂ²\"\n",
    "        ax5.text(0.98, 0.98, stats_text, transform=ax5.transAxes,\n",
    "                bbox=dict(facecolor='white', alpha=0.8), fontsize=9,\n",
    "                ha='right', va='top')\n",
    "    \n",
    "    # Map 6: Selection summary statistics (bottom right)\n",
    "    ax6 = axes[1, 2]\n",
    "    \n",
    "    # Create summary statistics\n",
    "    total_available = len(watersheds_df) if len(watersheds_df) > 0 else 0\n",
    "    total_selected = len(selected_df)\n",
    "    \n",
    "    # Count by various criteria\n",
    "    criteria_stats = [\n",
    "        ('Total Available', total_available),\n",
    "        ('Selected', total_selected),\n",
    "        ('Multi-Scale Sites', len(selected_df['Scale'].unique()) if 'Scale' in selected_df.columns else 0),\n",
    "        ('Large Basins\\n(>1000 kmÂ²)', len(selected_df[selected_df['Area_km2'] > 1000]) if 'Area_km2' in selected_df.columns else 0),\n",
    "        ('Small Basins\\n(<500 kmÂ²)', len(selected_df[selected_df['Area_km2'] < 500]) if 'Area_km2' in selected_df.columns else 0)\n",
    "    ]\n",
    "    \n",
    "    categories = [stat[0] for stat in criteria_stats]\n",
    "    counts = [stat[1] for stat in criteria_stats]\n",
    "    colors = ['lightblue', 'green', 'orange', 'purple', 'pink']\n",
    "    \n",
    "    bars = ax6.bar(categories, counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.1,\n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax6.set_ylabel('Number of Watersheds')\n",
    "    ax6.set_title('Streamflow Site Selection Summary')\n",
    "    ax6.tick_params(axis='x', rotation=45)\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle(f'CAMELS-SPAT Large Sample Streamflow Study - Site Selection Analysis\\\\n{streamflow_sample_config[\"experiment_name\"]}', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save visualization\n",
    "    selection_plot_path = experiment_dir / 'plots' / 'streamflow_site_selection_overview.png'\n",
    "    plt.savefig(selection_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"â Streamflow site selection visualization saved: {selection_plot_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"â ï¸ No watersheds selected - skipping visualization\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE SELECTED WATERSHEDS FOR PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nð¾ Saving Selected Watersheds for Large Sample Processing...\")\n",
    "\n",
    "if len(selected_df) > 0:\n",
    "    # Save selected sites to CSV\n",
    "    selected_sites_csv = experiment_dir / 'selected_streamflow_watersheds.csv'\n",
    "    selected_df.to_csv(selected_sites_csv, index=False)\n",
    "    \n",
    "    print(f\"â Selected streamflow watersheds saved: {selected_sites_csv}\")\n",
    "    print(f\"   ð Watersheds ready for processing: {len(selected_df)}\")\n",
    "    \n",
    "    # Create comprehensive summary report\n",
    "    summary_report = experiment_dir / 'reports' / 'streamflow_site_selection_summary.txt'\n",
    "    \n",
    "    with open(summary_report, 'w') as f:\n",
    "        f.write(\"CAMELS-SPAT Large Sample Streamflow Study - Site Selection Summary\\n\")\n",
    "        f.write(\"=\" * 65 + \"\\n\\n\")\n",
    "        f.write(f\"Experiment: {streamflow_sample_config['experiment_name']}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Selection Strategy: {streamflow_sample_config['site_selection_strategy']}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"WATERSHED SELECTION RESULTS:\\n\")\n",
    "        f.write(f\"  Available watersheds: {len(watersheds_df) if len(watersheds_df) > 0 else 0}\\n\")\n",
    "        f.write(f\"  Selected watersheds: {len(selected_df)}\\n\")\n",
    "        f.write(f\"  Selection ratio: {len(selected_df)/(len(watersheds_df) if len(watersheds_df) > 0 else 1)*100:.1f}%\\n\\n\")\n",
    "        \n",
    "        if 'Scale' in selected_df.columns:\n",
    "            f.write(f\"MULTI-SCALE REPRESENTATION:\\n\")\n",
    "            scale_counts = selected_df['Scale'].value_counts()\n",
    "            for scale, count in scale_counts.items():\n",
    "                f.write(f\"  {scale.capitalize()} scale: {count} watersheds\\n\")\n",
    "            f.write(f\"\\n\")\n",
    "        \n",
    "        if 'Area_km2' in selected_df.columns:\n",
    "            f.write(f\"WATERSHED SIZE CHARACTERISTICS:\\n\")\n",
    "            area_stats = selected_df['Area_km2'].describe()\n",
    "            f.write(f\"  Area range: {area_stats['min']:.1f} to {area_stats['max']:.1f} kmÂ²\\n\")\n",
    "            f.write(f\"  Mean area: {area_stats['mean']:.1f} kmÂ²\\n\")\n",
    "            f.write(f\"  Median area: {area_stats['50%']:.1f} kmÂ²\\n\")\n",
    "            f.write(f\"  Large watersheds (>1000 kmÂ²): {len(selected_df[selected_df['Area_km2'] > 1000])}\\n\")\n",
    "            f.write(f\"  Small watersheds (<500 kmÂ²): {len(selected_df[selected_df['Area_km2'] < 500])}\\n\\n\")\n",
    "        \n",
    "        if 'Lat' in selected_df.columns and 'Lon' in selected_df.columns:\n",
    "            f.write(f\"GEOGRAPHIC COVERAGE:\\n\")\n",
    "            f.write(f\"  Latitude range: {selected_df['Lat'].min():.1f}Â° to {selected_df['Lat'].max():.1f}Â°N\\n\")\n",
    "            f.write(f\"  Longitude range: {selected_df['Lon'].min():.1f}Â° to {selected_df['Lon'].max():.1f}Â°W\\n\\n\")\n",
    "        \n",
    "        f.write(f\"ANALYSIS CONFIGURATION:\\n\")\n",
    "        f.write(f\"  Temporal period: {streamflow_sample_config['start_year']}-{streamflow_sample_config['end_year']}\\n\")\n",
    "        f.write(f\"  Spatial scheme: {streamflow_sample_config['spatial_scheme']}\\n\")\n",
    "        f.write(f\"  Target variables: {', '.join(streamflow_sample_config['primary_variables'])}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Note: This selection prioritizes climate and scale diversity for comprehensive streamflow process validation.\\n\")\n",
    "    \n",
    "    print(f\"â Summary report saved: {summary_report}\")\n",
    "\n",
    "else:\n",
    "    print(f\"â ï¸ No watersheds selected - cannot save selection results\")\n",
    "\n",
    "# =============================================================================\n",
    "# STORE RESULTS FOR SUBSEQUENT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "# Store key variables for use in subsequent notebook cells\n",
    "if len(selected_df) > 0:\n",
    "    selected_watersheds = selected_df.copy()\n",
    "    streamflow_config = streamflow_sample_config.copy()\n",
    "    \n",
    "    print(f\"\\nð¯ Large Sample Streamflow Study Configuration Summary:\")\n",
    "    \n",
    "    configuration_summary = [\n",
    "        f\"Experimental design: {streamflow_sample_config['experiment_type']}\",\n",
    "        f\"Analysis scale: {streamflow_sample_config['analysis_scale']}\",\n",
    "        f\"Watershed selection: {len(selected_df)} watersheds from {len(watersheds_df) if len(watersheds_df) > 0 else 0} available\",\n",
    "        f\"Scale diversity: {', '.join(selected_df['Scale'].unique()) if 'Scale' in selected_df.columns else 'Mixed scales'}\",\n",
    "        f\"Size range: {selected_df['Area_km2'].min():.0f} to {selected_df['Area_km2'].max():.0f} kmÂ²\" if 'Area_km2' in selected_df.columns else \"Area data unavailable\",\n",
    "        f\"Template configuration: Validated and ready for streamflow modeling\"\n",
    "    ]\n",
    "    \n",
    "    for summary in configuration_summary:\n",
    "        print(f\"   â {summary}\")\n",
    "    \n",
    "    print(f\"\\nð Streamflow Science Objectives:\")\n",
    "    streamflow_objectives = [\n",
    "        f\"Multi-basin validation: Streamflow comparison across diverse watershed characteristics\",\n",
    "        f\"Scale effects: Systematic assessment of hydrological processes across watershed scales\",\n",
    "        f\"Regional patterns: Climate and landscape controls on streamflow generation\",\n",
    "        f\"Process integration: Comprehensive evaluation of watershed-scale process representation\",\n",
    "        f\"Model transferability: Parameter and performance consistency across environmental gradients\"\n",
    "    ]\n",
    "    \n",
    "    for objective in streamflow_objectives:\n",
    "        print(f\"   ð {objective}\")\n",
    "    \n",
    "    print(f\"\\nð Ready for Large Sample Streamflow Processing:\")\n",
    "    next_steps = [\n",
    "        f\"Multi-basin template configuration: Validated for streamflow modeling deployment\",\n",
    "        f\"Watershed selection: {len(selected_df)} diverse watersheds prepared for analysis\",\n",
    "        f\"Batch processing: Ready for systematic CONFLUENCE streamflow simulation execution\",\n",
    "        f\"Output analysis: Framework prepared for multi-basin streamflow validation result aggregation\",\n",
    "        f\"Statistical analysis: Tools ready for comparative streamflow hydrology insights\"\n",
    "    ]\n",
    "    \n",
    "    for step in next_steps:\n",
    "        print(f\"   â {step}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâ ï¸ No watersheds available for subsequent processing\")\n",
    "    selected_watersheds = pd.DataFrame()\n",
    "    streamflow_config = streamflow_sample_config.copy()\n",
    "\n",
    "print(f\"\\nâ Step 1 Complete: Large sample streamflow experiment designed and configured\")\n",
    "print(f\"   ð Next: Execute systematic multi-basin CONFLUENCE streamflow processing\")\n",
    "print(f\"   ð Goal: Comparative streamflow hydrology across continental watershed gradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328d0f5-3310-4565-bb3c-97a0abc44efd",
   "metadata": {},
   "source": [
    "## Step 2: Large Sample Multi-Basin Streamflow Processing Execution\n",
    "\n",
    "Building on the comprehensive watershed selection and experimental design from Step 1, we now execute the ultimate demonstration of CONFLUENCE's capabilities: systematic streamflow modeling across diverse watersheds using the CAMELS-SPAT dataset. This step represents the culmination of our large sample tutorial series, scaling from individual process validation to integrated watershed-scale streamflow prediction across continental environmental gradients.\n",
    "Streamflow Modeling Scaling: Single Basins â Continental Multi-Basin Analysis\n",
    "Traditional Watershed Modeling: Individual basin case studies with limited transferability\n",
    "\n",
    "Site-specific calibration and validation with unclear regional applicability\n",
    "Manual configuration for each watershed's unique characteristics\n",
    "Limited ability to identify universal vs. basin-specific hydrological controls\n",
    "Difficulty distinguishing model limitations from local environmental effects\n",
    "\n",
    "Large Sample Streamflow Modeling: Systematic validation across watershed gradients\n",
    "\n",
    "Automated multi-basin configuration across climate, topography, and scale gradients\n",
    "Parallel watershed simulations leveraging computational efficiency for integrated hydrology\n",
    "Standardized streamflow validation protocols enabling direct performance comparison\n",
    "Process-routing integration combining hillslope hydrology with channel hydraulics\n",
    "\n",
    "The Ultimate Hydrological Integration Challenge\n",
    "Streamflow modeling represents the most integrative test of hydrological models, requiring accurate simulation of all watershed processes:\n",
    "Complete Process Integration:\n",
    "\n",
    "Precipitation processing: Interception, infiltration, and surface runoff generation\n",
    "Evapotranspiration dynamics: Plant water use, soil moisture depletion, and energy balance\n",
    "Subsurface flow: Groundwater interactions, baseflow generation, and storage dynamics\n",
    "Snow processes: Seasonal accumulation, ablation, and snowmelt contributions (where applicable)\n",
    "Channel routing: Travel time, attenuation, and hydraulic processes\n",
    "\n",
    "Multi-Scale Interactions:\n",
    "\n",
    "Hillslope to watershed scaling: Aggregation of point-scale processes to basin response\n",
    "Temporal scale integration: Event response, seasonal cycles, and long-term storage dynamics\n",
    "Spatial heterogeneity: Landscape variability in climate, soils, vegetation, and topography\n",
    "Network effects: Channel network structure and routing process representation\n",
    "\n",
    "Validation Complexity:\n",
    "\n",
    "Integrated validation: Streamflow represents the integrated watershed response to all processes\n",
    "Multi-metric assessment: Flow magnitude, timing, variability, and extreme event representation\n",
    "Seasonal evaluation: Performance across different hydrological seasons and conditions\n",
    "Flow signature analysis: Characteristic watershed behaviors and response patterns\n",
    "\n",
    "CONFLUENCE's Advanced Multi-Basin Capabilities\n",
    "The large sample framework leverages CONFLUENCE's sophisticated multi-basin modeling infrastructure:\n",
    "SUMMA-mizuRoute Integration:\n",
    "\n",
    "Process-based hydrology: Detailed representation of all hydrological processes through SUMMA\n",
    "Distributed routing: Sophisticated channel routing through mizuRoute integration\n",
    "Multi-physics options: Alternative process representations enabling systematic evaluation\n",
    "Scale-appropriate modeling: Lumped and distributed configurations for different watershed scales\n",
    "\n",
    "Automated Workflow Management:\n",
    "\n",
    "Basin-specific configuration: Automatic adaptation to individual watershed characteristics\n",
    "Observational data integration: Systematic incorporation of CAMELS-SPAT streamflow observations\n",
    "Quality control protocols: Automated validation of model setup and output quality\n",
    "Batch processing efficiency: Parallel execution across hundreds of watersheds\n",
    "\n",
    "Continental-Scale Streamflow Science Applications\n",
    "Large sample streamflow modeling with CAMELS-SPAT enables investigation of fundamental hydrological questions:\n",
    "ð Hydrological Controls: Systematic assessment of climate vs. landscape controls on streamflow generation across environmental gradients\n",
    "ðï¸ Scale Dependencies: Quantification of how hydrological processes scale from hillslopes to watersheds across different basin sizes\n",
    "ð Regional Patterns: Identification of systematic regional variations in hydrological behavior and model performance\n",
    "ð Process Transferability: Testing whether hydrological process representations are consistent across diverse watershed environments\n",
    "ð Predictive Capability: Evaluation of model ability to predict streamflow in ungauged basins based on physical characteristics\n",
    "ð Climate Sensitivity: Assessment of watershed response to climate variability and change across different physiographic settings\n",
    "The automated workflow demonstrated here enables systematic streamflow model evaluation that was previously impossible due to the manual effort required for multi-basin hydrological studies, representing the future of watershed science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089af51-b285-48eb-aed0-40c899454844",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: EXECUTE LARGE SAMPLE MULTI-BASIN STREAMFLOW PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Step 2: CAMELS-SPAT Large Sample Streamflow Processing Execution ===\")\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_camelsspat_script_from_notebook():\n",
    "    \"\"\"\n",
    "    Execute the run_watersheds_camelsspat-3.py script from within the notebook\n",
    "    \"\"\"\n",
    "    print(f\"\\nð Executing CAMELS-SPAT Large Sample Streamflow Processing Script...\")\n",
    "    \n",
    "    script_path = \"./run_watersheds_camelsspat-3.py\"\n",
    "    \n",
    "    if not Path(script_path).exists():\n",
    "        print(f\"â Script not found: {script_path}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"   ð Script location: {script_path}\")\n",
    "    print(f\"   ð¯ Target watersheds: {len(selected_watersheds)} CAMELS-SPAT basins\")\n",
    "    print(f\"   â° Processing started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    try:\n",
    "        # Create a process with interactive input automation\n",
    "        process = subprocess.Popen(\n",
    "            ['python', script_path],\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "        \n",
    "        # Prepare automated responses for the script prompts\n",
    "        automated_inputs = [\n",
    "            'n',  # Don't reload shapefile information\n",
    "            'all',  # Process all scales\n",
    "            str(streamflow_config['max_watersheds']),  # Number of watersheds to process\n",
    "            'y' if not streamflow_config.get('dry_run_mode', False) else 'dry'  # Submit jobs or dry run\n",
    "        ]\n",
    "        \n",
    "        input_string = '\\n'.join(automated_inputs) + '\\n'\n",
    "        \n",
    "        # Send automated responses\n",
    "        stdout, stderr = process.communicate(input=input_string)\n",
    "        \n",
    "        # Print the output\n",
    "        if stdout:\n",
    "            print(\"ð Script Output:\")\n",
    "            for line in stdout.split('\\n'):\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "        \n",
    "        if stderr:\n",
    "            print(\"â ï¸  Script Warnings/Errors:\")\n",
    "            for line in stderr.split('\\n'):\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "            print(f\"â CAMELS-SPAT processing script completed successfully\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"â Script failed with return code: {process.returncode}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"â Error running script: {e}\")\n",
    "        return False\n",
    "\n",
    "def monitor_streamflow_job_progress():\n",
    "    \"\"\"\n",
    "    Monitor the progress of submitted CONFLUENCE streamflow modeling jobs\n",
    "    \"\"\"\n",
    "    print(f\"\\nð Monitoring Streamflow Modeling Job Progress...\")\n",
    "    \n",
    "    try:\n",
    "        # Check job queue status\n",
    "        result = subprocess.run(['squeue', '-u', '$USER'], \n",
    "                              capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            queue_lines = result.stdout.strip().split('\\n')\n",
    "            confluence_jobs = [line for line in queue_lines \n",
    "                             if 'CONFLUENCE' in line or any(ws in line \n",
    "                             for ws in selected_watersheds['ID'][:5].values)]\n",
    "            \n",
    "            print(f\"   ð Streamflow modeling jobs in queue: {len(confluence_jobs)}\")\n",
    "            \n",
    "            if confluence_jobs:\n",
    "                print(\"   ð Active CAMELS-SPAT CONFLUENCE jobs:\")\n",
    "                for job in confluence_jobs[:10]:  # Show first 10\n",
    "                    print(f\"     {job}\")\n",
    "                if len(confluence_jobs) > 10:\n",
    "                    print(f\"     ... and {len(confluence_jobs) - 10} more\")\n",
    "        else:\n",
    "            print(\"   â ï¸  Unable to check job queue status\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   â ï¸  Error checking job status: {e}\")\n",
    "\n",
    "# Execute the CAMELS-SPAT processing script\n",
    "script_success = run_camelsspat_script_from_notebook()\n",
    "\n",
    "if script_success:\n",
    "    print(f\"\\nâ Step 2 Complete: CAMELS-SPAT streamflow modeling initiated\")\n",
    "    \n",
    "    # Monitor initial job status\n",
    "    monitor_streamflow_job_progress()\n",
    "    \n",
    "    print(f\"\\nð Next Steps:\")\n",
    "    print(f\"   1. Multi-basin streamflow jobs will process in parallel on the cluster\")\n",
    "    print(f\"   2. Results will include simulated hydrographs and routing outputs\")\n",
    "    print(f\"   3. Step 3 will analyze streamflow validation metrics across watersheds\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâ ï¸  Step 2 Issue: Script execution had problems\")\n",
    "    print(f\"   Proceeding to Step 3 with any existing results...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17b4e1-e1d7-4606-b66a-d783b1404c40",
   "metadata": {},
   "source": [
    "## Step 3: Multi-Basin Streamflow Validation and Regional Analysis\n",
    "Having executed large sample streamflow modeling, we now demonstrate the analytical power that emerges from systematic multi-basin streamflow validation using CAMELS-SPAT observations. This step showcases comprehensive watershed response evaluation, regional performance assessment, and integrated process validationâthe scientific culmination of our entire CONFLUENCE tutorial series.\n",
    "Streamflow Science Evolution: Case Studies â Systematic Watershed Understanding\n",
    "Traditional Streamflow Validation: Individual basin model evaluation and calibration\n",
    "\n",
    "Basin-specific parameter tuning with limited transferability to other watersheds\n",
    "Difficulty separating universal hydrological principles from local environmental effects\n",
    "Manual comparison across different studies and modeling approaches\n",
    "Limited statistical power for robust hydrological process generalization\n",
    "\n",
    "Large Sample Streamflow Validation: Systematic multi-basin hydrological analysis\n",
    "\n",
    "Continental-scale pattern recognition across climate, topography, and scale gradients\n",
    "Statistical hypothesis testing for hydrological process representations with robust sample sizes\n",
    "Process universality assessment distinguishing general vs. basin-specific hydrological behaviors\n",
    "Model transferability evaluation across diverse continental watershed environments\n",
    "\n",
    "Comprehensive Multi-Basin Analysis Framework\n",
    "Tier 1: Watershed Domain Spatial Overview\n",
    "\n",
    "Automated discovery of completed streamflow modeling domains across environmental gradients\n",
    "Processing status assessment including simulation completion, routing success, and observation availability\n",
    "Continental spatial distribution showing streamflow modeling coverage across physiographic regions\n",
    "Scale-based analysis revealing streamflow modeling performance across watershed size gradients\n",
    "\n",
    "Tier 2: Integrated Streamflow Process Validation\n",
    "\n",
    "Hydrograph comparison: Comprehensive streamflow time series validation across diverse watersheds\n",
    "Multi-metric evaluation: Nash-Sutcliffe efficiency, Kling-Gupta efficiency, bias, and correlation assessment\n",
    "Flow signature analysis: Characteristic watershed response patterns and hydrological behavior\n",
    "Seasonal performance evaluation: Assessment across different hydrological seasons and flow conditions\n",
    "\n",
    "Watershed Hydrology Innovation at Scale\n",
    "Multi-basin streamflow validation across hundreds of CAMELS-SPAT watersheds represents cutting-edge watershed science:\n",
    "Integrated Process Understanding:\n",
    "\n",
    "Complete water cycle validation through streamflow as the integrative watershed response variable\n",
    "Climate-landscape interactions revealing complex controls on hydrological behavior across regions\n",
    "Scale effect quantification showing how hydrological processes change with watershed size\n",
    "Regional pattern identification distinguishing physiographic controls on watershed response\n",
    "\n",
    "Multi-Scale Performance Analysis:\n",
    "\n",
    "Headwater to large basin evaluation across the full spectrum of watershed scales\n",
    "Climate gradient assessment from arid to humid regions across continental gradients\n",
    "Topographic effect analysis across flat to mountainous terrain and drainage characteristics\n",
    "Land use impact evaluation on hydrological response and model performance\n",
    "\n",
    "Model Process Evaluation:\n",
    "\n",
    "Hydrological model physics assessment across different process representations in SUMMA\n",
    "Routing process evaluation through mizuRoute channel network representation\n",
    "Parameter regionalization testing consistency of model parameters across environmental gradients\n",
    "Structural adequacy assessment identifying where current models succeed vs. require improvement\n",
    "\n",
    "Breakthrough Multi-Basin Capabilities\n",
    "This multi-basin analysis framework delivers several revolutionary capabilities for watershed science:\n",
    "ð Continental Watershed Assessment: Comprehensive evaluation of streamflow model performance across the full range of continental watershed environments\n",
    "ð Hydrological Process Generalization: Statistical identification of universal watershed response patterns vs. region-specific behaviors\n",
    "ð¯ Integrated Model Validation: Systematic testing of complete hydrological model systems from precipitation to streamflow\n",
    "ð Uncertainty Quantification: Robust assessment of streamflow prediction reliability across diverse watershed environments\n",
    "ð Transferability Analysis: Evaluation of hydrological model parameter and process consistency across environmental gradients\n",
    "â°ï¸ Scale-Climate Synthesis: Understanding complex interactions between watershed scale, climate, and topographic controls on hydrological response\n",
    "Regional Streamflow Pattern Analysis\n",
    "The analysis emphasizes critical regional hydrological process evaluation:\n",
    "Climate Control Analysis:\n",
    "\n",
    "Aridity gradient effects on watershed response and model performance across precipitation gradients\n",
    "Temperature control assessment including freeze-thaw effects and energy balance impacts\n",
    "Seasonality evaluation across different precipitation timing and intensity patterns\n",
    "Extreme event representation during floods, droughts, and unusual hydrological conditions\n",
    "\n",
    "Landscape Control Analysis:\n",
    "\n",
    "Topographic effect quantification across flat to mountainous terrain characteristics\n",
    "Soil influence assessment on infiltration, storage, and baseflow generation processes\n",
    "Vegetation impact evaluation on evapotranspiration and surface runoff generation\n",
    "Geological control analysis on groundwater interactions and baseflow sustainability\n",
    "\n",
    "Scale Effect Integration:\n",
    "\n",
    "Basin size impacts on hydrological process representation and model performance\n",
    "Network effect evaluation through channel routing and travel time representation\n",
    "Aggregation scale analysis from point-scale processes to watershed-scale response\n",
    "Resolution sensitivity assessment across different spatial and temporal scales\n",
    "\n",
    "Multi-Basin Scientific Synthesis\n",
    "The multi-basin streamflow validation demonstrated here represents the ultimate achievement of our CONFLUENCE tutorial series:\n",
    "Complete Tutorial Integration:\n",
    "\n",
    "Point-scale foundation: Building on energy balance (FLUXNET) and snow dynamics (NorSWE) understanding\n",
    "Process scaling mastery: From individual processes to integrated watershed response\n",
    "Large sample methodology: Systematic multi-site analysis enabling robust scientific conclusions\n",
    "Computational efficiency: Workflow automation enabling unprecedented scope of analysis\n",
    "\n",
    "Hydrological Science Advancement:\n",
    "\n",
    "Process universality: Identification of fundamental hydrological principles across environments\n",
    "Regional specialization: Understanding of environment-specific adaptations and behaviors\n",
    "Model improvement: Evidence-based enhancement of hydrological model structure and parameters\n",
    "Predictive capability: Enhanced ability to predict streamflow in ungauged watersheds\n",
    "\n",
    "Practical Applications:\n",
    "\n",
    "Water resources management: Improved streamflow prediction for reservoir operations and water allocation\n",
    "Flood forecasting: Enhanced understanding of extreme event generation across different watersheds\n",
    "Climate change assessment: Robust projections of future streamflow changes across regions\n",
    "Ecosystem applications: Better representation of instream flows and aquatic habitat requirements\n",
    "\n",
    "The multi-basin streamflow analysis demonstrated here represents the future of watershed science: moving from individual basin case studies to systematic, statistically robust analysis across the full spectrum of continental watershed environments. This approach enables confident identification of universal hydrological patterns while quantifying regional variations and model uncertainties across diverse physiographic settings.\n",
    "This tutorial completes our journey from individual process understanding to integrated, large sample watershed scienceâdemonstrating the full power of CONFLUENCE for advancing hydrological knowledge across all scales and environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74a6ab-b842-459d-b5cf-bae05e4fb9a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: COMPREHENSIVE MULTI-BASIN STREAMFLOW ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n=== Step 3: CAMELS-SPAT Multi-Basin Streamflow Validation Analysis ===\")\n",
    "\n",
    "def discover_completed_streamflow_domains():\n",
    "    \"\"\"\n",
    "    Discover all completed CAMELS-SPAT domain directories and their streamflow outputs\n",
    "    \"\"\"\n",
    "    print(f\"\\nð Discovering Completed CAMELS-SPAT Streamflow Modeling Domains...\")\n",
    "    \n",
    "    # Base data directory pattern\n",
    "    base_path = Path(streamflow_config['base_data_path'])\n",
    "    domain_pattern = str(base_path / \"domain_*\")\n",
    "    \n",
    "    # Find all domain directories\n",
    "    domain_dirs = glob.glob(domain_pattern)\n",
    "    \n",
    "    print(f\"   ð Found {len(domain_dirs)} total domain directories\")\n",
    "    \n",
    "    completed_domains = []\n",
    "    \n",
    "    for domain_dir in domain_dirs:\n",
    "        domain_path = Path(domain_dir)\n",
    "        domain_name = domain_path.name.replace('domain_', '')\n",
    "        \n",
    "        # Check if this is a CAMELS-SPAT domain (should match our selected watersheds)\n",
    "        if any(domain_name.startswith(ws) for ws in selected_watersheds['ID'].values):\n",
    "            \n",
    "            # Check for key output files\n",
    "            shapefile_path = domain_path / \"shapefiles\" / \"river_basins\"\n",
    "            simulation_dir = domain_path / \"simulations\"\n",
    "            obs_dir = domain_path / \"observations\" / \"streamflow\" / \"preprocessed\"\n",
    "            \n",
    "            domain_info = {\n",
    "                'domain_name': domain_name,\n",
    "                'domain_path': domain_path,\n",
    "                'has_shapefile': shapefile_path.exists(),\n",
    "                'shapefile_path': shapefile_path if shapefile_path.exists() else None,\n",
    "                'has_simulations': simulation_dir.exists(),\n",
    "                'simulation_path': simulation_dir if simulation_dir.exists() else None,\n",
    "                'has_observations': obs_dir.exists(),\n",
    "                'observation_path': obs_dir if obs_dir.exists() else None,\n",
    "                'simulation_files': [],\n",
    "                'streamflow_obs_file': None\n",
    "            }\n",
    "            \n",
    "            # Find simulation output files\n",
    "            if simulation_dir.exists():\n",
    "                # Look for SUMMA outputs\n",
    "                summa_files = list(simulation_dir.glob(\"**/SUMMA/*.nc\"))\n",
    "                # Look for mizuRoute outputs (streamflow routing)\n",
    "                mizuroute_files = list(simulation_dir.glob(\"**/mizuRoute/*.nc\"))\n",
    "                \n",
    "                domain_info['simulation_files'] = summa_files + mizuroute_files\n",
    "                domain_info['has_results'] = len(domain_info['simulation_files']) > 0\n",
    "                domain_info['has_summa'] = len(summa_files) > 0\n",
    "                domain_info['has_routing'] = len(mizuroute_files) > 0\n",
    "            else:\n",
    "                domain_info['has_results'] = False\n",
    "                domain_info['has_summa'] = False\n",
    "                domain_info['has_routing'] = False\n",
    "            \n",
    "            # Find observation files\n",
    "            if obs_dir.exists():\n",
    "                streamflow_files = list(obs_dir.glob(\"*streamflow*.csv\"))\n",
    "                if streamflow_files:\n",
    "                    domain_info['streamflow_obs_file'] = streamflow_files[0]\n",
    "            \n",
    "            completed_domains.append(domain_info)\n",
    "    \n",
    "    print(f\"   ð CAMELS-SPAT domains found: {len(completed_domains)}\")\n",
    "    print(f\"   ð Domains with shapefiles: {sum(1 for d in completed_domains if d['has_shapefile'])}\")\n",
    "    print(f\"   ð Domains with simulation results: {sum(1 for d in completed_domains if d['has_results'])}\")\n",
    "    print(f\"   ð Domains with routing outputs: {sum(1 for d in completed_domains if d['has_routing'])}\")\n",
    "    print(f\"   ð Domains with observations: {sum(1 for d in completed_domains if d['has_observations'])}\")\n",
    "    \n",
    "    return completed_domains\n",
    "\n",
    "def create_streamflow_domain_overview_map(completed_domains):\n",
    "    \"\"\"\n",
    "    Create an overview map showing all streamflow domain locations and their completion status\n",
    "    \"\"\"\n",
    "    print(f\"\\nðºï¸  Creating Streamflow Domain Overview Map...\")\n",
    "    \n",
    "    # Create figure for overview map\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    \n",
    "    # Map 1: Global overview with completion status\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Plot all selected sites\n",
    "    if len(selected_watersheds) > 0:\n",
    "        ax1.scatter(selected_watersheds['Lon'], selected_watersheds['Lat'], \n",
    "                   c='lightgray', alpha=0.5, s=30, label='Selected watersheds', marker='o')\n",
    "    \n",
    "    # Plot completed domains with different colors for different completion levels\n",
    "    for domain in completed_domains:\n",
    "        domain_name = domain['domain_name']\n",
    "        \n",
    "        # Find corresponding site in selected_watersheds\n",
    "        site_row = None\n",
    "        for _, row in selected_watersheds.iterrows():\n",
    "            if domain_name.startswith(row['ID']):\n",
    "                site_row = row\n",
    "                break\n",
    "        \n",
    "        if site_row is not None:\n",
    "            lat = site_row['Lat']\n",
    "            lon = site_row['Lon']\n",
    "            \n",
    "            # Color based on completion status\n",
    "            if domain['has_routing'] and domain['has_observations']:\n",
    "                color = 'green'\n",
    "                label = 'Complete with streamflow validation'\n",
    "                marker = 's'\n",
    "                size = 80\n",
    "            elif domain['has_routing']:\n",
    "                color = 'orange' \n",
    "                label = 'Routing complete'\n",
    "                marker = '^'\n",
    "                size = 60\n",
    "            elif domain['has_results']:\n",
    "                color = 'blue'\n",
    "                label = 'Simulation complete'\n",
    "                marker = 'D'\n",
    "                size = 50\n",
    "            else:\n",
    "                color = 'red'\n",
    "                label = 'Processing started'\n",
    "                marker = 'v'\n",
    "                size = 40\n",
    "            \n",
    "            ax1.scatter(lon, lat, c=color, s=size, marker=marker, alpha=0.8,\n",
    "                       edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.set_title('CAMELS-SPAT Streamflow Domain Processing Status Overview')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(-130, -60)  # Focus on North America\n",
    "    ax1.set_ylim(25, 55)\n",
    "    \n",
    "    # Create custom legend\n",
    "    legend_elements = [\n",
    "        plt.scatter([], [], c='green', s=80, marker='s', label='Complete with validation'),\n",
    "        plt.scatter([], [], c='orange', s=60, marker='^', label='Routing complete'),\n",
    "        plt.scatter([], [], c='blue', s=50, marker='D', label='Simulation complete'),\n",
    "        plt.scatter([], [], c='red', s=40, marker='v', label='Processing started'),\n",
    "        plt.scatter([], [], c='lightgray', s=30, marker='o', label='Selected watersheds')\n",
    "    ]\n",
    "    ax1.legend(handles=legend_elements, loc='lower left')\n",
    "    \n",
    "    # Map 2: Completion statistics by scale\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    if len(selected_watersheds) > 0 and 'Scale' in selected_watersheds.columns:\n",
    "        # Create scale-based completion analysis\n",
    "        scale_completion = {}\n",
    "        \n",
    "        for domain in completed_domains:\n",
    "            domain_name = domain['domain_name']\n",
    "            \n",
    "            # Find corresponding watershed\n",
    "            site_row = None\n",
    "            for _, row in selected_watersheds.iterrows():\n",
    "                if domain_name.startswith(row['ID']):\n",
    "                    site_row = row\n",
    "                    break\n",
    "            \n",
    "            if site_row is not None:\n",
    "                scale = site_row['Scale']\n",
    "                \n",
    "                if scale not in scale_completion:\n",
    "                    scale_completion[scale] = {'total': 0, 'complete': 0, 'partial': 0}\n",
    "                \n",
    "                scale_completion[scale]['total'] += 1\n",
    "                \n",
    "                if domain['has_routing'] and domain['has_observations']:\n",
    "                    scale_completion[scale]['complete'] += 1\n",
    "                elif domain['has_results']:\n",
    "                    scale_completion[scale]['partial'] += 1\n",
    "        \n",
    "        # Create stacked bar chart\n",
    "        if scale_completion:\n",
    "            scales = list(scale_completion.keys())\n",
    "            complete_counts = [scale_completion[s]['complete'] for s in scales]\n",
    "            partial_counts = [scale_completion[s]['partial'] for s in scales]\n",
    "            pending_counts = [scale_completion[s]['total'] - \n",
    "                             scale_completion[s]['complete'] - \n",
    "                             scale_completion[s]['partial'] for s in scales]\n",
    "            \n",
    "            x_pos = range(len(scales))\n",
    "            \n",
    "            ax2.bar(x_pos, complete_counts, label='Complete', color='green', alpha=0.7)\n",
    "            ax2.bar(x_pos, partial_counts, bottom=complete_counts, \n",
    "                   label='Partial', color='orange', alpha=0.7)\n",
    "            ax2.bar(x_pos, pending_counts, \n",
    "                   bottom=[c+p for c,p in zip(complete_counts, partial_counts)], \n",
    "                   label='Pending', color='red', alpha=0.7)\n",
    "            \n",
    "            ax2.set_xticks(x_pos)\n",
    "            ax2.set_xticklabels([s.capitalize() for s in scales])\n",
    "            ax2.set_ylabel('Number of Watersheds')\n",
    "            ax2.set_title('Processing Status by Watershed Scale')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Map 3: Watershed area vs simulation status\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    domain_areas = []\n",
    "    completion_status = []\n",
    "    \n",
    "    for domain in completed_domains:\n",
    "        domain_name = domain['domain_name']\n",
    "        \n",
    "        # Find corresponding watershed\n",
    "        site_row = None\n",
    "        for _, row in selected_watersheds.iterrows():\n",
    "            if domain_name.startswith(row['ID']):\n",
    "                site_row = row\n",
    "                break\n",
    "        \n",
    "        if site_row is not None and 'Area_km2' in site_row:\n",
    "            area = site_row['Area_km2']\n",
    "            domain_areas.append(area)\n",
    "            \n",
    "            # Determine completion status\n",
    "            if domain['has_routing'] and domain['has_observations']:\n",
    "                status = 'Complete'\n",
    "                color = 'green'\n",
    "            elif domain['has_routing']:\n",
    "                status = 'Routing'\n",
    "                color = 'orange'\n",
    "            elif domain['has_results']:\n",
    "                status = 'Simulation'\n",
    "                color = 'blue'\n",
    "            else:\n",
    "                status = 'Started'\n",
    "                color = 'red'\n",
    "            \n",
    "            completion_status.append(status)\n",
    "            ax3.scatter(area, len(completion_status), c=color, alpha=0.7, s=60, \n",
    "                       edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax3.set_xlabel('Watershed Area (kmÂ²)')\n",
    "    ax3.set_ylabel('Processing Order')\n",
    "    ax3.set_title('Watershed Size vs Processing Status')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Map 4: Processing summary statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_selected = len(selected_watersheds) if len(selected_watersheds) > 0 else 0\n",
    "    total_discovered = len(completed_domains)\n",
    "    total_with_results = sum(1 for d in completed_domains if d['has_results'])\n",
    "    total_with_routing = sum(1 for d in completed_domains if d['has_routing'])\n",
    "    total_with_obs = sum(1 for d in completed_domains if d['has_observations'])\n",
    "    total_complete = sum(1 for d in completed_domains if d['has_routing'] and d['has_observations'])\n",
    "    \n",
    "    categories = ['Selected', 'Processing\\nStarted', 'Simulation\\nComplete', 'Routing\\nComplete', 'Observations\\nAvailable', 'Ready for\\nValidation']\n",
    "    counts = [total_selected, total_discovered, total_with_results, total_with_routing, total_with_obs, total_complete]\n",
    "    colors = ['lightblue', 'yellow', 'blue', 'orange', 'cyan', 'green']\n",
    "    \n",
    "    bars = ax4.bar(categories, counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.2,\n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax4.set_ylabel('Number of Watersheds')\n",
    "    ax4.set_title('Streamflow Modeling Processing Progress')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('CAMELS-SPAT Large Sample Streamflow Study - Domain Overview', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the overview map\n",
    "    overview_path = experiment_dir / 'plots' / 'streamflow_domain_overview_map.png'\n",
    "    plt.savefig(overview_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"â Streamflow domain overview map saved: {overview_path}\")\n",
    "    \n",
    "    return total_selected, total_discovered, total_with_results, total_with_routing, total_with_obs, total_complete\n",
    "\n",
    "def extract_streamflow_results_from_domains(completed_domains):\n",
    "    \"\"\"\n",
    "    Extract streamflow simulation results from all completed domains\n",
    "    \"\"\"\n",
    "    print(f\"\\nð Extracting Streamflow Results from Completed Domains...\")\n",
    "    \n",
    "    streamflow_results = []\n",
    "    processing_summary = {\n",
    "        'total_domains': len(completed_domains),\n",
    "        'domains_with_routing': 0,\n",
    "        'domains_with_streamflow': 0,\n",
    "        'failed_extractions': 0\n",
    "    }\n",
    "    \n",
    "    for domain in completed_domains:\n",
    "        if not domain['has_routing']:\n",
    "            continue\n",
    "            \n",
    "        domain_name = domain['domain_name']\n",
    "        processing_summary['domains_with_routing'] += 1\n",
    "        \n",
    "        try:\n",
    "            print(f\"   ð Processing {domain_name}...\")\n",
    "            \n",
    "            # Find routing output files (mizuRoute)\n",
    "            mizuroute_files = [f for f in domain['simulation_files'] if 'mizuRoute' in str(f)]\n",
    "            \n",
    "            if not mizuroute_files:\n",
    "                print(f\"     â No mizuRoute files found\")\n",
    "                processing_summary['failed_extractions'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Use the first mizuRoute file\n",
    "            output_file = mizuroute_files[0]\n",
    "            \n",
    "            # Load the netCDF file\n",
    "            ds = xr.open_dataset(output_file)\n",
    "            \n",
    "            # Look for streamflow variables\n",
    "            streamflow_vars = {}\n",
    "            \n",
    "            # Common mizuRoute streamflow variable names\n",
    "            potential_vars = ['IRFroutedRunoff', 'routedRunoff', 'discharge', 'streamflow']\n",
    "            \n",
    "            for var in potential_vars:\n",
    "                if var in ds.data_vars:\n",
    "                    streamflow_vars['discharge'] = var\n",
    "                    break\n",
    "            \n",
    "            if not streamflow_vars:\n",
    "                print(f\"     â ï¸  No streamflow variables found in {output_file.name}\")\n",
    "                available_vars = list(ds.data_vars.keys())\n",
    "                print(f\"     Available variables: {available_vars[:5]}...\")\n",
    "                processing_summary['failed_extractions'] += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"     ð Using streamflow variable: {streamflow_vars['discharge']}\")\n",
    "            \n",
    "            # Extract streamflow data\n",
    "            streamflow_var = streamflow_vars['discharge']\n",
    "            streamflow_data = ds[streamflow_var]\n",
    "            \n",
    "            # Handle multi-dimensional data (time x reaches)\n",
    "            if len(streamflow_data.dims) > 1:\n",
    "                # Find the time dimension\n",
    "                time_dim = 'time'\n",
    "                reach_dims = [dim for dim in streamflow_data.dims if dim != time_dim]\n",
    "                \n",
    "                if reach_dims:\n",
    "                    reach_dim = reach_dims[0]\n",
    "                    # Use the last reach (often the outlet)\n",
    "                    outlet_idx = streamflow_data.sizes[reach_dim] - 1\n",
    "                    streamflow_data = streamflow_data.isel({reach_dim: outlet_idx})\n",
    "                    print(f\"     ð Using outlet reach (index {outlet_idx})\")\n",
    "            \n",
    "            # Convert to pandas Series\n",
    "            streamflow_series = streamflow_data.to_pandas()\n",
    "            \n",
    "            # Handle unit conversion if needed (assume mÂ³/s is correct)\n",
    "            # Remove any negative values (set to 0)\n",
    "            streamflow_series = streamflow_series.clip(lower=0)\n",
    "            \n",
    "            # Get site information\n",
    "            site_row = None\n",
    "            for _, row in selected_watersheds.iterrows():\n",
    "                if domain_name.startswith(row['ID']):\n",
    "                    site_row = row\n",
    "                    break\n",
    "            \n",
    "            if site_row is None:\n",
    "                print(f\"     â ï¸  Site information not found for {domain_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate streamflow statistics\n",
    "            streamflow_stats = {\n",
    "                'mean_flow': streamflow_series.mean(),\n",
    "                'max_flow': streamflow_series.max(),\n",
    "                'min_flow': streamflow_series.min(),\n",
    "                'std_flow': streamflow_series.std(),\n",
    "                'flow_variability': streamflow_series.std() / streamflow_series.mean() if streamflow_series.mean() > 0 else np.nan\n",
    "            }\n",
    "            \n",
    "            # Calculate flow percentiles\n",
    "            percentiles = [5, 25, 50, 75, 95]\n",
    "            for p in percentiles:\n",
    "                streamflow_stats[f'q{p}'] = streamflow_series.quantile(p/100)\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'domain_name': domain_name,\n",
    "                'watershed_id': site_row['ID'],\n",
    "                'latitude': site_row['Lat'],\n",
    "                'longitude': site_row['Lon'],\n",
    "                'area_km2': site_row.get('Area_km2', np.nan),\n",
    "                'scale': site_row.get('Scale', 'unknown'),\n",
    "                'streamflow_timeseries': streamflow_series,\n",
    "                'data_period': f\"{streamflow_series.index.min()} to {streamflow_series.index.max()}\",\n",
    "                'data_points': len(streamflow_series),\n",
    "                'streamflow_variable': streamflow_var,\n",
    "                'output_file': str(output_file)\n",
    "            }\n",
    "            \n",
    "            # Add statistics\n",
    "            result.update(streamflow_stats)\n",
    "            \n",
    "            streamflow_results.append(result)\n",
    "            processing_summary['domains_with_streamflow'] += 1\n",
    "            \n",
    "            print(f\"     â Streamflow extracted: {result['mean_flow']:.2f} mÂ³/s (range: {result['min_flow']:.2f}-{result['max_flow']:.2f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"     â Error processing {domain_name}: {e}\")\n",
    "            processing_summary['failed_extractions'] += 1\n",
    "    \n",
    "    print(f\"\\nð Streamflow Extraction Summary:\")\n",
    "    print(f\"   Total domains: {processing_summary['total_domains']}\")\n",
    "    print(f\"   Domains with routing: {processing_summary['domains_with_routing']}\")\n",
    "    print(f\"   Successful extractions: {processing_summary['domains_with_streamflow']}\")\n",
    "    print(f\"   Failed extractions: {processing_summary['failed_extractions']}\")\n",
    "    \n",
    "    return streamflow_results, processing_summary\n",
    "\n",
    "def load_camelsspat_observations(completed_domains):\n",
    "    \"\"\"\n",
    "    Load CAMELS-SPAT observation data for streamflow validation\n",
    "    \"\"\"\n",
    "    print(f\"\\nð¥ Loading CAMELS-SPAT Streamflow Observation Data...\")\n",
    "    \n",
    "    camelsspat_obs = {}\n",
    "    obs_summary = {\n",
    "        'sites_found': 0,\n",
    "        'sites_with_streamflow': 0,\n",
    "        'total_observations': 0\n",
    "    }\n",
    "    \n",
    "    # Look for processed CAMELS-SPAT observation data in domain directories\n",
    "    for domain in completed_domains:\n",
    "        if not domain['has_observations']:\n",
    "            continue\n",
    "            \n",
    "        domain_name = domain['domain_name']\n",
    "        \n",
    "        try:\n",
    "            print(f\"   ð Loading {domain_name}...\")\n",
    "            \n",
    "            obs_summary['sites_found'] += 1\n",
    "            \n",
    "            # Load streamflow observations\n",
    "            if domain['streamflow_obs_file']:\n",
    "                obs_df = pd.read_csv(domain['streamflow_obs_file'])\n",
    "                \n",
    "                # Find time and discharge columns\n",
    "                time_col = None\n",
    "                for col in ['datetime', 'date', 'time']:\n",
    "                    if col in obs_df.columns:\n",
    "                        time_col = col\n",
    "                        break\n",
    "                \n",
    "                discharge_col = None\n",
    "                for col in ['discharge_cms', 'streamflow', 'flow', 'Q']:\n",
    "                    if col in obs_df.columns:\n",
    "                        discharge_col = col\n",
    "                        break\n",
    "                \n",
    "                if time_col and discharge_col:\n",
    "                    obs_df[time_col] = pd.to_datetime(obs_df[time_col])\n",
    "                    obs_df.set_index(time_col, inplace=True)\n",
    "                    \n",
    "                    streamflow_obs = obs_df[discharge_col].dropna()\n",
    "                    \n",
    "                    if len(streamflow_obs) > 0:\n",
    "                        # Calculate streamflow statistics\n",
    "                        obs_stats = {\n",
    "                            'mean_flow': streamflow_obs.mean(),\n",
    "                            'max_flow': streamflow_obs.max(),\n",
    "                            'min_flow': streamflow_obs.min(),\n",
    "                            'std_flow': streamflow_obs.std(),\n",
    "                            'flow_variability': streamflow_obs.std() / streamflow_obs.mean() if streamflow_obs.mean() > 0 else np.nan\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate flow percentiles\n",
    "                        percentiles = [5, 25, 50, 75, 95]\n",
    "                        for p in percentiles:\n",
    "                            obs_stats[f'q{p}'] = streamflow_obs.quantile(p/100)\n",
    "                        \n",
    "                        # Store observation data\n",
    "                        site_obs = {\n",
    "                            'streamflow_timeseries': streamflow_obs,\n",
    "                            'data_period': f\"{streamflow_obs.index.min()} to {streamflow_obs.index.max()}\",\n",
    "                            'data_points': len(streamflow_obs)\n",
    "                        }\n",
    "                        \n",
    "                        # Add statistics\n",
    "                        site_obs.update(obs_stats)\n",
    "                        \n",
    "                        # Add site metadata\n",
    "                        site_row = None\n",
    "                        for _, row in selected_watersheds.iterrows():\n",
    "                            if domain_name.startswith(row['ID']):\n",
    "                                site_row = row\n",
    "                                break\n",
    "                        \n",
    "                        if site_row is not None:\n",
    "                            site_obs['latitude'] = site_row['Lat']\n",
    "                            site_obs['longitude'] = site_row['Lon']\n",
    "                            site_obs['area_km2'] = site_row.get('Area_km2', np.nan)\n",
    "                            site_obs['scale'] = site_row.get('Scale', 'unknown')\n",
    "                            site_obs['watershed_id'] = site_row['ID']\n",
    "                        \n",
    "                        camelsspat_obs[domain_name] = site_obs\n",
    "                        \n",
    "                        obs_summary['sites_with_streamflow'] += 1\n",
    "                        obs_summary['total_observations'] += len(streamflow_obs)\n",
    "                        \n",
    "                        print(f\"     ð Streamflow obs: {streamflow_obs.mean():.2f} mÂ³/s (range: {streamflow_obs.min():.2f}-{streamflow_obs.max():.2f}) ({len(streamflow_obs)} points)\")\n",
    "                else:\n",
    "                    print(f\"     â ï¸ Could not find time/discharge columns in observation file\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"     â Error loading {domain_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nð CAMELS-SPAT Observation Summary:\")\n",
    "    print(f\"   Sites with observation files: {obs_summary['sites_found']}\")\n",
    "    print(f\"   Sites with streamflow observations: {obs_summary['sites_with_streamflow']}\")\n",
    "    print(f\"   Total streamflow observations: {obs_summary['total_observations']}\")\n",
    "    \n",
    "    return camelsspat_obs, obs_summary\n",
    "\n",
    "def create_streamflow_comparison_analysis(streamflow_results, camelsspat_obs):\n",
    "    \"\"\"\n",
    "    Create comprehensive streamflow comparison analysis between simulated and observed\n",
    "    \"\"\"\n",
    "    print(f\"\\nð Creating Streamflow Comparison Analysis...\")\n",
    "    \n",
    "    # Find sites with both simulated and observed data\n",
    "    common_sites = []\n",
    "    \n",
    "    for sim_result in streamflow_results:\n",
    "        domain_name = sim_result['domain_name']\n",
    "        \n",
    "        if domain_name in camelsspat_obs:\n",
    "            # Align time periods\n",
    "            sim_flow = sim_result['streamflow_timeseries']\n",
    "            obs_flow = camelsspat_obs[domain_name]['streamflow_timeseries']\n",
    "            \n",
    "            # Find common time period\n",
    "            common_start = max(sim_flow.index.min(), obs_flow.index.min())\n",
    "            common_end = min(sim_flow.index.max(), obs_flow.index.max())\n",
    "            \n",
    "            if common_start < common_end:\n",
    "                # Resample to daily and align\n",
    "                sim_daily = sim_flow.resample('D').mean().loc[common_start:common_end]\n",
    "                obs_daily = obs_flow.resample('D').mean().loc[common_start:common_end]\n",
    "                \n",
    "                # Remove NaN values\n",
    "                valid_mask = ~(sim_daily.isna() | obs_daily.isna())\n",
    "                sim_valid = sim_daily[valid_mask]\n",
    "                obs_valid = obs_daily[valid_mask]\n",
    "                \n",
    "                if len(sim_valid) > 50:  # Need minimum data for meaningful comparison\n",
    "                    \n",
    "                    # Calculate performance metrics\n",
    "                    def calculate_nse(obs, sim):\n",
    "                        return 1 - ((obs - sim) ** 2).sum() / ((obs - obs.mean()) ** 2).sum()\n",
    "                    \n",
    "                    def calculate_kge(obs, sim):\n",
    "                        # Kling-Gupta Efficiency\n",
    "                        r = np.corrcoef(obs, sim)[0, 1]\n",
    "                        alpha = sim.std() / obs.std()\n",
    "                        beta = sim.mean() / obs.mean()\n",
    "                        kge = 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "                        return kge\n",
    "                    \n",
    "                    # Performance metrics\n",
    "                    nse = calculate_nse(obs_valid, sim_valid)\n",
    "                    rmse = np.sqrt(((obs_valid - sim_valid) ** 2).mean())\n",
    "                    bias = (sim_valid - obs_valid).mean()\n",
    "                    pbias = 100 * bias / obs_valid.mean() if obs_valid.mean() > 0 else np.nan\n",
    "                    \n",
    "                    # Correlation\n",
    "                    try:\n",
    "                        correlation = obs_valid.corr(sim_valid)\n",
    "                        if pd.isna(correlation):\n",
    "                            correlation = 0.0\n",
    "                    except:\n",
    "                        correlation = 0.0\n",
    "                    \n",
    "                    # KGE\n",
    "                    try:\n",
    "                        kge = calculate_kge(obs_valid.values, sim_valid.values)\n",
    "                        if pd.isna(kge):\n",
    "                            kge = -999\n",
    "                    except:\n",
    "                        kge = -999\n",
    "                    \n",
    "                    common_site = {\n",
    "                        'domain_name': domain_name,\n",
    "                        'watershed_id': sim_result['watershed_id'],\n",
    "                        'latitude': sim_result['latitude'],\n",
    "                        'longitude': sim_result['longitude'],\n",
    "                        'area_km2': sim_result['area_km2'],\n",
    "                        'scale': sim_result['scale'],\n",
    "                        'sim_flow': sim_valid,\n",
    "                        'obs_flow': obs_valid,\n",
    "                        'sim_mean': sim_valid.mean(),\n",
    "                        'obs_mean': obs_valid.mean(),\n",
    "                        'nse': nse,\n",
    "                        'kge': kge,\n",
    "                        'rmse': rmse,\n",
    "                        'bias': bias,\n",
    "                        'pbias': pbias,\n",
    "                        'correlation': correlation,\n",
    "                        'n_points': len(sim_valid),\n",
    "                        'common_period': f\"{common_start.date()} to {common_end.date()}\"\n",
    "                    }\n",
    "                    \n",
    "                    common_sites.append(common_site)\n",
    "                    \n",
    "                    print(f\"   â {domain_name}: NSE={nse:.3f}, KGE={kge:.3f}, r={correlation:.3f}, Bias={bias:+.2f} ({len(sim_valid)} points)\")\n",
    "    \n",
    "    print(f\"\\nð Streamflow Comparison Summary:\")\n",
    "    print(f\"   Sites with both sim and obs: {len(common_sites)}\")\n",
    "    \n",
    "    if len(common_sites) == 0:\n",
    "        print(\"   â ï¸  No sites with overlapping sim/obs data for comparison\")\n",
    "        return None\n",
    "    \n",
    "    # Create comprehensive streamflow comparison visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    # Scatter plot: Observed vs Simulated (top left)\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    all_obs = np.concatenate([site['obs_flow'].values for site in common_sites])\n",
    "    all_sim = np.concatenate([site['sim_flow'].values for site in common_sites])\n",
    "    \n",
    "    ax1.scatter(all_obs, all_sim, alpha=0.3, s=8, c='blue')\n",
    "    \n",
    "    # 1:1 line\n",
    "    min_val = min(all_obs.min(), all_sim.min())\n",
    "    max_val = max(all_obs.max(), all_sim.max())\n",
    "    ax1.plot([min_val, max_val], [min_val, max_val], 'k--', label='1:1 line')\n",
    "    \n",
    "    ax1.set_xlabel('Observed Streamflow (mÂ³/s)')\n",
    "    ax1.set_ylabel('Simulated Streamflow (mÂ³/s)')\n",
    "    ax1.set_title('All Sites: Simulated vs Observed Streamflow')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    # Add overall statistics\n",
    "    overall_corr = np.corrcoef(all_obs, all_sim)[0,1] if len(all_obs) > 1 else 0\n",
    "    overall_nse = 1 - ((all_obs - all_sim) ** 2).sum() / ((all_obs - all_obs.mean()) ** 2).sum()\n",
    "    overall_bias = np.mean(all_sim - all_obs)\n",
    "    \n",
    "    stats_text = f'r = {overall_corr:.3f}\\nNSE = {overall_nse:.3f}\\nBias = {overall_bias:+.2f}'\n",
    "    ax1.text(0.05, 0.95, stats_text, transform=ax1.transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8), fontsize=10, verticalalignment='top')\n",
    "    \n",
    "    # Performance by watershed scale (top middle)\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    if any('scale' in site for site in common_sites):\n",
    "        scale_stats = {}\n",
    "        for site in common_sites:\n",
    "            scale = site.get('scale', 'unknown')\n",
    "            if scale not in scale_stats:\n",
    "                scale_stats[scale] = {'nse': [], 'kge': [], 'corr': []}\n",
    "            \n",
    "            scale_stats[scale]['nse'].append(site['nse'])\n",
    "            scale_stats[scale]['kge'].append(site['kge'])\n",
    "            scale_stats[scale]['corr'].append(site['correlation'])\n",
    "        \n",
    "        # Plot NSE by scale\n",
    "        scales = list(scale_stats.keys())\n",
    "        nse_means = [np.mean(scale_stats[s]['nse']) for s in scales]\n",
    "        nse_stds = [np.std(scale_stats[s]['nse']) for s in scales]\n",
    "        \n",
    "        x_pos = range(len(scales))\n",
    "        bars = ax2.bar(x_pos, nse_means, yerr=nse_stds, capsize=5, alpha=0.7, color='skyblue')\n",
    "        ax2.set_xticks(x_pos)\n",
    "        ax2.set_xticklabels([s.capitalize() for s in scales])\n",
    "        ax2.set_ylabel('Nash-Sutcliffe Efficiency')\n",
    "        ax2.set_title('Streamflow Performance by Watershed Scale')\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, mean_val in zip(bars, nse_means):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
    "                    f'{mean_val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Performance vs watershed area (top right)\n",
    "    ax3 = axes[0, 2]\n",
    "    \n",
    "    areas = [site['area_km2'] for site in common_sites if not np.isnan(site['area_km2'])]\n",
    "    nses = [site['nse'] for site in common_sites if not np.isnan(site['area_km2'])]\n",
    "    \n",
    "    if areas and nses:\n",
    "        scatter3 = ax3.scatter(areas, nses, alpha=0.7, s=40, c='green')\n",
    "        ax3.set_xlabel('Watershed Area (kmÂ²)')\n",
    "        ax3.set_ylabel('Nash-Sutcliffe Efficiency')\n",
    "        ax3.set_title('Performance vs Watershed Size')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.set_xscale('log')\n",
    "        ax3.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "        ax3.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='NSE = 0.5')\n",
    "        ax3.legend()\n",
    "    \n",
    "    # Bias distribution (bottom left)\n",
    "    ax4 = axes[1, 0]\n",
    "    \n",
    "    biases = [site['bias'] for site in common_sites]\n",
    "    ax4.hist(biases, bins=15, color='orange', alpha=0.7, edgecolor='black')\n",
    "    ax4.axvline(x=0, color='red', linestyle='--', label='Zero bias')\n",
    "    ax4.set_xlabel('Bias (mÂ³/s)')\n",
    "    ax4.set_ylabel('Number of Watersheds')\n",
    "    ax4.set_title('Distribution of Streamflow Bias')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # KGE vs NSE comparison (bottom middle)\n",
    "    ax5 = axes[1, 1]\n",
    "    \n",
    "    nse_vals = [site['nse'] for site in common_sites]\n",
    "    kge_vals = [site['kge'] for site in common_sites if site['kge'] != -999]\n",
    "    \n",
    "    if len(kge_vals) > 0:\n",
    "        ax5.scatter(nse_vals[:len(kge_vals)], kge_vals, alpha=0.7, s=40, c='purple')\n",
    "        ax5.set_xlabel('Nash-Sutcliffe Efficiency')\n",
    "        ax5.set_ylabel('Kling-Gupta Efficiency')\n",
    "        ax5.set_title('NSE vs KGE Performance')\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add reference lines\n",
    "        ax5.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "        ax5.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "        ax5.plot([-1, 1], [-1, 1], 'k--', alpha=0.3, label='1:1 line')\n",
    "        ax5.legend()\n",
    "    \n",
    "    # Performance summary (bottom right)\n",
    "    ax6 = axes[1, 2]\n",
    "    \n",
    "    # Create performance categories\n",
    "    perf_categories = {\n",
    "        'Excellent (NSE > 0.75)': len([s for s in common_sites if s['nse'] > 0.75]),\n",
    "        'Good (0.5 < NSE â¤ 0.75)': len([s for s in common_sites if 0.5 < s['nse'] <= 0.75]),\n",
    "        'Satisfactory (0.2 < NSE â¤ 0.5)': len([s for s in common_sites if 0.2 < s['nse'] <= 0.5]),\n",
    "        'Unsatisfactory (NSE â¤ 0.2)': len([s for s in common_sites if s['nse'] <= 0.2])\n",
    "    }\n",
    "    \n",
    "    categories = list(perf_categories.keys())\n",
    "    counts = list(perf_categories.values())\n",
    "    colors = ['darkgreen', 'green', 'yellow', 'red']\n",
    "    \n",
    "    bars = ax6.bar(range(len(categories)), counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax6.set_xticks(range(len(categories)))\n",
    "    ax6.set_xticklabels([c.split('(')[0].strip() for c in categories], rotation=45, ha='right')\n",
    "    ax6.set_ylabel('Number of Watersheds')\n",
    "    ax6.set_title('Performance Category Distribution')\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.1,\n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('CAMELS-SPAT Large Sample Streamflow Comparison Analysis', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save comparison plot\n",
    "    comparison_path = experiment_dir / 'plots' / 'streamflow_comparison_analysis.png'\n",
    "    plt.savefig(comparison_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"â Streamflow comparison analysis saved: {comparison_path}\")\n",
    "    \n",
    "    # Create spatial performance map\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Map 1: NSE spatial distribution\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    lats = [site['latitude'] for site in common_sites]\n",
    "    lons = [site['longitude'] for site in common_sites]\n",
    "    nse_values = [site['nse'] for site in common_sites]\n",
    "    \n",
    "    scatter1 = ax1.scatter(lons, lats, c=nse_values, cmap='RdYlGn', s=100, \n",
    "                          vmin=-0.5, vmax=1.0, edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.set_title('Streamflow Model Performance: NSE')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(-130, -60)\n",
    "    ax1.set_ylim(25, 55)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "    cbar1.set_label('Nash-Sutcliffe Efficiency')\n",
    "    \n",
    "    # Map 2: Bias spatial distribution\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    bias_values = [site['bias'] for site in common_sites]\n",
    "    max_abs_bias = max(abs(min(bias_values)), abs(max(bias_values)))\n",
    "    \n",
    "    scatter2 = ax2.scatter(lons, lats, c=bias_values, cmap='RdBu_r', s=100,\n",
    "                          vmin=-max_abs_bias, vmax=max_abs_bias, \n",
    "                          edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax2.set_xlabel('Longitude')\n",
    "    ax2.set_ylabel('Latitude')\n",
    "    ax2.set_title('Streamflow Model Performance: Bias (Sim - Obs)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(-130, -60)\n",
    "    ax2.set_ylim(25, 55)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "    cbar2.set_label('Bias (mÂ³/s)')\n",
    "    \n",
    "    plt.suptitle('CAMELS-SPAT Large Sample Streamflow Performance - Spatial Distribution', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save spatial analysis\n",
    "    spatial_path = experiment_dir / 'plots' / 'streamflow_spatial_performance.png'\n",
    "    plt.savefig(spatial_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"â Streamflow spatial performance map saved: {spatial_path}\")\n",
    "    \n",
    "    return common_sites\n",
    "\n",
    "# Execute Step 3 Analysis\n",
    "print(f\"\\nð Step 3.1: Streamflow Domain Discovery and Overview\")\n",
    "\n",
    "# Discover completed domains\n",
    "completed_domains = discover_completed_streamflow_domains()\n",
    "\n",
    "# Create domain overview map\n",
    "if len(completed_domains) > 0:\n",
    "    total_selected, total_discovered, total_with_results, total_with_routing, total_with_obs, total_complete = create_streamflow_domain_overview_map(completed_domains)\n",
    "else:\n",
    "    print(\"   â ï¸ No completed domains found for overview map\")\n",
    "    total_selected = len(selected_watersheds) if 'selected_watersheds' in locals() else 0\n",
    "    total_discovered = total_with_results = total_with_routing = total_with_obs = total_complete = 0\n",
    "\n",
    "print(f\"\\nð Step 3.2: Streamflow Results Extraction\")\n",
    "\n",
    "# Extract streamflow results from simulations\n",
    "if len(completed_domains) > 0:\n",
    "    streamflow_results, streamflow_processing_summary = extract_streamflow_results_from_domains(completed_domains)\n",
    "    \n",
    "    # Load CAMELS-SPAT observations\n",
    "    camelsspat_obs, obs_summary = load_camelsspat_observations(completed_domains)\n",
    "else:\n",
    "    print(\"   â ï¸ No completed domains available for analysis\")\n",
    "    streamflow_results = []\n",
    "    camelsspat_obs = {}\n",
    "    streamflow_processing_summary = {'domains_with_streamflow': 0}\n",
    "    obs_summary = {'sites_with_streamflow': 0}\n",
    "\n",
    "print(f\"\\nð Step 3.3: Streamflow Comparison Analysis\")\n",
    "\n",
    "# Create streamflow comparison analysis\n",
    "if streamflow_results and camelsspat_obs:\n",
    "    common_sites = create_streamflow_comparison_analysis(streamflow_results, camelsspat_obs)\n",
    "else:\n",
    "    print(\"   â ï¸  Insufficient data for streamflow comparison analysis\")\n",
    "    common_sites = None\n",
    "\n",
    "# Create final summary report\n",
    "print(f\"\\nð Creating Final CAMELS-SPAT Streamflow Study Summary Report...\")\n",
    "\n",
    "summary_report_path = experiment_dir / 'reports' / 'camelsspat_final_report.txt'\n",
    "\n",
    "with open(summary_report_path, 'w') as f:\n",
    "    f.write(\"CAMELS-SPAT Large Sample Streamflow Study - Final Analysis Report\\n\")\n",
    "    f.write(\"=\" * 68 + \"\\n\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    f.write(\"PROCESSING SUMMARY:\\n\")\n",
    "    f.write(f\"  Watersheds selected for analysis: {total_selected}\\n\")\n",
    "    f.write(f\"  Processing initiated: {total_discovered}\\n\")\n",
    "    f.write(f\"  Simulation results available: {total_with_results}\\n\")\n",
    "    f.write(f\"  Routing outputs available: {total_with_routing}\\n\")\n",
    "    f.write(f\"  Observations available: {total_with_obs}\\n\")\n",
    "    f.write(f\"  Complete streamflow validation: {total_complete}\\n\")\n",
    "    f.write(f\"  Streamflow extractions successful: {streamflow_processing_summary['domains_with_streamflow']}\\n\")\n",
    "    f.write(f\"  CAMELS-SPAT observations available: {obs_summary['sites_with_streamflow']}\\n\")\n",
    "    \n",
    "    if common_sites:\n",
    "        f.write(f\"  Sites with sim/obs comparison: {len(common_sites)}\\n\\n\")\n",
    "        \n",
    "        # Streamflow performance summary\n",
    "        nse_values = [site['nse'] for site in common_sites]\n",
    "        kge_values = [site['kge'] for site in common_sites if site['kge'] != -999]\n",
    "        bias_values = [site['bias'] for site in common_sites]\n",
    "        corr_values = [site['correlation'] for site in common_sites]\n",
    "        \n",
    "        f.write(\"STREAMFLOW PERFORMANCE SUMMARY:\\n\")\n",
    "        f.write(f\"  Mean NSE: {np.mean(nse_values):.3f} Â± {np.std(nse_values):.3f}\\n\")\n",
    "        if kge_values:\n",
    "            f.write(f\"  Mean KGE: {np.mean(kge_values):.3f} Â± {np.std(kge_values):.3f}\\n\")\n",
    "        f.write(f\"  Mean correlation: {np.mean(corr_values):.3f} Â± {np.std(corr_values):.3f}\\n\")\n",
    "        f.write(f\"  Mean bias: {np.mean(bias_values):+.2f} Â± {np.std(bias_values):.2f} mÂ³/s\\n\\n\")\n",
    "        \n",
    "        # Performance categories\n",
    "        excellent = len([s for s in common_sites if s['nse'] > 0.75])\n",
    "        good = len([s for s in common_sites if 0.5 < s['nse'] <= 0.75])\n",
    "        satisfactory = len([s for s in common_sites if 0.2 < s['nse'] <= 0.5])\n",
    "        unsatisfactory = len([s for s in common_sites if s['nse'] <= 0.2])\n",
    "        \n",
    "        f.write(\"PERFORMANCE CATEGORIES:\\n\")\n",
    "        f.write(f\"  Excellent (NSE > 0.75): {excellent} watersheds\\n\")\n",
    "        f.write(f\"  Good (0.5 < NSE â¤ 0.75): {good} watersheds\\n\")\n",
    "        f.write(f\"  Satisfactory (0.2 < NSE â¤ 0.5): {satisfactory} watersheds\\n\")\n",
    "        f.write(f\"  Unsatisfactory (NSE â¤ 0.2): {unsatisfactory} watersheds\\n\\n\")\n",
    "        \n",
    "        f.write(\"BEST PERFORMING WATERSHEDS (by NSE):\\n\")\n",
    "        sorted_sites = sorted(common_sites, key=lambda x: x['nse'], reverse=True)\n",
    "        for i, site in enumerate(sorted_sites[:5]):\n",
    "            f.write(f\"  {i+1}. {site['watershed_id']}: NSE={site['nse']:.3f}, KGE={site['kge']:.3f}, Area={site['area_km2']:.0f} kmÂ²\\n\")\n",
    "\n",
    "print(f\"â Final summary report saved: {summary_report_path}\")\n",
    "\n",
    "print(f\"\\nð Step 3 Complete: CAMELS-SPAT Streamflow Validation Analysis\")\n",
    "print(f\"   ð Results saved to: {experiment_dir}\")\n",
    "print(f\"   ð Streamflow domain overview: {total_complete}/{total_selected} watersheds with complete validation\")\n",
    "\n",
    "if common_sites:\n",
    "    nse_values = [site['nse'] for site in common_sites]\n",
    "    kge_values = [site['kge'] for site in common_sites if site['kge'] != -999]\n",
    "    \n",
    "    print(f\"   ð Streamflow analysis: {len(common_sites)} watersheds with sim/obs comparison\")\n",
    "    print(f\"   ð NSE performance: Mean = {np.mean(nse_values):.3f}\")\n",
    "    if kge_values:\n",
    "        print(f\"   ð KGE performance: Mean = {np.mean(kge_values):.3f}\")\n",
    "else:\n",
    "    print(f\"   ð Performance: Awaiting more simulation results\")\n",
    "\n",
    "print(f\"\\nâ Large Sample CAMELS-SPAT Streamflow Analysis Complete!\")\n",
    "print(f\"   ð Multi-basin streamflow hydrology validation achieved\")\n",
    "print(f\"   ð Statistical patterns identified across continental watershed gradients\")\n",
    "print(f\"   ðï¸ Tutorial series culmination: Point â Watershed â Continental â Multi-site analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041626d9-f819-456a-a159-b8fed3e9ce0b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
