{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARAVAN Large Sample Experiment Tutorial\n",
    "\n",
    "This notebook demonstrates how to run CONFLUENCE over multiple watersheds from the CARAVAN dataset for large-sample hydrology analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the large sample experiment\n",
    "experiment_config = {\n",
    "    'dataset': 'camels',  # CARAVAN dataset to use\n",
    "    'max_watersheds': 5,  # Number of watersheds to process\n",
    "    'dry_run': False,  # Set to True to test without submitting jobs\n",
    "    'experiment_name': 'caravan_tutorial',\n",
    "    'template_config': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/config_caravan_template.yaml',\n",
    "    'config_dir': '/home/darri.eythorsson/code/CONFLUENCE/0_config_files/caravan',\n",
    "    'caravan_script': '/home/darri.eythorsson/code/CONFLUENCE/9_scripts/run_watersheds_caravan.py'\n",
    "}\n",
    "\n",
    "# Create experiment directory\n",
    "experiment_dir = Path(f\"./experiments/{experiment_config['experiment_name']}\")\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "with open(experiment_dir / 'experiment_config.yaml', 'w') as f:\n",
    "    yaml.dump(experiment_config, f)\n",
    "\n",
    "print(f\"Experiment configured: {experiment_config['experiment_name']}\")\n",
    "print(f\"Processing {experiment_config['max_watersheds']} watersheds from {experiment_config['dataset']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. List Available CARAVAN Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available CARAVAN datasets\n",
    "cmd = ['python', experiment_config['caravan_script'], '--list-datasets']\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discover Watersheds in Selected Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get watershed information for the selected dataset\n",
    "watersheds_csv = experiment_dir / f\"{experiment_config['dataset']}_watersheds.csv\"\n",
    "\n",
    "cmd = [\n",
    "    'python', experiment_config['caravan_script'],\n",
    "    '--dataset', experiment_config['dataset'],\n",
    "    '--watersheds-csv', str(watersheds_csv)\n",
    "]\n",
    "\n",
    "print(f\"Discovering watersheds in {experiment_config['dataset']}...\")\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "# Load watershed information\n",
    "if watersheds_csv.exists():\n",
    "    watersheds_df = pd.read_csv(watersheds_csv)\n",
    "    print(f\"Found {len(watersheds_df)} watersheds\")\n",
    "    print(\"\\nFirst 5 watersheds:\")\n",
    "    print(watersheds_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Launch CONFLUENCE for Multiple Watersheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the large sample experiment\n",
    "cmd = [\n",
    "    'python', experiment_config['caravan_script'],\n",
    "    '--dataset', experiment_config['dataset'],\n",
    "    '--template', experiment_config['template_config'],\n",
    "    '--config-dir', experiment_config['config_dir'],\n",
    "    '--max-watersheds', str(experiment_config['max_watersheds']),\n",
    "    '--watersheds-csv', str(watersheds_csv)\n",
    "]\n",
    "\n",
    "if experiment_config['dry_run']:\n",
    "    cmd.append('--dry-run')\n",
    "    print(\"DRY RUN MODE - No jobs will be submitted\")\n",
    "\n",
    "print(f\"Launching CONFLUENCE for {experiment_config['max_watersheds']} watersheds...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "\n",
    "# Execute\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(result.stdout[:500] + \"...\" if len(result.stdout) > 500 else result.stdout)\n",
    "\n",
    "# Save submission log\n",
    "with open(experiment_dir / 'submission.log', 'w') as f:\n",
    "    f.write(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitor Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check SLURM job status\n",
    "def check_job_status(user=None):\n",
    "    user = user or os.environ.get('USER')\n",
    "    cmd = ['squeue', '-u', user]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return result.stdout\n",
    "\n",
    "print(\"Current jobs:\")\n",
    "print(check_job_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Find Completed Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find completed watershed simulations\n",
    "confluence_data_dir = Path(\"/work/comphyd_lab/data/CONFLUENCE_data\")\n",
    "caravan_dir = confluence_data_dir / \"caravan\"\n",
    "\n",
    "completed = []\n",
    "if caravan_dir.exists():\n",
    "    for domain_dir in caravan_dir.glob(f\"domain_{experiment_config['dataset']}_*\"):\n",
    "        watershed_id = domain_dir.name.split('_')[-1]\n",
    "        sim_dir = domain_dir / \"simulations\"\n",
    "        \n",
    "        # Check if simulation files exist\n",
    "        if sim_dir.exists() and list(sim_dir.rglob(\"*.nc\")):\n",
    "            completed.append({\n",
    "                'watershed_id': watershed_id,\n",
    "                'domain_dir': domain_dir,\n",
    "                'sim_dir': sim_dir\n",
    "            })\n",
    "\n",
    "print(f\"Completed simulations: {len(completed)}\")\n",
    "for ws in completed:\n",
    "    print(f\"  - Watershed {ws['watershed_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to load results\n",
    "def load_summa_output(sim_dir, variable='scalarSWE'):\n",
    "    import xarray as xr\n",
    "    \n",
    "    output_files = list(sim_dir.rglob(\"*timestep*.nc\"))\n",
    "    if output_files:\n",
    "        ds = xr.open_dataset(output_files[0])\n",
    "        if variable in ds.variables:\n",
    "            return pd.DataFrame({\n",
    "                'time': pd.to_datetime(ds.time.values),\n",
    "                'value': ds[variable].values.flatten()\n",
    "            })\n",
    "    return None\n",
    "\n",
    "# Plot results for completed watersheds\n",
    "if completed:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for ws in completed[:3]:  # Plot first 3\n",
    "        data = load_summa_output(ws['sim_dir'])\n",
    "        if data is not None:\n",
    "            ax.plot(data['time'], data['value'], \n",
    "                   label=f\"Watershed {ws['watershed_id']}\", \n",
    "                   linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Snow Water Equivalent (mm)')\n",
    "    ax.set_title(f'SWE Comparison - {experiment_config[\"dataset\"].upper()} Watersheds')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate Simple Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NSE for watersheds with streamflow data\n",
    "def calculate_nse(obs, sim):\n",
    "    \"\"\"Calculate Nash-Sutcliffe Efficiency\"\"\"\n",
    "    mask = ~(np.isnan(obs) | np.isnan(sim))\n",
    "    obs, sim = obs[mask], sim[mask]\n",
    "    \n",
    "    if len(obs) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return 1 - np.sum((obs - sim)**2) / np.sum((obs - np.mean(obs))**2)\n",
    "\n",
    "# Example of loading observed data and calculating metrics\n",
    "metrics = []\n",
    "for ws in completed[:3]:  # Process first 3\n",
    "    try:\n",
    "        # Load observed streamflow\n",
    "        obs_file = ws['domain_dir'] / 'observations' / 'streamflow' / 'raw_data' / f\"{experiment_config['dataset']}_{ws['watershed_id']}_Discharge.csv\"\n",
    "        \n",
    "        if obs_file.exists():\n",
    "            obs_df = pd.read_csv(obs_file)\n",
    "            # Here you would align with simulated data and calculate metrics\n",
    "            print(f\"Found observations for watershed {ws['watershed_id']}\")\n",
    "            \n",
    "            # Placeholder for actual metric calculation\n",
    "            metrics.append({\n",
    "                'watershed_id': ws['watershed_id'],\n",
    "                'nse': np.random.random()  # Replace with actual calculation\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ws['watershed_id']}: {e}\")\n",
    "\n",
    "if metrics:\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate experiment summary\n",
    "print(\"=== CARAVAN Large Sample Experiment Summary ===\")\n",
    "print(f\"Dataset: {experiment_config['dataset']}\")\n",
    "print(f\"Experiment: {experiment_config['experiment_name']}\")\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nWatersheds:\")\n",
    "print(f\"  Requested: {experiment_config['max_watersheds']}\")\n",
    "print(f\"  Completed: {len(completed)}\")\n",
    "\n",
    "if metrics:\n",
    "    print(f\"\\nPerformance:\")\n",
    "    print(f\"  Mean NSE: {metrics_df['nse'].mean():.3f}\")\n",
    "    print(f\"  Best NSE: {metrics_df['nse'].max():.3f}\")\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    'experiment': experiment_config,\n",
    "    'completed_watersheds': [ws['watershed_id'] for ws in completed],\n",
    "    'date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(experiment_dir / 'summary.yaml', 'w') as f:\n",
    "    yaml.dump(summary, f)\n",
    "\n",
    "print(f\"\\nResults saved to: {experiment_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This tutorial covered the basics of running CONFLUENCE over multiple CARAVAN watersheds. For more advanced analysis:\n",
    "\n",
    "1. **Regional Analysis**: Group watersheds by climate or geography\n",
    "2. **Model Comparison**: Test different model structures\n",
    "3. **Parameter Transfer**: Develop regionalization relationships\n",
    "4. **Machine Learning**: Predict performance from attributes\n",
    "5. **Climate Scenarios**: Run future projections\n",
    "\n",
    "See the full documentation for detailed examples of these analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE",
   "language": "python",
   "name": "confluence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}