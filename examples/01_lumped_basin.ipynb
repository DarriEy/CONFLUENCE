{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Lumped Basin Workflow (Bow River at Banff)\n",
    "\n",
    "This notebook walks through the complete CONFLUENCE workflow for a lumped basin model using the Bow River at Banff as an example. We'll execute each step individually to understand what's happening at each stage.\n",
    "\n",
    "## Introduction to CONFLUENCE\n",
    "\n",
    "CONFLUENCE (Community Optimization and Numerical Framework for Large-domain Understanding of Environmental Networks and Computational Exploration) is designed to address a fundamental challenge in hydrological modeling: the overwhelming number of decisions required to set up and run a hydrological model.\n",
    "\n",
    "### The Challenge of Hydrological Modeling Decisions\n",
    "\n",
    "Hydrological modeling involves numerous interconnected decisions at every stage:\n",
    "- **Domain Definition**: What area should we model? How should we delineate the watershed?\n",
    "- **Data Processing**: Which forcing datasets? What temporal and spatial resolution? \n",
    "- **Model Selection**: Which hydrological model? What process representations?\n",
    "- **Parameterization**: Which parameters to calibrate? What are reasonable ranges?\n",
    "- **Evaluation**: What metrics? Which observation datasets?\n",
    "\n",
    "Each decision impacts the others, creating a complex decision tree that can be overwhelming for both novice and experienced modelers.\n",
    "\n",
    "### How CONFLUENCE Helps\n",
    "\n",
    "CONFLUENCE addresses this complexity by:\n",
    "1. **Organizing the workflow** into clear, sequential steps\n",
    "2. **Standardizing data structures** across different models and datasets\n",
    "3. **Providing sensible defaults** while allowing full customization\n",
    "4. **Maintaining detailed provenance** of all decisions made\n",
    "5. **Enabling reproducibility** through comprehensive configuration management\n",
    "\n",
    "### CONFLUENCE's Code Structure: Organized by Function\n",
    "\n",
    "CONFLUENCE uses an object-oriented design where different aspects of hydrological modeling are handled by specialized classes called \"managers\". This is like having different experts, each responsible for their domain:\n",
    "\n",
    "```python\n",
    "# Each manager handles a specific task\n",
    "project_manager = ProjectManager(config, logger)     # Project setup\n",
    "domain_manager = DomainManager(config, logger)       # Watershed delineation  \n",
    "data_manager = DataManager(config, logger)           # Data processing\n",
    "model_manager = ModelManager(config, logger)         # Model operations\n",
    "```\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Instead of one giant script with thousands of lines, CONFLUENCE breaks the workflow into logical pieces:\n",
    "\n",
    "```python\n",
    "# Traditional approach - everything mixed together\n",
    "def run_model():\n",
    "    # 1000+ lines of mixed code...\n",
    "    setup_directories()\n",
    "    download_data()\n",
    "    delineate_watershed()\n",
    "    process_forcings()\n",
    "    run_simulation()\n",
    "    # etc...\n",
    "\n",
    "# CONFLUENCE approach - organized by function\n",
    "project_manager.setup_project()          # All project setup code in one place\n",
    "domain_manager.define_domain()           # All watershed code in one place\n",
    "data_manager.acquire_forcings()          # All data code in one place\n",
    "model_manager.run_model()               # All model code in one place\n",
    "```\n",
    "\n",
    "This organization makes it easier to:\n",
    "\n",
    "Find and modify specific functionality\n",
    "Add new models or data sources\n",
    "Debug issues in specific components\n",
    "Reuse code for different projects\n",
    "\n",
    "Throughout this tutorial, you'll see how each manager handles its part of the workflow, working together to complete the full modeling process.\n",
    "\n",
    "\n",
    "## Overview of This Tutorial\n",
    "\n",
    "We'll work through the simplest case in hydrological modeling: a lumped basin model. This treats the entire watershed as a single unit, making it an ideal starting point for understanding the CONFLUENCE workflow.\n",
    "\n",
    "We'll run through:\n",
    "1. Project setup and configuration\n",
    "2. Domain definition (watershed delineation)\n",
    "3. Data acquisition (forcings and attributes)\n",
    "4. Model preprocessing\n",
    "5. Model execution\n",
    "6. Results visualization\n",
    "\n",
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import contextily as cx\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import CONFLUENCE components\n",
    "from utils.project.project_manager import ProjectManager\n",
    "from utils.project.workflow_orchestrator import WorkflowOrchestrator\n",
    "from utils.config.config_utils import ConfigManager\n",
    "from utils.config.logging_manager import LoggingManager\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize CONFLUENCE\n",
    "First, let's set up our directories and load the configuration. CONFLUENCE uses a centralized configuration file that controls all aspects of the modeling workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # ‚Üê User should modify this path\n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the template configuration\n",
    "config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "\n",
    "# Update the config with our directory paths\n",
    "config_manager = ConfigManager(config_path)\n",
    "config = config_manager.config\n",
    "\n",
    "# Update paths\n",
    "config['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "\n",
    "# Initialize logger\n",
    "logging_manager = LoggingManager(config)\n",
    "logger = logging_manager.logger\n",
    "\n",
    "# Display key configuration settings\n",
    "print(\"=== Directory Configuration ===\")\n",
    "print(f\"Code Directory: {CONFLUENCE_CODE_DIR}\")\n",
    "print(f\"Data Directory: {CONFLUENCE_DATA_DIR}\")\n",
    "print(\"\\n=== Key Configuration Settings ===\")\n",
    "print(f\"Domain Name: {config['DOMAIN_NAME']}\")\n",
    "print(f\"Pour Point: {config['POUR_POINT_COORDS']}\")\n",
    "print(f\"Spatial Mode: {config['SPATIAL_MODE']}\")\n",
    "print(f\"Model: {config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Simulation Period: {config['EXPERIMENT_TIME_START']} to {config['EXPERIMENT_TIME_END']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step 1: Project Setup - Organizing the Modeling Workflow\n",
    "The first step in any CONFLUENCE workflow is to establish a well-organized project structure. This might seem trivial, but it's crucial for:\n",
    "\n",
    "Maintaining consistency across different experiments\n",
    "Ensuring all components can find required files\n",
    "Enabling reproducibility\n",
    "Facilitating collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the project manager\n",
    "project_manager = ProjectManager(config, logger)\n",
    "\n",
    "# Setup project directories\n",
    "print(\"Creating project directory structure...\")\n",
    "project_dir = project_manager.setup_project()\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  üìÅ {item.name}\")\n",
    "\n",
    "# Explain what each directory is for\n",
    "print(\"\\nDirectory purposes:\")\n",
    "print(\"  üìÅ shapefiles: Domain geometry (watershed, pour points, river network)\")\n",
    "print(\"  üìÅ attributes: Static characteristics (elevation, soil, land cover)\")\n",
    "print(\"  üìÅ forcing: Meteorological inputs (precipitation, temperature)\")\n",
    "print(\"  üìÅ simulations: Model outputs\")\n",
    "print(\"  üìÅ evaluation: Performance metrics and comparisons\")\n",
    "print(\"  üìÅ plots: Visualizations\")\n",
    "print(\"  üìÅ optimisation: Calibration results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step 2: Define the Pour Point - The Starting Point of Watershed Modeling\n",
    "For lumped catchment modeling, everything begins with defining a single point: the watershed outlet or \"pour point\". This is where all water from the upstream area flows through. In our case, it's at the WSC gauging station where the Bow River flows past the town of Banff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pour point shapefile from coordinates\n",
    "print(f\"Creating pour point shapefile from coordinates: {config['POUR_POINT_COORDS']}\")\n",
    "pour_point_path = project_manager.create_pour_point()\n",
    "\n",
    "# Visualize the pour point\n",
    "if pour_point_path and pour_point_path.exists():\n",
    "    gdf = gpd.read_file(pour_point_path)\n",
    "    \n",
    "    # Reproject to Web Mercator for basemap compatibility\n",
    "    gdf_web = gdf.to_crs(epsg=3857)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Plot the pour point\n",
    "    gdf_web.plot(ax=ax, color='red', markersize=200, marker='o', \n",
    "                 edgecolor='white', linewidth=2, zorder=5)\n",
    "    \n",
    "    # Add basemap\n",
    "    cx.add_basemap(ax, \n",
    "                   source=cx.providers.CartoDB.Positron,\n",
    "                   zoom=10,\n",
    "                   alpha=0.8)\n",
    "    \n",
    "    # Calculate bounds with some padding\n",
    "    minx, miny, maxx, maxy = gdf_web.total_bounds\n",
    "    pad = 5000  # 5km padding\n",
    "    ax.set_xlim(minx - pad, maxx + pad)\n",
    "    ax.set_ylim(miny - pad, maxy + pad)\n",
    "    \n",
    "    # Add context\n",
    "    lat, lon = gdf.geometry.iloc[0].y, gdf.geometry.iloc[0].x\n",
    "    ax.text(minx + 1000, maxy - 1000,\n",
    "            'Pour Point: Where all upstream\\nwater flows through', \n",
    "            fontsize=14, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.8),\n",
    "            fontweight='bold')\n",
    "    \n",
    "    ax.set_title(f'Pour Point Location: Bow River at Banff\\nCoordinates: {lat:.4f}¬∞N, {lon:.4f}¬∞W', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step 3: Acquire Geospatial Data - Characterizing the Landscape\n",
    "Before we can delineate the watershed, we need elevation data. CONFLUENCE also acquires soil and land cover data at this stage for later use in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data manager\n",
    "from utils.geospatial.geospatial_utils import GeospatialDataAcquisition\n",
    "geospatial_acquisition = GeospatialDataAcquisition(config, logger)\n",
    "\n",
    "print(\"Acquiring geospatial attributes (DEM, soil, land cover)...\")\n",
    "print(\"This step downloads data from configured sources.\")\n",
    "print(f\"Bounding box: {config['BOUNDING_BOX_COORDS']}\")\n",
    "\n",
    "# Acquire digital elevation model (DEM)\n",
    "geospatial_acquisition.acquire_dem()\n",
    "\n",
    "# Check downloaded files\n",
    "attribute_dirs = {\n",
    "    'DEM': project_dir / 'attributes' / 'elevation' / 'dem',\n",
    "}\n",
    "\n",
    "print(\"\\nDownloaded attribute files:\")\n",
    "for name, path in attribute_dirs.items():\n",
    "    if path.exists():\n",
    "        files = list(path.glob('*.tif')) + list(path.glob('*.tiff'))\n",
    "        print(f\"  {name}: {len(files)} files\")\n",
    "        \n",
    "print(\"\\nThe DEM is crucial for:\")\n",
    "print(\"  - Watershed delineation\")\n",
    "print(\"  - Flow direction calculation\")\n",
    "print(\"  - Elevation-dependent processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Step 4: Watershed Delineation - Defining the Model Domain\n",
    "Now comes a critical step: delineating the watershed boundary. This defines exactly which area contributes water to our pour point. CONFLUENCE uses terrain analysis algorithms to trace upstream from the pour point, identifying all areas that drain to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize domain manager\n",
    "from utils.geospatial.domain_manager import DomainManager\n",
    "domain_manager = DomainManager(config, logger)\n",
    "\n",
    "print(f\"Delineating watershed using method: {config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "print(f\"Tool: {config['LUMPED_WATERSHED_METHOD']}\")\n",
    "print(\"\\nWhat's happening:\")\n",
    "print(\"  1. Calculate flow directions from DEM\")\n",
    "print(\"  2. Trace upstream from pour point\")\n",
    "print(\"  3. Identify contributing area\")\n",
    "print(\"  4. Create watershed boundary\")\n",
    "\n",
    "# Delineate the domain\n",
    "watershed_path = domain_manager.define_domain()\n",
    "\n",
    "# Check outputs\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "if basin_path.exists():\n",
    "    basin_files = list(basin_path.glob('*.shp'))\n",
    "    print(f\"\\nCreated {len(basin_files)} basin shapefile(s)\")\n",
    "    for f in basin_files:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the Delineated Domain\n",
    "Let's see what our watershed looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the watershed\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Load and plot watershed\n",
    "if basin_files:\n",
    "    basin_gdf = gpd.read_file(basin_files[0])\n",
    "    \n",
    "    # Reproject for visualization\n",
    "    basin_web = basin_gdf.to_crs(epsg=3857)\n",
    "    pour_web = gdf.to_crs(epsg=3857)\n",
    "    \n",
    "    # Plot watershed\n",
    "    basin_web.plot(ax=ax, facecolor='lightblue', edgecolor='navy', \n",
    "                   linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Add pour point\n",
    "    pour_web.plot(ax=ax, color='red', markersize=200, marker='o', \n",
    "                  edgecolor='white', linewidth=2, zorder=5)\n",
    "    \n",
    "    # Add basemap\n",
    "    cx.add_basemap(ax, source=cx.providers.OSM.TopoMap, zoom=9)\n",
    "    \n",
    "    # Set extent\n",
    "    minx, miny, maxx, maxy = basin_web.total_bounds\n",
    "    pad = 5000\n",
    "    ax.set_xlim(minx - pad, maxx + pad)\n",
    "    ax.set_ylim(miny - pad, maxy + pad)\n",
    "    \n",
    "    # Add labels\n",
    "    ax.text(minx + 1000, maxy - 1000,\n",
    "            f'Watershed Area: {basin_gdf.geometry.area.sum() / 1e6:.0f} km¬≤', \n",
    "            fontsize=14, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "            fontweight='bold')\n",
    "    \n",
    "    ax.set_title('Bow River Watershed at Banff\\nAll water from this area flows to the pour point', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Step 5: Create Hydrologic Response Units (HRUs)\n",
    "For a lumped model, the entire watershed becomes a single Hydrologic Response Unit (HRU). This simplification assumes uniform characteristics across the watershed - obviously an approximation, but useful for many applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Creating lumped HRU using method: {config['DOMAIN_DISCRETIZATION']}\")\n",
    "print(\"\\nFor lumped modeling:\")\n",
    "print(\"  - Entire watershed = 1 HRU\")\n",
    "print(\"  - Spatially averaged properties\")\n",
    "print(\"  - Simplified computational domain\")\n",
    "\n",
    "# Create HRU\n",
    "hru_path = domain_manager.discretize_domain()\n",
    "\n",
    "# Check the created HRU shapefile\n",
    "hru_dir = project_dir / 'shapefiles' / 'catchment'\n",
    "if hru_dir.exists():\n",
    "    hru_files = list(hru_dir.glob('*.shp'))\n",
    "    print(f\"\\nCreated {len(hru_files)} HRU shapefile(s)\")\n",
    "    \n",
    "    if hru_files:\n",
    "        # Load and display HRU properties\n",
    "        hru_gdf = gpd.read_file(hru_files[0])\n",
    "        print(\"\\nHRU Properties:\")\n",
    "        print(f\"Number of HRUs: {len(hru_gdf)}\")\n",
    "        print(f\"Total area: {hru_gdf.geometry.area.sum() / 1e6:.2f} km¬≤\")\n",
    "        \n",
    "        # For lumped model, should be single HRU\n",
    "        if len(hru_gdf) == 1:\n",
    "            print(\"‚úì Successfully created single lumped HRU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Step 6: Process Observed Streamflow Data\n",
    "To evaluate our model, we need observed streamflow data. CONFLUENCE can work with various data sources. For the Bow River, we'll use Water Survey of Canada (WSC) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data manager\n",
    "from utils.data.data_utils import ObservedDataProcessor\n",
    "obs_processor = ObservedDataProcessor(config, logger)\n",
    "\n",
    "print(f\"Processing observed streamflow data from: {config['STREAMFLOW_DATA_PROVIDER']}\")\n",
    "print(f\"Station ID: {config['STATION_ID']}\")\n",
    "print(\"\\nThis step:\")\n",
    "print(\"  - Downloads or loads streamflow observations\")\n",
    "print(\"  - Converts units if needed\")\n",
    "print(\"  - Resamples to model timestep\")\n",
    "print(\"  - Fills gaps where possible\")\n",
    "\n",
    "# Process streamflow data\n",
    "obs_processor.process_streamflow_data()\n",
    "\n",
    "# Visualize the data\n",
    "obs_path = project_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "if obs_path.exists():\n",
    "    obs_df = pd.read_csv(obs_path)\n",
    "    obs_df['datetime'] = pd.to_datetime(obs_df['datetime'])\n",
    "    \n",
    "    print(f\"\\nProcessed streamflow data:\")\n",
    "    print(f\"Period: {obs_df['datetime'].min()} to {obs_df['datetime'].max()}\")\n",
    "    print(f\"Number of records: {len(obs_df)}\")\n",
    "    \n",
    "    # Create informative plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(obs_df['datetime'], obs_df['discharge_cms'], \n",
    "            linewidth=1.5, color='blue', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Discharge (m¬≥/s)', fontsize=12)\n",
    "    ax.set_title(f'Observed Streamflow - Bow River at Banff (WSC Station: {config[\"STATION_ID\"]})\\nShowing seasonal patterns and interannual variability', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add context\n",
    "    ax.text(0.02, 0.95, f'Mean: {obs_df[\"discharge_cms\"].mean():.1f} m¬≥/s\\nMax: {obs_df[\"discharge_cms\"].max():.1f} m¬≥/s', \n",
    "            transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "            verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Step 7: Acquire Meteorological Forcing Data\n",
    "Hydrological models need meteorological inputs (forcings) like precipitation and temperature. CONFLUENCE handles the complex process of downloading, processing, and formatting this data.\n",
    "python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize forcing data acquisition\n",
    "from utils.data.data_utils import DataAcquisitionProcessor\n",
    "data_processor = DataAcquisitionProcessor(config, logger)\n",
    "\n",
    "print(f\"Acquiring forcing data: {config['FORCING_DATASET']}\")\n",
    "print(f\"Period: {config['EXPERIMENT_TIME_START']} to {config['EXPERIMENT_TIME_END']}\")\n",
    "print(\"\\nThis step:\")\n",
    "print(\"  - Downloads gridded meteorological data\")\n",
    "print(\"  - Extracts data for our watershed\")\n",
    "print(\"  - Converts units to model requirements\")\n",
    "print(\"  - Handles missing data\")\n",
    "\n",
    "# Acquire forcing data\n",
    "data_processor.run_data_acquisition()\n",
    "\n",
    "# Check progress\n",
    "forcing_path = project_dir / 'forcing' / 'easymore-outputs'\n",
    "if forcing_path.exists():\n",
    "    files = list(forcing_path.glob('*.nc'))\n",
    "    print(f\"\\nProcessed {len(files)} forcing files\")\n",
    "    \n",
    "    if files:\n",
    "        # Quick look at the data\n",
    "        import xarray as xr\n",
    "        ds = xr.open_dataset(files[0])\n",
    "        print(f\"\\nForcing variables: {list(ds.variables)}\")\n",
    "        print(f\"Time period: {ds.time.values[0]} to {ds.time.values[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Step 8: Model-Agnostic Preprocessing\n",
    "Before running any specific hydrological model, CONFLUENCE performs model-agnostic preprocessing. This creates standardized inputs that can be used by different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model manager\n",
    "from utils.models.model_manager import ModelManager\n",
    "model_manager = ModelManager(config, logger)\n",
    "\n",
    "print(\"Running model-agnostic preprocessing...\")\n",
    "print(\"This step:\")\n",
    "print(\"  - Calculates basin-averaged forcing\")\n",
    "print(\"  - Computes derived variables (like specific humidity)\")\n",
    "print(\"  - Creates model-agnostic NetCDF files\")\n",
    "\n",
    "# Run preprocessing\n",
    "model_manager.prepare_inputs()\n",
    "\n",
    "# Check outputs\n",
    "basin_forcing_path = project_dir / 'forcing' / 'basin_averaged_data'\n",
    "if basin_forcing_path.exists():\n",
    "    files = list(basin_forcing_path.glob('*.nc'))\n",
    "    print(f\"\\nCreated {len(files)} basin-averaged forcing files\")\n",
    "    \n",
    "    # Show a sample of the processed data\n",
    "    if files:\n",
    "        ds = xr.open_dataset(files[0])\n",
    "        print(f\"\\nProcessed variables: {list(ds.variables)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Step 9: Model-Specific Preprocessing\n",
    "Now we prepare inputs specific to our chosen hydrological model (SUMMA in this case). Each model has its own requirements for input format and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preparing {config['HYDROLOGICAL_MODEL']} input files...\")\n",
    "print(\"This includes:\")\n",
    "print(\"  - Model configuration files\")\n",
    "print(\"  - Parameter files\")\n",
    "print(\"  - Initial conditions\")\n",
    "print(\"  - Output specifications\")\n",
    "\n",
    "# Run model-specific preprocessing\n",
    "model_manager.configure_model()\n",
    "\n",
    "# Check created files\n",
    "settings_path = project_dir / 'settings' / config['HYDROLOGICAL_MODEL']\n",
    "if settings_path.exists():\n",
    "    files = list(settings_path.glob('*'))\n",
    "    print(f\"\\nCreated {len(files)} model configuration files:\")\n",
    "    for f in files[:10]:  # Show first 10\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Step 10: Run the Hydrological Model\n",
    "Finally, we run the actual hydrological simulation. CONFLUENCE manages the execution and monitors progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running {config['HYDROLOGICAL_MODEL']} model...\")\n",
    "print(\"This may take several minutes depending on:\")\n",
    "print(\"  - Simulation period length\")\n",
    "print(\"  - Model complexity\")\n",
    "print(\"  - System performance\")\n",
    "\n",
    "# Run the model\n",
    "model_manager.run_model()\n",
    "\n",
    "# Check outputs\n",
    "sim_path = project_dir / 'simulations' / config['EXPERIMENT_ID'] / config['HYDROLOGICAL_MODEL']\n",
    "if sim_path.exists():\n",
    "    files = list(sim_path.glob('*.nc'))\n",
    "    print(f\"\\nModel completed. Created {len(files)} output files.\")\n",
    "    \n",
    "    # Also check routing outputs if applicable\n",
    "    if config.get('ROUTING_MODEL') == 'mizuRoute':\n",
    "        mizu_path = project_dir / 'simulations' / config['EXPERIMENT_ID'] / 'mizuRoute'\n",
    "        if mizu_path.exists():\n",
    "            files = list(mizu_path.glob('*.nc'))\n",
    "            print(f\"Routing completed. Created {len(files)} output files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Step 11: Visualize and Evaluate Results\n",
    "Let's see how our model performed compared to observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analysis manager\n",
    "from utils.evaluation.analysis_manager import AnalysisManager\n",
    "analysis_manager = AnalysisManager(config, logger)\n",
    "\n",
    "print(\"Creating model evaluation plots...\")\n",
    "analysis_manager.evaluate_model()\n",
    "\n",
    "# Load and plot results\n",
    "results_path = project_dir / 'evaluation' / 'model_performance.csv'\n",
    "if results_path.exists():\n",
    "    results = pd.read_csv(results_path, index_col=0, parse_dates=True)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), height_ratios=[3, 1])\n",
    "    \n",
    "    # Time series comparison\n",
    "    ax1.plot(results.index, results['observed'], label='Observed', \n",
    "             color='blue', linewidth=2, alpha=0.7)\n",
    "    ax1.plot(results.index, results['simulated'], label='Simulated', \n",
    "             color='red', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    ax1.set_ylabel('Discharge (m¬≥/s)', fontsize=12)\n",
    "    ax1.set_title(f'Model Results: {config[\"DOMAIN_NAME\"]}\\nComparing simulated vs observed streamflow', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax2.scatter(results['observed'], results['simulated'], \n",
    "                alpha=0.5, s=20, color='purple')\n",
    "    ax2.plot([0, results[['observed', 'simulated']].max().max()], \n",
    "             [0, results[['observed', 'simulated']].max().max()], \n",
    "             'k--', alpha=0.5, label='1:1 line')\n",
    "    \n",
    "    ax2.set_xlabel('Observed Discharge (m¬≥/s)', fontsize=12)\n",
    "    ax2.set_ylabel('Simulated Discharge (m¬≥/s)', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance metrics\n",
    "    from utils.evaluation.metrics import calculate_metrics\n",
    "    metrics = calculate_metrics(results['observed'], results['simulated'])\n",
    "    \n",
    "    metric_text = f\"NSE: {metrics['NSE']:.3f}\\nKGE: {metrics['KGE']:.3f}\\nRMSE: {metrics['RMSE']:.2f} m¬≥/s\"\n",
    "    ax1.text(0.02, 0.15, metric_text, transform=ax1.transAxes,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "             verticalalignment='top', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary: Understanding the CONFLUENCE Workflow\n",
    "Congratulations! You've completed a full lumped basin modeling workflow with CONFLUENCE. Let's reflect on what we accomplished and how CONFLUENCE helped navigate the complex decision tree of hydrological modeling.\n",
    "The Decision Tree We Navigated:\n",
    "\n",
    "### Project Organization: Established a consistent structure for all files\n",
    "Domain Definition: From pour point ‚Üí watershed boundary ‚Üí single HRU\n",
    "Data Acquisition: Gathered forcing data, observations, and static attributes\n",
    "Model Configuration: Set up SUMMA with appropriate parameters\n",
    "Simulation: Ran the model for our specified period\n",
    "Evaluation: Compared results with observations\n",
    "\n",
    "## How CONFLUENCE Helped:\n",
    "\n",
    "### Standardized each step into a clear, reproducible process\n",
    "Handled complex data transformations behind the scenes\n",
    "Maintained consistency across different data sources and formats\n",
    "Provided sensible defaults while allowing customization\n",
    "Created a complete record of all decisions and processes\n",
    "\n",
    "## Next Steps You Could Try:\n",
    "\n",
    "### Experiment with different models (change HYDROLOGICAL_MODEL)\n",
    "Try distributed modeling (change SPATIAL_MODE to 'Distributed')\n",
    "Calibrate the model (use the optimization module)\n",
    "Analyze model sensitivity to different parameters\n",
    "Compare multiple model structures (decision analysis)\n",
    "\n",
    "## Key Outputs Created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of key outputs\n",
    "print(\"=== Workflow Complete ===\\n\")\n",
    "print(f\"Project: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Experiment: {confluence.config['EXPERIMENT_ID']}\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(\"=== Workflow Complete ===\\n\")\n",
    "print(f\"Project: {config['DOMAIN_NAME']}\")\n",
    "print(f\"Experiment: {config['EXPERIMENT_ID']}\")\n",
    "print(f\"Model: {config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"\\nKey outputs:\")\n",
    "print(f\"  - Watershed boundary: {project_dir}/shapefiles/river_basins/\")\n",
    "print(f\"  - Model configuration: {project_dir}/settings/{config['HYDROLOGICAL_MODEL']}/\")\n",
    "print(f\"  - Simulation results: {project_dir}/simulations/{config['EXPERIMENT_ID']}/\")\n",
    "print(f\"  - Performance metrics: {project_dir}/evaluation/\")\n",
    "print(f\"  - Visualizations: {project_dir}/plots/\")\n",
    "\n",
    "# Create a summary figure showing the workflow\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.text(0.5, 0.5, 'CONFLUENCE Workflow Complete!', \n",
    "        ha='center', va='center', fontsize=24, fontweight='bold')\n",
    "ax.text(0.5, 0.4, f'Successfully modeled {config[\"DOMAIN_NAME\"]}', \n",
    "        ha='center', va='center', fontsize=16)\n",
    "ax.text(0.5, 0.3, f'From {config[\"EXPERIMENT_TIME_START\"]} to {config[\"EXPERIMENT_TIME_END\"]}', \n",
    "        ha='center', va='center', fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()print(f\"  - Watershed shapefile: shapefiles/river_basins/\")\n",
    "print(f\"  - Model results: simulations/{confluence.config['EXPERIMENT_ID']}/\")\n",
    "print(f\"  - Plots: plots/results/\")\n",
    "print(f\"  - Forcing data: forcing/basin_averaged_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE (HPC Modules)",
   "language": "python",
   "name": "conf-env-hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
