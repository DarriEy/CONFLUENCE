{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Lumped Basin Workflow (Bow River at Banff)\n",
    "\n",
    "This notebook walks through the complete CONFLUENCE workflow for a lumped basin model using the Bow River at Banff as an example. We'll execute each step individually to understand what's happening at each stage.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll run through:\n",
    "1. Project setup and configuration\n",
    "2. Domain definition (watershed delineation)\n",
    "3. Data acquisition (forcings and attributes)\n",
    "4. Model preprocessing\n",
    "5. Model execution\n",
    "6. Results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import contextily as cx\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import CONFLUENCE\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Examine Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:18:35,619 - confluence_general - INFO - Initializing VariableHandler for dataset: ERA5 and model: SUMMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Directory Configuration ===\n",
      "Code Directory: /home/darri.eythorsson/code/CONFLUENCE\n",
      "Data Directory: /work/comphyd_lab/data/CONFLUENCE_data\n",
      "\n",
      "=== Key Configuration Settings ===\n",
      "Domain Name: Bow_at_Banff_lumped\n",
      "Pour Point: 51.1722/-115.5717\n",
      "Spatial Mode: Lumped\n",
      "Model: SUMMA\n",
      "Simulation Period: 2011-01-01 01:00 to 2022-12-31 23:00\n",
      "Project Directory: /work/comphyd_lab/data/CONFLUENCE_data/domain_Bow_at_Banff_lumped\n"
     ]
    }
   ],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # ‚Üê User should modify this path \n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the template configuration\n",
    "config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "\n",
    "# Before loading, let's update the config with our directory paths\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update the directory paths in the config\n",
    "config_dict['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config_dict['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "\n",
    "# Save updated config to a temporary file\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / 'config_active.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False)\n",
    "\n",
    "# Initialize CONFLUENCE with updated config\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "# Display key configuration settings\n",
    "print(\"=== Directory Configuration ===\")\n",
    "print(f\"Code Directory: {CONFLUENCE_CODE_DIR}\")\n",
    "print(f\"Data Directory: {CONFLUENCE_DATA_DIR}\")\n",
    "print(\"\\n=== Key Configuration Settings ===\")\n",
    "print(f\"Domain Name: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Pour Point: {confluence.config['POUR_POINT_COORDS']}\")\n",
    "print(f\"Spatial Mode: {confluence.config['SPATIAL_MODE']}\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Simulation Period: {confluence.config['EXPERIMENT_TIME_START']} to {confluence.config['EXPERIMENT_TIME_END']}\")\n",
    "print(f\"Project Directory: {confluence.project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step 1: Setup Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:18:37,465 - confluence_general - INFO - Setting up project for domain: Bow_at_Banff_lumped\n",
      "2025-05-10 13:18:37,479 - confluence_general - INFO - Project directory created at: /work/comphyd_lab/data/CONFLUENCE_data/domain_Bow_at_Banff_lumped\n",
      "2025-05-10 13:18:37,480 - confluence_general - INFO - shapefiles directories created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project directory structure...\n",
      "\n",
      "Created directories:\n",
      "  üìÅ _workLog_Bow_at_Banff_lumped\n",
      "  üìÅ attributes\n",
      "  üìÅ cache\n",
      "  üìÅ documentation\n",
      "  üìÅ emulation\n",
      "  üìÅ evaluation\n",
      "  üìÅ forcing\n",
      "  üìÅ observations\n",
      "  üìÅ optimisation\n",
      "  üìÅ plots\n",
      "  üìÅ settings\n",
      "  üìÅ shapefiles\n",
      "  üìÅ simulations\n"
     ]
    }
   ],
   "source": [
    "# Setup project directories\n",
    "print(\"Creating project directory structure...\")\n",
    "confluence.setup_project()\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(confluence.project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  üìÅ {item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step 2: Create Pour Point Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pour point shapefile from coordinates: 51.1722/-115.5717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:18:40,018 - pyogrio._io - INFO - Created 1 records\n",
      "2025-05-10 13:18:40,021 - confluence_general - INFO - Pour point shapefile created successfully: /work/comphyd_lab/data/CONFLUENCE_data/domain_Bow_at_Banff_lumped/shapefiles/pour_point/Bow_at_Banff_lumped_pourPoint.shp\n"
     ]
    }
   ],
   "source": [
    "# Create pour point shapefile from coordinates\n",
    "print(f\"Creating pour point shapefile from coordinates: {confluence.config['POUR_POINT_COORDS']}\")\n",
    "confluence.create_pourPoint()\n",
    "\n",
    "# Visualize the pour point\n",
    "pour_point_path = confluence.project_dir / 'shapefiles' / 'pour_point' / f\"{confluence.config['DOMAIN_NAME']}_pourPoint.shp\"\n",
    "if pour_point_path.exists():\n",
    "    import contextily as cx\n",
    "    \n",
    "    gdf = gpd.read_file(pour_point_path)\n",
    "    \n",
    "    # Reproject to Web Mercator for basemap compatibility\n",
    "    gdf_web = gdf.to_crs(epsg=3857)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Plot the pour point\n",
    "    gdf_web.plot(ax=ax, color='red', markersize=200, marker='o', \n",
    "                 edgecolor='white', linewidth=2, zorder=5)\n",
    "    \n",
    "    # Add basemap\n",
    "    cx.add_basemap(ax, \n",
    "                   source=cx.providers.CartoDB.Positron,\n",
    "                   zoom=15,\n",
    "                   alpha=0.8)\n",
    "    \n",
    "    # Calculate bounds with some padding\n",
    "    minx, miny, maxx, maxy = gdf_web.total_bounds\n",
    "    pad = 5000  # 5km padding in Web Mercator units\n",
    "    ax.set_xlim(minx - pad, maxx + pad)\n",
    "    ax.set_ylim(miny - pad, maxy + pad)\n",
    "    \n",
    "    # Add context label\n",
    "    # Convert back to lat/lon for the label positioning\n",
    "    lat, lon = gdf.geometry.iloc[0].y, gdf.geometry.iloc[0].x\n",
    "    label_point = gpd.GeoDataFrame(\n",
    "        geometry=gpd.points_from_xy([lon + 0.01], [lat + 0.01]),\n",
    "        crs='EPSG:4326'\n",
    "    ).to_crs(epsg=3857)\n",
    "    \n",
    "    ax.text(label_point.geometry.iloc[0].x, \n",
    "            label_point.geometry.iloc[0].y,\n",
    "            'Bow River at Banff\\n(Pour Point)', \n",
    "            fontsize=14, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.8),\n",
    "            fontweight='bold',\n",
    "            verticalalignment='bottom')\n",
    "    \n",
    "    # Add north arrow and scale bar\n",
    "    from matplotlib.patches import FancyArrowPatch\n",
    "    \n",
    "    # North arrow\n",
    "    arrow_x = ax.get_xlim()[0] + (ax.get_xlim()[1] - ax.get_xlim()[0]) * 0.9\n",
    "    arrow_y = ax.get_ylim()[0] + (ax.get_ylim()[1] - ax.get_ylim()[0]) * 0.85\n",
    "    arrow = FancyArrowPatch((arrow_x, arrow_y), \n",
    "                           (arrow_x, arrow_y + 1000),\n",
    "                           mutation_scale=20, \n",
    "                           color='black',\n",
    "                           zorder=10)\n",
    "    ax.add_patch(arrow)\n",
    "    ax.text(arrow_x, arrow_y + 1500, 'N', ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Add coordinates to title\n",
    "    ax.set_title(f'Pour Point Location: Bow River at Banff\\nCoordinates: {lat:.4f}¬∞N, {lon:.4f}¬∞W', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Remove axis labels (not meaningful in Web Mercator)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Pour point shapefile not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step 3: Acquire Geospatial Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire DEM, soil classes, and land cover\n",
    "print(\"Acquiring geospatial attributes (DEM, soil, land cover)...\")\n",
    "print(\"This step downloads data from configured sources.\")\n",
    "print(f\"Bounding box: {confluence.config['BOUNDING_BOX_COORDS']}\")\n",
    "\n",
    "confluence.acquire_attributes()\n",
    "\n",
    "# Check downloaded files\n",
    "attribute_dirs = {\n",
    "    'DEM': confluence.project_dir / 'attributes' / 'elevation' / 'dem',\n",
    "    'Soil': confluence.project_dir / 'attributes' / 'soilclass',\n",
    "    'Land': confluence.project_dir / 'attributes' / 'landclass'\n",
    "}\n",
    "\n",
    "print(\"\\nDownloaded attribute files:\")\n",
    "for name, path in attribute_dirs.items():\n",
    "    if path.exists():\n",
    "        files = list(path.glob('*.tif')) + list(path.glob('*.tiff'))\n",
    "        print(f\"  {name}: {len(files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Step 4: Define Domain (Watershed Delineation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delineate the watershed\n",
    "print(f\"Delineating watershed using method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "print(f\"Tool: {confluence.config['LUMPED_WATERSHED_METHOD']}\")\n",
    "print(f\"Stream threshold: {confluence.config['STREAM_THRESHOLD']}\")\n",
    "\n",
    "confluence.define_domain()\n",
    "\n",
    "# Check outputs\n",
    "basin_path = confluence.project_dir / 'shapefiles' / 'river_basins'\n",
    "if basin_path.exists():\n",
    "    basin_files = list(basin_path.glob('*.shp'))\n",
    "    print(f\"\\nCreated {len(basin_files)} basin shapefile(s)\")\n",
    "    for f in basin_files:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the Delineated Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the delineated domain\n",
    "print(\"Creating domain visualization...\")\n",
    "confluence.plot_domain()\n",
    "\n",
    "# Display the plot if created\n",
    "plot_path = confluence.project_dir / 'plots' / 'domain' / 'domain_map.png'\n",
    "if plot_path.exists():\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=str(plot_path)))\n",
    "else:\n",
    "    print(\"Domain plot not found. Creating simple visualization...\")\n",
    "    \n",
    "    # Try to load and plot the basin shapefile\n",
    "    basin_files = list((confluence.project_dir / 'shapefiles' / 'river_basins').glob('*.shp'))\n",
    "    if basin_files:\n",
    "        basin_gdf = gpd.read_file(basin_files[0])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        basin_gdf.plot(ax=ax, facecolor='lightblue', edgecolor='navy', linewidth=2)\n",
    "        \n",
    "        # Add pour point\n",
    "        if pour_point_path.exists():\n",
    "            pour_gdf = gpd.read_file(pour_point_path)\n",
    "            pour_gdf.plot(ax=ax, color='red', markersize=100, marker='o', zorder=5)\n",
    "        \n",
    "        ax.set_title('Bow River Basin at Banff', fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Step 5: Domain Discretization (Create Lumped HRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lumped HRU\n",
    "print(f\"Creating lumped HRU using method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "confluence.discretize_domain()\n",
    "\n",
    "# Check the created HRU shapefile\n",
    "hru_path = confluence.project_dir / 'shapefiles' / 'catchment'\n",
    "if hru_path.exists():\n",
    "    hru_files = list(hru_path.glob('*.shp'))\n",
    "    print(f\"\\nCreated {len(hru_files)} HRU shapefile(s)\")\n",
    "    \n",
    "    if hru_files:\n",
    "        # Load and display HRU properties\n",
    "        hru_gdf = gpd.read_file(hru_files[0])\n",
    "        print(\"\\nHRU Properties:\")\n",
    "        print(f\"Number of HRUs: {len(hru_gdf)}\")\n",
    "        print(f\"Total area: {hru_gdf.geometry.area.sum() / 1e6:.2f} km¬≤\")\n",
    "        \n",
    "        # For lumped model, should be single HRU\n",
    "        if len(hru_gdf) == 1:\n",
    "            print(\"‚úì Successfully created single lumped HRU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Step 6: Process Observed Streamflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process observed streamflow data\n",
    "print(f\"Processing observed streamflow data from: {confluence.config['STREAMFLOW_DATA_PROVIDER']}\")\n",
    "print(f\"Station ID: {confluence.config['STATION_ID']}\")\n",
    "\n",
    "confluence.process_observed_data()\n",
    "\n",
    "# Check if processed data exists\n",
    "obs_path = confluence.project_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{confluence.config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "if obs_path.exists():\n",
    "    obs_df = pd.read_csv(obs_path)\n",
    "    print(f\"\\nProcessed streamflow data:\")\n",
    "    print(f\"Period: {obs_df.iloc[0]['Date']} to {obs_df.iloc[-1]['Date']}\")\n",
    "    print(f\"Number of records: {len(obs_df)}\")\n",
    "    \n",
    "    # Quick plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(pd.to_datetime(obs_df['Date']), obs_df['dischargeCubicMetresPerSecond'])\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Discharge (m¬≥/s)')\n",
    "    ax.set_title(f'Observed Streamflow - Bow River at Banff ({confluence.config[\"STATION_ID\"]})')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Step 7: Acquire Forcing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire forcing data\n",
    "print(f\"Acquiring forcing data: {confluence.config['FORCING_DATASET']}\")\n",
    "print(f\"Period: {confluence.config['FORCING_START_YEAR']} to {confluence.config['FORCING_END_YEAR']}\")\n",
    "print(f\"Variables: {confluence.config['FORCING_VARIABLES']}\")\n",
    "\n",
    "confluence.acquire_forcings()\n",
    "\n",
    "# Check downloaded data\n",
    "forcing_path = confluence.project_dir / 'forcing' / 'raw_data'\n",
    "if forcing_path.exists():\n",
    "    files = list(forcing_path.glob('*'))\n",
    "    print(f\"\\nDownloaded {len(files)} forcing files\")\n",
    "    for f in files[:5]:  # Show first 5\n",
    "        print(f\"  - {f.name}\")\n",
    "    if len(files) > 5:\n",
    "        print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Step 8: Model-Agnostic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process forcing data for the basin\n",
    "print(\"Running model-agnostic preprocessing...\")\n",
    "print(\"This step:\")\n",
    "print(\"  - Calculates basin-averaged forcing\")\n",
    "print(\"  - Applies lapse rate corrections\")\n",
    "print(\"  - Creates intersection shapefiles\")\n",
    "\n",
    "confluence.model_agnostic_pre_processing()\n",
    "\n",
    "# Check outputs\n",
    "basin_forcing_path = confluence.project_dir / 'forcing' / 'basin_averaged_data'\n",
    "if basin_forcing_path.exists():\n",
    "    files = list(basin_forcing_path.glob('*.nc'))\n",
    "    print(f\"\\nCreated {len(files)} basin-averaged forcing files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Step 9: Model-Specific Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model-specific input files\n",
    "print(f\"Preparing {confluence.config['HYDROLOGICAL_MODEL']} input files...\")\n",
    "confluence.model_specific_pre_processing()\n",
    "\n",
    "# Check model input directory\n",
    "model_input_path = confluence.project_dir / 'forcing' / f\"{confluence.config['HYDROLOGICAL_MODEL']}_input\"\n",
    "if model_input_path.exists():\n",
    "    files = list(model_input_path.glob('*'))\n",
    "    print(f\"\\nCreated {len(files)} model input files\")\n",
    "    \n",
    "# Check model settings\n",
    "settings_path = confluence.project_dir / 'settings' / confluence.config['HYDROLOGICAL_MODEL']\n",
    "if settings_path.exists():\n",
    "    files = list(settings_path.glob('*'))\n",
    "    print(f\"\\nCreated {len(files)} model configuration files\")\n",
    "    for f in files[:10]:  # Show first 10\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Step 10: Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hydrological model\n",
    "print(f\"Running {confluence.config['HYDROLOGICAL_MODEL']} model...\")\n",
    "print(\"This may take several minutes depending on simulation length and system performance.\")\n",
    "\n",
    "confluence.run_models()\n",
    "\n",
    "# Check output files\n",
    "sim_path = confluence.project_dir / 'simulations' / confluence.config['EXPERIMENT_ID'] / confluence.config['HYDROLOGICAL_MODEL']\n",
    "if sim_path.exists():\n",
    "    files = list(sim_path.glob('*.nc'))\n",
    "    print(f\"\\nModel completed. Created {len(files)} output files.\")\n",
    "    \n",
    "    if confluence.config['ROUTING_MODEL'] == 'mizuRoute':\n",
    "        mizu_path = confluence.project_dir / 'simulations' / confluence.config['EXPERIMENT_ID'] / 'mizuRoute'\n",
    "        if mizu_path.exists():\n",
    "            files = list(mizu_path.glob('*.nc'))\n",
    "            print(f\"Routing completed. Created {len(files)} output files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Step 11: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "print(\"Creating model output visualization...\")\n",
    "confluence.visualise_model_output()\n",
    "\n",
    "# Display the streamflow comparison plot\n",
    "plot_path = confluence.project_dir / 'plots' / 'results' / 'streamflow_comparison.png'\n",
    "if plot_path.exists():\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=str(plot_path)))\n",
    "else:\n",
    "    print(\"Streamflow comparison plot not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary and Next Steps\n",
    "\n",
    "Congratulations! You've completed a full lumped basin modeling workflow with CONFLUENCE.\n",
    "\n",
    "### What we accomplished:\n",
    "1. Set up a project for the Bow River at Banff\n",
    "2. Delineated the watershed as a single lumped unit\n",
    "3. Acquired and processed forcing data\n",
    "4. Ran a hydrological model (SUMMA)\n",
    "5. Visualized results against observations\n",
    "\n",
    "### Next steps you could try:\n",
    "1. Run model calibration (see notebook 05)\n",
    "2. Try different model configurations\n",
    "3. Extend the simulation period\n",
    "4. Compare with distributed model results\n",
    "\n",
    "### Key files created:\n",
    "- Project configuration: `config_template.yaml`\n",
    "- Model outputs: `simulations/{experiment_id}/`\n",
    "- Plots: `plots/results/`\n",
    "- Processed data: `forcing/basin_averaged_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of key outputs\n",
    "print(\"=== Workflow Complete ===\\n\")\n",
    "print(f\"Project: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Experiment: {confluence.config['EXPERIMENT_ID']}\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"\\nKey outputs:\")\n",
    "print(f\"  - Watershed shapefile: shapefiles/river_basins/\")\n",
    "print(f\"  - Model results: simulations/{confluence.config['EXPERIMENT_ID']}/\")\n",
    "print(f\"  - Plots: plots/results/\")\n",
    "print(f\"  - Forcing data: forcing/basin_averaged_data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE (HPC Modules)",
   "language": "python",
   "name": "conf-env-hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
