{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Lumped Basin Workflow (Bow River at Banff)\n",
    "\n",
    "This notebook walks through the complete CONFLUENCE workflow for a lumped basin model using the Bow River at Banff as an example. We'll execute each step individually to understand what's happening at each stage.\n",
    "\n",
    "## Introduction to CONFLUENCE\n",
    "\n",
    "CONFLUENCE is designed to address a fundamental challenge in hydrological modeling: the overwhelming number of decisions required to set up and run a hydrological model.\n",
    "\n",
    "### CONFLUENCE's Code Structure: Organized by Function\n",
    "\n",
    "CONFLUENCE uses an object-oriented design where different aspects of hydrological modeling are handled by specialized classes called \"managers\". This is like having different experts, each responsible for their domain:\n",
    "\n",
    "```python\n",
    "# Each manager handles a specific task\n",
    "project_manager = ProjectManager(config, logger)     # Project setup\n",
    "domain_manager = DomainManager(config, logger)       # Watershed delineation  \n",
    "data_manager = DataManager(config, logger)           # Data processing\n",
    "model_manager = ModelManager(config, logger)         # Model operations\n",
    "```\n",
    "\n",
    "Throughout this tutorial, you'll see how each manager handles its part of the workflow, working together to complete the full modeling process.\n",
    "\n",
    "\n",
    "## Overview of This Tutorial\n",
    "\n",
    "We'll work through the simplest case in hydrological modeling: a lumped basin model. This treats the entire watershed as a single unit, making it an ideal starting point for understanding the CONFLUENCE workflow.\n",
    "\n",
    "We'll run through:\n",
    "1. Project setup and configuration\n",
    "2. Domain definition (watershed delineation)\n",
    "3. Data acquisition (forcings and attributes)\n",
    "4. Model preprocessing\n",
    "5. Model execution\n",
    "6. Results visualization\n",
    "\n",
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize CONFLUENCE\n",
    "First, let's set up our directories and load the configuration. CONFLUENCE uses a centralized configuration file that controls all aspects of the modeling workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # ‚Üê User should modify this path\n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load and update configuration\n",
    "config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "\n",
    "# Read config file and update paths\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "config_dict['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config_dict['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "\n",
    "# Save updated config to a temporary file\n",
    "temp_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_notebook.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f)\n",
    "\n",
    "# Initialize CONFLUENCE\n",
    "confluence = CONFLUENCE(temp_config_path)\n",
    "\n",
    "# Display configuration\n",
    "print(\"=== Directory Configuration ===\")\n",
    "print(f\"Code Directory: {CONFLUENCE_CODE_DIR}\")\n",
    "print(f\"Data Directory: {CONFLUENCE_DATA_DIR}\")\n",
    "print(\"\\n=== Key Configuration Settings ===\")\n",
    "print(f\"Domain Name: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Pour Point: {confluence.config['POUR_POINT_COORDS']}\")\n",
    "print(f\"Spatial Mode: {confluence.config['SPATIAL_MODE']}\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Simulation Period: {confluence.config['EXPERIMENT_TIME_START']} to {confluence.config['EXPERIMENT_TIME_END']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Project Setup - Organizing the Modeling Workflow\n",
    "The first step in any CONFLUENCE workflow is to establish a well-organized project structure. This might seem trivial, but it's crucial for:\n",
    "\n",
    "- Maintaining consistency across different experiments\n",
    "- Ensuring all components can find required files\n",
    "- Enabling reproducibility\n",
    "- Facilitating collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Project Initialization\n",
    "print(\"=== Step 1: Project Initialization ===\")\n",
    "\n",
    "# Setup project\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# Create pour point\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  üìÅ {item.name}\")\n",
    "\n",
    "print(\"\\nDirectory purposes:\")\n",
    "print(\"  üìÅ shapefiles: Domain geometry (watershed, pour points, river network)\")\n",
    "print(\"  üìÅ attributes: Static characteristics (elevation, soil, land cover)\")\n",
    "print(\"  üìÅ forcing: Meteorological inputs (precipitation, temperature)\")\n",
    "print(\"  üìÅ simulations: Model outputs\")\n",
    "print(\"  üìÅ evaluation: Performance metrics and comparisons\")\n",
    "print(\"  üìÅ plots: Visualizations\")\n",
    "print(\"  üìÅ optimisation: Calibration results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geospatial Domain Definition and Analysis - A data acquisition \n",
    "Before we can delineate the watershed, we need elevation data. CONFLUENCE also acquires soil and land cover data at this stage for later use in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Geospatial Domain Definition and Analysis\n",
    "print(\"=== Step 2: Geospatial Domain Definition and Analysis ===\")\n",
    "\n",
    "# Acquire attributes\n",
    "print(\"Acquiring geospatial attributes (DEM, soil, land cover)...\")\n",
    "confluence.managers['data'].acquire_attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Geospatial Domain Definition and Analysis - Delineation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define domain\n",
    "print(f\"\\nDelineating watershed using method: {confluence.config['DOMAIN_DEFINITION_METHOD']}\")\n",
    "watershed_path = confluence.managers['domain'].define_domain()\n",
    "\n",
    "# Check outputs\n",
    "print(\"\\nDomain definition complete:\")\n",
    "print(f\"  - Watershed defined: {watershed_path is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geospatial Domain Definition and Analysis - Discretisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Discretize domain\n",
    "print(f\"\\nCreating HRUs using method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "# Check outputs\n",
    "print(\"\\nDomain definition complete:\")\n",
    "print(f\"  - HRUs created: {hru_path is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the Delineated Domain\n",
    "Let's see what our watershed looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the watershed\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "if basin_path.exists():\n",
    "    basin_files = list(basin_path.glob('*.shp'))\n",
    "    \n",
    "    if basin_files:\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        # Load watershed and pour point\n",
    "        basin_gdf = gpd.read_file(basin_files[0])\n",
    "        pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "        \n",
    "        # Reproject for visualization\n",
    "        basin_web = basin_gdf.to_crs(epsg=3857)\n",
    "        pour_web = pour_point_gdf.to_crs(epsg=3857)\n",
    "        \n",
    "        # Plot watershed\n",
    "        basin_web.plot(ax=ax, facecolor='lightblue', edgecolor='navy', \n",
    "                       linewidth=2, alpha=0.7)\n",
    "        \n",
    "        # Add pour point\n",
    "        pour_web.plot(ax=ax, color='red', markersize=200, marker='o', \n",
    "                      edgecolor='white', linewidth=2, zorder=5)\n",
    "                \n",
    "        # Set extent\n",
    "        minx, miny, maxx, maxy = basin_web.total_bounds\n",
    "        pad = 5000\n",
    "        ax.set_xlim(minx - pad, maxx + pad)\n",
    "        ax.set_ylim(miny - pad, maxy + pad)\n",
    "        \n",
    "        # Add labels\n",
    "        ax.text(minx + 1000, maxy - 1000,\n",
    "                f'Watershed Area: {basin_gdf.geometry.area.sum() / 1e6:.0f} km¬≤', \n",
    "                fontsize=14, \n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "                fontweight='bold')\n",
    "        \n",
    "        ax.set_title('Bow River Watershed at Banff\\\\nAll water from this area flows to the pour point', \n",
    "                    fontsize=16, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Agnostic Data Pre-Processing - Observed data\n",
    "For a lumped model, the entire watershed becomes a single Hydrologic Response Unit (HRU). This simplification assumes uniform characteristics across the watershed - obviously an approximation, but useful for many applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Model Agnostic Data Pre-Processing\n",
    "print(\"=== Step 3: Model Agnostic Data Pre-Processing ===\")\n",
    "\n",
    "# Process observed data\n",
    "print(\"Processing observed streamflow data...\")\n",
    "confluence.managers['data'].process_observed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize observed streamflow data\n",
    "obs_path = project_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{confluence.config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "if obs_path.exists():\n",
    "    obs_df = pd.read_csv(obs_path)\n",
    "    obs_df['datetime'] = pd.to_datetime(obs_df['datetime'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(obs_df['datetime'], obs_df['discharge_cms'], \n",
    "            linewidth=1.5, color='blue', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Discharge (m¬≥/s)', fontsize=12)\n",
    "    ax.set_title(f'Observed Streamflow - Bow River at Banff (WSC Station: {confluence.config[\"STATION_ID\"]})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    ax.text(0.02, 0.95, f'Mean: {obs_df[\"discharge_cms\"].mean():.1f} m¬≥/s\\\\nMax: {obs_df[\"discharge_cms\"].max():.1f} m¬≥/s', \n",
    "            transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "            verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Agnostic Data Pre-Processing - Forcing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Acquire forcings\n",
    "print(f\"\\nAcquiring forcing data: {confluence.config['FORCING_DATASET']}\")\n",
    "confluence.managers['data'].acquire_forcings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Agnostic Data Pre-Processing - Remapping and zonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run model-agnostic preprocessing\n",
    "print(\"\\nRunning model-agnostic preprocessing...\")\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model-Specific - Preprocessing\n",
    "Now we prepare inputs specific to our chosen hydrological model (SUMMA in this case). Each model has its own requirements for input format and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Model Specific Processing and Initialization\n",
    "print(\"=== Step 4: Model Specific Processing and Initialization ===\")\n",
    "\n",
    "# Preprocess models\n",
    "print(f\"Preparing {confluence.config['HYDROLOGICAL_MODEL']} input files...\")\n",
    "confluence.managers['model'].preprocess_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Model-Specific - Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run models\n",
    "print(f\"\\nRunning {confluence.config['HYDROLOGICAL_MODEL']} model...\")\n",
    "confluence.managers['model'].run_models()\n",
    "\n",
    "print(\"\\nModel run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Agnostic Data Pre-Processing - Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarking\n",
    "print(\"\\nRunning benchmarking analysis...\")\n",
    "benchmark_results = confluence.managers['analysis'].run_benchmarking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Optional Steps - Optimization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 & 6: Optional Steps (Optimization and Analysis)\n",
    "print(\"=== Step 5 & 6: Optional Steps ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative - Run Complete Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Run the complete workflow in one step\n",
    "# (Uncomment to use this instead of the step-by-step approach)\n",
    "\n",
    "# confluence.run_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Understanding the CONFLUENCE Workflow\n",
    "Congratulations! You've completed a full lumped basin modeling workflow with CONFLUENCE. Let's reflect on what we accomplished and how CONFLUENCE helped navigate the complex decision tree of hydrological modeling.\n",
    "The Decision Tree We Navigated:\n",
    "\n",
    "### Project Organization: Established a consistent structure for all files\n",
    "Domain Definition: From pour point ‚Üí watershed boundary ‚Üí single HRU\n",
    "Data Acquisition: Gathered forcing data, observations, and static attributes\n",
    "Model Configuration: Set up SUMMA with appropriate parameters\n",
    "Simulation: Ran the model for our specified period\n",
    "Evaluation: Compared results with observations\n",
    "\n",
    "## Next Steps You Could Try:\n",
    "\n",
    "### Experiment with different models (change HYDROLOGICAL_MODEL)\n",
    "Try distributed modeling (change SPATIAL_MODE to 'Distributed')\n",
    "Calibrate the model (use the optimization module)\n",
    "Analyze model sensitivity to different parameters\n",
    "Compare multiple model structures (decision analysis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
