{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# FLUXNET Large Sample Experiment Tutorial\n\nThis notebook demonstrates how to run CONFLUENCE over multiple FLUXNET tower sites for point-scale large-sample analysis."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import sys\nimport os\nfrom pathlib import Path\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport subprocess\nimport yaml\nfrom datetime import datetime\nimport seaborn as sns\n\n# Add CONFLUENCE to path\nconfluence_path = Path('../').resolve()\nsys.path.append(str(confluence_path))\n\n# Set up plotting style\nplt.style.use('default')\nsns.set_palette(\"husl\")\n%matplotlib inline\n\nprint(\"Setup complete!\")"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Configuration for the FLUXNET large sample experiment\nexperiment_config = {\n    'experiment_name': 'fluxnet_tutorial',\n    'max_sites': 5,\n    'dry_run': False,\n    'template_config': '../CONFLUENCE/0_config_files/config_point_template.yaml',\n    'config_dir': '../CONFLUENCE/0_config_files/fluxnet',\n    'fluxnet_script': '../CONFLUENCE/9_scripts/run_towers_fluxnet.py',\n    'fluxnet_csv': 'fluxnet_transformed.csv'\n}\n\n# Create experiment directory\nexperiment_dir = Path(f\"./experiments/{experiment_config['experiment_name']}\")\nexperiment_dir.mkdir(parents=True, exist_ok=True)\n\n# Save configuration\nwith open(experiment_dir / 'experiment_config.yaml', 'w') as f:\n    yaml.dump(experiment_config, f)\n\nprint(f\"Experiment configured: {experiment_config['experiment_name']}\")"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Load FLUXNET sites data\nfluxnet_df = pd.read_csv(experiment_config['fluxnet_csv'])\n\nprint(f\"Loaded {len(fluxnet_df)} FLUXNET sites\")\nprint(\"\\nColumns in dataset:\")\nfor col in fluxnet_df.columns:\n    print(f\"  - {col}\")\n\n# Display first few sites\nprint(\"\\nFirst 5 sites:\")\ndisplay(fluxnet_df[['ID', 'Watershed_Name', 'KG', 'Dominant_LC', 'Area_km2']].head())"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Extract coordinates from POUR_POINT_COORDS\ncoords = fluxnet_df['POUR_POINT_COORDS'].str.split('/', expand=True)\nfluxnet_df['lat'] = coords[0].astype(float)\nfluxnet_df['lon'] = coords[1].astype(float)\n\n# Create global distribution plot\nplt.figure(figsize=(15, 8))\nplt.scatter(fluxnet_df['lon'], fluxnet_df['lat'], c='red', alpha=0.6)\nplt.title('Global Distribution of FLUXNET Sites')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.grid(True, alpha=0.3)\nplt.xlim(-180, 180)\nplt.ylim(-60, 80)\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Select sites based on criteria - diverse climate types\nclimate_types = fluxnet_df['KG'].unique()\n\n# Select one site from each climate type (up to max_sites)\nselected_sites = []\nfor climate in climate_types[:experiment_config['max_sites']]:\n    site = fluxnet_df[fluxnet_df['KG'] == climate].iloc[0]\n    selected_sites.append(site)\n\nselected_df = pd.DataFrame(selected_sites)\n\nprint(f\"Selected {len(selected_df)} sites for processing:\")\ndisplay(selected_df[['ID', 'Watershed_Name', 'KG', 'Dominant_LC']])"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Generate configs for selected sites\nconfig_dir = Path(experiment_config['config_dir'])\nconfig_dir.mkdir(parents=True, exist_ok=True)\n\ngenerated_configs = []\n\nfor _, site in selected_df.iterrows():\n    site_name = site['Watershed_Name']\n    pour_point = site['POUR_POINT_COORDS']\n    bounding_box = site['BOUNDING_BOX_COORDS']\n    \n    # Create config file name\n    config_path = config_dir / f\"config_{site_name}.yaml\"\n    \n    # Generate config using the script function\n    cmd = [\n        'python', '-c',\n        f\"\"\"\nimport sys\nsys.path.append('{str(confluence_path)}/9_scripts')\nfrom run_towers_fluxnet import generate_config_file\ngenerate_config_file(\n    '{experiment_config['template_config']}',\n    '{config_path}',\n    '{site_name}',\n    '{pour_point}',\n    '{bounding_box}'\n)\n\"\"\"\n    ]\n    \n    result = subprocess.run(cmd, capture_output=True, text=True)\n    if result.returncode == 0:\n        generated_configs.append(config_path)\n        print(f\"Generated config for {site_name}\")\n\nprint(f\"\\nGenerated {len(generated_configs)} configuration files\")"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Launch CONFLUENCE runs\ncmd = ['python', experiment_config['fluxnet_script']]\n\n# For dry run, add appropriate option\nif experiment_config['dry_run']:\n    print(\"DRY RUN MODE - No jobs will be submitted\")\n\nprint(f\"Launching CONFLUENCE for FLUXNET sites...\")\n\n# Execute the script (requires user input)\nresult = subprocess.run(cmd, input='n\\n' if experiment_config['dry_run'] else 'y\\n', \n                       capture_output=True, text=True)\n\nprint(\"\\nOutput:\")\nprint(result.stdout[:500] + \"...\" if len(result.stdout) > 500 else result.stdout)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Check job status and find completed simulations\ndef check_job_status(user=None):\n    user = user or os.environ.get('USER')\n    cmd = ['squeue', '-u', user]\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    return result.stdout\n\nprint(\"Current jobs:\")\nprint(check_job_status())\n\n# Find completed FLUXNET simulations\nconfluence_data_dir = Path(\"/work/comphyd_lab/data/CONFLUENCE_data\")\nfluxnet_dir = confluence_data_dir / \"fluxnet\"\n\ncompleted = []\nif fluxnet_dir.exists():\n    for domain_dir in fluxnet_dir.glob(\"domain_*\"):\n        site_name = domain_dir.name.replace(\"domain_\", \"\")\n        sim_dir = domain_dir / \"simulations\"\n        \n        if sim_dir.exists() and list(sim_dir.rglob(\"*.nc\")):\n            completed.append({\n                'site_name': site_name,\n                'sim_dir': sim_dir\n            })\n\nprint(f\"Completed simulations: {len(completed)}\")"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Load and analyze model results\ndef load_summa_output(sim_dir, variable='scalarLatHeatTotal'):\n    import xarray as xr\n    \n    output_files = list(sim_dir.rglob(\"*timestep*.nc\"))\n    if output_files:\n        ds = xr.open_dataset(output_files[0])\n        if variable in ds.variables:\n            return pd.DataFrame({\n                'time': pd.to_datetime(ds.time.values),\n                'value': ds[variable].values.flatten()\n            })\n    return None\n\n# Summary Report\nif completed:\n    print(\"### FLUXNET Experiment Summary Report ###\")\n    print(f\"Experiment Name: {experiment_config['experiment_name']}\")\n    print(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\")\n    print(f\"Total Sites Selected: {len(selected_df)}\")\n    print(f\"Completed Simulations: {len(completed)}\")\n    \n    # Save report to file\n    with open(experiment_dir / 'experiment_report.txt', 'w') as f:\n        f.write(f\"FLUXNET Experiment Summary\\n\")\n        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\\n\")\n        f.write(f\"Sites Processed: {len(completed)} of {len(selected_df)}\\n\")\n    \n    print(f\"Summary report saved to {experiment_dir / 'experiment_report.txt'}\")"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}