{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial: Elevation-Based HRU Discretization\n",
    "\n",
    "This notebook demonstrates elevation-based HRU discretization, building on the distributed domain from Tutorial 3. We'll:\n",
    "\n",
    "1. Use the existing GRUs from Tutorial 3\n",
    "2. Apply elevation-based discretization\n",
    "3. Run the model\n",
    "4. Compare results with lumped and GRU-based approaches\n",
    "\n",
    "**Prerequisites**: Tutorial 3 must be completed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "import shutil\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize CONFLUENCE\n",
    "First, let's set up our directories and load the configuration. We'll modify the configuration from Tutorial 3 to use elevation-based discretization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/work/comphyd_lab/data/CONFLUENCE_data')  # â† User should modify this path\n",
    "\n",
    "# Verify paths exist\n",
    "if not CONFLUENCE_CODE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"CONFLUENCE code directory not found: {CONFLUENCE_CODE_DIR}\")\n",
    "\n",
    "if not CONFLUENCE_DATA_DIR.exists():\n",
    "    print(f\"Data directory doesn't exist. Creating: {CONFLUENCE_DATA_DIR}\")\n",
    "    CONFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the distributed configuration from Tutorial 3\n",
    "distributed_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_distributed.yaml'\n",
    "if not distributed_config_path.exists():\n",
    "    raise FileNotFoundError(\"Tutorial 3 must be run first! Distributed config file not found.\")\n",
    "\n",
    "# Read config file\n",
    "with open(distributed_config_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update core paths\n",
    "config_dict['CONFLUENCE_CODE_DIR'] = str(CONFLUENCE_CODE_DIR)\n",
    "config_dict['CONFLUENCE_DATA_DIR'] = str(CONFLUENCE_DATA_DIR)\n",
    "\n",
    "# Modify for elevation-based discretization\n",
    "config_dict['DOMAIN_NAME'] = 'Bow_at_Banff_elevation'\n",
    "config_dict['EXPERIMENT_ID'] = 'elevation_tutorial'\n",
    "config_dict['DOMAIN_DISCRETIZATION'] = 'elevation'  # Key change!\n",
    "config_dict['ELEVATION_BAND_SIZE'] = 200  # 200m bands\n",
    "config_dict['MIN_HRU_SIZE'] = 4  # 4 kmÂ² minimum\n",
    "# Keep SPATIAL_MODE as 'Distributed'\n",
    "\n",
    "# Save updated config to a temporary file\n",
    "elevation_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_elevation.yaml'\n",
    "with open(elevation_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f)\n",
    "\n",
    "# Initialize CONFLUENCE\n",
    "confluence = CONFLUENCE(elevation_config_path)\n",
    "\n",
    "# Display configuration\n",
    "print(\"=== Directory Configuration ===\")\n",
    "print(f\"Code Directory: {CONFLUENCE_CODE_DIR}\")\n",
    "print(f\"Data Directory: {CONFLUENCE_DATA_DIR}\")\n",
    "print(\"\\n=== Key Configuration Settings ===\")\n",
    "print(f\"Domain Name: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Pour Point: {confluence.config['POUR_POINT_COORDS']}\")\n",
    "print(f\"Discretization Method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "print(f\"Elevation Band Size: {confluence.config['ELEVATION_BAND_SIZE']} m\")\n",
    "print(f\"Minimum HRU Size: {confluence.config['MIN_HRU_SIZE']} kmÂ²\")\n",
    "print(f\"Spatial Mode: {confluence.config['SPATIAL_MODE']}\")\n",
    "print(f\"Model: {confluence.config['HYDROLOGICAL_MODEL']}\")\n",
    "print(f\"Simulation Period: {confluence.config['EXPERIMENT_TIME_START']} to {confluence.config['EXPERIMENT_TIME_END']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Domain Discretization Approaches\n",
    "\n",
    "Before we start building the elevation-based model, let's visualize the three approaches to domain discretization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization comparing approaches\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Lumped representation (Tutorial 1)\n",
    "ax1.add_patch(plt.Rectangle((0, 0), 1, 1, fill=True, color='lightblue', alpha=0.7))\n",
    "ax1.text(0.5, 0.5, 'Entire Basin\\n(1 Unit)', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "ax1.arrow(0.5, 0.05, 0, -0.1, head_width=0.03, head_length=0.02, fc='blue', ec='blue')\n",
    "ax1.text(0.5, -0.08, 'Single Output', ha='center', fontsize=10)\n",
    "ax1.set_xlim(-0.1, 1.1)\n",
    "ax1.set_ylim(-0.15, 1.1)\n",
    "ax1.set_title('Lumped Model (Tutorial 1)', fontsize=16, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Distributed GRU-based representation (Tutorial 3)\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "positions = [(0.2, 0.7), (0.7, 0.7), (0.2, 0.3), (0.5, 0.1)]\n",
    "labels = ['GRU 1', 'GRU 2', 'GRU 3', 'GRU 4']\n",
    "\n",
    "for i, (pos, color, label) in enumerate(zip(positions, colors, labels)):\n",
    "    circle = plt.Circle(pos, 0.15, fill=True, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax2.add_patch(circle)\n",
    "    ax2.text(pos[0], pos[1], label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Draw river network\n",
    "ax2.plot([0.2, 0.2, 0.5], [0.7, 0.3, 0.1], 'b-', linewidth=3)  # Main stem\n",
    "ax2.plot([0.7, 0.5], [0.7, 0.1], 'b-', linewidth=2)  # Tributary\n",
    "ax2.arrow(0.5, 0.1, 0, -0.1, head_width=0.03, head_length=0.02, fc='blue', ec='blue')\n",
    "ax2.text(0.5, -0.02, 'Routed Output', ha='center', fontsize=10)\n",
    "\n",
    "ax2.set_xlim(-0.1, 1.1)\n",
    "ax2.set_ylim(-0.15, 1.1)\n",
    "ax2.set_title('GRU-Based Model (Tutorial 3)', fontsize=16, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Elevation-based representation (Tutorial 4)\n",
    "# Create a more complex visualization showing elevation bands\n",
    "positions = [(0.2, 0.7), (0.7, 0.7), (0.2, 0.3), (0.5, 0.1)]\n",
    "gru_labels = ['GRU 1', 'GRU 2', 'GRU 3', 'GRU 4']\n",
    "colors = ['#fee5d9', '#fcae91', '#fb6a4a', '#de2d26', '#a50f15']  # Red color gradient\n",
    "\n",
    "for i, (pos, label) in enumerate(zip(positions, gru_labels)):\n",
    "    # Draw the GRU\n",
    "    circle = plt.Circle(pos, 0.18, fill=False, edgecolor='black', linestyle='--')\n",
    "    ax3.add_patch(circle)\n",
    "    \n",
    "    # Draw elevation bands within each GRU (concentric circles)\n",
    "    for j, size in enumerate([0.15, 0.12, 0.09, 0.06, 0.03]):\n",
    "        band = plt.Circle(pos, size, fill=True, color=colors[j], alpha=0.7, edgecolor='gray')\n",
    "        ax3.add_patch(band)\n",
    "    \n",
    "    ax3.text(pos[0], pos[1]-0.25, label, ha='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Draw river network\n",
    "ax3.plot([0.2, 0.2, 0.5], [0.7, 0.3, 0.1], 'b-', linewidth=3)  # Main stem\n",
    "ax3.plot([0.7, 0.5], [0.7, 0.1], 'b-', linewidth=2)  # Tributary\n",
    "ax3.arrow(0.5, 0.1, 0, -0.1, head_width=0.03, head_length=0.02, fc='blue', ec='blue')\n",
    "ax3.text(0.5, -0.02, 'Routed Output', ha='center', fontsize=10)\n",
    "\n",
    "# Add color legend for elevation\n",
    "cmap = plt.cm.Reds\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=800, vmax=3000))\n",
    "sm._A = []\n",
    "cbar = plt.colorbar(sm, ax=ax3, orientation='horizontal', pad=0.05, shrink=0.5)\n",
    "cbar.set_label('Elevation (m)', fontsize=10)\n",
    "\n",
    "ax3.set_xlim(-0.1, 1.1)\n",
    "ax3.set_ylim(-0.3, 1.1)\n",
    "ax3.set_title('Elevation-Based Model (This Tutorial)', fontsize=16, fontweight='bold')\n",
    "ax3.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Project Setup - Organizing the Modeling Workflow\n",
    "\n",
    "First, we'll establish a well-organized project structure, similar to what we did in Tutorial 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Project Initialization\n",
    "print(\"=== Step 1: Project Initialization ===\")\n",
    "\n",
    "# Setup project\n",
    "project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# List created directories\n",
    "print(\"\\nCreated directories:\")\n",
    "for item in sorted(project_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  ðŸ“ {item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Copy Domain Data from Tutorial 3\n",
    "\n",
    "We'll reuse the existing domain and GRUs from Tutorial 3 (distributed model) instead of starting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source domain from Tutorial 3\n",
    "source_domain = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_distributed'\n",
    "\n",
    "# Check if Tutorial 3 domain exists\n",
    "if not source_domain.exists():\n",
    "    raise FileNotFoundError(\"Tutorial 3 domain not found! Please run Tutorial 3 first.\")\n",
    "\n",
    "# Copy necessary directories from Tutorial 3\n",
    "print(\"=== Step 2: Copying Domain Data from Tutorial 3 ===\")\n",
    "dirs_to_copy = ['shapefiles', 'attributes']\n",
    "\n",
    "for dir_name in dirs_to_copy:\n",
    "    source_dir = source_domain / dir_name\n",
    "    target_dir = project_dir / dir_name\n",
    "    \n",
    "    if source_dir.exists():\n",
    "        print(f\"Copying {dir_name} from Tutorial 3...\")\n",
    "        # Create target directory if it doesn't exist\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy files\n",
    "        for src_file in source_dir.glob('**/*'):\n",
    "            if src_file.is_file():\n",
    "                # Calculate relative path\n",
    "                rel_path = src_file.relative_to(source_dir)\n",
    "                dest_file = target_dir / rel_path\n",
    "                \n",
    "                # Create parent directories if needed\n",
    "                dest_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Copy the file, replacing 'distributed' with 'elevation' in filename\n",
    "                shutil.copy2(src_file, dest_file)\n",
    "                if 'distributed' in dest_file.name:\n",
    "                    new_name = dest_file.parent / dest_file.name.replace('distributed', 'elevation')\n",
    "                    dest_file.rename(new_name)\n",
    "    else:\n",
    "        print(f\"Warning: {source_dir} not found in Tutorial 3 domain.\")\n",
    "\n",
    "print(\"\\nâœ“ Domain data copied from Tutorial 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify GRU Boundaries\n",
    "\n",
    "Let's check the existing GRU boundaries that we'll use as a basis for our elevation-based HRUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check river basins (GRUs) and network\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "network_path = project_dir / 'shapefiles' / 'river_network'\n",
    "\n",
    "basin_files = list(basin_path.glob('*.shp'))\n",
    "network_files = list(network_path.glob('*.shp'))\n",
    "\n",
    "if basin_files and network_files:\n",
    "    # Load data\n",
    "    basins = gpd.read_file(basin_files[0])\n",
    "    rivers = gpd.read_file(network_files[0])\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Plot basins (GRUs)\n",
    "    basins.plot(ax=ax, column='GRU_ID', cmap='viridis', \n",
    "               alpha=0.7, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Plot river network\n",
    "    rivers.plot(ax=ax, color='blue', linewidth=1.5)\n",
    "    \n",
    "    # Format plot\n",
    "    ax.set_title(f'GRU Boundaries for Elevation-Based Discretization\\n({len(basins)} Sub-basins)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    # Add colorbar for GRU IDs\n",
    "    sm = plt.cm.ScalarMappable(cmap='viridis', \n",
    "                             norm=plt.Normalize(vmin=basins['GRU_ID'].min(), \n",
    "                                               vmax=basins['GRU_ID'].max()))\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, ax=ax, shrink=0.8)\n",
    "    cbar.set_label('GRU ID', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Number of GRUs: {len(basins)}\")\n",
    "    print(f\"Total area: {basins.geometry.area.sum() / 1e6:.2f} kmÂ²\")\n",
    "else:\n",
    "    print(\"GRU files not found. Make sure Tutorial 3 was completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Elevation-Based HRUs\n",
    "\n",
    "Now we'll apply elevation-based discretization to create HRUs within each GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create Elevation-Based HRUs\n",
    "print(\"=== Step 3: Creating Elevation-Based HRUs ===\")\n",
    "print(f\"Discretization Method: {confluence.config['DOMAIN_DISCRETIZATION']}\")\n",
    "print(f\"Elevation Band Size: {confluence.config['ELEVATION_BAND_SIZE']} m\")\n",
    "print(f\"Minimum HRU Size: {confluence.config['MIN_HRU_SIZE']} kmÂ²\")\n",
    "\n",
    "# Apply discretization\n",
    "print(\"\\nApplying elevation-based discretization...\")\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "# Load and analyze the resulting HRU shapefile\n",
    "catchment_path = project_dir / 'shapefiles' / 'catchment'\n",
    "if catchment_path.exists():\n",
    "    hru_files = list(catchment_path.glob('*.shp'))\n",
    "    if hru_files:\n",
    "        hru_gdf = gpd.read_file(hru_files[0])\n",
    "        \n",
    "        # Store the GRU GeoDataFrame for later use\n",
    "        gru_gdf = gpd.read_file(basin_files[0])\n",
    "        \n",
    "        print(f\"\\nâœ“ Created elevation-based HRUs\")\n",
    "        print(f\"Number of HRUs: {len(hru_gdf)}\")\n",
    "        print(f\"Number of GRUs: {hru_gdf['GRU_ID'].nunique()}\")\n",
    "        \n",
    "        # Calculate HRUs per GRU\n",
    "        hru_counts = hru_gdf.groupby('GRU_ID').size()\n",
    "        avg_hrus_per_gru = hru_counts.mean()\n",
    "        print(f\"Average HRUs per GRU: {avg_hrus_per_gru:.1f}\")\n",
    "        \n",
    "        # Show the first few GRUs with their HRU counts\n",
    "        print(\"\\nHRUs per GRU (first 10):\")\n",
    "        for gru_id, count in hru_counts.head(10).items():\n",
    "            print(f\"  GRU {gru_id}: {count} HRUs\")\n",
    "else:\n",
    "    print(\"Failed to create elevation-based HRUs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Elevation-Based HRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the HRUs\n",
    "if 'hru_gdf' in locals() and len(hru_gdf) > 0:\n",
    "    # Check if mean elevation is available in the data\n",
    "    has_elevation = 'mean_elev' in hru_gdf.columns\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Plot HRUs colored by elevation if available, otherwise by HRU ID\n",
    "    if has_elevation:\n",
    "        hru_gdf.plot(ax=ax, column='mean_elev', cmap='terrain', \n",
    "                   edgecolor='gray', linewidth=0.5, alpha=0.7,\n",
    "                   legend=True, legend_kwds={'label': 'Mean Elevation (m)'})\n",
    "    else:\n",
    "        hru_gdf.plot(ax=ax, column='HRU_ID', cmap='viridis', \n",
    "                   edgecolor='gray', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Overlay GRU boundaries\n",
    "    gru_gdf.boundary.plot(ax=ax, color='red', linewidth=1)\n",
    "    \n",
    "    # Add river network for context\n",
    "    if 'rivers' in locals():\n",
    "        rivers.plot(ax=ax, color='blue', linewidth=1)\n",
    "    \n",
    "    # Add title and labels\n",
    "    ax.set_title(f'Elevation-Based HRUs\\n{len(hru_gdf)} HRUs in {hru_gdf[\"GRU_ID\"].nunique()} GRUs',\n",
    "                fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No HRUs available to visualize.\")"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Complete the Modeling Workflow\n",
    "\n",
    "Now we'll complete the model setup and run the simulation using our elevation-based HRUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Process Observed Data\n",
    "print(\"=== Step 4: Processing Observed Data ===\")\n",
    "\n",
    "# Check if we can reuse observed data from previous tutorials\n",
    "obs_dir = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_distributed' / 'observations' / 'streamflow' / 'preprocessed'\n",
    "if obs_dir.exists() and list(obs_dir.glob('*.csv')):\n",
    "    print(\"Reusing observed data from Tutorial 3...\")\n",
    "    \n",
    "    # Copy observed data\n",
    "    target_dir = project_dir / 'observations' / 'streamflow' / 'preprocessed'\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for src_file in obs_dir.glob('*.csv'):\n",
    "        dest_file = target_dir / src_file.name.replace('distributed', 'elevation')\n",
    "        shutil.copy2(src_file, dest_file)\n",
    "        print(f\"Copied {src_file.name} to {dest_file.name}\")\n",
    "else:\n",
    "    print(\"Processing observed streamflow data from scratch...\")\n",
    "    confluence.managers['data'].process_observed_data()\n",
    "\n",
    "print(\"\\nâœ“ Observed data processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Acquire and Process Forcing Data\n",
    "print(\"=== Step 5: Acquiring and Processing Forcing Data ===\")\n",
    "\n",
    "# Check if we can reuse forcing data from previous tutorials\n",
    "forcing_dir = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_distributed' / 'forcing'\n",
    "if forcing_dir.exists():\n",
    "    print(\"Reusing forcing data from Tutorial 3...\")\n",
    "    \n",
    "    # Copy forcing data\n",
    "    target_dir = project_dir / 'forcing'\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy all subdirectories\n",
    "    for src_dir in forcing_dir.iterdir():\n",
    "        if src_dir.is_dir():\n",
    "            dest_dir = target_dir / src_dir.name\n",
    "            if not dest_dir.exists():\n",
    "                shutil.copytree(src_dir, dest_dir)\n",
    "            print(f\"Copied {src_dir.name} forcing data\")\n",
    "    \n",
    "    # Run model-agnostic preprocessing to handle the new HRU structure\n",
    "    print(\"\\nRunning model-agnostic preprocessing for new HRU structure...\")\n",
    "    confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "else:\n",
    "    print(\"Acquiring forcing data from scratch...\")\n",
    "    confluence.managers['data'].acquire_forcings()\n",
    "    print(\"\\nRunning model-agnostic preprocessing...\")\n",
    "    confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "\n",
    "print(\"\\nâœ“ Forcing data processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prepare Model-Specific Files\n",
    "print(\"=== Step 6: Preparing Model-Specific Files ===\")\n",
    "\n",
    "print(f\"Preparing {confluence.config['HYDROLOGICAL_MODEL']} input files...\")\n",
    "print(f\"This step will generate configuration files for {len(hru_gdf)} HRUs across {hru_gdf['GRU_ID'].nunique()} GRUs\")\n",
    "\n",
    "# Preprocess models\n",
    "confluence.managers['model'].preprocess_models()\n",
    "\n",
    "print(\"\\nâœ“ Model-specific preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Run the Model\n",
    "print(\"=== Step 7: Running the Model ===\")\n",
    "\n",
    "# Run the model\n",
    "print(f\"Running {confluence.config['HYDROLOGICAL_MODEL']} with elevation-based HRUs...\")\n",
    "print(\"Note: This may take some time depending on the number of HRUs.\")\n",
    "print(f\"Number of HRUs: {len(hru_gdf)}\")\n",
    "\n",
    "# You can comment this out if you want to skip the actual model run\n",
    "# confluence.managers['model'].run_models()\n",
    "\n",
    "print(\"\\n(Model run is commented out for demonstration purposes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize and Compare Results\n",
    "\n",
    "After running the model, we can visualize the results and compare them with the lumped and GRU-based approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run benchmarking\n",
    "print(\"=== Optional: Run Benchmarking ===\")\n",
    "print(\"Skipping benchmarking step for this tutorial\")\n",
    "\n",
    "# Uncomment this line to run benchmarking\n",
    "# benchmark_results = confluence.managers['analysis'].run_benchmarking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mock visualization of model results\n",
    "# In a real workflow, you would load actual simulation results\n",
    "\n",
    "print(\"Creating mock visualization of model comparison...\")\n",
    "\n",
    "# Create example date range (2 months of hourly data)\n",
    "dates = pd.date_range(start='2020-06-01', end='2020-08-01', freq='H')\n",
    "example_data = pd.DataFrame(index=dates)\n",
    "\n",
    "# Create synthetic observed flow data (higher in summer)\n",
    "obs_values = []\n",
    "for i, date in enumerate(dates):\n",
    "    # Base flow with daily and seasonal patterns\n",
    "    day_of_year = date.dayofyear\n",
    "    hour_of_day = date.hour\n",
    "    base_flow = 20 + 15 * np.sin(2 * np.pi * day_of_year / 365 - np.pi/2)  # Seasonal pattern\n",
    "    daily_pattern = 2 * np.sin(2 * np.pi * hour_of_day / 24)  # Daily pattern\n",
    "    noise = np.random.normal(0, 2)  # Random noise\n",
    "    \n",
    "    value = max(5, base_flow + daily_pattern + noise)  # Ensure positive flow\n",
    "    obs_values.append(value)\n",
    "    \n",
    "example_data['observed'] = obs_values\n",
    "\n",
    "# Create synthetic model outputs (with different errors)\n",
    "example_data['lumped'] = example_data['observed'] * 0.85 + np.random.normal(0, 5, len(dates))  # Underestimates\n",
    "example_data['gru_based'] = example_data['observed'] * 0.95 + np.random.normal(0, 3, len(dates))  # Better\n",
    "example_data['elevation'] = example_data['observed'] * 0.98 + np.random.normal(0, 2, len(dates))  # Best\n",
    "\n",
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot 7-day sample for clearer visualization (June 15-22)\n",
    "sample_data = example_data.loc['2020-06-15':'2020-06-22']\n",
    "\n",
    "ax.plot(sample_data.index, sample_data['observed'], color='black', linewidth=2, label='Observed')\n",
    "ax.plot(sample_data.index, sample_data['lumped'], color='blue', linewidth=1.5, alpha=0.7, label='Lumped Model (Tutorial 1)')\n",
    "ax.plot(sample_data.index, sample_data['gru_based'], color='green', linewidth=1.5, alpha=0.7, label='GRU-Based (Tutorial 3)')\n",
    "ax.plot(sample_data.index, sample_data['elevation'], color='red', linewidth=1.5, alpha=0.7, label='Elevation-Based (Tutorial 4)')\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Discharge (mÂ³/s)', fontsize=12)\n",
    "ax.set_title('Comparison of Model Results\\nBow River at Banff (June 15-22, 2020)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# Add example performance metrics\n",
    "metrics = {\n",
    "    'Approach': ['Lumped', 'GRU-Based', 'Elevation-Based'],\n",
    "    'NSE': [0.72, 0.83, 0.89],\n",
    "    'KGE': [0.68, 0.81, 0.87],\n",
    "    'PBIAS (%)': [-15.0, -5.0, -2.0]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics).set_index('Approach')\n",
    "\n",
    "# Add metrics table to plot\n",
    "table = plt.table(cellText=metrics_df.values, rowLabels=metrics_df.index, \n",
    "                 colLabels=metrics_df.columns, cellLoc='center',\n",
    "                 bbox=[0.15, -0.3, 0.7, 0.2])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.3)  # Make room for the table\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compare Domain Structures\n",
    "\n",
    "Let's create a visual comparison of the three domain structures we've seen in these tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create domain comparison visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Load domain data from all tutorials (if available)\n",
    "\n",
    "# Lumped domain (Tutorial 1)\n",
    "lumped_path = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_lumped' / 'shapefiles' / 'river_basins'\n",
    "lumped_files = list(lumped_path.glob('*.shp')) if lumped_path.exists() else []\n",
    "\n",
    "# GRU-based distributed domain (Tutorial 3)\n",
    "distributed_path = CONFLUENCE_DATA_DIR / 'domain_Bow_at_Banff_distributed' / 'shapefiles' / 'catchment'\n",
    "distributed_files = list(distributed_path.glob('*.shp')) if distributed_path.exists() else []\n",
    "\n",
    "# Elevation-based domain (Tutorial 4)\n",
    "elevation_path = project_dir / 'shapefiles' / 'catchment'\n",
    "elevation_files = list(elevation_path.glob('*.shp')) if elevation_path.exists() else []\n",
    "\n",
    "# Plot lumped domain\n",
    "if lumped_files:\n",
    "    lumped_gdf = gpd.read_file(lumped_files[0])\n",
    "    lumped_gdf.plot(ax=axes[0], color='lightblue', edgecolor='navy', linewidth=1)\n",
    "    axes[0].set_title('Lumped Domain\\n(1 HRU)', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    # Create placeholder visualization\n",
    "    axes[0].add_patch(plt.Rectangle((0, 0), 1, 1, fill=True, color='lightblue', alpha=0.7))\n",
    "    axes[0].text(0.5, 0.5, 'Entire Basin\\n(1 Unit)', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_title('Lumped Model (Tutorial 1)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot GRU-based distributed domain\n",
    "if distributed_files:\n",
    "    gru_gdf = gpd.read_file(distributed_files[0])\n",
    "    gru_gdf.plot(ax=axes[1], column='GRU_ID', cmap='tab20', \n",
    "                edgecolor='black', linewidth=0.5)\n",
    "    axes[1].set_title(f'GRU-Based Domain\\n({len(gru_gdf)} HRUs)', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    # Create placeholder visualization\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "    positions = [(0.2, 0.7), (0.7, 0.7), (0.2, 0.3), (0.5, 0.1)]\n",
    "    labels = ['GRU 1', 'GRU 2', 'GRU 3', 'GRU 4']\n",
    "    \n",
    "    for i, (pos, color, label) in enumerate(zip(positions, colors, labels)):\n",
    "        circle = plt.Circle(pos, 0.15, fill=True, color=color, alpha=0.7, edgecolor='black')\n",
    "        axes[1].add_patch(circle)\n",
    "        axes[1].text(pos[0], pos[1], label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    axes[1].set_title('GRU-Based Model (Tutorial 3)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot elevation-based domain\n",
    "if elevation_files and 'hru_gdf' in locals():\n",
    "    if 'mean_elev' in hru_gdf.columns:\n",
    "        hru_gdf.plot(ax=axes[2], column='mean_elev', cmap='terrain', \n",
    "                    edgecolor='gray', linewidth=0.5)\n",
    "        # Add color legend for elevation\n",
    "        sm = plt.cm.ScalarMappable(cmap='terrain', norm=plt.Normalize(vmin=hru_gdf['mean_elev'].min(), \n",
    "                                                                 vmax=hru_gdf['mean_elev'].max()))\n",
    "        sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=axes[2], shrink=0.8)\n",
    "        cbar.set_label('Elevation (m)', fontsize=10)\n",
    "    else:\n",
    "        hru_gdf.plot(ax=axes[2], column='HRU_ID', cmap='viridis', \n",
    "                    edgecolor='gray', linewidth=0.5)\n",
    "    \n",
    "    # Overlay GRU boundaries if available\n",
    "    if 'gru_gdf' in locals():\n",
    "        gru_gdf.boundary.plot(ax=axes[2], color='red', linewidth=1)\n",
    "    \n",
    "    axes[2].set_title(f'Elevation-Based Domain\\n({len(hru_gdf)} HRUs)', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    # Create placeholder visualization with elevation bands\n",
    "    positions = [(0.2, 0.7), (0.7, 0.7), (0.2, 0.3), (0.5, 0.1)]\n",
    "    gru_labels = ['GRU 1', 'GRU 2', 'GRU 3', 'GRU 4']\n",
    "    colors = ['#fee5d9', '#fcae91', '#fb6a4a', '#de2d26', '#a50f15']  # Red color gradient\n",
    "\n",
    "    for i, (pos, label) in enumerate(zip(positions, gru_labels)):\n",
    "        # Draw the GRU\n",
    "        circle = plt.Circle(pos, 0.18, fill=False, edgecolor='black', linestyle='--')\n",
    "        axes[2].add_patch(circle)\n",
    "        \n",
    "        # Draw elevation bands within each GRU (concentric circles)\n",
    "        for j, size in enumerate([0.15, 0.12, 0.09, 0.06, 0.03]):\n",
    "            band = plt.Circle(pos, size, fill=True, color=colors[j], alpha=0.7, edgecolor='gray')\n",
    "            axes[2].add_patch(band)\n",
    "    \n",
    "    axes[2].set_title('Elevation-Based Model (This Tutorial)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add color legend for elevation\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=800, vmax=3000))\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, ax=axes[2], shrink=0.8)\n",
    "    cbar.set_label('Elevation (m)', fontsize=10)\n",
    "\n",
    "# Format all axes\n",
    "for ax in axes:\n",
    "    ax.set_xlim(-0.1, 1.1) if 'gru_gdf' not in locals() else None\n",
    "    ax.set_ylim(-0.3, 1.1) if 'gru_gdf' not in locals() else None\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Comparison of Domain Discretization Approaches', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary Table\n",
    "\n",
    "Let's create a summary table comparing the three approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = [\n",
    "    {\n",
    "        'Approach': 'Lumped',\n",
    "        'GRUs': 1,\n",
    "        'HRUs': 1,\n",
    "        'HRUs per GRU': 1.0,\n",
    "        'Computational Cost': 'Low',\n",
    "        'Process Representation': 'Limited',\n",
    "        'Best For': 'Quick assessments, small watersheds'\n",
    "    },\n",
    "    {\n",
    "        'Approach': 'GRU-Based',\n",
    "        'GRUs': len(gru_gdf) if 'gru_gdf' in locals() else 'N/A',\n",
    "        'HRUs': len(gru_gdf) if 'gru_gdf' in locals() else 'N/A',\n",
    "        'HRUs per GRU': 1.0,\n",
    "        'Computational Cost': 'Medium',\n",
    "        'Process Representation': 'Moderate',\n",
    "        'Best For': 'Standard distributed modeling'\n",
    "    },\n",
    "    {\n",
    "        'Approach': 'Elevation-Based',\n",
    "        'GRUs': len(gru_gdf) if 'gru_gdf' in locals() else 'N/A',\n",
    "        'HRUs': len(hru_gdf) if 'hru_gdf' in locals() else 'N/A',\n",
    "        'HRUs per GRU': round(len(hru_gdf)/len(gru_gdf), 1) if 'hru_gdf' in locals() and 'gru_gdf' in locals() else 'N/A',\n",
    "        'Computational Cost': 'High',\n",
    "        'Process Representation': 'Detailed',\n",
    "        'Best For': 'Mountainous regions, snow processes'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame and display\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=== Summary of Discretization Approaches ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Create a visual table\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table\n",
    "table = ax.table(cellText=summary_df.values,\n",
    "                colLabels=summary_df.columns,\n",
    "                cellLoc='center',\n",
    "                loc='center')\n",
    "\n",
    "# Format table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 1.8)\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:  # Header row\n",
    "        cell.set_text_props(weight='bold')\n",
    "\n",
    "plt.title('Comparison of Domain Discretization Approaches', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Key Takeaways\n",
    "\n",
    "### Advantages of Elevation-Based Discretization\n",
    "\n",
    "1. **Better Process Representation**: \n",
    "   - Captures elevation-dependent processes such as snow accumulation and melt\n",
    "   - Accounts for temperature and precipitation gradients with elevation\n",
    "   - Represents orographic effects on meteorological variables\n",
    "\n",
    "2. **Improved Performance**: \n",
    "   - Generally produces better simulation results in mountainous regions\n",
    "   - Especially valuable for snowmelt-dominated watersheds\n",
    "   - Can better represent processes like rain-on-snow events\n",
    "\n",
    "3. **More Detailed Spatial Patterns**: \n",
    "   - Allows for finer spatial resolution where it matters most\n",
    "   - Preserves sub-basin hydrological connectivity\n",
    "   - Enables more realistic representation of complex terrain\n",
    "\n",
    "### Challenges and Considerations\n",
    "\n",
    "1. **Computational Cost**: \n",
    "   - More HRUs means longer simulation times\n",
    "   - Increased memory requirements\n",
    "   - More complex setup and management\n",
    "\n",
    "2. **Parameterization**: \n",
    "   - More parameters to estimate or calibrate\n",
    "   - Potential for equifinality issues\n",
    "   - Requires careful handling of parameter transfers between elevation bands\n",
    "\n",
    "3. **Data Requirements**: \n",
    "   - Needs high-quality DEM and other spatial data\n",
    "   - May require additional meteorological data to properly represent elevation gradients\n",
    "   - Benefits from snow observations at different elevations for validation\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "- **Lumped (Tutorial 1)**: Useful for initial assessments, small watersheds, limited data availability, or when computational resources are constrained.\n",
    "\n",
    "- **GRU-Based (Tutorial 3)**: Good for capturing spatial variability in land cover and soil types, moderate complexity, and when sub-basin dynamics are important.\n",
    "\n",
    "- **Elevation-Based (This Tutorial)**: Best for mountainous watersheds, snowmelt-dominated hydrology, and when vertical gradients significantly affect hydrological processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final output locations\n",
    "print(\"=== Elevation-Based Discretization Complete ===\\n\")\n",
    "print(f\"Project: {confluence.config['DOMAIN_NAME']}\")\n",
    "print(f\"Experiment ID: {confluence.config['EXPERIMENT_ID']}\")\n",
    "print(f\"HRU shapefile: {project_dir / 'shapefiles' / 'catchment'}\")\n",
    "print(f\"Model results: {project_dir / 'simulations' / confluence.config['EXPERIMENT_ID']}\")\n",
    "print(f\"Plots directory: {project_dir / 'plots'}\")\n",
    "print(\"\\nThank you for completing this tutorial on elevation-based HRU discretization!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONFLUENCE (HPC Modules)",
   "language": "python",
   "name": "conf-env-hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}