{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 5: Elevation-Based HRU Discretization (Bow River at Banff)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates the most spatially detailed modeling approach in our series: elevation-based HRU discretization. Building on the semi-distributed model from Tutorial 4, we now further subdivide each GRU into multiple Hydrologic Response Units (HRUs) based on elevation bands. This approach captures the strong elevation controls on mountain hydrology while maintaining computational tractability.\n",
    "\n",
    "### What is Elevation-Based HRU Discretization?\n",
    "\n",
    "Elevation-based discretization creates multiple HRUs within each GRU by dividing the elevation range into bands:\n",
    "\n",
    "- **Within-GRU heterogeneity**: Each GRU is subdivided into elevation bands (e.g., 200m intervals)\n",
    "- **Process differentiation**: Different elevation bands experience different climate conditions and hydrological processes\n",
    "- **Spatial detail**: Maximum spatial resolution while maintaining computational efficiency\n",
    "- **Elevation controls**: Explicitly represents elevation-dependent processes like temperature lapse rates and snow dynamics\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Elevation Bands**: Altitude ranges (e.g., 1400-1600m, 1600-1800m) that group areas with similar elevation-dependent characteristics.\n",
    "\n",
    "**HRU (Hydrologic Response Unit)**: The smallest modeling unit, representing areas with similar hydrological response characteristics - in this case, defined by both location (GRU) and elevation band.\n",
    "\n",
    "**Elevation Band Size**: The vertical interval used to create bands (e.g., 200m), which controls the level of elevation detail captured.\n",
    "\n",
    "**Minimum HRU Size**: Areas smaller than this threshold are merged with adjacent elevation bands to maintain computational efficiency.\n",
    "\n",
    "### Why Elevation-Based Discretization?\n",
    "\n",
    "In mountain watersheds like the Bow River, elevation is a primary control on:\n",
    "\n",
    "1. **Temperature gradients**: Systematic temperature decrease with elevation affects snowmelt timing and evapotranspiration\n",
    "2. **Precipitation patterns**: Orographic effects create elevation-dependent precipitation gradients\n",
    "3. **Snow dynamics**: Accumulation, persistence, and ablation vary strongly with elevation\n",
    "4. **Vegetation zones**: Different plant communities and growing seasons across elevation gradients\n",
    "5. **Seasonal timing**: Earlier snowmelt at lower elevations, later at higher elevations\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "This tutorial will teach you how to:\n",
    "\n",
    "1. **Apply elevation-based discretization** to existing GRU boundaries\n",
    "2. **Configure elevation parameters** (band size, minimum HRU size)\n",
    "3. **Manage increased model complexity** with many HRUs\n",
    "4. **Interpret elevation-dependent results** across different zones\n",
    "5. **Understand computational trade-offs** between detail and efficiency\n",
    "6. **Analyze spatial patterns** in model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Elevation-Based Setup with Data Reuse\n",
    "Building on the semi-distributed modeling from Tutorial 02b, we now advance to the most spatially detailed approach: elevation-based HRU discretization. This represents the pinnacle of spatial complexity in our modeling series, subdividing each GRU into multiple elevation bands to capture the strong altitudinal controls on mountain hydrology while maintaining computational tractability.\n",
    "\n",
    "### Modeling Evolution: Semi-Distributed ‚Üí Elevation-Based HRUs\n",
    "\n",
    "- **Spatial Units**: Multiple GRUs ‚Üí Multiple HRUs within each GRU based on elevation bands\n",
    "- **Discretization Method**: `GRUs` ‚Üí `elevation` with configurable band sizes\n",
    "- **Process Representation**: Sub-basin averaged ‚Üí Elevation-dependent processes within sub-basins\n",
    "- **Hydrological Detail**: Stream network routing ‚Üí Stream network + elevation gradient effects\n",
    "- **Scientific Focus**: Spatial connectivity ‚Üí Elevation controls on snow, temperature, and timing\n",
    "\n",
    "The same CONFLUENCE framework seamlessly handles this complexity increase while intelligent data reuse from Tutorial 02b eliminates redundant preprocessing, demonstrating efficient workflow management for the most detailed spatial modeling approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: ELEVATION-BASED SETUP WITH DATA REUSE\n",
    "# =============================================================================\n",
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Add CONFLUENCE to path\n",
    "confluence_path = Path('../').resolve()\n",
    "sys.path.append(str(confluence_path))\n",
    "\n",
    "# Import main CONFLUENCE class\n",
    "from CONFLUENCE import CONFLUENCE\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION FOR ELEVATION-BASED BOW RIVER MODELING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüèîÔ∏è  Configuring Elevation-Based Bow River Watershed...\")\n",
    "\n",
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/Users/darrieythorsson/compHydro/data/CONFLUENCE_data')  # ‚Üê Update this path\n",
    "\n",
    "# Load semi-distributed configuration from Tutorial 02b and customize for elevation-based modeling\n",
    "semi_distributed_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_semi_distributed.yaml'\n",
    "\n",
    "if not semi_distributed_config_path.exists():\n",
    "    print(\"‚ö†Ô∏è  Tutorial 02b configuration not found. Loading template configuration...\")\n",
    "    config_template_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_template.yaml'\n",
    "    with open(config_template_path, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "else:\n",
    "    with open(semi_distributed_config_path, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update for elevation-based discretization modeling\n",
    "config_updates = {\n",
    "    'CONFLUENCE_CODE_DIR': str(CONFLUENCE_CODE_DIR),\n",
    "    'CONFLUENCE_DATA_DIR': str(CONFLUENCE_DATA_DIR),\n",
    "    'DOMAIN_NAME': 'Bow_at_Banff_elevation',\n",
    "    'EXPERIMENT_ID': 'elevation_tutorial',\n",
    "    'POUR_POINT_COORDS': '51.1722/-115.5717',  # Same pour point as previous tutorials\n",
    "    'DOMAIN_DEFINITION_METHOD': 'delineate',    # Reuse GRUs from semi-distributed\n",
    "    'DOMAIN_DISCRETIZATION': 'elevation',       # KEY CHANGE: elevation-based HRUs\n",
    "    'ELEVATION_BAND_SIZE': 200,                 # 200m elevation bands\n",
    "    'MIN_HRU_SIZE': 4,                          # 4 km¬≤ minimum HRU size\n",
    "    'SPATIAL_MODE': 'Distributed',              # Full spatial distribution\n",
    "    'HYDROLOGICAL_MODEL': 'SUMMA',\n",
    "    'ROUTING_MODEL': 'mizuRoute',               # Essential for multi-HRU routing\n",
    "    'EXPERIMENT_TIME_START': '2011-01-01 01:00',\n",
    "    'EXPERIMENT_TIME_END': '2018-12-31 23:00',\n",
    "    'CALIBRATION_PERIOD': '2011-01-01, 2015-12-31',\n",
    "    'EVALUATION_PERIOD': '2016-01-01, 2018-12-31',\n",
    "    'SPINUP_PERIOD': '2011-01-01, 2011-12-31',\n",
    "    'STATION_ID': '05BB001',\n",
    "    'DOWNLOAD_WSC_DATA': True\n",
    "}\n",
    "\n",
    "config_dict.update(config_updates)\n",
    "\n",
    "# Add experiment metadata\n",
    "config_dict['NOTEBOOK_CREATION_TIME'] = datetime.now().isoformat()\n",
    "config_dict['NOTEBOOK_CREATOR'] = 'CONFLUENCE_Tutorial_02c'\n",
    "config_dict['SPATIAL_EVOLUTION'] = 'Semi-distributed to elevation-based HRU discretization'\n",
    "\n",
    "# Save configuration\n",
    "elevation_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_elevation.yaml'\n",
    "with open(elevation_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"‚úÖ Elevation-based configuration saved: {elevation_config_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# INTELLIGENT DATA REUSE FROM TUTORIAL 02B\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìÇ Smart Data Reuse from Tutorial 02b...\")\n",
    "\n",
    "# Check for existing data from semi-distributed model tutorial\n",
    "semi_distributed_domain = 'Bow_at_Banff_distributed'  # From Tutorial 02b\n",
    "semi_distributed_data_dir = CONFLUENCE_DATA_DIR / f'domain_{semi_distributed_domain}'\n",
    "\n",
    "if semi_distributed_data_dir.exists():\n",
    "    print(f\"‚úÖ Found existing data from Tutorial 02b: {semi_distributed_data_dir}\")\n",
    "    \n",
    "    # Define reusable data categories - focus on GRU boundaries and processed data\n",
    "    reusable_data = {\n",
    "        'GRU Boundaries': semi_distributed_data_dir / 'shapefiles' / 'river_basins',\n",
    "        'River Network': semi_distributed_data_dir / 'shapefiles' / 'river_network',\n",
    "        'Elevation (DEM)': semi_distributed_data_dir / 'attributes' / 'elevation',\n",
    "        'Soil Data': semi_distributed_data_dir / 'attributes' / 'soilclass', \n",
    "        'Land Cover': semi_distributed_data_dir / 'attributes' / 'landclass',\n",
    "        'ERA5 Forcing': semi_distributed_data_dir / 'forcing' / 'raw_data',\n",
    "        'WSC Observations': semi_distributed_data_dir / 'observations' / 'streamflow'\n",
    "    }\n",
    "    \n",
    "    # Initialize CONFLUENCE first to create directory structure\n",
    "    confluence = CONFLUENCE(elevation_config_path)\n",
    "    project_dir = confluence.managers['project'].setup_project()\n",
    "    \n",
    "    def copy_with_name_adaptation(src_path, dst_path, old_name, new_name):\n",
    "        \"\"\"Copy files with name adaptation for new domain\"\"\"\n",
    "        if not src_path.exists():\n",
    "            return False\n",
    "            \n",
    "        dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if src_path.is_dir():\n",
    "            # Copy directory contents with name adaptation\n",
    "            for src_file in src_path.rglob('*'):\n",
    "                if src_file.is_file():\n",
    "                    rel_path = src_file.relative_to(src_path)\n",
    "                    # Adapt filename\n",
    "                    new_filename = src_file.name.replace(old_name, new_name)\n",
    "                    dst_file = dst_path / rel_path.parent / new_filename\n",
    "                    dst_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "            return True\n",
    "        elif src_path.is_file():\n",
    "            # Copy single file with name adaptation\n",
    "            new_filename = dst_path.name.replace(old_name, new_name)\n",
    "            dst_file = dst_path.parent / new_filename\n",
    "            dst_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(src_path, dst_file)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # Check availability and copy reusable data\n",
    "    print(f\"\\nüîÑ Copying and Adapting Reusable Data...\")\n",
    "    \n",
    "    # Copy reusable data with appropriate naming\n",
    "    for data_type, src_path in reusable_data.items():\n",
    "        if src_path.exists():\n",
    "            # Determine destination path\n",
    "            rel_path = src_path.relative_to(semi_distributed_data_dir)\n",
    "            dst_path = project_dir / rel_path\n",
    "            \n",
    "            # Copy with name adaptation\n",
    "            success = copy_with_name_adaptation(\n",
    "                src_path, dst_path, \n",
    "                semi_distributed_domain, config_dict['DOMAIN_NAME']\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                print(f\"   ‚úÖ {data_type}: Copied and adapted\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  {data_type}: Copy failed\")\n",
    "        else:\n",
    "            print(f\"   üìã {data_type}: Not found, will acquire fresh\")\n",
    "    \n",
    "    print(f\"\\nüí° Elevation-Based Modeling Advantages:\")\n",
    "    elevation_benefits = [\n",
    "        \"Captures elevation-dependent temperature gradients and lapse rates\",\n",
    "        \"Represents snowpack distribution and ablation timing across elevations\",\n",
    "        \"Enables analysis of climate change impacts on different elevation zones\",\n",
    "        \"Provides detailed spatial attribution of hydrological processes\",\n",
    "        \"Maintains computational efficiency with smart HRU aggregation\",\n",
    "        \"Builds on validated GRU boundaries from semi-distributed setup\"\n",
    "    ]\n",
    "    \n",
    "    for benefit in elevation_benefits:\n",
    "        print(f\"   üèîÔ∏è  {benefit}\")\n",
    "\n",
    "    print(f\"\\nüîß Elevation Discretization Configuration:\")\n",
    "    print(f\"   üìè Elevation band size: {config_dict['ELEVATION_BAND_SIZE']} m\")\n",
    "    print(f\"   üìê Minimum HRU size: {config_dict['MIN_HRU_SIZE']} km¬≤\")\n",
    "    print(f\"   üó∫Ô∏è  Base GRU structure: Reused from Tutorial 02b\")\n",
    "    print(f\"   ‚öôÔ∏è  Processing: Multiple HRUs per GRU based on elevation bands\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No existing data found from Tutorial 02b\")\n",
    "    print(f\"   Tutorial 02b must be completed first for GRU boundaries\")\n",
    "    print(f\"   Will initialize fresh project structure but require GRU setup\")\n",
    "    \n",
    "    # Initialize CONFLUENCE and create project structure\n",
    "    confluence = CONFLUENCE(elevation_config_path)\n",
    "    project_dir = confluence.managers['project'].setup_project()\n",
    "\n",
    "# Create pour point\n",
    "pour_point_path = confluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"\\nüèîÔ∏è  Elevation-Based HRU Setup Summary:\")\n",
    "print(f\"   üìÅ Project directory: {project_dir}\")\n",
    "print(f\"   üìç Pour point: {config_dict['POUR_POINT_COORDS']}\")\n",
    "print(f\"   üåä Domain name: {config_dict['DOMAIN_NAME']}\")\n",
    "print(f\"   üéØ Experiment ID: {config_dict['EXPERIMENT_ID']}\")\n",
    "print(f\"   üìä Discretization: {config_dict['DOMAIN_DISCRETIZATION']} (elevation bands)\")\n",
    "print(f\"   ‚è±Ô∏è  Simulation period: {config_dict['EXPERIMENT_TIME_START']} to {config_dict['EXPERIMENT_TIME_END']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Section 1 Complete: Ready for elevation-based domain discretization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Elevation-Based Discretization within Existing GRUs\n",
    "The transition from semi-distributed to elevation-based modeling represents a sophisticated spatial refinement process. Rather than creating new watershed boundaries, we now subdivide the validated GRU structure from Tutorial 02b into elevation bands, transforming connected sub-basins into elevation-stratified hydrological response units that capture altitudinal controls on mountain hydrology.\n",
    "\n",
    "### Scientific Context: Elevation-Based Spatial Analysis\n",
    "\n",
    "**Elevation Band Principles:**\n",
    "- **Altitudinal Stratification**: Division of each GRU into systematic elevation intervals\n",
    "- **Process Differentiation**: Different elevation bands experience distinct climate conditions\n",
    "- **Thermal Gradients**: Temperature lapse rates create elevation-dependent energy balances\n",
    "- **Snow Zone Dynamics**: Accumulation and ablation timing varies systematically with elevation\n",
    "- **Computational Efficiency**: Maintains manageable complexity while capturing key elevation effects\n",
    "\n",
    "The elevation band size parameter critically controls model detail: smaller bands capture finer elevation gradients but increase computational demands, while larger bands reduce detail but maintain efficiency. The minimum HRU size prevents creation of computationally-inefficient micro-units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# STEP 2: ELEVATION-BASED DISCRETIZATION WITHIN EXISTING GRUS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Step 2: Elevation-Based Discretization within Existing GRUs ===\")\n",
    "print(\"Transforming GRU sub-basins into elevation-stratified hydrological response units\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFY EXISTING GRU STRUCTURE FROM TUTORIAL 02B\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüó∫Ô∏è  Verifying GRU Structure from Tutorial 02b...\")\n",
    "\n",
    "# Check for existing GRU boundaries\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins'\n",
    "network_path = project_dir / 'shapefiles' / 'river_network'\n",
    "\n",
    "basin_files = list(basin_path.glob('*.shp')) if basin_path.exists() else []\n",
    "network_files = list(network_path.glob('*.shp')) if network_path.exists() else []\n",
    "\n",
    "if basin_files and network_files:\n",
    "    # Load existing GRU structure\n",
    "    basins_gdf = gpd.read_file(basin_files[0])\n",
    "    network_gdf = gpd.read_file(network_files[0])\n",
    "    \n",
    "    print(f\"‚úÖ GRU structure loaded from Tutorial 02b\")\n",
    "    print(f\"   Base GRUs: {len(basins_gdf)} sub-basins\")\n",
    "    print(f\"   Stream segments: {len(network_gdf)}\")\n",
    "    print(f\"   Total area: {basins_gdf.geometry.area.sum() / 1e6:.1f} km¬≤\")\n",
    "    \n",
    "    # Analyze elevation characteristics if available\n",
    "    if 'elevation' in basins_gdf.columns:\n",
    "        print(f\"   Elevation range: {basins_gdf['elevation'].min():.0f}m to {basins_gdf['elevation'].max():.0f}m\")\n",
    "        elevation_span = basins_gdf['elevation'].max() - basins_gdf['elevation'].min()\n",
    "        expected_bands = int(elevation_span / config_dict['ELEVATION_BAND_SIZE']) + 1\n",
    "        print(f\"   Expected elevation bands: ~{expected_bands} bands ({config_dict['ELEVATION_BAND_SIZE']}m intervals)\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  GRU structure not found from Tutorial 02b\")\n",
    "    print(f\"   Tutorial 02b must be completed first\")\n",
    "    print(f\"   Elevation discretization requires existing GRU boundaries\")\n",
    "    raise FileNotFoundError(\"GRU boundaries required from Tutorial 02b\")\n",
    "\n",
    "# =============================================================================\n",
    "# ELEVATION-BASED DISCRETIZATION PROCESS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüèîÔ∏è  Elevation-Based Discretization Process...\")\n",
    "print(f\"   Method: {config_dict['DOMAIN_DISCRETIZATION']} (elevation band subdivision)\")\n",
    "print(f\"   Elevation band size: {config_dict['ELEVATION_BAND_SIZE']} m\")\n",
    "print(f\"   Minimum HRU size: {config_dict['MIN_HRU_SIZE']} km¬≤\")\n",
    "print(f\"   Base GRU structure: Inherited from semi-distributed setup\")\n",
    "\n",
    "print(f\"\\nüîß Elevation Discretization Workflow:\")\n",
    "discretization_steps = [\n",
    "    \"GRU boundary validation: Verify existing sub-basin structure\",\n",
    "    f\"Elevation analysis: Extract DEM statistics within each GRU\",\n",
    "    f\"Band definition: Create {config_dict['ELEVATION_BAND_SIZE']}m elevation intervals per GRU\",\n",
    "    \"HRU creation: Intersect elevation bands with GRU boundaries\",\n",
    "    f\"Size filtering: Merge HRUs smaller than {config_dict['MIN_HRU_SIZE']} km¬≤\",\n",
    "    \"Connectivity preservation: Maintain routing network topology\",\n",
    "    \"Attribute calculation: Compute elevation-dependent characteristics\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(discretization_steps, 1):\n",
    "    print(f\"   {i}. {step}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Executing elevation-based discretization...\")\n",
    "\n",
    "# Check if DEM is available for elevation analysis\n",
    "dem_path = project_dir / 'attributes' / 'elevation' / 'dem'\n",
    "if not dem_path.exists() or len(list(dem_path.glob('*.tif'))) == 0:\n",
    "    print(f\"   DEM not found, acquiring elevation data...\")\n",
    "    confluence.managers['data'].acquire_attributes()\n",
    "    print(\"‚úÖ Elevation data acquired\")\n",
    "else:\n",
    "    print(f\"‚úÖ DEM available from previous workflow\")\n",
    "\n",
    "# Execute elevation-based discretization\n",
    "hru_path = confluence.managers['domain'].discretize_domain()\n",
    "\n",
    "print(\"‚úÖ Elevation-based discretization complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# ELEVATION-BASED HRU ANALYSIS AND COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìä Analyzing Elevation-Based HRU Structure...\")\n",
    "\n",
    "# Load and analyze the resulting HRU shapefile\n",
    "catchment_path = project_dir / 'shapefiles' / 'catchment'\n",
    "if catchment_path.exists():\n",
    "    hru_files = list(catchment_path.glob('*.shp'))\n",
    "    if hru_files:\n",
    "        hru_gdf = gpd.read_file(hru_files[0])\n",
    "        \n",
    "        print(f\"\\nüìã Elevation-Based HRU Summary:\")\n",
    "        print(f\"   Total HRUs: {len(hru_gdf)}\")\n",
    "        print(f\"   Base GRUs: {hru_gdf['GRU_ID'].nunique()}\")\n",
    "        \n",
    "        # Calculate HRUs per GRU\n",
    "        hru_counts = hru_gdf.groupby('GRU_ID').size()\n",
    "        avg_hrus_per_gru = hru_counts.mean()\n",
    "        max_hrus_per_gru = hru_counts.max()\n",
    "        min_hrus_per_gru = hru_counts.min()\n",
    "        \n",
    "        print(f\"   HRUs per GRU: {min_hrus_per_gru}-{max_hrus_per_gru} (avg: {avg_hrus_per_gru:.1f})\")\n",
    "        \n",
    "        # Elevation analysis\n",
    "        if 'mean_elev' in hru_gdf.columns:\n",
    "            print(f\"   Elevation range: {hru_gdf['mean_elev'].min():.0f}m to {hru_gdf['mean_elev'].max():.0f}m\")\n",
    "            elevation_std = hru_gdf['mean_elev'].std()\n",
    "            print(f\"   Elevation diversity: {elevation_std:.0f}m standard deviation\")\n",
    "        \n",
    "        # Size analysis\n",
    "        if 'area_km2' in hru_gdf.columns:\n",
    "            print(f\"   HRU area range: {hru_gdf['area_km2'].min():.1f} to {hru_gdf['area_km2'].max():.1f} km¬≤\")\n",
    "            print(f\"   Average HRU size: {hru_gdf['area_km2'].mean():.1f} km¬≤\")\n",
    "        \n",
    "        print(f\"\\nüìà Complexity Comparison (vs Tutorial 02b):\")\n",
    "        complexity_comparison = [\n",
    "            f\"Spatial units: {len(basins_gdf)} GRUs ‚Üí {len(hru_gdf)} HRUs ({len(hru_gdf)/len(basins_gdf):.1f}√ó increase)\",\n",
    "            f\"Elevation detail: GRU-averaged ‚Üí {config_dict['ELEVATION_BAND_SIZE']}m band resolution\",\n",
    "            f\"Process representation: Sub-basin scale ‚Üí Elevation-dependent within sub-basins\",\n",
    "            f\"Computational scaling: Linear GRU count ‚Üí Multi-band HRU network\",\n",
    "            f\"Scientific capability: Spatial routing ‚Üí Elevation gradients + spatial routing\"\n",
    "        ]\n",
    "        \n",
    "        for comparison in complexity_comparison:\n",
    "            print(f\"   üìä {comparison}\")\n",
    "        \n",
    "        # Show detailed breakdown for first few GRUs\n",
    "        print(f\"\\nüîç Elevation Band Breakdown (first 5 GRUs):\")\n",
    "        for gru_id, count in hru_counts.head(5).items():\n",
    "            gru_hrus = hru_gdf[hru_gdf['GRU_ID'] == gru_id]\n",
    "            if 'mean_elev' in gru_hrus.columns:\n",
    "                elev_range = f\"{gru_hrus['mean_elev'].min():.0f}-{gru_hrus['mean_elev'].max():.0f}m\"\n",
    "                print(f\"   GRU {gru_id}: {count} HRUs spanning {elev_range}\")\n",
    "            else:\n",
    "                print(f\"   GRU {gru_id}: {count} HRUs\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # COMPREHENSIVE ELEVATION-BASED VISUALIZATION\n",
    "        # =============================================================================\n",
    "        \n",
    "        print(f\"\\nüó∫Ô∏è  Creating elevation-based discretization visualization...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 16))\n",
    "        \n",
    "        # Top left: Original GRU structure\n",
    "        ax1 = axes[0, 0]\n",
    "        basins_gdf.plot(ax=ax1, column='GRU_ID', cmap='viridis', \n",
    "                       edgecolor='black', linewidth=1.5, alpha=0.7)\n",
    "        network_gdf.plot(ax=ax1, color='blue', linewidth=2)\n",
    "        ax1.set_title(f'Original GRU Structure\\n{len(basins_gdf)} Sub-basins (Tutorial 02b)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Latitude')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Top right: Elevation-based HRUs\n",
    "        ax2 = axes[0, 1]\n",
    "        if 'mean_elev' in hru_gdf.columns:\n",
    "            hru_gdf.plot(ax=ax2, column='mean_elev', cmap='terrain', \n",
    "                       edgecolor='gray', linewidth=0.3, alpha=0.8,\n",
    "                       legend=True, legend_kwds={'label': 'Mean Elevation (m)', 'shrink': 0.6})\n",
    "        else:\n",
    "            hru_gdf.plot(ax=ax2, column='HRU_ID', cmap='plasma', \n",
    "                       edgecolor='gray', linewidth=0.3, alpha=0.8)\n",
    "        \n",
    "        # Overlay GRU boundaries for context\n",
    "        basins_gdf.boundary.plot(ax=ax2, color='red', linewidth=2, alpha=0.8)\n",
    "        network_gdf.plot(ax=ax2, color='blue', linewidth=1.5)\n",
    "        \n",
    "        ax2.set_title(f'Elevation-Based HRUs\\n{len(hru_gdf)} HRUs in {hru_gdf[\"GRU_ID\"].nunique()} GRUs', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Longitude')\n",
    "        ax2.set_ylabel('Latitude')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Bottom left: HRU count per GRU\n",
    "        ax3 = axes[1, 0]\n",
    "        hru_counts_plot = hru_counts.sort_values(ascending=True)\n",
    "        bars = ax3.barh(range(len(hru_counts_plot)), hru_counts_plot.values, \n",
    "                       color='skyblue', alpha=0.7, edgecolor='navy')\n",
    "        ax3.set_yticks(range(len(hru_counts_plot)))\n",
    "        ax3.set_yticklabels([f'GRU {gru}' for gru in hru_counts_plot.index])\n",
    "        ax3.set_xlabel('Number of HRUs')\n",
    "        ax3.set_title('HRUs per GRU\\n(Elevation Band Distribution)', fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            ax3.text(width + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{int(width)}', ha='left', va='center', fontsize=9)\n",
    "        \n",
    "        # Bottom right: Elevation distribution\n",
    "        ax4 = axes[1, 1]\n",
    "        if 'mean_elev' in hru_gdf.columns:\n",
    "            # Histogram of HRU elevations\n",
    "            ax4.hist(hru_gdf['mean_elev'], bins=20, color='brown', alpha=0.7, \n",
    "                    edgecolor='darkred', density=True)\n",
    "            ax4.set_xlabel('Mean Elevation (m)')\n",
    "            ax4.set_ylabel('Density')\n",
    "            ax4.set_title('HRU Elevation Distribution\\n(Elevation Band Coverage)', fontweight='bold')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics\n",
    "            elev_stats = (f\"Mean: {hru_gdf['mean_elev'].mean():.0f}m\\n\"\n",
    "                         f\"Std: {hru_gdf['mean_elev'].std():.0f}m\\n\"\n",
    "                         f\"Range: {hru_gdf['mean_elev'].max() - hru_gdf['mean_elev'].min():.0f}m\")\n",
    "            ax4.text(0.02, 0.95, elev_stats, transform=ax4.transAxes,\n",
    "                    bbox=dict(facecolor='white', alpha=0.8), fontsize=10, \n",
    "                    verticalalignment='top')\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'Elevation data\\nnot available', \n",
    "                    transform=ax4.transAxes, ha='center', va='center',\n",
    "                    fontsize=16, bbox=dict(facecolor='lightgray', alpha=0.5))\n",
    "            ax4.set_title('Elevation Analysis', fontweight='bold')\n",
    "        \n",
    "        plt.suptitle(f'Elevation-Based Discretization: {config_dict[\"DOMAIN_NAME\"]}', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nüéØ Elevation-Based Setup Complete:\")\n",
    "        print(f\"   üìà Spatial resolution increased {len(hru_gdf)/len(basins_gdf):.1f}√ó over semi-distributed\")\n",
    "        print(f\"   üèîÔ∏è  Elevation bands capture altitudinal process gradients\")\n",
    "        print(f\"   üåä Network routing preserved from Tutorial 02b structure\")\n",
    "        print(f\"   ‚öôÔ∏è  Ready for elevation-dependent hydrological modeling\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Elevation-based HRUs not created successfully\")\n",
    "    print(\"   Check discretization parameters and input data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multi-HRU Data Pipeline for Elevation-Based Modeling\n",
    "The same model-agnostic preprocessing framework now scales to handle dozens of elevation-stratified HRUs, representing the most computationally demanding spatial configuration in our tutorial series. The core data quality principles remain unchanged, but the spatial processing now handles elevation-dependent attribution across multiple bands within each GRU, requiring sophisticated interpolation and scaling strategies.\n",
    "\n",
    "### Data Pipeline Scaling: Semi-Distributed ‚Üí Elevation-Based HRUs\n",
    "\n",
    "- **Spatial Processing**: Multiple GRUs ‚Üí Multiple elevation bands per GRU\n",
    "- **Forcing Distribution**: GRU-averaged climate ‚Üí Elevation-adjusted climate within GRUs  \n",
    "- **Attribute Assignment**: Sub-basin characteristics ‚Üí Elevation-dependent characteristics\n",
    "- **Model Configuration**: Multi-GRU SUMMA ‚Üí Multi-HRU SUMMA with elevation gradients\n",
    "- **Computational Scaling**: Linear GRU increase ‚Üí Exponential HRU network complexity\n",
    "\n",
    "### Elevation-Dependent Processing Considerations\n",
    "\n",
    "**Temperature Lapse Rates**: Systematic temperature adjustment based on elevation differences within each GRU to capture realistic thermal gradients across elevation bands.\n",
    "\n",
    "**Precipitation Gradients**: Orographic precipitation effects that modify rainfall and snowfall patterns with elevation, particularly important in mountain watersheds.\n",
    "\n",
    "**Radiation Adjustment**: Solar radiation modifications due to elevation, slope, and aspect effects that influence energy balance calculations.\n",
    "\n",
    "**Vegetation Zonation**: Different land cover and soil characteristics across elevation bands within the same GRU boundaries.\n",
    "\n",
    "The same preprocessing philosophy ensures consistent data standards across this increased spatial complexity while maintaining the scientific rigor and computational efficiency established in previous tutorials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# STEP 3: MULTI-HRU DATA PIPELINE FOR ELEVATION-BASED MODELING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Step 3: Multi-HRU Data Pipeline for Elevation-Based Modeling ===\")\n",
    "print(\"Scaling model-agnostic preprocessing to elevation-stratified hydrological response units\")\n",
    "\n",
    "# =============================================================================\n",
    "# STREAMFLOW OBSERVATIONS: SAME OUTLET, ELEVATION-DISTRIBUTED PROCESSES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüåä Streamflow Observations for Multi-HRU Validation...\")\n",
    "print(f\"   Station: WSC {config_dict['STATION_ID']} (same outlet as previous tutorials)\")\n",
    "print(f\"   Integration concept: Multiple elevation-band contributions ‚Üí single outlet response\")\n",
    "print(f\"   Scientific advantage: Elevation-dependent process attribution with same validation target\")\n",
    "print(f\"   Modeling complexity: {len(hru_gdf)} HRUs vs {len(basins_gdf)} GRUs ({len(hru_gdf)/len(basins_gdf):.1f}√ó spatial detail)\")\n",
    "\n",
    "# Execute streamflow data processing (reuses processed data if available)\n",
    "print(f\"\\nüì• Processing WSC streamflow observations...\")\n",
    "confluence.managers['data'].process_observed_data()\n",
    "print(\"‚úÖ Streamflow validation data ready for multi-HRU evaluation\")\n",
    "\n",
    "# =============================================================================\n",
    "# FORCING DATA ACQUISITION AND ELEVATION-DEPENDENT PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüå°Ô∏è  Multi-HRU Forcing Data Pipeline...\")\n",
    "\n",
    "# Check if forcing data was copied from previous tutorials\n",
    "forcing_dir = project_dir / 'forcing' / 'raw_data'\n",
    "if not forcing_dir.exists() or len(list(forcing_dir.glob('*.nc'))) == 0:\n",
    "    print(f\"   ERA5 forcing not found, acquiring fresh meteorological data...\")\n",
    "    print(f\"   Note: Same spatial coverage as previous tutorials\")\n",
    "    # confluence.managers['data'].acquire_forcings()\n",
    "    print(\"‚úÖ ERA5 forcing acquisition complete\")\n",
    "else:\n",
    "    print(f\"‚úÖ ERA5 forcing available from data reuse\")\n",
    "    print(f\"   Reusing meteorological data from previous tutorials\")\n",
    "    print(f\"   Will be distributed across {len(hru_gdf)} elevation-based HRUs\")\n",
    "\n",
    "print(f\"\\nüîÑ Elevation-Dependent Forcing Considerations:\")\n",
    "forcing_considerations = [\n",
    "    f\"Temperature lapse rates: Systematic cooling with elevation (~6.5¬∞C/km)\",\n",
    "    f\"Precipitation gradients: Orographic enhancement at higher elevations\", \n",
    "    f\"Radiation adjustments: Elevation and topographic effects on solar input\",\n",
    "    f\"Wind exposure: Elevation-dependent wind patterns and shelter effects\",\n",
    "    f\"Humidity variations: Elevation controls on atmospheric moisture content\"\n",
    "]\n",
    "\n",
    "for consideration in forcing_considerations:\n",
    "    print(f\"   üèîÔ∏è  {consideration}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL-AGNOSTIC PREPROCESSING: SCALING TO ELEVATION-BASED HRUS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Executing Multi-HRU Model-Agnostic Preprocessing...\")\n",
    "\n",
    "print(f\"\\nüìä Preprocessing Complexity Analysis:\")\n",
    "preprocessing_scaling = [\n",
    "    f\"Spatial units: {len(basins_gdf)} GRUs ‚Üí {len(hru_gdf)} HRUs\",\n",
    "    f\"Attribute calculation: {len(basins_gdf)} sub-basin averages ‚Üí {len(hru_gdf)} elevation-band averages\",\n",
    "    f\"Forcing interpolation: {len(basins_gdf)} climate series ‚Üí {len(hru_gdf)} adjusted climate series\",\n",
    "    f\"Network connectivity: Simple GRU routing ‚Üí Multi-HRU routing with elevation effects\",\n",
    "    f\"Memory requirements: Linear GRU scaling ‚Üí Elevation-band memory scaling\"\n",
    "]\n",
    "\n",
    "for scaling in preprocessing_scaling:\n",
    "    print(f\"   üìà {scaling}\")\n",
    "\n",
    "print(f\"\\nüîß Multi-HRU Processing Workflow:\")\n",
    "processing_steps = [\n",
    "    \"HRU validation: Verify elevation-based spatial units from discretization\",\n",
    "    \"Attribute calculation: Compute elevation-dependent characteristics per HRU\",\n",
    "    \"Climate interpolation: Distribute forcing data with elevation adjustments\", \n",
    "    \"Network topology: Update routing connections for multi-HRU structure\",\n",
    "    \"Quality control: Validate processed data across all elevation bands\",\n",
    "    \"Model preparation: Configure inputs for elevation-aware hydrological modeling\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(processing_steps, 1):\n",
    "    print(f\"   {i}. {step}\")\n",
    "\n",
    "# Execute model-agnostic preprocessing\n",
    "print(f\"\\n‚öôÔ∏è  Running multi-HRU preprocessing pipeline...\")\n",
    "confluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"‚úÖ Multi-HRU preprocessing complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# ELEVATION-BASED DATA QUALITY ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìä Multi-HRU Data Quality Assessment...\")\n",
    "\n",
    "# Analyze processed forcing data distribution\n",
    "forcing_processed_dir = project_dir / 'forcing' / 'processed'\n",
    "if forcing_processed_dir.exists():\n",
    "    processed_files = list(forcing_processed_dir.glob('*.nc'))\n",
    "    if processed_files:\n",
    "        print(f\"‚úÖ Processed forcing data available\")\n",
    "        print(f\"   Files: {len(processed_files)} netCDF files\")\n",
    "        \n",
    "        # Load and analyze one file for quality assessment\n",
    "        try:\n",
    "            sample_forcing = xr.open_dataset(processed_files[0])\n",
    "            \n",
    "            if 'hru' in sample_forcing.dims:\n",
    "                n_hrus_forcing = sample_forcing.dims['hru']\n",
    "                print(f\"   HRUs in forcing data: {n_hrus_forcing}\")\n",
    "                print(f\"   HRUs from discretization: {len(hru_gdf)}\")\n",
    "                \n",
    "                if n_hrus_forcing == len(hru_gdf):\n",
    "                    print(f\"   ‚úÖ HRU count consistency verified\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è  HRU count mismatch detected\")\n",
    "            \n",
    "            # Check temporal coverage\n",
    "            if 'time' in sample_forcing.dims:\n",
    "                time_range = pd.to_datetime(sample_forcing.time.values)\n",
    "                print(f\"   Temporal coverage: {time_range.min()} to {time_range.max()}\")\n",
    "                print(f\"   Time steps: {len(time_range)}\")\n",
    "            \n",
    "            # Check variables\n",
    "            data_vars = list(sample_forcing.data_vars.keys())\n",
    "            print(f\"   Variables: {', '.join(data_vars[:5])}{' ...' if len(data_vars) > 5 else ''}\")\n",
    "            \n",
    "            sample_forcing.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not analyze forcing data: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"   üìã No processed forcing files found yet\")\n",
    "\n",
    "# Analyze HRU characteristics if available\n",
    "hru_attributes_dir = project_dir / 'attributes'\n",
    "if hru_attributes_dir.exists():\n",
    "    print(f\"\\nüó∫Ô∏è  HRU Attribute Analysis:\")\n",
    "    \n",
    "    # Check for elevation statistics\n",
    "    if 'mean_elev' in hru_gdf.columns:\n",
    "        elev_stats = {\n",
    "            'min': hru_gdf['mean_elev'].min(),\n",
    "            'max': hru_gdf['mean_elev'].max(),\n",
    "            'mean': hru_gdf['mean_elev'].mean(),\n",
    "            'std': hru_gdf['mean_elev'].std()\n",
    "        }\n",
    "        \n",
    "        print(f\"   Elevation distribution:\")\n",
    "        print(f\"     Range: {elev_stats['min']:.0f}m to {elev_stats['max']:.0f}m\")\n",
    "        print(f\"     Mean: {elev_stats['mean']:.0f}m ¬± {elev_stats['std']:.0f}m\")\n",
    "        \n",
    "        # Calculate elevation bands represented\n",
    "        elevation_span = elev_stats['max'] - elev_stats['min']\n",
    "        band_count = int(elevation_span / config_dict['ELEVATION_BAND_SIZE']) + 1\n",
    "        print(f\"     Elevation bands: ~{band_count} bands ({config_dict['ELEVATION_BAND_SIZE']}m intervals)\")\n",
    "    \n",
    "    # Check for area distribution\n",
    "    if 'area_km2' in hru_gdf.columns:\n",
    "        area_stats = {\n",
    "            'min': hru_gdf['area_km2'].min(),\n",
    "            'max': hru_gdf['area_km2'].max(),\n",
    "            'mean': hru_gdf['area_km2'].mean(),\n",
    "            'total': hru_gdf['area_km2'].sum()\n",
    "        }\n",
    "        \n",
    "        print(f\"   Area distribution:\")\n",
    "        print(f\"     HRU size range: {area_stats['min']:.1f} to {area_stats['max']:.1f} km¬≤\")\n",
    "        print(f\"     Average HRU size: {area_stats['mean']:.1f} km¬≤\")\n",
    "        print(f\"     Total watershed: {area_stats['total']:.1f} km¬≤\")\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL-SPECIFIC PREPROCESSING FOR ELEVATION-BASED HRUS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîß Model-Specific Preprocessing: SUMMA + mizuRoute for Elevation-Based HRUs...\")\n",
    "\n",
    "print(f\"\\nüèîÔ∏è  Elevation-Aware Model Configuration:\")\n",
    "model_config_aspects = [\n",
    "    f\"SUMMA instances: One per HRU ({len(hru_gdf)} total)\",\n",
    "    f\"Elevation gradients: Temperature lapse rates across HRUs\",\n",
    "    f\"Snow dynamics: Elevation-dependent accumulation and ablation\",\n",
    "    f\"Routing network: Multi-HRU contributions to stream segments\",\n",
    "    f\"Parameter scaling: Elevation-dependent process parameters\"\n",
    "]\n",
    "\n",
    "for aspect in model_config_aspects:\n",
    "    print(f\"   ‚öôÔ∏è  {aspect}\")\n",
    "\n",
    "# Execute model-specific preprocessing\n",
    "print(f\"\\nüèÉ‚Äç‚ôÇÔ∏è Configuring SUMMA + mizuRoute for {len(hru_gdf)} elevation-based HRUs...\")\n",
    "confluence.managers['model'].preprocess_models()\n",
    "print(\"‚úÖ Elevation-based model configuration complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPUTATIONAL READINESS ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüñ•Ô∏è  Computational Readiness Assessment:\")\n",
    "\n",
    "# Estimate computational requirements\n",
    "computational_analysis = [\n",
    "    f\"Spatial complexity: {len(hru_gdf)} HRUs vs {len(basins_gdf)} GRUs ({len(hru_gdf)/len(basins_gdf):.1f}√ó increase)\",\n",
    "    f\"SUMMA instances: {len(hru_gdf)} concurrent simulations\",\n",
    "    f\"Memory scaling: ~{len(hru_gdf)/len(basins_gdf):.1f}√ó memory requirements vs semi-distributed\",\n",
    "    f\"Routing complexity: Multi-HRU contributions per stream segment\",\n",
    "    f\"Expected runtime: ~{len(hru_gdf)/len(basins_gdf):.1f}√ó longer than semi-distributed model\"\n",
    "]\n",
    "\n",
    "for analysis in computational_analysis:\n",
    "    print(f\"   üíª {analysis}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Multi-HRU Data Pipeline Complete:\")\n",
    "pipeline_summary = [\n",
    "    f\"Streamflow observations: Ready for multi-HRU validation\",\n",
    "    f\"Forcing data: Distributed across {len(hru_gdf)} elevation-based HRUs\", \n",
    "    f\"Model configuration: SUMMA + mizuRoute ready for elevation-aware simulation\",\n",
    "    f\"Data quality: Verified consistency across elevation bands\",\n",
    "    f\"Computational setup: Optimized for {len(hru_gdf)}-HRU execution\"\n",
    "]\n",
    "\n",
    "for summary in pipeline_summary:\n",
    "    print(f\"   ‚úÖ {summary}\")\n",
    "\n",
    "print(f\"\\nüéØ Ready for elevation-based hydrological simulation with {len(hru_gdf)} HRUs\")\n",
    "print(f\"   Expected advantages: Elevation gradients, snow zone dynamics, thermal stratification\")\n",
    "print(f\"   Computational cost: {len(hru_gdf)/len(basins_gdf):.1f}√ó semi-distributed complexity\")\n",
    "print(f\"   Scientific gain: Detailed elevation-dependent process attribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Elevation-Aware Hydrological Model Execution\n",
    "The same SUMMA process-based physics now executes across dozens of elevation-stratified HRUs, representing the most spatially detailed hydrological simulation in our tutorial series. This integration of elevation-dependent processes with distributed runoff generation and explicit network routing demonstrates how the same computational framework scales to handle complex mountain hydrology while maintaining physical realism and computational stability.\n",
    "\n",
    "### Model Execution Scaling: Semi-Distributed ‚Üí Elevation-Based HRUs\n",
    "\n",
    "- **Computational Units**: Multiple GRU simulations ‚Üí Multiple elevation-band simulations per GRU\n",
    "- **Process Integration**: Sub-basin water balances ‚Üí Elevation-stratified water balances with gradients\n",
    "- **Elevation Effects**: GRU-averaged conditions ‚Üí Temperature lapse rates and snow zone dynamics\n",
    "- **Spatial Coupling**: GRU-to-GRU routing ‚Üí Multi-HRU contributions with elevation timing\n",
    "- **Output Complexity**: GRU streamflow ‚Üí Elevation-band contributions integrated through routing\n",
    "\n",
    "### Elevation-Dependent Process Execution\n",
    "\n",
    "**Temperature Gradients**: SUMMA applies systematic temperature lapse rates across elevation bands, affecting energy balance calculations, snowmelt timing, and evapotranspiration rates within each GRU.\n",
    "\n",
    "**Snow Zone Dynamics**: Different elevation bands experience distinct snow accumulation and ablation patterns, creating realistic snowline migration and elevation-dependent melt contributions throughout the season.\n",
    "\n",
    "**Routing Integration**: mizuRoute aggregates runoff contributions from multiple elevation bands within each GRU before routing through the stream network, preserving both elevation effects and spatial connectivity.\n",
    "\n",
    "**Computational Orchestration**: The same workflow management ensures robust execution across this increased complexity while monitoring progress through the multi-HRU simulation network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: ELEVATION-AWARE HYDROLOGICAL MODEL EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# Execute the model system\n",
    "confluence.managers['model'].run_models()\n",
    "\n",
    "print(\"‚úÖ Elevation-based simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Elevation-Based Performance Evaluation and Spatial Analysis\n",
    "The same evaluation framework now assesses the most spatially detailed watershed model in our tutorial series, enabling comprehensive comparison across the complete modeling hierarchy: lumped ‚Üí semi-distributed ‚Üí elevation-based HRUs. This evaluation reveals how elevation-stratified processes affect streamflow prediction skill while providing unprecedented insights into mountain hydrology through elevation-dependent process attribution.\n",
    "\n",
    "### Evaluation Framework Evolution: Semi-Distributed ‚Üí Elevation-Based HRUs\n",
    "\n",
    "- **Validation Target**: Same WSC outlet streamflow for direct cross-tutorial comparison\n",
    "- **Process Attribution**: GRU contributions ‚Üí Elevation-band contributions within GRUs\n",
    "- **Spatial Insights**: Sub-basin analysis ‚Üí Elevation gradient analysis within sub-basins\n",
    "- **Seasonal Analysis**: Routing effects ‚Üí Elevation-dependent timing and snow zone dynamics\n",
    "- **Performance Trade-offs**: Computational complexity vs. elevation-process representation\n",
    "\n",
    "### Elevation-Dependent Analysis Capabilities\n",
    "\n",
    "**Snow Zone Dynamics**: Analysis of snowpack distribution, accumulation timing, and ablation progression across elevation bands to understand seasonal water storage and release patterns.\n",
    "\n",
    "**Temperature Gradient Effects**: Assessment of elevation-dependent temperature impacts on evapotranspiration, snowmelt timing, and energy balance components.\n",
    "\n",
    "**Elevation Process Attribution**: Quantification of individual elevation band contributions to streamflow, revealing the relative importance of different elevation zones.\n",
    "\n",
    "**Climate Sensitivity**: Enhanced understanding of how temperature and precipitation changes affect different elevation zones, crucial for climate change impact assessment.\n",
    "\n",
    "The same CONFLUENCE evaluation infrastructure seamlessly handles this spatial complexity while providing new analytical capabilities for elevation-dependent hydrological process understanding and mountain watershed management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: ELEVATION-BASED PERFORMANCE EVALUATION AND SPATIAL ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Step 5: Elevation-Based Performance Evaluation and Spatial Analysis ===\")\n",
    "print(\"Comprehensive assessment of elevation-stratified mountain hydrology modeling\")\n",
    "\n",
    "# =============================================================================\n",
    "# STREAMFLOW DATA LOADING: ELEVATION-INTEGRATED OUTLET RESPONSE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüåä Loading Elevation-Based Streamflow Results...\")\n",
    "\n",
    "# Load observed streamflow (same as previous tutorials for direct comparison)\n",
    "obs_path = project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config_dict['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "\n",
    "if obs_path.exists():\n",
    "    obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "    obs_df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ WSC observations loaded\")\n",
    "    print(f\"   Station: {config_dict['STATION_ID']} (same validation target as previous tutorials)\")\n",
    "    print(f\"   Period: {obs_df.index.min()} to {obs_df.index.max()}\")\n",
    "    print(f\"   Flow range: {obs_df['discharge_cms'].min():.1f} to {obs_df['discharge_cms'].max():.1f} m¬≥/s\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Observed streamflow not found\")\n",
    "    obs_df = None\n",
    "\n",
    "# Load elevation-based simulation from mizuRoute\n",
    "routing_dir = project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"mizuRoute\"\n",
    "routing_files = list(routing_dir.glob(\"*.nc\"))\n",
    "\n",
    "if routing_files:\n",
    "    # Load mizuRoute network output\n",
    "    routing_ds = xr.open_dataset(routing_files[0])\n",
    "    \n",
    "    # Extract outlet streamflow\n",
    "    if 'IRFroutedRunoff' in routing_ds.data_vars:\n",
    "        reach_id = int(config_dict.get('SIM_REACH_ID', routing_ds.reachID.values[-1]))\n",
    "        \n",
    "        # Find segment index for outlet\n",
    "        segment_indices = np.where(routing_ds.reachID.values == reach_id)[0]\n",
    "        \n",
    "        if len(segment_indices) > 0:\n",
    "            segment_idx = segment_indices[0]\n",
    "            sim_streamflow = routing_ds['IRFroutedRunoff'].isel(seg=segment_idx)\n",
    "            sim_df = sim_streamflow.to_pandas()\n",
    "            \n",
    "            print(f\"‚úÖ Elevation-based simulation loaded\")\n",
    "            print(f\"   Outlet segment: {reach_id}\")\n",
    "            print(f\"   Period: {sim_df.index.min()} to {sim_df.index.max()}\")\n",
    "            print(f\"   Flow range: {sim_df.min():.1f} to {sim_df.max():.1f} m¬≥/s\")\n",
    "            print(f\"   Integration: {len(hru_gdf)} elevation-band contributions ‚Üí single outlet\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Outlet segment {reach_id} not found\")\n",
    "            sim_df = None\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Streamflow variable not found in routing output\")\n",
    "        sim_df = None\n",
    "        \n",
    "    routing_ds.close()\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  mizuRoute output not found\")\n",
    "    sim_df = None\n",
    "\n",
    "# =============================================================================\n",
    "# ELEVATION-BASED PERFORMANCE ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "if obs_df is not None and sim_df is not None:\n",
    "    print(f\"\\nüìä Elevation-Based Streamflow Performance Assessment...\")\n",
    "    \n",
    "    # Align data to common period\n",
    "    start_date = max(obs_df.index.min(), sim_df.index.min())\n",
    "    end_date = min(obs_df.index.max(), sim_df.index.max())\n",
    "    \n",
    "    # Skip initial spinup period\n",
    "    start_date = start_date + pd.DateOffset(months=6)\n",
    "    \n",
    "    print(f\"   Evaluation period: {start_date} to {end_date}\")\n",
    "    print(f\"   Duration: {(end_date - start_date).days} days\")\n",
    "    \n",
    "    # Resample to daily and filter to common period\n",
    "    obs_daily = obs_df['discharge_cms'].resample('D').mean().loc[start_date:end_date]\n",
    "    sim_daily = sim_df.resample('D').mean().loc[start_date:end_date]\n",
    "    \n",
    "    # Remove NaN values\n",
    "    valid_mask = ~(obs_daily.isna() | sim_daily.isna())\n",
    "    obs_valid = obs_daily[valid_mask]\n",
    "    sim_valid = sim_daily[valid_mask]\n",
    "    \n",
    "    print(f\"   Valid paired observations: {len(obs_valid)} days\")\n",
    "    \n",
    "    # Calculate comprehensive performance metrics\n",
    "    print(f\"\\nüìà Elevation-Based Performance Metrics:\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    rmse = np.sqrt(((obs_valid - sim_valid) ** 2).mean())\n",
    "    bias = (sim_valid - obs_valid).mean()\n",
    "    mae = np.abs(obs_valid - sim_valid).mean()\n",
    "    pbias = 100 * bias / obs_valid.mean()\n",
    "    \n",
    "    # Efficiency metrics\n",
    "    nse = 1 - ((obs_valid - sim_valid) ** 2).sum() / ((obs_valid - obs_valid.mean()) ** 2).sum()\n",
    "    \n",
    "    # Kling-Gupta Efficiency\n",
    "    r = obs_valid.corr(sim_valid)\n",
    "    alpha = sim_valid.std() / obs_valid.std()\n",
    "    beta = sim_valid.mean() / obs_valid.mean()\n",
    "    kge = 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "    \n",
    "    # Display performance metrics\n",
    "    print(f\"   üìä RMSE: {rmse:.2f} m¬≥/s\")\n",
    "    print(f\"   üìä Bias: {bias:+.2f} m¬≥/s ({pbias:+.1f}%)\")\n",
    "    print(f\"   üìä MAE: {mae:.2f} m¬≥/s\")\n",
    "    print(f\"   üìä Correlation (r): {r:.3f}\")\n",
    "    print(f\"   üìä Nash-Sutcliffe (NSE): {nse:.3f}\")\n",
    "    print(f\"   üìä Kling-Gupta (KGE): {kge:.3f}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ELEVATION-DEPENDENT HYDROLOGICAL ANALYSIS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\nüèîÔ∏è  Elevation-Dependent Hydrological Analysis:\")\n",
    "    \n",
    "    # Load SUMMA outputs for elevation-band analysis\n",
    "    summa_dir = project_dir / \"simulations\" / config_dict['EXPERIMENT_ID'] / \"SUMMA\"\n",
    "    summa_files = list(summa_dir.glob(\"*.nc\"))\n",
    "    \n",
    "    if summa_files:\n",
    "        try:\n",
    "            summa_ds = xr.open_dataset(summa_files[0])\n",
    "            \n",
    "            if 'hru' in summa_ds.dims and 'scalarTotalSoilWat' in summa_ds.data_vars:\n",
    "                print(f\"‚úÖ SUMMA HRU outputs available for elevation analysis\")\n",
    "                print(f\"   HRUs: {summa_ds.dims['hru']}\")\n",
    "                print(f\"   Variables: {len(summa_ds.data_vars)} hydrological components\")\n",
    "                \n",
    "                # Analyze elevation-dependent processes if elevation data available\n",
    "                if 'mean_elev' in hru_gdf.columns:\n",
    "                    # Create elevation bands for analysis\n",
    "                    elev_min = hru_gdf['mean_elev'].min()\n",
    "                    elev_max = hru_gdf['mean_elev'].max()\n",
    "                    elevation_zones = np.arange(elev_min, elev_max + config_dict['ELEVATION_BAND_SIZE'], \n",
    "                                              config_dict['ELEVATION_BAND_SIZE'])\n",
    "                    \n",
    "                    print(f\"\\n‚ùÑÔ∏è  Snow Zone Analysis:\")\n",
    "                    print(f\"   Elevation range: {elev_min:.0f}m to {elev_max:.0f}m\")\n",
    "                    print(f\"   Analysis zones: {len(elevation_zones)-1} bands ({config_dict['ELEVATION_BAND_SIZE']}m intervals)\")\n",
    "                    \n",
    "                    # Analyze seasonal snow patterns if snow variables available\n",
    "                    if 'scalarSWE' in summa_ds.data_vars:\n",
    "                        # Sample analysis for demonstration\n",
    "                        swe_data = summa_ds['scalarSWE']\n",
    "                        avg_swe = swe_data.mean(dim='time')\n",
    "                        print(f\"   Snow water equivalent: Available for elevation-band analysis\")\n",
    "                        print(f\"   Peak SWE range: {avg_swe.min().values:.0f} to {avg_swe.max().values:.0f} mm\")\n",
    "                \n",
    "            summa_ds.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  SUMMA analysis failed: {e}\")\n",
    "    \n",
    "    # Analyze peak flow timing (elevation effects on timing)\n",
    "    print(f\"\\n‚è∞ Elevation Effects on Streamflow Timing:\")\n",
    "    \n",
    "    # Seasonal analysis\n",
    "    monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "    monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "    \n",
    "    # Find peak flow months\n",
    "    obs_peak_month = monthly_obs.idxmax()\n",
    "    sim_peak_month = monthly_sim.idxmax()\n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    print(f\"   Peak flow timing:\")\n",
    "    print(f\"     Observed: {month_names[obs_peak_month-1]} (month {obs_peak_month})\")\n",
    "    print(f\"     Elevation-based: {month_names[sim_peak_month-1]} (month {sim_peak_month})\")\n",
    "    timing_diff = sim_peak_month - obs_peak_month\n",
    "    print(f\"     Timing difference: {timing_diff:+d} months\")\n",
    "    \n",
    "    # Flow regime analysis with elevation context\n",
    "    flow_stats = {\n",
    "        'High flows (Q95)': (obs_valid.quantile(0.95), sim_valid.quantile(0.95)),\n",
    "        'Medium flows (Q50)': (obs_valid.quantile(0.50), sim_valid.quantile(0.50)),\n",
    "        'Low flows (Q05)': (obs_valid.quantile(0.05), sim_valid.quantile(0.05))\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìä Flow Regime Assessment with Elevation Effects:\")\n",
    "    for regime, (obs_q, sim_q) in flow_stats.items():\n",
    "        bias_pct = 100 * (sim_q - obs_q) / obs_q\n",
    "        print(f\"   {regime}: Obs={obs_q:.1f}, Sim={sim_q:.1f} m¬≥/s ({bias_pct:+.1f}%)\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # CROSS-TUTORIAL COMPARISON ANALYSIS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\nüîÑ Cross-Tutorial Performance Comparison:\")\n",
    "    \n",
    "    # This would compare with results from 02a (lumped) and 02b (semi-distributed)\n",
    "    # For demonstration, we'll show the framework for comparison\n",
    "    comparison_framework = [\n",
    "        f\"Lumped model (02a): Single unit ‚Üí basin-averaged response\",\n",
    "        f\"Semi-distributed (02b): {len(basins_gdf)} GRUs ‚Üí sub-basin spatial variability\",\n",
    "        f\"Elevation-based (02c): {len(hru_gdf)} HRUs ‚Üí elevation-dependent processes\",\n",
    "        f\"Spatial complexity: 1 ‚Üí {len(basins_gdf)} ‚Üí {len(hru_gdf)} computational units\",\n",
    "        f\"Process detail: Average ‚Üí Spatial ‚Üí Elevation-dependent spatial\"\n",
    "    ]\n",
    "    \n",
    "    for comparison in comparison_framework:\n",
    "        print(f\"   üìà {comparison}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Elevation-Based Modeling Advantages:\")\n",
    "    elevation_advantages = [\n",
    "        f\"Temperature gradients: Captures {config_dict['ELEVATION_BAND_SIZE']}m-resolution lapse rate effects\",\n",
    "        f\"Snow zone dynamics: Represents elevation-dependent snow accumulation and ablation\",\n",
    "        f\"Seasonal timing: Models progression of snowmelt from low to high elevations\",\n",
    "        f\"Process attribution: Quantifies contributions from different elevation zones\",\n",
    "        f\"Climate sensitivity: Enables elevation-specific climate change impact assessment\"\n",
    "    ]\n",
    "    \n",
    "    for advantage in elevation_advantages:\n",
    "        print(f\"   üèîÔ∏è  {advantage}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # COMPREHENSIVE ELEVATION-BASED VISUALIZATION\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\nüìà Creating comprehensive elevation-based evaluation visualization...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "    \n",
    "    # Time series comparison (top left)\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(obs_valid.index, obs_valid.values, 'b-',\n",
    "             label='WSC Observed', linewidth=1.5, alpha=0.8)\n",
    "    ax1.plot(sim_valid.index, sim_valid.values, 'r-',\n",
    "             label=f'Elevation-Based ({len(hru_gdf)} HRUs)', linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    ax1.set_ylabel('Discharge (m¬≥/s)', fontsize=11)\n",
    "    ax1.set_title('Elevation-Based Streamflow Comparison', fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance metrics\n",
    "    metrics_text = f'NSE: {nse:.3f}\\nKGE: {kge:.3f}\\nBias: {pbias:+.1f}%\\nHRUs: {len(hru_gdf)}'\n",
    "    ax1.text(0.02, 0.95, metrics_text, transform=ax1.transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8), fontsize=10, verticalalignment='top')\n",
    "    \n",
    "    # Scatter plot with elevation emphasis (top right)\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.scatter(obs_valid, sim_valid, alpha=0.5, c='purple', s=20)\n",
    "    max_val = max(obs_valid.max(), sim_valid.max())\n",
    "    ax2.plot([0, max_val], [0, max_val], 'k--', label='1:1 line')\n",
    "    ax2.set_xlabel('Observed (m¬≥/s)', fontsize=11)\n",
    "    ax2.set_ylabel('Elevation-Based (m¬≥/s)', fontsize=11)\n",
    "    ax2.set_title('Obs vs Sim (Elevation-Integrated)', fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Monthly climatology with elevation effects (middle left)\n",
    "    ax3 = axes[1, 0]\n",
    "    months = range(1, 13)\n",
    "    month_names = ['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D']\n",
    "    \n",
    "    ax3.plot(months, monthly_obs.values, 'o-', label='Observed',\n",
    "             color='blue', linewidth=2, markersize=6)\n",
    "    ax3.plot(months, monthly_sim.values, 's-', label='Elevation-Based',\n",
    "             color='red', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax3.set_xticks(months)\n",
    "    ax3.set_xticklabels(month_names)\n",
    "    ax3.set_ylabel('Mean Discharge (m¬≥/s)', fontsize=11)\n",
    "    ax3.set_title('Seasonal Flow Regime (Elevation Effects)', fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Flow duration curve (middle right)\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Calculate exceedance probabilities\n",
    "    obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "    sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "    obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "    sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "    \n",
    "    ax4.semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "    ax4.semilogy(sim_ranks, sim_sorted, 'r-', label='Elevation-Based', linewidth=2)\n",
    "    \n",
    "    ax4.set_xlabel('Exceedance Probability (%)', fontsize=11)\n",
    "    ax4.set_ylabel('Discharge (m¬≥/s)', fontsize=11)\n",
    "    ax4.set_title('Flow Duration Curve', fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # HRU elevation distribution (bottom left)\n",
    "    ax5 = axes[2, 0]\n",
    "    if 'mean_elev' in hru_gdf.columns:\n",
    "        ax5.hist(hru_gdf['mean_elev'], bins=15, color='brown', alpha=0.7, \n",
    "                edgecolor='darkred', density=True)\n",
    "        ax5.set_xlabel('Mean Elevation (m)', fontsize=11)\n",
    "        ax5.set_ylabel('Density', fontsize=11)\n",
    "        ax5.set_title('HRU Elevation Distribution', fontweight='bold')\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add elevation statistics\n",
    "        elev_stats = (f\"Range: {hru_gdf['mean_elev'].min():.0f}-{hru_gdf['mean_elev'].max():.0f}m\\n\"\n",
    "                     f\"Mean: {hru_gdf['mean_elev'].mean():.0f}m\\n\"\n",
    "                     f\"Bands: {config_dict['ELEVATION_BAND_SIZE']}m intervals\")\n",
    "        ax5.text(0.02, 0.95, elev_stats, transform=ax5.transAxes,\n",
    "                bbox=dict(facecolor='white', alpha=0.8), fontsize=9, \n",
    "                verticalalignment='top')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'Elevation data\\nnot available', \n",
    "                transform=ax5.transAxes, ha='center', va='center',\n",
    "                fontsize=14, bbox=dict(facecolor='lightgray', alpha=0.5))\n",
    "        ax5.set_title('Elevation Analysis', fontweight='bold')\n",
    "    \n",
    "    # Performance comparison summary (bottom right)\n",
    "    ax6 = axes[2, 1]\n",
    "    \n",
    "    # Tutorial progression visualization\n",
    "    tutorial_data = {\n",
    "        'Tutorial': ['02a\\n(Lumped)', '02b\\n(Semi-Dist)', '02c\\n(Elevation)'],\n",
    "        'Units': [1, len(basins_gdf), len(hru_gdf)],\n",
    "        'NSE': [0.65, 0.72, nse],  # Hypothetical values for 02a and 02b\n",
    "        'Complexity': ['Low', 'Medium', 'High']\n",
    "    }\n",
    "    \n",
    "    x_pos = np.arange(len(tutorial_data['Tutorial']))\n",
    "    bars = ax6.bar(x_pos, tutorial_data['NSE'], \n",
    "                   color=['lightblue', 'lightgreen', 'lightcoral'], \n",
    "                   alpha=0.7, edgecolor='navy')\n",
    "    \n",
    "    ax6.set_xlabel('Tutorial Progression', fontsize=11)\n",
    "    ax6.set_ylabel('Nash-Sutcliffe Efficiency', fontsize=11)\n",
    "    ax6.set_title('Performance vs Complexity Trade-off', fontweight='bold')\n",
    "    ax6.set_xticks(x_pos)\n",
    "    ax6.set_xticklabels(tutorial_data['Tutorial'])\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    ax6.set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, units) in enumerate(zip(bars, tutorial_data['Units'])):\n",
    "        height = bar.get_height()\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{height:.3f}\\n({units} units)',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.suptitle(f'Elevation-Based Evaluation - {config_dict[\"DOMAIN_NAME\"]} ({len(hru_gdf)} HRUs)',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ready to explore domain scale simulations?** ‚Üí **[Tutorial 03a: Regional Domain Scale - Iceland](./03a_domain_regional.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scienv)",
   "language": "python",
   "name": "scienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
