{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFLUENCE Tutorial - 04h: GGMN Large Sample Study (Groundwater Monitoring Network)\n",
    "\n",
    "## Introduction\n",
    "This tutorial demonstrates large sample groundwater modeling using the Global Groundwater Monitoring Network (GGMN) dataset. Building on the multi-site analysis framework established in previous tutorials, we apply CONFLUENCE to systematically evaluate groundwater simulation performance across diverse hydrogeological settings throughout North America.\n",
    "\n",
    "## GGMN: A Critical Groundwater Observation Network\n",
    "The Global Groundwater Monitoring Network represents one of the most comprehensive collections of groundwater level observations available for hydrological model validation. The network provides extensive spatial coverage across diverse hydrogeological environments, from shallow alluvial aquifers to deep confined systems. Stations span climatic gradients from arid to humid regions, capturing the full spectrum of groundwater-surface water interactions.\n",
    "\n",
    "The observational richness of GGMN includes direct measurements of groundwater levels and complementary hydrogeological information that provide critical insights into subsurface water storage dynamics. Many sites contain multi-decade records processed through standardized measurement protocols, making them ideal for systematic groundwater model evaluation.\n",
    "\n",
    "## Scientific Importance of Groundwater Validation\n",
    "Groundwater processes represent some of the most challenging aspects of hydrological modeling due to their subsurface complexity and long timescales. Groundwater systems exhibit complex flow patterns influenced by geological heterogeneity, while storage dynamics depend on aquifer properties and recharge patterns. The coupling between surface and groundwater systems creates feedback mechanisms that significantly influence streamflow generation and water availability.\n",
    "\n",
    "## Learning Outcomes\n",
    "This tutorial demonstrates systematic groundwater validation through large sample analysis. We show how to adapt CONFLUENCE configurations for groundwater monitoring sites, focus analysis on baseflow periods and storage dynamics, implement multi-variable validation comparing simulated and observed groundwater levels, and assess model performance across different hydrogeological settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Large Sample Groundwater Study Design and Site Selection\n",
    "Establishing the foundation for large sample groundwater modeling using the comprehensive GGMN observation network. We demonstrate how CONFLUENCE's workflow efficiency enables systematic groundwater process evaluation across diverse hydrogeological environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style for groundwater visualization\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "%matplotlib inline\n",
    "confluence_path = Path('../').resolve()\n",
    "\n",
    "# =============================================================================\n",
    "# LARGE SAMPLE GROUNDWATER EXPERIMENTAL DESIGN CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Set directory paths\n",
    "CONFLUENCE_CODE_DIR = confluence_path\n",
    "CONFLUENCE_DATA_DIR = Path('/Users/darrieythorsson/compHydro/data/CONFLUENCE_data')  # ‚Üê Update this path\n",
    "\n",
    "# Experiment configuration\n",
    "experiment_config = {\n",
    "    'ggmn_stations': 'ggmn_stations.csv',\n",
    "    'ggmn_data_dir': '/path/to/ggmn/data',  # Update with actual GGMN data path\n",
    "    'template_config': str(CONFLUENCE_CODE_DIR / '0_config_files' / 'config_point_template.yaml'),\n",
    "    'output_dir': 'ggmn_output',\n",
    "    'config_dir': 'ggmn_configs', \n",
    "    'base_path': str(CONFLUENCE_DATA_DIR / 'ggmn'),\n",
    "    'min_completeness': 70.0,\n",
    "    'min_records': 100,\n",
    "    'max_stations': 50,\n",
    "    'start_year': 2010,\n",
    "    'end_year': 2020,\n",
    "    'no_submit': True  # Set to False to actually submit jobs\n",
    "}\n",
    "\n",
    "experiment_dir = Path('ggmn_experiment_results')\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Load groundwater configuration template\n",
    "gw_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_point_template.yaml'\n",
    "with open(gw_config_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update for groundwater tutorial-specific settings\n",
    "config_updates = {\n",
    "    'CONFLUENCE_CODE_DIR': str(CONFLUENCE_CODE_DIR),\n",
    "    'CONFLUENCE_DATA_DIR': str(CONFLUENCE_DATA_DIR),\n",
    "    'DOMAIN_NAME': 'ggmn_template',\n",
    "    'EXPERIMENT_ID': 'run_1',\n",
    "    'EXPERIMENT_TIME_START': '2015-01-01 01:00',\n",
    "    'EXPERIMENT_TIME_END': '2020-12-31 23:00',\n",
    "    'DOWNLOAD_USGS_GW': True,\n",
    "    'ANALYSES': ['benchmarking', 'groundwater']\n",
    "}\n",
    "\n",
    "config_dict.update(config_updates)\n",
    "\n",
    "# Save groundwater configuration template\n",
    "ggmn_config_path = CONFLUENCE_CODE_DIR / '0_config_files' / 'config_ggmn_template.yaml'\n",
    "with open(ggmn_config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"‚úÖ GGMN template configuration saved: {ggmn_config_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND EXAMINE GGMN GROUNDWATER STATIONS DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüíß Loading GGMN Groundwater Station Database...\")\n",
    "\n",
    "# Load or create demonstration GGMN dataset\n",
    "try:\n",
    "    ggmn_df = pd.read_csv('ggmn_stations.csv')\n",
    "    print(f\"‚úÖ Successfully loaded GGMN database: {len(ggmn_df)} groundwater stations available\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è  GGMN database not found, creating demonstration dataset...\")\n",
    "    \n",
    "    # Create demonstration GGMN dataset for tutorial\n",
    "    np.random.seed(42)\n",
    "    n_stations = 200\n",
    "    \n",
    "    # Generate realistic North American groundwater station locations\n",
    "    regions = [\n",
    "        {'name': 'Great_Plains', 'lat_range': (35, 50), 'lon_range': (-105, -95), 'n': 50},\n",
    "        {'name': 'Eastern_US', 'lat_range': (30, 45), 'lon_range': (-85, -70), 'n': 40},\n",
    "        {'name': 'Western_US', 'lat_range': (32, 48), 'lon_range': (-125, -105), 'n': 35},\n",
    "        {'name': 'Canadian_Prairies', 'lat_range': (49, 60), 'lon_range': (-115, -95), 'n': 30},\n",
    "        {'name': 'Southwest_US', 'lat_range': (25, 40), 'lon_range': (-115, -100), 'n': 25},\n",
    "        {'name': 'Other_NA', 'lat_range': (25, 65), 'lon_range': (-140, -60), 'n': 20}\n",
    "    ]\n",
    "    \n",
    "    stations_data = []\n",
    "    station_id = 1\n",
    "    \n",
    "    for region in regions:\n",
    "        for i in range(region['n']):\n",
    "            lat = np.random.uniform(region['lat_range'][0], region['lat_range'][1])\n",
    "            lon = np.random.uniform(region['lon_range'][0], region['lon_range'][1])\n",
    "            \n",
    "            # Well depth based on region (deeper in plains, shallower in mountains)\n",
    "            if region['name'] in ['Great_Plains', 'Canadian_Prairies']:\n",
    "                well_depth = np.random.uniform(10, 150)\n",
    "            elif region['name'] == 'Southwest_US':\n",
    "                well_depth = np.random.uniform(5, 300)  # High variability in arid regions\n",
    "            else:\n",
    "                well_depth = np.random.uniform(5, 80)\n",
    "            \n",
    "            # Data completeness (varies by accessibility and monitoring program)\n",
    "            base_completeness = 85 - np.random.uniform(0, 20)\n",
    "            data_completeness = max(30, np.random.normal(base_completeness, 10))\n",
    "            \n",
    "            # Aquifer type\n",
    "            aquifer_types = ['Alluvial', 'Bedrock', 'Glacial', 'Volcanic', 'Confined', 'Unconfined']\n",
    "            aquifer_type = np.random.choice(aquifer_types)\n",
    "            \n",
    "            # Create station entry\n",
    "            station = {\n",
    "                'station_id': f\"GGMN_{station_id:05d}\",\n",
    "                'station_name': f\"{region['name']}_GW_{i+1:03d}\",\n",
    "                'latitude': round(lat, 4),\n",
    "                'longitude': round(lon, 4),\n",
    "                'well_depth': round(well_depth, 1),\n",
    "                'aquifer_type': aquifer_type,\n",
    "                'data_completeness': round(min(95, max(30, data_completeness)), 1),\n",
    "                'record_count': int(np.random.uniform(50, 3000)),\n",
    "                'region': region['name']\n",
    "            }\n",
    "            \n",
    "            # Add CONFLUENCE formatting\n",
    "            buffer = 0.05\n",
    "            station['BOUNDING_BOX_COORDS'] = f\"{lat + buffer}/{lon - buffer}/{lat - buffer}/{lon + buffer}\"\n",
    "            station['POUR_POINT_COORDS'] = f\"{lat}/{lon}\"\n",
    "            station['Watershed_Name'] = station['station_id'].replace(' ', '_')\n",
    "            \n",
    "            stations_data.append(station)\n",
    "            station_id += 1\n",
    "    \n",
    "    ggmn_df = pd.DataFrame(stations_data)\n",
    "    ggmn_df.to_csv('ggmn_stations.csv', index=False)\n",
    "    print(f\"‚úÖ Created demonstration GGMN dataset: {len(ggmn_df)} stations\")\n",
    "\n",
    "# Display basic dataset information\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"  Total groundwater stations: {len(ggmn_df)}\")\n",
    "print(f\"  Well depth range: {ggmn_df['well_depth'].min():.1f}m to {ggmn_df['well_depth'].max():.1f}m\")\n",
    "print(f\"  Data completeness: {ggmn_df['data_completeness'].mean():.1f}% ¬± {ggmn_df['data_completeness'].std():.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# GROUNDWATER-SPECIFIC DATASET CHARACTERISTICS ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüíß Analyzing Groundwater Dataset Characteristics...\")\n",
    "\n",
    "# Well depth categories\n",
    "depth_zones = [\n",
    "    (0, 10, 'Shallow (<10m)'),\n",
    "    (10, 30, 'Intermediate (10-30m)'),\n",
    "    (30, 100, 'Deep (30-100m)'),\n",
    "    (100, 1000, 'Very Deep (>100m)')\n",
    "]\n",
    "\n",
    "ggmn_df['depth_category'] = 'Unknown'\n",
    "for min_depth, max_depth, category in depth_zones:\n",
    "    mask = (ggmn_df['well_depth'] >= min_depth) & (ggmn_df['well_depth'] < max_depth)\n",
    "    ggmn_df.loc[mask, 'depth_category'] = category\n",
    "\n",
    "depth_counts = ggmn_df['depth_category'].value_counts()\n",
    "print(f\"  Well depth categories: {len(depth_counts)}\")\n",
    "print(f\"    Most common: {depth_counts.index[0]} ({depth_counts.iloc[0]} wells)\")\n",
    "\n",
    "# Aquifer type analysis\n",
    "if 'aquifer_type' in ggmn_df.columns:\n",
    "    aquifer_counts = ggmn_df['aquifer_type'].value_counts()\n",
    "    print(f\"  Aquifer types: {len(aquifer_counts)}\")\n",
    "    print(f\"    Most common: {aquifer_counts.index[0]} ({aquifer_counts.iloc[0]} wells)\")\n",
    "\n",
    "# Regional distribution\n",
    "if 'region' in ggmn_df.columns:\n",
    "    region_counts = ggmn_df['region'].value_counts()\n",
    "    print(f\"  Regions: {len(region_counts)}\")\n",
    "    print(f\"    Most sampled: {region_counts.index[0]} ({region_counts.iloc[0]} wells)\")\n",
    "\n",
    "# =============================================================================\n",
    "# GROUNDWATER DATASET VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìà Creating Groundwater Dataset Overview Visualization...\")\n",
    "\n",
    "# Create comprehensive groundwater dataset overview\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. North American groundwater station distribution map\n",
    "ax1 = axes[0, 0]\n",
    "scatter = ax1.scatter(ggmn_df['longitude'], ggmn_df['latitude'], \n",
    "                     c=ggmn_df['well_depth'], cmap='plasma', \n",
    "                     alpha=0.7, s=30, edgecolors='black', linewidth=0.3)\n",
    "ax1.set_xlabel('Longitude')\n",
    "ax1.set_ylabel('Latitude')\n",
    "ax1.set_title(f'GGMN Groundwater Station Distribution\\n({len(ggmn_df)} wells)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(-140, -60)\n",
    "ax1.set_ylim(25, 65)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax1)\n",
    "cbar.set_label('Well Depth (m)')\n",
    "\n",
    "# 2. Well depth distribution\n",
    "ax2 = axes[0, 1]\n",
    "depth_counts = ggmn_df['depth_category'].value_counts()\n",
    "bars = ax2.bar(range(len(depth_counts)), depth_counts.values, \n",
    "               color='lightblue', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(depth_counts)))\n",
    "ax2.set_xticklabels(depth_counts.index, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Number of Wells')\n",
    "ax2.set_title('Wells by Depth Category')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, count in zip(bars, depth_counts.values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1,\n",
    "            str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Aquifer type distribution\n",
    "ax3 = axes[0, 2]\n",
    "if 'aquifer_type' in ggmn_df.columns:\n",
    "    aquifer_counts = ggmn_df['aquifer_type'].value_counts()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(aquifer_counts)))\n",
    "    bars = ax3.bar(range(len(aquifer_counts)), aquifer_counts.values, \n",
    "                   color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax3.set_xticks(range(len(aquifer_counts)))\n",
    "    ax3.set_xticklabels(aquifer_counts.index, rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Number of Wells')\n",
    "    ax3.set_title('Wells by Aquifer Type')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Well depth vs latitude\n",
    "ax4 = axes[1, 0]\n",
    "ax4.scatter(ggmn_df['latitude'], ggmn_df['well_depth'], \n",
    "           alpha=0.6, s=25, c='green', edgecolors='black', linewidth=0.2)\n",
    "ax4.set_xlabel('Latitude (¬∞N)')\n",
    "ax4.set_ylabel('Well Depth (m)')\n",
    "ax4.set_title('Well Depth vs Latitude')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Data quality assessment\n",
    "ax5 = axes[1, 1]\n",
    "ax5.scatter(ggmn_df['data_completeness'], ggmn_df['record_count'], \n",
    "           alpha=0.6, s=25, c='orange', edgecolors='black', linewidth=0.2)\n",
    "ax5.set_xlabel('Data Completeness (%)')\n",
    "ax5.set_ylabel('Record Count')\n",
    "ax5.set_title('Data Quality Assessment')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "ax5.axvline(x=70, color='red', linestyle='--', alpha=0.7, label='70% threshold')\n",
    "ax5.legend()\n",
    "\n",
    "# 6. Regional distribution\n",
    "ax6 = axes[1, 2]\n",
    "if 'region' in ggmn_df.columns:\n",
    "    region_counts = ggmn_df['region'].value_counts()\n",
    "    wedges, texts, autotexts = ax6.pie(region_counts.values, labels=region_counts.index, \n",
    "                                      autopct='%1.1f%%', startangle=90)\n",
    "    ax6.set_title('Wells by Region')\n",
    "    \n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontweight('bold')\n",
    "\n",
    "plt.suptitle('GGMN Groundwater Monitoring Network - Dataset Overview', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# FILTER HIGH-QUALITY STATIONS FOR ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîç Filtering High-Quality Groundwater Stations...\")\n",
    "\n",
    "# Apply quality filters\n",
    "quality_mask = (\n",
    "    (ggmn_df['data_completeness'] >= experiment_config['min_completeness']) &\n",
    "    (ggmn_df['record_count'] >= experiment_config['min_records'])\n",
    ")\n",
    "\n",
    "complete_stations = ggmn_df[quality_mask].copy()\n",
    "\n",
    "if len(complete_stations) > experiment_config['max_stations']:\n",
    "    # Select stations with highest data quality\n",
    "    complete_stations = complete_stations.sort_values(\n",
    "        ['data_completeness', 'record_count'], \n",
    "        ascending=False\n",
    "    ).head(experiment_config['max_stations'])\n",
    "\n",
    "print(f\"‚úÖ Selected {len(complete_stations)} high-quality groundwater stations\")\n",
    "print(f\"  Quality criteria: ‚â•{experiment_config['min_completeness']}% completeness, ‚â•{experiment_config['min_records']} records\")\n",
    "print(f\"  Mean data completeness: {complete_stations['data_completeness'].mean():.1f}%\")\n",
    "print(f\"  Mean record count: {complete_stations['record_count'].mean():.0f}\")\n",
    "\n",
    "# Regional distribution of selected stations\n",
    "if 'region' in complete_stations.columns:\n",
    "    selected_regions = complete_stations['region'].value_counts()\n",
    "    print(f\"\\nüó∫Ô∏è  Selected stations by region:\")\n",
    "    for region, count in selected_regions.items():\n",
    "        print(f\"    {region}: {count} wells\")\n",
    "\n",
    "print(f\"\\n‚úÖ Step 1 Complete: GGMN Dataset Analysis and Site Selection\")\n",
    "print(f\"   üìä Dataset loaded: {len(ggmn_df)} total groundwater monitoring wells\")\n",
    "print(f\"   üéØ High-quality selection: {len(complete_stations)} wells for analysis\")\n",
    "print(f\"   üåç Geographic coverage: North American groundwater monitoring network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Large Sample Groundwater Modeling Execution\n",
    "Execute systematic groundwater modeling across diverse hydrogeological environments using the GGMN station selection. This demonstrates CONFLUENCE's capability for large sample groundwater process validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ggmn_script_from_notebook():\n",
    "    \"\"\"\n",
    "    Execute the run_ggmn.py script from within the notebook\n",
    "    \"\"\"\n",
    "    print(f\"\\nüíß Executing GGMN Large Sample Groundwater Processing Script...\")\n",
    "    \n",
    "    script_path = \"./run_ggmn.py\"\n",
    "    \n",
    "    if not Path(script_path).exists():\n",
    "        print(f\"‚ùå Script not found: {script_path}\")\n",
    "        print(f\"   Please ensure run_ggmn.py is in the current directory\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"   üìù Script location: {script_path}\")\n",
    "    print(f\"   üéØ Target sites: {len(complete_stations)} GGMN stations\")\n",
    "    print(f\"   ‚è∞ Processing started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare script arguments\n",
    "        script_args = [\n",
    "            'python', script_path,\n",
    "            '--ggmn_stations', experiment_config['ggmn_stations'],\n",
    "            '--ggmn_data_dir', experiment_config['ggmn_data_dir'],\n",
    "            '--template_config', experiment_config['template_config'],\n",
    "            '--output_dir', experiment_config['output_dir'],\n",
    "            '--config_dir', experiment_config['config_dir'],\n",
    "            '--min_completeness', str(experiment_config['min_completeness']),\n",
    "            '--min_records', str(experiment_config['min_records']),\n",
    "            '--max_stations', str(experiment_config['max_stations']),\n",
    "            '--base_path', experiment_config['base_path']\n",
    "        ]\n",
    "        \n",
    "        # Add optional parameters\n",
    "        if experiment_config.get('start_year'):\n",
    "            script_args.extend(['--start_year', str(experiment_config['start_year'])])\n",
    "        if experiment_config.get('end_year'):\n",
    "            script_args.extend(['--end_year', str(experiment_config['end_year'])])\n",
    "        \n",
    "        if experiment_config.get('no_submit', False):\n",
    "            script_args.append('--no_submit')\n",
    "        \n",
    "        print(f\"   üîß Key arguments: stations={experiment_config['max_stations']}, quality‚â•{experiment_config['min_completeness']}%\")\n",
    "        \n",
    "        # Execute script\n",
    "        process = subprocess.Popen(\n",
    "            script_args,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "        \n",
    "        # Handle input for job submission\n",
    "        if not experiment_config.get('no_submit', False):\n",
    "            stdout, stderr = process.communicate(input='y\\n')\n",
    "        else:\n",
    "            stdout, stderr = process.communicate()\n",
    "        \n",
    "        # Display output\n",
    "        if stdout:\n",
    "            print(\"\\nüìã Script Output:\")\n",
    "            key_lines = [line for line in stdout.split('\\n') if any(keyword in line.lower() for keyword in \n",
    "                        ['found', 'processing', 'generated', 'submitted', 'complete', 'error', 'success'])]\n",
    "            for line in key_lines[:10]:  # Show first 10 relevant lines\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "            if len(key_lines) > 10:\n",
    "                print(f\"   ... and {len(key_lines) - 10} more lines\")\n",
    "        \n",
    "        if stderr and len(stderr.strip()) > 0:\n",
    "            print(\"\\n‚ö†Ô∏è  Script Messages:\")\n",
    "            for line in stderr.split('\\n')[:5]:  # Show first 5 error lines\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "            print(f\"\\n‚úÖ GGMN processing script completed successfully\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Script failed with return code: {process.returncode}\")\n",
    "            return False\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Python or script not found. Please check paths.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running script: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_manual_ggmn_configs():\n",
    "    \"\"\"\n",
    "    Create CONFLUENCE config files manually if script is not available\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîß Creating CONFLUENCE Configuration Files for GGMN Stations...\")\n",
    "    \n",
    "    config_dir = Path(experiment_config['config_dir'])\n",
    "    config_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    configs_created = 0\n",
    "    \n",
    "    for idx, station in complete_stations.iterrows():\n",
    "        station_id = station['station_id']\n",
    "        domain_name = station['Watershed_Name']\n",
    "        pour_point = station['POUR_POINT_COORDS']\n",
    "        bounding_box = station['BOUNDING_BOX_COORDS']\n",
    "        \n",
    "        # Load template config\n",
    "        with open(experiment_config['template_config'], 'r') as f:\n",
    "            config_content = f.read()\n",
    "        \n",
    "        # Update for this station\n",
    "        config_content = config_content.replace('DOMAIN_NAME: \"ggmn_template\"', f'DOMAIN_NAME: \"{domain_name}\"')\n",
    "        config_content = config_content.replace('POUR_POINT_COORDS: 51.1722/-115.5717', f'POUR_POINT_COORDS: {pour_point}')\n",
    "        config_content = config_content.replace('BOUNDING_BOX_COORDS: 51.76/-116.55/50.95/-115.5', f'BOUNDING_BOX_COORDS: {bounding_box}')\n",
    "        \n",
    "        # Enable groundwater settings\n",
    "        config_content = config_content.replace('DOWNLOAD_USGS_GW: \\'true\\'', 'DOWNLOAD_USGS_GW: true')\n",
    "        config_content = config_content.replace('USGS_STATION: \\'06306300\\'', f'USGS_STATION: \\'{station_id}\\'')\n",
    "        \n",
    "        # Save config file\n",
    "        config_path = config_dir / f\"config_{domain_name}.yaml\"\n",
    "        with open(config_path, 'w') as f:\n",
    "            f.write(config_content)\n",
    "        \n",
    "        configs_created += 1\n",
    "        \n",
    "        if configs_created <= 3:  # Print first few for verification\n",
    "            print(f\"   ‚úÖ Created config for {domain_name}: {config_path}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Created {configs_created} CONFLUENCE configuration files\")\n",
    "    print(f\"   üìÅ Configuration directory: {config_dir}\")\n",
    "    \n",
    "    return configs_created\n",
    "\n",
    "# Try to execute the GGMN script\n",
    "script_success = run_ggmn_script_from_notebook()\n",
    "\n",
    "# If script fails or is not available, create configs manually\n",
    "if not script_success:\n",
    "    print(f\"\\nüîÑ Script execution failed or unavailable. Creating configurations manually...\")\n",
    "    configs_created = create_manual_ggmn_configs()\n",
    "    \n",
    "    print(f\"\\nüìã Manual Configuration Summary:\")\n",
    "    print(f\"   ‚öôÔ∏è  Configuration files created: {configs_created}\")\n",
    "    print(f\"   üéØ Ready for CONFLUENCE execution\")\n",
    "    print(f\"   üìÅ Next step: Submit jobs using created configurations\")\n",
    "    \n",
    "    if experiment_config.get('no_submit', True):\n",
    "        print(f\"\\nüí° To submit jobs:\")\n",
    "        print(f\"   1. Review configs in: {experiment_config['config_dir']}\")\n",
    "        print(f\"   2. Submit individual jobs: python CONFLUENCE.py --config path/to/config.yaml\")\n",
    "        print(f\"   3. Or use batch submission scripts\")\n",
    "\n",
    "print(f\"\\n‚úÖ Step 2 Complete: GGMN Large Sample Processing Setup\")\n",
    "print(f\"   üéØ Stations configured: {len(complete_stations)}\")\n",
    "print(f\"   ‚öôÔ∏è  Processing approach: {'Script execution' if script_success else 'Manual configuration'}\")\n",
    "print(f\"   üìä Ready for groundwater simulation and validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multi-Site Groundwater Validation and Analysis\n",
    "Demonstrate comprehensive groundwater validation through systematic multi-site analysis using GGMN observations. This showcases groundwater process evaluation and hydrogeological performance assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "\n",
    "def discover_completed_groundwater_domains():\n",
    "    \"\"\"\n",
    "    Discover completed GGMN domain directories and groundwater outputs\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Discovering Completed GGMN Groundwater Modeling Domains...\")\n",
    "    \n",
    "    base_path = Path(experiment_config['base_path'])\n",
    "    domain_pattern = str(base_path / \"domain_*\")\n",
    "    domain_dirs = glob.glob(domain_pattern)\n",
    "    \n",
    "    print(f\"   üìÅ Found {len(domain_dirs)} total domain directories\")\n",
    "    \n",
    "    completed_domains = []\n",
    "    \n",
    "    for domain_dir in domain_dirs:\n",
    "        domain_path = Path(domain_dir)\n",
    "        domain_name = domain_path.name.replace('domain_', '')\n",
    "        \n",
    "        # Check if this is a GGMN domain\n",
    "        if any(domain_name in site for site in complete_stations['Watershed_Name'].values):\n",
    "            \n",
    "            domain_info = {\n",
    "                'domain_name': domain_name,\n",
    "                'domain_path': domain_path,\n",
    "                'has_shapefile': (domain_path / \"shapefiles\" / \"catchment\").exists(),\n",
    "                'has_simulations': (domain_path / \"simulations\").exists(),\n",
    "                'has_observations': (domain_path / \"observations\" / \"groundwater\").exists(),\n",
    "                'simulation_files': [],\n",
    "                'groundwater_obs_file': None\n",
    "            }\n",
    "            \n",
    "            # Find simulation files\n",
    "            if domain_info['has_simulations']:\n",
    "                sim_dir = domain_path / \"simulations\"\n",
    "                nc_files = list(sim_dir.glob(\"**/*.nc\"))\n",
    "                domain_info['simulation_files'] = nc_files\n",
    "                domain_info['has_results'] = len(nc_files) > 0\n",
    "            else:\n",
    "                domain_info['has_results'] = False\n",
    "            \n",
    "            # Find groundwater observation files\n",
    "            if domain_info['has_observations']:\n",
    "                gw_dir = domain_path / \"observations\" / \"groundwater\" / \"raw_data\"\n",
    "                if gw_dir.exists():\n",
    "                    gw_files = list(gw_dir.glob(\"*.csv\"))\n",
    "                    if gw_files:\n",
    "                        domain_info['groundwater_obs_file'] = gw_files[0]\n",
    "            \n",
    "            completed_domains.append(domain_info)\n",
    "    \n",
    "    print(f\"   üíß GGMN domains found: {len(completed_domains)}\")\n",
    "    print(f\"   üìä Domains with simulation results: {sum(1 for d in completed_domains if d['has_results'])}\")\n",
    "    print(f\"   üìã Domains with observations: {sum(1 for d in completed_domains if d['has_observations'])}\")\n",
    "    \n",
    "    return completed_domains\n",
    "\n",
    "def create_groundwater_overview_visualization(completed_domains):\n",
    "    \"\"\"\n",
    "    Create overview visualization of groundwater domain processing status\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìà Creating Groundwater Domain Overview Visualization...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Processing status map\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Plot all selected sites\n",
    "    ax1.scatter(complete_stations['longitude'], complete_stations['latitude'], \n",
    "               c='lightgray', alpha=0.5, s=25, label='Selected stations', marker='o')\n",
    "    \n",
    "    # Plot completed domains with status colors\n",
    "    for domain in completed_domains:\n",
    "        domain_name = domain['domain_name']\n",
    "        site_row = complete_stations[complete_stations['Watershed_Name'] == domain_name]\n",
    "        \n",
    "        if not site_row.empty:\n",
    "            lat = site_row['latitude'].iloc[0]\n",
    "            lon = site_row['longitude'].iloc[0]\n",
    "            \n",
    "            if domain['has_results'] and domain['has_observations']:\n",
    "                color, marker, size = 'green', 's', 50\n",
    "            elif domain['has_results']:\n",
    "                color, marker, size = 'orange', '^', 40\n",
    "            elif domain['has_observations']:\n",
    "                color, marker, size = 'blue', 'D', 35\n",
    "            else:\n",
    "                color, marker, size = 'red', 'v', 25\n",
    "            \n",
    "            ax1.scatter(lon, lat, c=color, s=size, marker=marker, alpha=0.8,\n",
    "                       edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.set_title('GGMN Groundwater Processing Status')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(-140, -60)\n",
    "    ax1.set_ylim(25, 65)\n",
    "    \n",
    "    # 2. Processing statistics\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    total_selected = len(complete_stations)\n",
    "    total_discovered = len(completed_domains)\n",
    "    total_with_results = sum(1 for d in completed_domains if d['has_results'])\n",
    "    total_with_obs = sum(1 for d in completed_domains if d['has_observations'])\n",
    "    total_complete = sum(1 for d in completed_domains if d['has_results'] and d['has_observations'])\n",
    "    \n",
    "    categories = ['Selected', 'Processing\\nStarted', 'Simulation\\nComplete', 'Observations\\nFound', 'Ready for\\nValidation']\n",
    "    counts = [total_selected, total_discovered, total_with_results, total_with_obs, total_complete]\n",
    "    colors = ['lightblue', 'yellow', 'orange', 'cyan', 'green']\n",
    "    \n",
    "    bars = ax2.bar(categories, counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax2.set_ylabel('Number of Sites')\n",
    "    ax2.set_title('Groundwater Processing Progress')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 3. Well depth distribution of processed sites\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    processed_wells = []\n",
    "    for domain in completed_domains:\n",
    "        domain_name = domain['domain_name']\n",
    "        site_row = complete_stations[complete_stations['Watershed_Name'] == domain_name]\n",
    "        if not site_row.empty:\n",
    "            processed_wells.append(site_row['well_depth'].iloc[0])\n",
    "    \n",
    "    if processed_wells:\n",
    "        ax3.hist(processed_wells, bins=15, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        ax3.set_xlabel('Well Depth (m)')\n",
    "        ax3.set_ylabel('Number of Wells')\n",
    "        ax3.set_title('Processed Wells by Depth')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Regional processing status\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    if 'region' in complete_stations.columns:\n",
    "        region_status = {}\n",
    "        \n",
    "        for domain in completed_domains:\n",
    "            domain_name = domain['domain_name']\n",
    "            site_row = complete_stations[complete_stations['Watershed_Name'] == domain_name]\n",
    "            \n",
    "            if not site_row.empty:\n",
    "                region = site_row['region'].iloc[0]\n",
    "                if region not in region_status:\n",
    "                    region_status[region] = {'total': 0, 'complete': 0}\n",
    "                \n",
    "                region_status[region]['total'] += 1\n",
    "                if domain['has_results'] and domain['has_observations']:\n",
    "                    region_status[region]['complete'] += 1\n",
    "        \n",
    "        if region_status:\n",
    "            regions = list(region_status.keys())\n",
    "            complete_counts = [region_status[r]['complete'] for r in regions]\n",
    "            total_counts = [region_status[r]['total'] for r in regions]\n",
    "            pending_counts = [total_counts[i] - complete_counts[i] for i in range(len(regions))]\n",
    "            \n",
    "            x_pos = range(len(regions))\n",
    "            \n",
    "            ax4.bar(x_pos, complete_counts, label='Complete', color='green', alpha=0.7)\n",
    "            ax4.bar(x_pos, pending_counts, bottom=complete_counts, \n",
    "                   label='Pending', color='orange', alpha=0.7)\n",
    "            \n",
    "            ax4.set_xticks(x_pos)\n",
    "            ax4.set_xticklabels([r.replace('_', ' ') for r in regions], rotation=45, ha='right')\n",
    "            ax4.set_ylabel('Number of Sites')\n",
    "            ax4.set_title('Processing Status by Region')\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('GGMN Large Sample Groundwater Study - Processing Overview', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    overview_path = experiment_dir / 'plots' / 'groundwater_domain_overview.png'\n",
    "    overview_path.parent.mkdir(exist_ok=True)\n",
    "    plt.savefig(overview_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Groundwater overview saved: {overview_path}\")\n",
    "    \n",
    "    return total_selected, total_discovered, total_with_results, total_with_obs, total_complete\n",
    "\n",
    "def create_groundwater_analysis_summary(completed_domains):\n",
    "    \"\"\"\n",
    "    Create summary analysis of groundwater modeling results\n",
    "    \"\"\"\n",
    "    print(f\"\\nüíß Creating Groundwater Analysis Summary...\")\n",
    "    \n",
    "    # Analyze completed simulations\n",
    "    simulation_summary = {\n",
    "        'domains_with_results': 0,\n",
    "        'domains_with_observations': 0,\n",
    "        'total_simulation_files': 0,\n",
    "        'average_well_depth': 0,\n",
    "        'depth_range': (0, 0)\n",
    "    }\n",
    "    \n",
    "    well_depths = []\n",
    "    regions_represented = set()\n",
    "    \n",
    "    for domain in completed_domains:\n",
    "        if domain['has_results']:\n",
    "            simulation_summary['domains_with_results'] += 1\n",
    "            simulation_summary['total_simulation_files'] += len(domain['simulation_files'])\n",
    "        \n",
    "        if domain['has_observations']:\n",
    "            simulation_summary['domains_with_observations'] += 1\n",
    "        \n",
    "        # Get site metadata\n",
    "        domain_name = domain['domain_name']\n",
    "        site_row = complete_stations[complete_stations['Watershed_Name'] == domain_name]\n",
    "        \n",
    "        if not site_row.empty:\n",
    "            well_depths.append(site_row['well_depth'].iloc[0])\n",
    "            if 'region' in site_row.columns:\n",
    "                regions_represented.add(site_row['region'].iloc[0])\n",
    "    \n",
    "    if well_depths:\n",
    "        simulation_summary['average_well_depth'] = np.mean(well_depths)\n",
    "        simulation_summary['depth_range'] = (min(well_depths), max(well_depths))\n",
    "    \n",
    "    # Create summary visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # 1. Processing efficiency\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    labels = ['With Results', 'With Observations', 'Complete']\n",
    "    values = [\n",
    "        simulation_summary['domains_with_results'],\n",
    "        simulation_summary['domains_with_observations'],\n",
    "        sum(1 for d in completed_domains if d['has_results'] and d['has_observations'])\n",
    "    ]\n",
    "    colors = ['orange', 'blue', 'green']\n",
    "    \n",
    "    bars = ax1.bar(labels, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    for bar, value in zip(bars, values):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "                str(value), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax1.set_ylabel('Number of Domains')\n",
    "    ax1.set_title('Processing Completion Status')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Well depth distribution\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    if well_depths:\n",
    "        ax2.hist(well_depths, bins=12, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "        ax2.axvline(x=np.mean(well_depths), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(well_depths):.1f}m')\n",
    "        ax2.set_xlabel('Well Depth (m)')\n",
    "        ax2.set_ylabel('Number of Wells')\n",
    "        ax2.set_title('Well Depth Distribution')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Regional representation\n",
    "    ax3 = axes[2]\n",
    "    \n",
    "    if regions_represented:\n",
    "        region_counts = {}\n",
    "        for domain in completed_domains:\n",
    "            domain_name = domain['domain_name']\n",
    "            site_row = complete_stations[complete_stations['Watershed_Name'] == domain_name]\n",
    "            if not site_row.empty and 'region' in site_row.columns:\n",
    "                region = site_row['region'].iloc[0]\n",
    "                region_counts[region] = region_counts.get(region, 0) + 1\n",
    "        \n",
    "        if region_counts:\n",
    "            regions = list(region_counts.keys())\n",
    "            counts = list(region_counts.values())\n",
    "            \n",
    "            ax3.pie(counts, labels=[r.replace('_', ' ') for r in regions], \n",
    "                   autopct='%1.1f%%', startangle=90)\n",
    "            ax3.set_title('Regional Distribution')\n",
    "    \n",
    "    plt.suptitle('GGMN Groundwater Study - Analysis Summary', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    summary_path = experiment_dir / 'plots' / 'groundwater_analysis_summary.png'\n",
    "    plt.savefig(summary_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Groundwater analysis summary saved: {summary_path}\")\n",
    "    \n",
    "    return simulation_summary\n",
    "\n",
    "def create_final_ggmn_report(completed_domains, processing_stats, simulation_summary):\n",
    "    \"\"\"\n",
    "    Create final comprehensive report for GGMN study\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìã Creating Final GGMN Groundwater Study Report...\")\n",
    "    \n",
    "    report_path = experiment_dir / 'reports' / 'ggmn_final_report.txt'\n",
    "    report_path.parent.mkdir(exist_ok=True)\n",
    "    \n",
    "    total_selected, total_discovered, total_with_results, total_with_obs, total_complete = processing_stats\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"GGMN Large Sample Groundwater Study - Final Report\\n\")\n",
    "        f.write(\"=\" * 52 + \"\\n\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"PROCESSING SUMMARY:\\n\")\n",
    "        f.write(f\"  Stations selected: {total_selected}\\n\")\n",
    "        f.write(f\"  Processing initiated: {total_discovered}\\n\")\n",
    "        f.write(f\"  Simulation results: {total_with_results}\\n\")\n",
    "        f.write(f\"  Observations found: {total_with_obs}\\n\")\n",
    "        f.write(f\"  Complete validation: {total_complete}\\n\\n\")\n",
    "        \n",
    "        f.write(\"DATASET CHARACTERISTICS:\\n\")\n",
    "        f.write(f\"  Quality threshold: ‚â•{experiment_config['min_completeness']}% completeness\\n\")\n",
    "        f.write(f\"  Minimum records: {experiment_config['min_records']}\\n\")\n",
    "        f.write(f\"  Time period: {experiment_config.get('start_year', 'N/A')} - {experiment_config.get('end_year', 'N/A')}\\n\")\n",
    "        \n",
    "        if simulation_summary['average_well_depth'] > 0:\n",
    "            f.write(f\"  Average well depth: {simulation_summary['average_well_depth']:.1f}m\\n\")\n",
    "            f.write(f\"  Depth range: {simulation_summary['depth_range'][0]:.1f} - {simulation_summary['depth_range'][1]:.1f}m\\n\")\n",
    "        \n",
    "        f.write(\"\\nSIMULATION RESULTS:\\n\")\n",
    "        f.write(f\"  Domains with results: {simulation_summary['domains_with_results']}\\n\")\n",
    "        f.write(f\"  Total output files: {simulation_summary['total_simulation_files']}\\n\")\n",
    "        f.write(f\"  Observation files: {simulation_summary['domains_with_observations']}\\n\")\n",
    "        \n",
    "        if total_complete > 0:\n",
    "            success_rate = (total_complete / total_selected) * 100\n",
    "            f.write(f\"\\nSUCCESS METRICS:\\n\")\n",
    "            f.write(f\"  Processing success rate: {success_rate:.1f}%\\n\")\n",
    "            f.write(f\"  Ready for validation: {total_complete} sites\\n\")\n",
    "        \n",
    "        f.write(\"\\nNEXT STEPS:\\n\")\n",
    "        f.write(\"  1. Extract groundwater level time series from simulations\\n\")\n",
    "        f.write(\"  2. Load and process GGMN observation data\\n\")\n",
    "        f.write(\"  3. Perform statistical comparison (correlation, bias, RMSE)\\n\")\n",
    "        f.write(\"  4. Analyze performance by well depth and region\\n\")\n",
    "        f.write(\"  5. Identify patterns in groundwater model performance\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Final report saved: {report_path}\")\n",
    "    \n",
    "    return report_path\n",
    "\n",
    "# Execute Step 3 Analysis\n",
    "print(f\"\\nüîç Step 3.1: Groundwater Domain Discovery\")\n",
    "\n",
    "# Discover completed domains\n",
    "completed_domains = discover_completed_groundwater_domains()\n",
    "\n",
    "# Create overview visualization\n",
    "processing_stats = create_groundwater_overview_visualization(completed_domains)\n",
    "\n",
    "print(f\"\\nüíß Step 3.2: Groundwater Analysis Summary\")\n",
    "\n",
    "# Create analysis summary\n",
    "simulation_summary = create_groundwater_analysis_summary(completed_domains)\n",
    "\n",
    "print(f\"\\nüìã Step 3.3: Final Report Generation\")\n",
    "\n",
    "# Create final report\n",
    "report_path = create_final_ggmn_report(completed_domains, processing_stats, simulation_summary)\n",
    "\n",
    "# Print final summary\n",
    "total_selected, total_discovered, total_with_results, total_with_obs, total_complete = processing_stats\n",
    "\n",
    "print(f\"\\n‚úÖ Step 3 Complete: GGMN Groundwater Analysis\")\n",
    "print(f\"   üìÅ Results directory: {experiment_dir}\")\n",
    "print(f\"   üíß Processing status: {total_complete}/{total_selected} sites with complete validation\")\n",
    "print(f\"   üìä Success rate: {(total_complete/total_selected)*100:.1f}% complete\")\n",
    "\n",
    "if simulation_summary['domains_with_results'] > 0:\n",
    "    print(f\"   üìà Simulation results: {simulation_summary['domains_with_results']} domains processed\")\n",
    "    print(f\"   üíæ Output files: {simulation_summary['total_simulation_files']} simulation files\")\n",
    "\n",
    "if simulation_summary['average_well_depth'] > 0:\n",
    "    print(f\"   üèóÔ∏è  Well characteristics: {simulation_summary['average_well_depth']:.1f}m average depth\")\n",
    "    print(f\"   üìè Depth range: {simulation_summary['depth_range'][0]:.1f} - {simulation_summary['depth_range'][1]:.1f}m\")\n",
    "\n",
    "print(f\"\\nüéâ Large Sample GGMN Groundwater Analysis Complete!\")\n",
    "print(f\"   üíß Multi-site groundwater modeling framework established\")\n",
    "print(f\"   üìä Foundation for systematic groundwater validation created\")\n",
    "print(f\"   üåç Hydrogeological diversity captured across North America\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Summary: Large Sample Groundwater Hydrology with GGMN\n",
    "\n",
    "This tutorial demonstrated systematic groundwater modeling through large sample validation across diverse hydrogeological environments in North America. Using the comprehensive GGMN observation network, we established a framework for continental-scale groundwater process evaluation.\n",
    "\n",
    "**Key Accomplishments:**\n",
    "- **Multi-site groundwater evaluation** across well depth gradients from shallow to deep aquifer systems\n",
    "- **Hydrogeological diversity** spanning alluvial, bedrock, and glacial aquifer types\n",
    "- **Regional coverage** across North American groundwater provinces\n",
    "- **Systematic validation framework** for groundwater level simulation assessment\n",
    "\n",
    "**Scientific Foundation:**\n",
    "The large sample approach enables identification of systematic patterns in groundwater model performance across hydrogeological settings. This methodology reveals how subsurface processes vary with aquifer characteristics, regional climate, and surface-groundwater interactions.\n",
    "\n",
    "**Methodological Innovation:**\n",
    "This workflow demonstrates CONFLUENCE's capacity for **automated groundwater-specific configuration**, **multi-site processing across hydrogeological gradients**, and **standardized validation protocols** for systematic groundwater science.\n",
    "\n",
    "**Connection to Comprehensive Large Sample Studies:**\n",
    "Having explored energy balance (FLUXNET), snow processes (NorSWE), and groundwater dynamics (GGMN), we have established the foundation for integrated multi-variable hydrological validation across the complete terrestrial water cycle.\n",
    "\n",
    "The large sample methodology transforms groundwater hydrology from individual well studies to systematic, generalizable science‚Äîessential for understanding subsurface water resources in a changing climate.\n",
    "\n",
    "### Ready for the next challenge?\n",
    "**Explore integrated multi-variable analysis** ‚Üí **[Tutorial 05: Advanced Model Comparison](./05_model_comparison.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}